{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxMTkyNDEx", "number": 1660, "title": "GG-31094: cluster wide collection", "bodyText": "Cluster-wide statistics collection.\nGoal: main reason - to allow:\n\nto collect/clear statistics on each node of the cluster (each data node)\nto get local statistics on each node of the cluster (each data node)\nto get global statistics on each node\n\nGeneral information about statistics:\n\nWe can only collect the same statistics for each column in SQL table, at least for now. Each table can be scanned to collect all columns or just a specified subset of columns. To collect global statistics (which should contain globally minimum&maximum values, total nulls count and so on) we'll aggregate partition level statistics in two-step: partition level to the local one and local ones to the global one.\nStatistics types:\n\n\npartition level - collected by some partition, contains updateCounter and partId for the future improvements. Need to speedup local statistics updates after rebalancing.\nlocal level - collected by aggregating all primary local partitions statistics, need to local query execution optimization.\nglobal level - collected by aggregating all local partitions statistics, need to global query execution optimization.\n\n\nPartition statistics for backups will be sended from the master node for that partition to all backups.\n\nMain operations:\n\nget local/global statistics by key(s)\nclear statistics (partition, local and global) by key(s)\ncollect statistics by key(s)\n\n\nMain class:\n\nIgniteStatisticsManager/IgniteStatisticsManagerImpl - interface/class for gathering, getting and clearing statistics. Handle only high-level logical gathering task. Track active operation (statistics gathering task) map.\nIgniteStatisticsRepository/IgniteStatisticsRepositoryImpl - interface/class for high-level storage of statistics (can merge collected statistics with existing ones, just in case when one collect only subset of columns)\nIgniteStatisticsStore/IgniteStatistics{InMemory|Persistence|Dummy}StoreImpl - interface/class for low level storage of statistics in memory or in local metastorage.\nStatisticsGatheringRequestCrawler/StatisticsGatheringRequestCrawlerImpl - network-aware service which generates, send and track statistics request/response. Isolate IgniteStatisticsManager from any topology events and either resend requests or cancel the operation in statistics manager. Track active network request map.\nIgniteStatisticsHelper - simplest utility methods to build messages from internal objects, extract groups and partitions and so on.\nIn addition there are important objects:\nStatisticsKeyMessage - key to collect statistics by:\n\nschema - Schema name\nobj - Object (SQL table for now, index in future) name\ncolumns[] - columns to collect statistics by (in future - list of columns to collect combined statistics, possibly)\n\n\nStatisticsGatheringContext - hold gathering state:\n\ngatId - unique id of statistics gathering task.\nkeys - collection of keys by which statistics should be collected\ncollectedStatistics - map of keys to received local level statistics\ndoneFut - future to allow wait for statistics collection or cancel it\n\n\n\nMain idea for cluster wide statistics collection:\nUser may call collect statistics method with any set of keys to collect, but all keys will be separated by its cache groups and processed as a set of independent tasks (with it's own StatisticsGatheringContext each)\nInitiator node (any node which get the request from user) will:\n\nIgnStatManager: create StatisticsGatheringContext for the task (with a total number of partitions in group), put it into active tasks map (currColls) and ask StatisticsGatheringRequestCrawler to send all necessary requests to collect statistics by requested key (SCHEMA.TABLE[columns]).\nStatisticsGatheringRequestCrawler in its own pool will ask IgniteStatisticsHelper to generate all necessary requests to collect statistics (with target nodes and list of partition which should be collected on each node)\nIgniteStatisticsHelper will calculate lists or primary partitions for specified cache group and generate requests to that nodes to collect statistics on their primary partitions\nStatisticsGatheringRequestCrawler adds all request to active request map and send it. If it get some errors - failed messages will be removed from active requests and rescheduled.\nFor local gathering request - StatisticsGatheringRequestCrawler will call IgnStatManager.gatherLocalObjectStatisticsAsync. For remote gathering request - StatisticsGatheringRequestCrawler will catch such request, add it into active request and call the same gatherLocalObjectStatisticsAsync method.\nIgnStatManager just checks if there are active context for such gatId and ask StatisticsGathering to collect statistics with specified requested and cancel future from StatisticsGatheringContext.\nHere it can get race1:\nThread1: start gathering, create gathering context in StatMgr, start sending in StatisticsGatheringRequestCrawler, generate local request and ...\nThread2: cancel gathering, cancel gathering context in StatMgr, ask StatisticsGatheringRequestCrawler to cancel all request.\nThread1: ask StatMgr to gather statistics, find that there is no context for such task and create it agait... then statistics will be collected and only while sending response StatisticsGatheringRequestCrawler will drop its result.\nOr race2:\nThread1: StatisticsGatheringRequestCrawler generate collection requests and put it into active collection requests\nThread2: StatisticsGatheringRequestCrawler got cancel request and send cancel collection requests\nThread1: send generated requests. Then the remote node will log unexpected cancel request, collect statistics by further request and initiator node will log unexpected response.\nStatisticsGathering in its own thread pool will try to scan each specified partition in cache group and collect statistics for each table simultaneously. After each partition, StatisticsGatheringImpl will ask StatisticsGatheringRequestCrawler to send collected partition level statistics to backup nodes. After all partition statistics will be crawled - StatisticsGatheringImpl will aggregate them into local level statistics (with help by IgniteStatisticsRepository) and ask StatisticsGatheringRequestCrawler to send the response to the specified request (local statistics with a collection of crawled partitions)\nStatisticsGatheringRequestCrawler in its own thread pool will remove remaining request by specified id and if it was from local node - directly call IgniteStatisticsManagerImpl.registerLocalResult (add collected to the context and try to finish the task), if the request was from remote node - notify local IgniteStatisticsManagerImpl just to remove local context and send the results through communication to initiator node.\nWhen the last piece of the results got to IgniteStatisticsManagerImpl.registerLocalResult - gathering context will shows that it got all necessary partitions and initiator node could aggregate local statistics to the global one. To distribute global statistics to each data node - IgniteStatisticsManagerImpl call StatisticsGatheringRequestCrawler to send aggregated statistics to each data node and IgniteStatisticsRepository to store it locally.\n\nWhat can go wrong during statistics collection:\n\n\nit can be cancelled by the user. To cancel collection initiator node will:\n1.1) find statistics collection status by its collection id.\n1.2) generate a cancel request for that gatId to all nodes, mentioned as target node in the remaining request, i.e. to all participated in the task nodes.\n1.3) cancel doneFuture in local collection status and remove status from the active collections map\n\n\nsome partition can move between initial map generation (see step 1 in cluster-wide statistics collection main ides) and actual processing on the data node\n2.1) data node won't (and not able to) collect partition level statistics for all specified in request partitions so in response, such partition will be lack\n2.2) initiator node during the processing of such response will find out absent partitions and reschedule it in additional statistics collection request (exactly the same as at the first time, but only for absent partitions). Additional requests will be added into statistics collection statuses remaining request too.\n2.3) new data node will process another collection request as usual.\n\n\nOne of the statistics collection nodes can left. Initiator node will:\n3.1) handle node left/node failed event\n3.2) scan all current active collections to reschedule collections on new topology if one of the remaining collection request belongs to the failed node\nTODO: cancel statistics collections request if initiator node failed.\n\n\nNetwork messages and related internal objects:\n\nStatsCollectRequest - request to collect local statistics:\n\ncolId : UUID\nreqId : UUID\nkeys : Map<StatsKeyMessage, partIds[]>\n\n\nStatsPropagationMsg - request from master node to backup one to save partition level statistics\nStatsCollectResponse - response to the statistics collection initiator with:\n\ndata : Map<StatsObjectData, collectedPartIds[]> - object statistics data (key and all requested columns) with array of actually scanned partitions.\n\n\nCancelStatsCollectionRequest - request to cancel local statistics collection tasks:\n\ncolId : UUID\nreqIds : UUID[] - requests to cancel. There can be more that one request on single data node if some partition was rescheduled to such node.\n\n\n\nContexts for the locally initiated collection process store in the same map (by gathering id) with the contexts for the remotelly initiated collections (by the same remotely generated gathering id) in the StatisticsGatheringContext objects.", "createdAt": "2020-12-16T14:10:59Z", "url": "https://github.com/gridgain/gridgain/pull/1660", "merged": true, "mergeCommit": {"oid": "baf94dd2b9a49d96b7043541aa6268320cdb908f"}, "closed": true, "closedAt": "2021-01-26T16:15:49Z", "author": {"login": "Berkof"}, "timelineItems": {"totalCount": 90, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfVjZAgH2gAyNTQxMTkyNDExOmMzNzc2NzVmNGIyYzFlMGZlOWMyMTc1MGYzODkxYTRiNmVjM2VmYzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdz91WJgH2gAyNTQxMTkyNDExOmFjYmRjY2MwNDk2Mzc3ZmMyYjNiN2Q1MjM2M2FlYTIxODVkMzMyMzk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "committedDate": "2020-11-23T13:55:33Z", "message": "GG-31027: Statistics storage implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "committedDate": "2020-11-23T16:17:37Z", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31027"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "652ab10b366070d91d2396b14dfc2cfad786f99f", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/652ab10b366070d91d2396b14dfc2cfad786f99f", "committedDate": "2020-11-24T10:56:39Z", "message": "GG-31027: minor autotests fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "committedDate": "2020-12-07T13:56:53Z", "message": "GG-31094: add messages to collect and clear statistics cluster wide."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "593ddab1a7c8c9eb84af8c04e252381a5edae79b", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/593ddab1a7c8c9eb84af8c04e252381a5edae79b", "committedDate": "2020-12-16T14:05:25Z", "message": "GG-31094: cluster wide statistics collection routine"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "committedDate": "2020-12-16T14:20:44Z", "message": "GG-31094: small fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0OTQ5Mzg4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-554949388", "createdAt": "2020-12-17T20:08:56Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDowODo1N1rOIIG2zQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDowODo1N1rOIIG2zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3MTg1Mw==", "bodyText": "FYI: You can try IntMap instead of HashMap for per-partition stats. It can be a bit more efficient.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545371853", "createdAt": "2020-12-17T20:08:57Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteLogger;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsInMemoryStoreImpl implements IgniteStatisticsStore {\n+    /** Table -> Partition -> Partition Statistics map, populated only on server nodes without persistence enabled. */\n+    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0OTU2NDg4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-554956488", "createdAt": "2020-12-17T20:19:21Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDoxOToyMVrOIIHOZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDoxOToyMVrOIIHOZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3Nzg5NQ==", "bodyText": "Let's move this method to the listener object, like it is done for nodeLeft event.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545377895", "createdAt": "2020-12-17T20:19:21Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 877}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDE3OTMz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555017933", "createdAt": "2020-12-17T21:53:03Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMTo1MzowM1rOIIKPig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMTo1MzowM1rOIIKPig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQyNzMzOA==", "bodyText": "Why is colNames a part of StatsKeyMessage, but not a part of StatsKey?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545427338", "createdAt": "2020-12-17T21:53:03Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 168}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDI2NjM4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555026638", "createdAt": "2020-12-17T22:07:47Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjowNzo0N1rOIIKsUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjowNzo0N1rOIIKsUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNDcwNw==", "bodyText": "Statistic is collected by a 'key' not by a 'message', right?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545434707", "createdAt": "2020-12-17T22:07:47Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 179}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDI3NDk3", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555027497", "createdAt": "2020-12-17T22:09:18Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjowOToxOFrOIIKvLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjowOToxOFrOIIKvLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA==", "bodyText": "Why do we need to pass a Cancel supplier as it look like method is executed synchronously?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545435438", "createdAt": "2020-12-17T22:09:18Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 197}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDMxODcx", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555031871", "createdAt": "2020-12-17T22:17:00Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjoxNzowMFrOIIK-nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjoxNzowMFrOIIK-nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzOTM4OA==", "bodyText": "Is aggregated statistics can be updated only after all partitions were processed only?\nWhat if we got updates from primary? Will we update aggregates instantly?\nIf so, why we can't update aggregates after every single local partition is processed?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545439388", "createdAt": "2020-12-17T22:17:00Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 210}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDM1ODMy", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555035832", "createdAt": "2020-12-17T22:24:05Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjoyNDowNVrOIILMCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjoyNDowNVrOIILMCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ0MjgyNQ==", "bodyText": "Method 'sendPartitionStatisticsToBackupNodes' name would look more expressive.\nI believe method name should has exact meaning, in opposite to variable, that can be short as variable exists in much narrower scope.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545442825", "createdAt": "2020-12-17T22:24:05Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 222}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDQ0OTgx", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555044981", "createdAt": "2020-12-17T22:41:39Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0MTo0MFrOIILr2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0MTo0MFrOIILr2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MDk3MA==", "bodyText": "return Arrays.stream(cols).filter(colNamesSet::contains).toArray()", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545450970", "createdAt": "2020-12-17T22:41:40Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 357}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDQ3MTIx", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555047121", "createdAt": "2020-12-17T22:45:40Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0NTo0MFrOIILzRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0NTo0MFrOIILzRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1Mjg2OA==", "bodyText": "What is 'doneFut' future purpose? Why we pass a future to status object constructor from outside?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545452868", "createdAt": "2020-12-17T22:45:40Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 375}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDQ4MDY2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555048066", "createdAt": "2020-12-17T22:47:39Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0Nzo0MFrOIIL2qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo0Nzo0MFrOIIL2qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MzczOQ==", "bodyText": "Does \"colId\" mean \"collectionId\" or mean \"columnId\", like a \"colNames\" means column names?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545453739", "createdAt": "2020-12-17T22:47:40Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 373}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDUwNzcz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555050773", "createdAt": "2020-12-17T22:52:55Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1Mjo1NVrOIIMAVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1Mjo1NVrOIIMAVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NjIxMw==", "bodyText": "What does 'sendLocalRequests' mean? Why 'local'?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545456213", "createdAt": "2020-12-17T22:52:55Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 388}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDUxOTE3", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555051917", "createdAt": "2020-12-17T22:54:58Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1NDo1OFrOIIMEZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1NDo1OFrOIIMEZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ==", "bodyText": "'status' doesn't reflect it's role here.\nIt is actually a context of current task\\operation.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545457255", "createdAt": "2020-12-17T22:54:58Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 398}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDUzOTI2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555053926", "createdAt": "2020-12-17T22:59:07Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1OTowN1rOIIMLwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMjo1OTowN1rOIIMLwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1OTEzNg==", "bodyText": "localNodeId is available via KernalConext.localNodeId().", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545459136", "createdAt": "2020-12-17T22:59:07Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 399}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDYwODE5", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555060819", "createdAt": "2020-12-17T23:09:16Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzowOToxNlrOIIMgng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzowOToxNlrOIIMgng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NDQ3OA==", "bodyText": "I think MOVING partitions can be safely skipped here.\nThere is no need to wait for preloader synchronously, you can subscribe to the future and reschedule statistic gathering once it's done.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545464478", "createdAt": "2020-12-17T23:09:16Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n \n-        Column[] selectedColumns;\n-        boolean fullStat;\n-        if (F.isEmpty(colNames)) {\n-            fullStat = true;\n-            selectedColumns = tbl.getColumns();\n+        synchronized (status) {\n+            currCollections.put(colId, status);\n+            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n+                status.doneFut().cancel();\n+                currCollections.remove(colId);\n+                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+            }\n         }\n-        else {\n-            fullStat = false;\n-            selectedColumns = filterColumns(tbl.getColumns(), colNames);\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+\n+        doneFut.get();\n+        */\n+\n+//\n+//        StatsKey key = new StatsKey(schemaName, objName);\n+//\n+//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n+//\n+//        assert grpContexts.size() == 1;\n+//\n+//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n+//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n+//\n+//        synchronized (status) {\n+//            currCollections.put(colId, status);\n+//\n+//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//\n+//            if (failedReqs != null) {\n+//                for (UUID failedReqId : failedReqs.keySet())\n+//                    status.remainingCollectionReqs().remove(failedReqId);\n+//\n+//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n+//\n+//                assert failedPartIds.size() == 1;\n+//\n+//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n+//\n+//                assert newPartIds != null;\n+//\n+//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n+//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n+//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n+//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//                if (newFailedReqs != null) {\n+//                    doneFut.cancel();\n+//\n+//                    // TODO: is it safe?\n+//                    currCollections.remove(colId);\n+//\n+//                    throw new IgniteCheckedException(String.format(\n+//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n+//                            newFailedReqs.size(), colId));\n+//                }\n+//                status.remainingCollectionReqs().putAll(newReqs);\n+//\n+//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n+//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n+//            }\n+//            UUID locNode = ctx.discovery().localNode().id();\n+//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n+//            if (locReq != null)\n+//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+//\n+//        }\n+//\n+//        doneFut.get();\n+    }\n+\n+    /**\n+     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n+     * into currCollections map. REMOVE!!!!\n+     *\n+     * @param status Status to process.\n+     * @param keys Collection of object keys to collect statistics by.\n+     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n+     * status from cullCollections.\n+     */\n+    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n+                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n+\n         }\n+        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n \n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedColumns);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedColumns, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.remainingCollectionReqs().putAll(reqs);\n+\n+        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+        // TODO: cycle replanning and sending\n+        return failedReqs.isEmpty();\n+\n+         */\n+        return false;\n+    }\n+\n+    /**\n+     * Group request by target node id. REMOVE!!!!\n+     *\n+     * @param reqsByGrps Requests to compress, map.\n+     * @return Grouped requests.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> compressRequests(List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps) {\n+        // NodeId to base request map\n+        Map<UUID, StatsCollectionAddrRequest> reqByNode = new HashMap<>();\n+        for (Map<UUID, StatsCollectionAddrRequest> grpReqs : reqsByGrps)\n+            for (StatsCollectionAddrRequest addReq : grpReqs.values())\n+                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n+\n+        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n+            Map.Entry::getValue));\n+    }\n+\n+    /**\n+     * Add keys from add request to the base one and return it.\n+     *\n+     * @param base Base request to add to.\n+     * @param add Add request to add.\n+     * @return Request with all keys from both specified.\n+     */\n+    protected StatsCollectionAddrRequest addKey(StatsCollectionAddrRequest base, StatsCollectionAddrRequest add) {\n+        assert base.nodeId().equals(add.nodeId());\n+\n+        base.req().keys().putAll(add.req().keys());\n+        return base;\n+    }\n+\n+\n+    /**\n+     * Prepare statistics collection request for each nodes. MOVED!!!!\n+     *\n+     * @param colId Collection id.\n+     * @param keyMsg Key to collect statistics by.\n+     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n+     * @return Map: request id to statistics collection addressed request.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> _____prepareRequests(\n+            UUID colId,\n+            StatsKeyMessage keyMsg,\n+            Map<UUID, List<Integer>> reqNodes\n+    ) {\n+        Map<UUID, StatsCollectionAddrRequest> res = new HashMap<>(reqNodes.size());\n+        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n+            UUID reqId = UUID.randomUUID();\n+            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n+                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+            StatsCollectionAddrRequest addrReq = new StatsCollectionAddrRequest(colReq, reqNode.getKey());\n+            res.put(reqId, addrReq);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * TODO\n+     */\n+    public void stop() {\n+        if (statMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n     }\n \n     /**\n      * Collect partition level statistics.\n      *\n      * @param tbl Table to collect statistics by.\n-     * @param selectedColumns Columns to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n      * @return Collection of partition level statistics by local primary partitions.\n      * @throws IgniteCheckedException in case of error.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(GridH2Table tbl, Column[] selectedColumns)\n-            throws IgniteCheckedException {\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n         List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n         GridH2RowDescriptor desc = tbl.rowDescriptor();\n         String tblName = tbl.getName();\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n             final boolean reserved = locPart.reserve();\n \n             try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 641}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDYxNjQw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555061640", "createdAt": "2020-12-17T23:11:05Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoxMTowNVrOIIMjxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoxMTowNVrOIIMjxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NTI4Nw==", "bodyText": "Let's remove redundant method.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545465287", "createdAt": "2020-12-17T23:11:05Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -225,51 +679,58 @@ public IgniteStatisticsRepository statisticsRepository() {\n      * @param tblPartStats Collection of all local partition level statistics by specified key.\n      * @return Local level aggregated statistics.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> tblPartStats) {\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatsKey key,\n+            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n+    ) {\n         // For now there can be only tables\n-        GridH2Table table = schemaMgr.dataTable(key.schema(), key.obj());\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n \n-        if (table == null) {\n+        if (tbl == null) {\n             // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n+                        key.schema(), key.obj()));\n+\n             statsRepos.clearLocalPartitionsStatistics(key);\n         }\n-        return aggregateLocalStatistics(table, table.getColumns(), tblPartStats);\n+        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n     }\n \n     /**\n      * Aggregate partition level statistics to local level one.\n      *\n      * @param tbl Table to aggregate statistics by.\n-     * @param selectedColumns Columns to aggregate statistics by.\n+     * @param selectedCols Columns to aggregate statistics by.\n      * @param tblPartStats Collection of partition level statistics.\n      * @return Local level statistics.\n      */\n     private ObjectStatisticsImpl aggregateLocalStatistics(\n             GridH2Table tbl,\n-            Column[] selectedColumns,\n+            Column[] selectedCols,\n             Collection<ObjectPartitionStatisticsImpl> tblPartStats\n     ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 706}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDY3Mzg2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555067386", "createdAt": "2020-12-17T23:24:00Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyNDowMVrOIIM4Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyNDowMVrOIIM4Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MDU1OQ==", "bodyText": "Why a MOVING partition ignores incoming statistics from? It is feasible primary or backup.\nIf first then we will need to recalculate statistics, in other words make the job twice.\nIf second - we'll loose statistics?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545470559", "createdAt": "2020-12-17T23:24:01Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 775}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDY3ODg1", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555067885", "createdAt": "2020-12-17T23:25:15Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyNToxNVrOIIM6ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyNToxNVrOIIM6ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTA5OQ==", "bodyText": "What does mean 'local' in method name?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545471099", "createdAt": "2020-12-17T23:25:15Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 791}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDcyNTgw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555072580", "createdAt": "2020-12-17T23:36:18Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzozNjoxOFrOIINLtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzozNjoxOFrOIINLtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ==", "bodyText": "As I understand StatsGetRequest is just return current aggregated statistics and doesn't trigger gathering new stats, right?\nThis is a different floew and may be we need a separate component for this.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545475511", "createdAt": "2020-12-17T23:36:18Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 883}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDc0OTA1", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555074905", "createdAt": "2020-12-17T23:42:05Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo0MjowNlrOIINUaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo0MjowNlrOIINUaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ==", "bodyText": "You can use @IgniteLogger annotation and call kernalContext.resource().inject() from outside.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545477739", "createdAt": "2020-12-17T23:42:06Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDc3MDEw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555077010", "createdAt": "2020-12-17T23:47:24Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo0NzoyNFrOIINcRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo0NzoyNFrOIINcRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ==", "bodyText": "Is it ever unregistered?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545479751", "createdAt": "2020-12-17T23:47:24Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.db = db;\n+        this.repo = repo;\n+        subscriptionProcessor.registerMetastorageListener(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDgxMjUz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555081253", "createdAt": "2020-12-17T23:58:24Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo1ODoyNFrOIINshw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzo1ODoyNFrOIINshw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MzkxMQ==", "bodyText": "What the difference bw local and global stats?\nDoes it mean localStats contains only local per-partition raw statistics? or local aggregates as well?\nDoes it mean globalStats contains only aggregated cluster-wide statistics or raw remote partition stats as well?\nIf both contains raw partition statistics, can these collections has duplicates?\nI thought it make sense to store only raw statistics, and calculate aggregated on deman. Aggregated statistics can cached for performance purposes and thus can be easily invalidated.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545483911", "createdAt": "2020-12-17T23:58:24Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -16,27 +16,32 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+import org.apache.ignite.internal.util.typedef.F;\n \n+import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Map;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n \n /**\n  * Statistics repository implementation.\n  */\n public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepository {\n     /** Logger. */\n-    private IgniteLogger log;\n+    private final IgniteLogger log;\n \n-    /** Statistics manager. */\n-    private final IgniteStatisticsManagerImpl statisticsManager;\n+    /** Statistics store. */\n+    private final IgniteStatisticsStore store;\n \n-    /** Table->Partition->Partition Statistics map, populated only on server nodes without persistence enabled. */\n-    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats;\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> localStats;\n+    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n \n     /** Global (for whole cluster) object statistics. */\n     private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDgyNzAz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555082703", "createdAt": "2020-12-18T00:02:11Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowMjoxMVrOIINx3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowMjoxMVrOIINx3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTI3Ng==", "bodyText": "Let's pass correct implementation from outside.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485276", "createdAt": "2020-12-18T00:02:11Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDgzMzgz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555083383", "createdAt": "2020-12-18T00:03:53Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowMzo1M1rOIIN0Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowMzo1M1rOIIN0Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ==", "bodyText": "Does it make sense to have dummy repository implementation or may be do not create it on client node at all?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485875", "createdAt": "2020-12-18T00:03:53Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n+                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n+\n+            locStats = new ConcurrentHashMap<>();\n         }\n         else {\n             // Cache only global statistics, no store\n-            partsStats = null;\n-            localStats = null;\n-        }\n-        this.statisticsManager = statisticsManager;\n-        this.log = log;\n-    }\n-\n-    /**\n-     * Convert collection of partition level statistics into map(partId->partStatistics).\n-     *\n-     * @param key Object key.\n-     * @param statistics Collection of tables partition statistics.\n-     * @return Partition id to statistics map.\n-     */\n-    private Map<Integer, ObjectPartitionStatisticsImpl> buildStatisticsMap(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> statistics\n-    ) {\n-        Map<Integer, ObjectPartitionStatisticsImpl> statisticsMap = new ConcurrentHashMap<>();\n-        for (ObjectPartitionStatisticsImpl s : statistics) {\n-            if (statisticsMap.put(s.partId(), s) != null)\n-                log.warning(String.format(\"Trying to save more than one %s.%s partition statistics for partition %d\",\n-                        key.schema(), key.obj(), s.partId()));\n+            store = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDg0ODc5", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555084879", "createdAt": "2020-12-18T00:07:51Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowNzo1MVrOIIN5gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDowNzo1MVrOIIN5gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NzIzMw==", "bodyText": "Confusing javadoc.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545487233", "createdAt": "2020-12-18T00:07:51Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDg1NzU4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555085758", "createdAt": "2020-12-18T00:10:08Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxMDowOFrOIIN8iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxMDowOFrOIIN8iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODAwOA==", "bodyText": "Method is declared as to add a collection, but got 'status'.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488008", "createdAt": "2020-12-18T00:10:08Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDg2MjA4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555086208", "createdAt": "2020-12-18T00:11:26Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxMToyNlrOIIN-Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxMToyNlrOIIN-Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODQzNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Thread safe update of statistics collection.\n          \n          \n            \n                 * Update status of statistic gathering task", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488434", "createdAt": "2020-12-18T00:11:26Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDg3NzU2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555087756", "createdAt": "2020-12-18T00:16:00Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxNjowMFrOIIOEYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoxNjowMFrOIIOEYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDAxNw==", "bodyText": "What if one of cache was stopped somewhen in between, but other are operational?\nWill statistics task result be thrown away or task crashed?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545490017", "createdAt": "2020-12-18T00:16:00Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDg5MTUy", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555089152", "createdAt": "2020-12-18T00:20:02Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoyMDowM1rOIIOJ0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoyMDowM1rOIIOJ0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTQwOQ==", "bodyText": "Can we be sure both arrays are sorted?\nIf so, intersect will of sorted arrays is trivial.\nOr may be BitSet fits your needs better?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545491409", "createdAt": "2020-12-18T00:20:03Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsCollectionAddrRequest> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsCollectionAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array.\n+     * @param b Second array.\n+     * @return Arrays intersection.\n+     */\n+    protected static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 253}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDkwMjY1", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555090265", "createdAt": "2020-12-18T00:23:17Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoyMzoxN1rOIION4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDoyMzoxN1rOIION4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjQ1MQ==", "bodyText": "Why 'local'?\nDoes it mean we store statistics for local partitions only? primary or backups or both?\nMay it worth to rename the interface itself?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545492451", "createdAt": "2020-12-18T00:23:17Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import java.util.Collection;\n+\n+/**\n+ * Statistics store interface.\n+ */\n+public interface IgniteStatisticsStore {\n+    /**\n+     * Clear statistics of any type for any objects;\n+     */\n+    public void clearAllStatistics();\n+\n+    /**\n+     * Replace all tables partition statistics with specified ones.\n+     *\n+     * @param key Statistics key to replace statistics by.\n+     * @param statistics Collection of partition level statistics.\n+     */\n+    public void replaceLocalPartitionsStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> statistics);\n+\n+    /**\n+     * Get local partition statistics by specified object.\n+     *\n+     * @param key Key to get statistics by.\n+     * @return Collection of partitions statistics.\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> getLocalPartitionsStatistics(StatsKey key);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDk0MTYz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555094163", "createdAt": "2020-12-18T00:34:36Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDozNDozNlrOIIOckA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMDozNDozNlrOIIOckA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjIwOA==", "bodyText": "Why it serializable?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545496208", "createdAt": "2020-12-18T00:34:36Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java", "diffHunk": "@@ -15,17 +15,21 @@\n  */\n package org.apache.ignite.internal.processors.query.stat;\n \n+import java.io.Serializable;\n import java.util.Objects;\n \n /**\n  * Statistics key.\n  */\n-public class StatsKey {\n+public class StatsKey implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDk3Nzcw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-555097770", "createdAt": "2020-12-18T00:45:01Z", "commit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec4a9ef0e7691b605225c12527d496d07d573b42", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/ec4a9ef0e7691b605225c12527d496d07d573b42", "committedDate": "2020-12-18T05:59:41Z", "message": "gg-31094: fix main issues with cluster wide collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "committedDate": "2020-12-18T07:30:11Z", "message": "gg-31094: fix multiple local requests statistics handling."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "committedDate": "2020-12-18T12:23:00Z", "message": "gg-31094: minor fixes by review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/671a2471ef7d2a50a01f45f09289202a9528221d", "committedDate": "2020-12-21T08:37:07Z", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adb2fc38f05374d597d32f3164fa444dec40cb8f", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/adb2fc38f05374d597d32f3164fa444dec40cb8f", "committedDate": "2020-12-21T11:00:05Z", "message": "GG-31094: more tests on collection process"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2MzM0MDIw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-556334020", "createdAt": "2020-12-21T12:09:41Z", "commit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "state": "COMMENTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxMjowOTo0MVrOIJWLbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxNTozMzo0NFrOIJcUtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3MTQ3MA==", "bodyText": "it looks like statistics collection manager, so let's give it appropriate name", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546671470", "createdAt": "2020-12-21T12:09:41Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3NDMyMw==", "bodyText": "could be final", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546674323", "createdAt": "2020-12-21T12:16:51Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3OTYyMg==", "bodyText": "both invocations of locStatistics() assumes that locStatistics is always non null value", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546679622", "createdAt": "2020-12-21T12:29:38Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY4Mjk2NA==", "bodyText": "constructor ConcurrentHashMap requires non null argument", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546682964", "createdAt": "2020-12-21T12:37:58Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NTM5Mg==", "bodyText": "possible NPE here", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546695392", "createdAt": "2020-12-21T13:07:05Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjM3MA==", "bodyText": "btw it is not used anywhere, so let's remove it", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696370", "createdAt": "2020-12-21T13:09:22Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjYwMA==", "bodyText": "possible NPE here", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696600", "createdAt": "2020-12-21T13:09:51Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzAzMw==", "bodyText": "this is not used as well", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697033", "createdAt": "2020-12-21T13:10:52Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzEyOQ==", "bodyText": "misspell in param name", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697129", "createdAt": "2020-12-21T13:11:08Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjcwMzU0OQ==", "bodyText": "not used", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546703549", "createdAt": "2020-12-21T13:24:54Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);\n+        remainingColReqs.putAll(newReqs);\n+        remainingColReqs.remove(oldReqId);\n+    }\n+\n+    /**\n+     * Remove all requests to specified node id (due to its failure).\n+     *\n+     * @param nodeId node id to remove requests by.\n+     * @return Collection of removed requests.\n+     */\n+    public Collection<StatsCollectionRequest> removeNodeRequest(UUID nodeId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw==", "bodyText": "Is there any reason to have this as a field?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546760623", "createdAt": "2020-12-21T15:12:58Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -18,35 +18,73 @@\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.function.Supplier;\n import java.util.stream.Collectors;\n \n import org.apache.ignite.IgniteCheckedException;\n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.GridCacheUtils;\n import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsPropagationMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsGetRequest;\n+import org.apache.ignite.internal.util.lang.GridTuple3;\n import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n \n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.MOVING;\n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n \n /**\n  * Statistics manager implementation.\n  */\n-public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n+public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Size of statistics collection pool. */\n+    private static final int STATS_POOL_SIZE = 1;\n+\n+    /** Node left listener to complete statistics collection tasks without left nodes. */\n+    private final NodeLeftListener nodeLeftLsnr;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjMzMQ==", "bodyText": "this class could be static", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766331", "createdAt": "2020-12-21T15:23:18Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO\n+                    e.printStackTrace();\n+                }\n+\n+            }\n+            return null;\n+        });\n+    }\n+\n+    /**\n+     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n+     */\n+    private class NodeLeftListener implements GridLocalEventListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 945}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjcwOQ==", "bodyText": "this should be part of NodeLeftListener", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766709", "createdAt": "2020-12-21T15:23:57Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 917}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Njg1OA==", "bodyText": "commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766858", "createdAt": "2020-12-21T15:24:15Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 929}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NzYwNg==", "bodyText": "uncertain TODO", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767606", "createdAt": "2020-12-21T15:25:35Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 933}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Nzg4Mw==", "bodyText": "failedCollections is not used", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767883", "createdAt": "2020-12-21T15:26:01Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 918}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc3MjE1MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    currColls.keySet().forEach(k -> {\n          \n          \n            \n                        currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n          \n          \n            \n                    });\n          \n          \n            \n                    currColls.values().forEach(transformation::apply);", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546772150", "createdAt": "2020-12-21T15:33:44Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+*/\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Calculate node id to stats key map.\n+     *\n+     * @param groupKeys Cache group to stats key map.\n+     * @return Node id to stats key map.\n+     */\n+    public static Map<UUID, Set<StatsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> groupsKeys\n+    ) {\n+        Map<UUID, Set<StatsKeyMessage>> res = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> groupKeys : groupsKeys.entrySet()) {\n+            CacheGroupContext grp = groupKeys.getKey();\n+\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            for (List<ClusterNode> partNodes : assignments) {\n+                for (ClusterNode node : partNodes) {\n+                    res.compute(node.id(), (k, v) -> {\n+                        if (v == null)\n+                            v = new HashSet<>();\n+\n+                        v.addAll(groupKeys.getValue());\n+\n+                        return v;\n+                    });\n+                }\n+            }\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsClearRequest>> generateClearRequests(\n+        Collection<StatsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Set<StatsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+        List<StatsAddrRequest<StatsClearRequest>> res = new ArrayList<>(nodeKeys.size());\n+\n+        return nodeKeys.entrySet().stream().map(e -> new StatsAddrRequest<StatsClearRequest>(\n+                new StatsClearRequest(UUID.randomUUID(), new ArrayList<>(e.getValue())), e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest[] reqs) {\n+        Map<StatsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatsCollectionRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.colId());\n+            colId = req.colId();\n+\n+            for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Get failed partitions map from request and its response.\n+     *\n+     * @param req Request to get the original requested partitions from.\n+     * @param resp Response to get actually collected partitions.\n+     * @return Map of not collected partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest req, StatsCollectionResponse resp) {\n+        assert req.colId().equals(resp.colId());\n+\n+        Map<StatsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n+        for (Map.Entry<StatsObjectData, int[]> data : resp.data().entrySet())\n+            collected.put(data.getKey().key(), data.getValue());\n+\n+        Map<StatsKeyMessage, int[]> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n+\n+            if (failed.length > 0)\n+                res.put(keyEntry.getKey(), failed);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Apply specified transformation to each active statistics collection status.\n+     *\n+     * @param transformation Transformation to apply.\n+     */\n+    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.keySet().forEach(k -> {\n+            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n+        });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 379}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NDgwMTI5", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-556480129", "createdAt": "2020-12-21T15:53:18Z", "commit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxNTo1MzoxOFrOIJdBYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODozNzoyN1rOIJy1oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4MzU4Nw==", "bodyText": "it's not a DR pool", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546783587", "createdAt": "2020-12-21T15:53:18Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +113,32 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        currCollections = new IgniteStatisticsRequestCollection(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n+        ctx.io().addMessageListener(TOPIC, this);\n+\n         boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n+\n         statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n                 ctx::log);\n+\n+        nodeLeftLsnr = new NodeLeftListener();\n+\n+        statMgmtPool = new IgniteThreadPoolExecutor(\"dr-mgmt-pool\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDIyOQ==", "bodyText": "commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784229", "createdAt": "2020-12-21T15:54:31Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDU3Mg==", "bodyText": "doneFut is not used", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784572", "createdAt": "2020-12-21T15:55:03Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NzEwOA==", "bodyText": "sendRequests returns a list of failed request. Think there should be retries", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546787108", "createdAt": "2020-12-21T15:59:24Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEzODcxNw==", "bodyText": "unnecessary change", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547138717", "createdAt": "2020-12-22T08:32:11Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java", "diffHunk": "@@ -20,6 +20,7 @@\n \n import java.util.List;\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MDEyNA==", "bodyText": "unused imports", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547140124", "createdAt": "2020-12-22T08:35:28Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -16,6 +16,19 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.util.collection.IntHashMap;\n+import org.apache.ignite.internal.util.collection.IntMap;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAyNA==", "bodyText": "uncertain TODO", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547141024", "createdAt": "2020-12-22T08:37:27Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -197,6 +197,7 @@ public IgniteStatisticsRepositoryImpl(\n         store.clearLocalPartitionStatistics(key, partId);\n     }\n \n+    // TODO", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2OTA4NjMz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-556908633", "createdAt": "2020-12-22T08:41:37Z", "commit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODo0MTozOFrOIJy9dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwOToyNToyNVrOIJ0SHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzAzMQ==", "bodyText": "empty line", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143031", "createdAt": "2020-12-22T08:41:38Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzM5Mw==", "bodyText": "closing tag is not needed, I suppose", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143393", "createdAt": "2020-12-22T08:42:25Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2MTQxOQ==", "bodyText": "comment in Russian", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547161419", "createdAt": "2020-12-22T09:18:54Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA==", "bodyText": "this could be simplified by generating partition ids from assignments", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164224", "createdAt": "2020-12-22T09:24:31Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDcwMA==", "bodyText": "commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164700", "createdAt": "2020-12-22T09:25:25Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 207}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b595e90b5b480aaf80a9256558b1841334df97de", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/b595e90b5b480aaf80a9256558b1841334df97de", "committedDate": "2020-12-22T11:27:24Z", "message": "GG-31094: fix message processing, some new tests, batch cleaning"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MDE0NTYx", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-557014561", "createdAt": "2020-12-22T11:34:08Z", "commit": {"oid": "b595e90b5b480aaf80a9256558b1841334df97de"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxMTozNDowOFrOIJ4GKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxMTozNDowOFrOIJ4GKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzIyNzE3Nw==", "bodyText": "Actually, function return nothing.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547227177", "createdAt": "2020-12-22T11:34:08Z", "author": {"login": "AMashenkov"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b595e90b5b480aaf80a9256558b1841334df97de"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/29e078f2df2c845f1d97ba432d2033c88bdf6464", "committedDate": "2020-12-23T13:22:00Z", "message": "GG-31094: rename classes, implement dummy statistics storage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "committedDate": "2020-12-25T14:03:45Z", "message": "GG-31094: main refactoring changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ab0edf44f29bc0c45770c111905807af1982eb2", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/5ab0edf44f29bc0c45770c111905807af1982eb2", "committedDate": "2020-12-28T13:28:33Z", "message": "GG-31094: refactoring of message processing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/f03f0e0216f93edace9e8347eddc6ee68388c727", "committedDate": "2020-12-28T13:31:08Z", "message": "GG-31094: fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "committedDate": "2020-12-28T15:24:08Z", "message": "GG-31094: fix handling local statistics results (StatsGatheringResponse)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5MTA2OTYw", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559106960", "createdAt": "2020-12-28T11:30:25Z", "commit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQxMTozMDoyNVrOIL3goQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQxNToyNTo1MFrOIL75Kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNDcyMQ==", "bodyText": "I don't think GridTuple3 is a correct key type for a map.\nActually,  (new String[]{\"1\"}).equals(new String[]{\"1\"})  will always return \"fase\".", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549314721", "createdAt": "2020-12-28T11:30:25Z", "author": {"login": "AMashenkov"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNjA5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /**\n          \n          \n            \n             * Future to track statistics collection task. Allows to get collection id immediately.\n          \n          \n            \n             * @param <T>\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Statistics collection id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID colId();\n          \n          \n            \n            /**\n          \n          \n            \n             * Future to track gathering statistics task.\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatisticsGatheringTaskFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Task id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID taskId();\n          \n      \n    \n    \n  \n\nActually, it is just a task future.\nGeneric type is not specified, I think we can use certain type here instead of generic.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549316096", "createdAt": "2020-12-28T11:35:32Z", "author": {"login": "AMashenkov"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Future to track statistics collection task. Allows to get collection id immediately.\n+ * @param <T>\n+ */\n+public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n+    /**\n+     * @return Statistics collection id.\n+     */\n+    public UUID colId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDcwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n          \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> mapToCacheGroup(Collection<StatisticsKeyMessage> keys)", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324709", "createdAt": "2020-12-28T12:07:21Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDg1Ng==", "bodyText": "Invalid HTML tags.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324856", "createdAt": "2020-12-28T12:08:02Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTIyOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325229", "createdAt": "2020-12-28T12:09:27Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA==", "bodyText": "Braces.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325368", "createdAt": "2020-12-28T12:09:54Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM5OQ==", "bodyText": "Braces", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325399", "createdAt": "2020-12-28T12:10:02Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNjg1OA==", "bodyText": "\"requests will be\".. will be what?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549326858", "createdAt": "2020-12-28T12:15:35Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyODk3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n          \n          \n            \n                                Collection<StatisticsKeyMessage> grpValues= grpEntry.getValue();", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549328974", "createdAt": "2020-12-28T12:23:16Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMzMzIwNg==", "bodyText": "Using StatisticsKey->partitions leads to collections analyzing\\filtering\\copying that very hard to understand.\nMethod overall complexity is too high.\nCan this relation be turned into partition->StatisticKeys ?\nFor all keys that relates to same cache group you will do same actions that looks trivial with Partition->StatisticKeys.\nI thinks nodePartitions method result is useless, failedPartitions could be transformed to partition->statisticKeys, then the result can be easily mapped to nodes.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549333206", "createdAt": "2020-12-28T12:38:15Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MTg4NQ==", "bodyText": "Topology version is shared for all cache groups.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549341885", "createdAt": "2020-12-28T13:07:49Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjIyOA==", "bodyText": "Javadoc is not actual.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342228", "createdAt": "2020-12-28T13:08:52Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjU0Mw==", "bodyText": "empty line", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342543", "createdAt": "2020-12-28T13:09:53Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjY0Mg==", "bodyText": "Javadoc missed.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342642", "createdAt": "2020-12-28T13:10:18Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjkwMQ==", "bodyText": "Arrays.asList() ?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342901", "createdAt": "2020-12-28T13:11:26Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d"}, "originalPosition": 285}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1MDQyMA==", "bodyText": "My guess is the manager should be unsubscribed on stop\\deactivation.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549350420", "createdAt": "2020-12-28T13:36:13Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -18,35 +18,73 @@\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.function.Supplier;\n import java.util.stream.Collectors;\n \n import org.apache.ignite.IgniteCheckedException;\n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.GridCacheUtils;\n import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsPropagationMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsGetRequest;\n+import org.apache.ignite.internal.util.lang.GridTuple3;\n import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n \n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.MOVING;\n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n \n /**\n  * Statistics manager implementation.\n  */\n-public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n+public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Size of statistics collection pool. */\n+    private static final int STATS_POOL_SIZE = 1;\n+\n+    /** Node left listener to complete statistics collection tasks without left nodes. */\n+    private final NodeLeftListener nodeLeftLsnr;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw=="}, "originalCommit": {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1NzAzNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    else if (db == null)\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n          \n          \n            \n                    else if (!GridCacheUtils.isPersistenceEnabled(ctx.config()))\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(),  ctx.cache().context().database(), ctx::log);", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549357034", "createdAt": "2020-12-28T13:57:56Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NDY0Nw==", "bodyText": "Sure, see IgniteTestResources and GridAbstractTest.getTestResources()", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549364647", "createdAt": "2020-12-28T14:21:34Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NjUzMw==", "bodyText": "Ok, as IgniteStatisticsPersistenceStoreImpl is a node single instance.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549366533", "createdAt": "2020-12-28T14:27:05Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.db = db;\n+        this.repo = repo;\n+        subscriptionProcessor.registerMetastorageListener(this);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}, "originalCommit": {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MTMxMA==", "bodyText": "Javadoc", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549371310", "createdAt": "2020-12-28T14:41:31Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MzAxNw==", "bodyText": "Is it expected request will be processed in Query Pool?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549373017", "createdAt": "2020-12-28T14:46:47Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n+\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+            }\n+        }\n+        while (failedPartitions != null);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringRequestsAsync(UUID gatId, Collection<StatisticsKeyMessage> keys) {\n+        msgMgmtPool.submit(() -> sendGatheringRequests(gatId, keys, null));\n+    }\n+\n+    /**\n+     * Send response to given request.\n+     *\n+     * @param reqId Request id to response to.\n+     * @param statistics Collected statistics.\n+     */\n+    private void sendGatheringResponse(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        StatisticsAddrRequest<StatisticsGatheringRequest> req =  remainingRequests.remove(reqId);\n+        if (req == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Dropping results to cancelled collection request %s\", reqId));\n+\n+            return;\n+        }\n+        UUID gatId = req.req().gatId();\n+\n+        Map<StatisticsObjectData, int[]> dataParts = new HashMap<>(statistics.size());\n+        statistics.forEach((k,v) -> {\n+            try {\n+                StatisticsObjectData data = StatisticsUtils.toObjectData(k.getKey(), StatisticsType.LOCAL, k.getValue());\n+\n+                dataParts.put(data, v);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to format statistics %s.%s by request=%s gathering=%s\",\n+                            k.getKey().schema(), k.getKey().obj(), reqId, gatId));\n+\n+            }\n+        });\n+\n+\n+        if (locNodeId.equals(req.senderNodeId()))\n+            statMgr.registerLocalResult(gatId, dataParts);\n+        else {\n+            int parts = dataParts.values().stream().mapToInt(l -> l.length).sum();\n+            statMgr.onRemoteGatheringSend(gatid, parts);\n+            StatisticsGatheringResponse resp = new StatisticsGatheringResponse(req.req().gatId(), reqId, dataParts);\n+            safeSend(req.senderNodeId(), resp);\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringResponseAsync(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        msgMgmtPool.submit(() -> sendGatheringResponse(reqId, statistics));\n+    }\n+\n+    /**\n+     * Send requests to target nodes (except of local one).\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatisticsAddrRequest<T>> sendRequests(\n+        Collection<StatisticsAddrRequest<T>> reqs\n+    ) {\n+        Collection<StatisticsAddrRequest<T>> res = null;\n+\n+        for (StatisticsAddrRequest<T> req : reqs) {\n+            if (locNodeId.equals(req.targetNodeId()))\n+                continue;\n+\n+            try {\n+                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 271}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTA5OA==", "bodyText": "Let's move constant to static final field.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375098", "createdAt": "2020-12-28T14:53:23Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NzY1Nw==", "bodyText": "I don't like this object with hardcoded set of fields is a part of protocol.\nThis approach is not flexible, we can't change the content of message that may depends on user needs.\nAlso versioning will be a headache in a future if we will need to change format.\nCustom versioned (de)serializer will be better.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549377657", "createdAt": "2020-12-28T15:00:21Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsColumnData.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.processors.query.h2.twostep.msg.GridH2ValueMessage;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Statistics by column (or by set of columns, if they collected together)\n+ */\n+public class StatisticsColumnData implements Message {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NjUzOQ==", "bodyText": "Test missed.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549386539", "createdAt": "2020-12-28T15:25:50Z", "author": {"login": "AMashenkov"}, "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +202,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat2.put(\"col1\", cs3);\n+        colStat2.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+    /**\n+     *\n+     */\n+    @Test\n+    public void subtractTest() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5MTY4OTEx", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559168911", "createdAt": "2020-12-28T14:33:06Z", "commit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQxNDozMzowNlrOIL6ygw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQwODozNjoxOVrOIMJ-kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2ODQ1MQ==", "bodyText": "there is no need in circular dependency Store <--> Repo. So let's preserve only Repo --> Store", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549368451", "createdAt": "2020-12-28T14:33:06Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -56,7 +56,7 @@\n     private final IgniteCacheDatabaseSharedManager db;\n \n     /** Statistics repository. */\n-    private final IgniteStatisticsRepository repo;\n+    private IgniteStatisticsRepository repo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw==", "bodyText": "return locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374533", "createdAt": "2020-12-28T14:51:36Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -209,37 +173,45 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeLocalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public ObjectStatisticsImpl mergeLocalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         if (locStats == null) {\n             log.warning(\"Unable to merge local statistics for \" + key + \" on non server node.\");\n \n-            return;\n+            return null;\n         }\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        locStats.compute(key, (k, v) -> {\n+            v = (v == null) ? statistics : add(v, statistics);\n+\n+            res[0] = v;\n \n-        locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n+            return v;\n+        });\n+        return res[0];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDg0OA==", "bodyText": "please fix also other places with such pattern", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374848", "createdAt": "2020-12-28T14:52:38Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -209,37 +173,45 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeLocalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public ObjectStatisticsImpl mergeLocalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         if (locStats == null) {\n             log.warning(\"Unable to merge local statistics for \" + key + \" on non server node.\");\n \n-            return;\n+            return null;\n         }\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        locStats.compute(key, (k, v) -> {\n+            v = (v == null) ? statistics : add(v, statistics);\n+\n+            res[0] = v;\n \n-        locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n+            return v;\n+        });\n+        return res[0];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw=="}, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTEyNA==", "bodyText": "missed space", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375124", "createdAt": "2020-12-28T14:53:28Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -256,22 +228,30 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void saveGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public void saveGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         globalStats.put(key, statistics);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n-        globalStats.compute(key, (k,v) -> (v == null) ? statistics : add(v, statistics));\n+    @Override public ObjectStatisticsImpl mergeGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        globalStats.compute(key, (k,v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4MDg4Ng==", "bodyText": "mgr is not used anymore", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549380886", "createdAt": "2020-12-28T15:10:00Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -71,38 +73,29 @@ public IgniteStatisticsRepositoryImpl(\n         }\n         else {\n             // Cache only global statistics, no store\n-            store = null;\n+            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n             locStats = null;\n-        }\n+        }*/\n+        this.store = store;\n+        this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ==", "bodyText": "store should not know about repo", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549384029", "createdAt": "2020-12-28T15:18:23Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -56,29 +56,36 @@\n      * @param partId Partition id.\n      * @return Object partition statistics or {@code null} if there are no statistics collected for such partition.\n      */\n-    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatsKey key, int partId);\n+    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partition statistics.\n      *\n      * @param key Object which statistics needs to be cleaned.\n      * @param partId Partition id.\n      */\n-    public void clearLocalPartitionStatistics(StatsKey key, int partId);\n+    public void clearLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partitions statistics.\n      *\n      * @param key Object which statistics need to be cleaned.\n      * @param partIds Collection of partition ids.\n      */\n-    public void clearLocalPartitionsStatistics(StatsKey key, Collection<Integer> partIds);\n+    public void clearLocalPartitionsStatistics(StatisticsKey key, Collection<Integer> partIds);\n \n     /**\n      * Save partition statistics.\n      *\n      * @param key Object which partition statistics belongs to.\n      * @param statistics Statistics to save.\n      */\n-    public void saveLocalPartitionStatistics(StatsKey key, ObjectPartitionStatisticsImpl statistics);\n+    public void saveLocalPartitionStatistics(StatisticsKey key, ObjectPartitionStatisticsImpl statistics);\n+\n+    /**\n+     * Set statistics repository.\n+     *\n+     * @param repository Ignite statistics repository.\n+     */\n+    public void setRepository(IgniteStatisticsRepository repository);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNjk1Mg==", "bodyText": "I don't think we need a method to collect statistics by several objects at all", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549616952", "createdAt": "2020-12-29T08:35:12Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNzI5Ng==", "bodyText": "the same as for collection by several objects", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549617296", "createdAt": "2020-12-29T08:36:19Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -46,6 +73,15 @@\n      * @param schemaName Schema name.\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to remove statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public void clearObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+\n+    /**\n+     * Clear object statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    public void clearObjectStatistics(String schemaName, String objName, String... colNames);\n+    public void clearObjectStatistics(GridTuple3<String, String, String[]>... keys) throws IgniteCheckedException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5NDMwMDI0", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559430024", "createdAt": "2020-12-29T08:39:22Z", "commit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQwODozOToyM1rOIMKCYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMDo0MDo0MVrOIMMXtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA==", "bodyText": "please add empty lines", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618274", "createdAt": "2020-12-29T08:39:23Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODM2Mg==", "bodyText": "null handling", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618362", "createdAt": "2020-12-29T08:39:41Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());\n+        List<Integer> res = new ArrayList<>();\n+        for (int bVal : b)\n+            if (aSet.contains(bVal))\n+                res.add(bVal);\n+        return res.stream().mapToInt(Integer::intValue).toArray();\n+    }\n+\n+    /**\n+     * Subtract b array from a array.\n+     *\n+     * @param a Base array.\n+     * @param b Array to subtract from the base one.\n+     * @return Subtraction result.\n+     */\n+    public static int[] subtract(int[] a, int[] b) {\n+        Set<Integer> bSet = Arrays.stream(b).boxed().collect(Collectors.toSet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDI3OA==", "bodyText": "dot", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620278", "createdAt": "2020-12-29T08:46:09Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDYwNw==", "bodyText": "space", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620607", "createdAt": "2020-12-29T08:47:07Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDc5NQ==", "bodyText": "we use 'primary' term", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620795", "createdAt": "2020-12-29T08:47:47Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMTI1OA==", "bodyText": "todo", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549621258", "createdAt": "2020-12-29T08:49:29Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjExOQ==", "bodyText": "please do it with tradition for-each loop", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622119", "createdAt": "2020-12-29T08:52:26Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjE5OA==", "bodyText": "indentation", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622198", "createdAt": "2020-12-29T08:52:48Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyNDY1MQ==", "bodyText": "for-each loop", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549624651", "createdAt": "2020-12-29T09:00:55Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), locNodeId, node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, locNodeId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Filter columns from specified statistics.\n+     *\n+     * @param stat Statistics to filter columns from.\n+     * @param cols Column names to return in result object.\n+     * @return Statistics with only specified columns.\n+     */\n+    public static ObjectStatisticsImpl filterColumns(ObjectStatisticsImpl stat, Collection<String> cols) {\n+        ObjectStatisticsImpl res = stat.clone();\n+        res.columnsStatistics().clear();\n+        cols.forEach(col -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY1NjUwMg==", "bodyText": "I would prefer to have it final, cause it prevent from having issues in case of multithreaded modification", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549656502", "createdAt": "2020-12-29T10:40:41Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java", "diffHunk": "@@ -24,7 +24,7 @@\n  */\n public class ObjectStatisticsImpl implements Cloneable, ObjectStatistics {\n     /** Total number of rows in object. */\n-    private final long rowsCnt;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5NDgxNzc3", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559481777", "createdAt": "2020-12-29T10:59:49Z", "commit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMDo1OTo0OVrOIMMuLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMzowODo0OVrOIMO7sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjI1NQ==", "bodyText": "empty line and commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662255", "createdAt": "2020-12-29T10:59:49Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjM2OA==", "bodyText": "empty line", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662368", "createdAt": "2020-12-29T11:00:15Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n+\n+        store.setRepository(statsRepos);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjU2Mw==", "bodyText": "commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662563", "createdAt": "2020-12-29T11:01:03Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2ODIzMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n          \n          \n            \n                    currColls.compute(gatId, (k, v) -> {\n          \n          \n            \n                        if (v == null)\n          \n          \n            \n                            v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n          \n          \n            \n            \n          \n          \n            \n                        ctxs[0] = v;\n          \n          \n            \n            \n          \n          \n            \n                        return v;\n          \n          \n            \n                    });\n          \n          \n            \n                    StatisticsGatheringContext ctxs = currColls.computeIfAbsent(gatId, \n          \n          \n            \n                        k -> new StatisticsGatheringContext(gatId, keys.keySet(), parts));", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549668232", "createdAt": "2020-12-29T11:21:08Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 328}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY4NTEzNg==", "bodyText": "it's better to check this after every N rows processed", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549685136", "createdAt": "2020-12-29T12:24:38Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5MDk4Mw==", "bodyText": "this has to be WARN", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549690983", "createdAt": "2020-12-29T12:44:58Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n+\n+            final boolean reserved = locPart.reserve();\n+\n+            try {\n+                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n+                    continue;\n+\n+                long rowsCnt = 0;\n+\n+                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+\n+                for (Column col : selectedCols)\n+                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+\n+                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n+                        null, true)) {\n+                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(tbl.cacheName(),\n+                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n+                    if (!tblName.equals(typeDesc.tableName()))\n+                        continue;\n+\n+                    rowsCnt++;\n+\n+                    H2Row row0 = desc.createRow(row);\n+\n+                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n+                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+\n+                }\n+\n+                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n+                        csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+\n+                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n+                        locPart.updateCounter(), colStats));\n+\n+                if (log.isTraceEnabled())\n+                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n+                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjE3MQ==", "bodyText": "computeIfAbsent suits here better", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696171", "createdAt": "2020-12-29T13:01:35Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 551}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjYxMQ==", "bodyText": "is there any reason to convert this insert a compute's closure?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696611", "createdAt": "2020-12-29T13:03:11Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 560}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5ODQ4MA==", "bodyText": "StatisticsObjectData has default equals and hashcode methods. IS it OK?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549698480", "createdAt": "2020-12-29T13:08:49Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Message to send statistics.\n+ */\n+public class StatisticsGatheringResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 186;\n+\n+    /** Collection id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Map of collected local object statistics with array of included partitions. */\n+    @GridDirectMap(keyType = StatisticsObjectData.class, valueType = int[].class)\n+    private Map<StatisticsObjectData, int[]> data;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/bbc77144eac02f5ee7e71db9e138935ee5c280a3", "committedDate": "2020-12-29T14:02:19Z", "message": "GG-31094: statistics clear, cancel and some fixes to collect"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5NTk0MDE0", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559594014", "createdAt": "2020-12-29T15:56:07Z", "commit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxNTo1NjowN1rOIMScXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxNjowOTo0NFrOIMSvXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NTk5Ng==", "bodyText": "it's not going to work since it's possible to create column with comma in the name", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549755996", "createdAt": "2020-12-29T15:56:07Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,161 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)\n+    private List<String> colNames;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NjUwNQ==", "bodyText": "Message interface is partly implemented", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549756505", "createdAt": "2020-12-29T15:57:25Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA==", "bodyText": "StatisticsKeyMessage has default equals and hashcode methods. IS it OK?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549759940", "createdAt": "2020-12-29T16:07:03Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;\n+\n+    /** Gathering id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Keys to partitions to gather statistics by. */\n+    @GridDirectMap(keyType = StatisticsKeyMessage.class, valueType = int[].class)\n+    private Map<StatisticsKeyMessage, int[]> keys;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc2MDg2Mg==", "bodyText": "please leave a comment inside GridIoMessageFactory with used codes", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549760862", "createdAt": "2020-12-29T16:09:44Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5NjExOTI2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-559611926", "createdAt": "2020-12-29T16:39:51Z", "commit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxNjozOTo1MVrOIMTXyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxNzo0OToxNFrOIMUuBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTIxMA==", "bodyText": "wrong javadoc", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771210", "createdAt": "2020-12-29T16:39:51Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTU1OQ==", "bodyText": "computeIfAbsent", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771559", "createdAt": "2020-12-29T16:40:56Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTY2Nw==", "bodyText": "comment in Russian", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771667", "createdAt": "2020-12-29T16:41:18Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NDQyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        for (int i = 0; i < assignments.size(); i++)\n          \n          \n            \n                            fillPartition(res, assignments, i, isPrimary);\n          \n          \n            \n                    else\n          \n          \n            \n                        for (Integer partId : partIds)\n          \n          \n            \n                            fillPartition(res, assignments, partId, isPrimary);\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n          \n          \n            \n            \n          \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n            \n          \n          \n            \n                    for (Integer partId : partIds)\n          \n          \n            \n                        fillPartition(res, assignments, partId, isPrimary);", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549774426", "createdAt": "2020-12-29T16:50:09Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg==", "bodyText": "why we don't count the last node?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549775416", "createdAt": "2020-12-29T16:53:36Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master or backups node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n+     */\n+    protected static  void fillPartition(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId,\n+        boolean isPrimary\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(partId);\n+\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NjU3Mg==", "bodyText": "also braces", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549776572", "createdAt": "2020-12-29T16:56:53Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master or backups node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n+     */\n+    protected static  void fillPartition(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId,\n+        boolean isPrimary\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(partId);\n+\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg=="}, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4MDQ3Mw==", "bodyText": "No, it's not, since it used here: https://github.com/gridgain/gridgain/pull/1660/files#diff-f727e80fc5250f851bb87b1f9cd9b5c159e5ca0cf094623418d515211784c82eR459", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549780473", "createdAt": "2020-12-29T17:07:24Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;\n+\n+    /** Gathering id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Keys to partitions to gather statistics by. */\n+    @GridDirectMap(keyType = StatisticsKeyMessage.class, valueType = int[].class)\n+    private Map<StatisticsKeyMessage, int[]> keys;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA=="}, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4Njc3MQ==", "bodyText": "let's use class with meaningful name instead of GridTuple3", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549786771", "createdAt": "2020-12-29T17:27:22Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4NzQ3OQ==", "bodyText": "this is not used", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549787479", "createdAt": "2020-12-29T17:29:42Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 245}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5MzI4NQ==", "bodyText": "looks like debug code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549793285", "createdAt": "2020-12-29T17:49:14Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java", "diffHunk": "@@ -81,7 +81,11 @@ public void compareSelectWithIntConditions() throws IgniteCheckedException {\n                 String.format(lo_med_select, 7, 7), noHints);\n \n         statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\");\n-\n+        try {\n+            Thread.sleep(1000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ef165002105dd10417170217e86d65771c524bb", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/7ef165002105dd10417170217e86d65771c524bb", "committedDate": "2020-12-31T11:58:01Z", "message": "GG-31094: collect statistics by only one cache group by request"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/05b732cd7e8840c429c48f5561e7c98e0289bcf6", "committedDate": "2021-01-11T11:24:57Z", "message": "GG-31094: collect stats by only one cache group"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e54c934091d0917505fbe4bd919fd766a492897e", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/e54c934091d0917505fbe4bd919fd766a492897e", "committedDate": "2021-01-11T11:48:18Z", "message": "GG-31094: comment, docs and codestyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "committedDate": "2021-01-11T12:19:11Z", "message": "GG-31094: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "committedDate": "2021-01-11T13:35:43Z", "message": "GG-31094: PR fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/b385286d37cb759a2a308a055b12f32c5c22a976", "committedDate": "2021-01-12T13:20:32Z", "message": "GG-31094: fixes in test, backup sending and local saving."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MzMwNzk1", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-566330795", "createdAt": "2021-01-12T14:35:09Z", "commit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxNDozNTowOVrOISEWuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxNzowNDoyOFrOISLZHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgxNjYzMw==", "bodyText": "this is not used anymore", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555816633", "createdAt": "2021-01-12T14:35:09Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA=="}, "originalCommit": {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgyNzA2OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                        StatisticsKeyMessage key,\n          \n          \n            \n                        long rowsCnt,\n          \n          \n            \n                        StatisticsType type,\n          \n          \n            \n                        int partId,\n          \n          \n            \n                        long updCnt,\n          \n          \n            \n                        Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {\n          \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                    StatisticsKeyMessage key,\n          \n          \n            \n                    long rowsCnt,\n          \n          \n            \n                    StatisticsType type,\n          \n          \n            \n                    int partId,\n          \n          \n            \n                    long updCnt,\n          \n          \n            \n                    Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555827069", "createdAt": "2021-01-12T14:48:05Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java", "diffHunk": "@@ -0,0 +1,265 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.processors.query.stat.StatisticsType;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+import java.util.Map;\n+\n+/**\n+ * Statistics for some object (index or table) in database.\n+ */\n+public class StatisticsObjectData implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 184;\n+\n+    /** Statistics key. */\n+    private StatisticsKeyMessage key;\n+\n+    /** Total row count in current object. */\n+    private long rowsCnt;\n+\n+    /** Type of statistics. */\n+    private StatisticsType type;\n+\n+    /** Partition id if statistics was collected by partition. */\n+    private int partId;\n+\n+    /** Update counter if statistics was collected by partition. */\n+    private long updCnt;\n+\n+    /** Columns key to statistic map. */\n+    @GridDirectMap(keyType = String.class, valueType = StatisticsColumnData.class)\n+    private Map<String, StatisticsColumnData> data;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param key Statistics key.\n+     * @param rowsCnt Total row count.\n+     * @param type Statistics type.\n+     * @param partId Partition id.\n+     * @param updCnt Partition update counter.\n+     * @param data Map of statistics column data.\n+     */\n+    public StatisticsObjectData(\n+            StatisticsKeyMessage key,\n+            long rowsCnt,\n+            StatisticsType type,\n+            int partId,\n+            long updCnt,\n+            Map<String, StatisticsColumnData> data\n+    ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4MzEwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /** Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats. */\n          \n          \n            \n                @GridDirectCollection(String.class)\n          \n          \n            \n                /**\n          \n          \n            \n                 * Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats.\n          \n          \n            \n                 */\n          \n          \n            \n                @GridDirectCollection(String.class)", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555883106", "createdAt": "2021-01-12T15:57:59Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4NTUwNg==", "bodyText": "should not be 0", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555885506", "createdAt": "2021-01-12T16:01:00Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 188;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** List of keys to supply statistics by. */\n+    @GridDirectCollection(StatisticsObjectData.class)\n+    private List<StatisticsObjectData> data;\n+\n+    /**\n+     * Default constructor.\n+     */\n+    public StatisticsGetResponse() {\n+    }\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param reqId Request id.\n+     * @param data Statistics data.\n+     */\n+    public StatisticsGetResponse(UUID reqId, List<StatisticsObjectData> data) {\n+        this.reqId = reqId;\n+        this.data = data;\n+    }\n+\n+    /**\n+     * @return Request id.\n+     */\n+    public UUID reqId() {\n+        return reqId;\n+    }\n+\n+    /**\n+     * @return Statistics.\n+     */\n+    public List<StatisticsObjectData> data() {\n+        return data;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean writeTo(ByteBuffer buf, MessageWriter writer) {\n+        writer.setBuffer(buf);\n+\n+        if (!writer.isHeaderWritten()) {\n+            if (!writer.writeHeader(directType(), fieldsCount()))\n+                return false;\n+\n+            writer.onHeaderWritten();\n+        }\n+\n+        switch (writer.state()) {\n+            case 0:\n+                if (!writer.writeCollection(\"data\", data, MessageCollectionItemType.MSG))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+            case 1:\n+                if (!writer.writeUuid(\"reqId\", reqId))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+        }\n+\n+        return true;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean readFrom(ByteBuffer buf, MessageReader reader) {\n+        reader.setBuffer(buf);\n+\n+        if (!reader.beforeMessageRead())\n+            return false;\n+\n+        switch (reader.state()) {\n+            case 0:\n+                data = reader.readCollection(\"data\", MessageCollectionItemType.MSG);\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+            case 1:\n+                reqId = reader.readUuid(\"reqId\");\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+        }\n+\n+        return reader.afterMessageRead(StatisticsGetResponse.class);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public short directType() {\n+        return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkwOTEyNg==", "bodyText": "stale javadoc", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555909126", "createdAt": "2021-01-12T16:33:07Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -41,131 +40,98 @@\n     private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n+\n+    /** Statistics gathering. */\n+    private final StatisticsGathering statisticsGathering;\n \n     /** Global (for whole cluster) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n      *\n-     * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n      * @param db Database to use in storage if persistence enabled.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyODM4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                        UUID reqId,\n          \n          \n            \n                        Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                        int[] parts,\n          \n          \n            \n                        Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                        StatisticsKeyMessage keyMsg,\n          \n          \n            \n                        Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );\n          \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                    UUID reqId,\n          \n          \n            \n                    Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                    int[] parts,\n          \n          \n            \n                    Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                    StatisticsKeyMessage keyMsg,\n          \n          \n            \n                    Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555928381", "createdAt": "2021-01-12T16:59:35Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {\n+    /**\n+     * Collect local statistics by specified keys and partitions\n+     * and pass it to router to send in response to specified reqId.\n+     *\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     * @param parts Partitions to collect statistics by.\n+     * @param cancelled Supplier to track cancelled state.\n+     */\n+    public void collectLocalObjectsStatisticsAsync(\n+            UUID reqId,\n+            Set<StatisticsKeyMessage> keys,\n+            int[] parts,\n+            Supplier<Boolean> cancelled\n+    );\n+\n+    /**\n+     * @param statRepo Statistics repository.\n+     */\n+    public void repository(IgniteStatisticsRepository statRepo);\n+\n+    /**\n+     * Aggregate specified partition level statistics to local level statistics.\n+     *\n+     * @param keyMsg Aggregation key.\n+     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n+     * @return Local level aggregated statistics.\n+     */\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            Collection<? extends ObjectStatisticsImpl> stats\n+    );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTkzNQ==", "bodyText": "why it can't be just a class? do you plan to collect statistics in different ways?", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555931935", "createdAt": "2021-01-12T17:04:28Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976"}, "originalPosition": 28}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "committedDate": "2021-01-13T06:26:03Z", "message": "GG-31094: triple2StatTarget, minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca1e579abf9a1382be63c0d4ba860f969041b986", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/ca1e579abf9a1382be63c0d4ba860f969041b986", "committedDate": "2021-01-13T13:12:36Z", "message": "GG-31094: PR fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17a54090bea4d97c122cf06d6be8e60177006519", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/17a54090bea4d97c122cf06d6be8e60177006519", "committedDate": "2021-01-13T14:06:01Z", "message": "GG-31094: PR fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/efd6b5e9f1f91625c2e6106b4c75522dada68b46", "committedDate": "2021-01-14T10:58:17Z", "message": "GG-31094: tests, PR fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "committedDate": "2021-01-14T13:39:19Z", "message": "GG-31094: test fixes, test for clearance and cancell gathering"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4MjMwNDI5", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-568230429", "createdAt": "2021-01-14T13:27:54Z", "commit": {"oid": "efd6b5e9f1f91625c2e6106b4c75522dada68b46"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxMzoyNzo1NFrOITkmjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNTo0ODo0NVrOITq0Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM5MzU0OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n          \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557393549", "createdAt": "2021-01-14T13:27:54Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * Utility methods to statistics messages generation.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param schemaMgr Schema manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n+     */\n+    public IgniteStatisticsHelper(\n+        UUID locNodeId,\n+        SchemaManager schemaMgr,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.locNodeId = locNodeId;\n+        this.schemaMgr = schemaMgr;\n+        this.log = logSupplier.apply(IgniteStatisticsHelper.class);\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Split specified keys to cache groups.\n+     *\n+     * @param keys Keys to split.\n+     * @return Map cache group to collection of keys in group.\n+     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n+     */\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efd6b5e9f1f91625c2e6106b4c75522dada68b46"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ0MDk4NQ==", "bodyText": "wrong comment", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557440985", "createdAt": "2021-01-14T14:37:57Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -59,6 +66,18 @@\n     /** Statistics repository. */\n     private final IgniteStatisticsRepository statsRepos;\n \n+    /** Current statistics collections tasks. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ2NjA2NA==", "bodyText": "commented code", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557466064", "createdAt": "2021-01-14T15:10:13Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +205,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat3.put(\"col1\", cs3);\n+        colStat3.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat3);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+//    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NDQzMA==", "bodyText": "empty line", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557494430", "createdAt": "2021-01-14T15:47:39Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NTI5OQ==", "bodyText": "stale param", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557495299", "createdAt": "2021-01-14T15:48:45Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Ignite statistics repository. */\n+    private IgniteStatisticsRepository statRepo;\n+\n+    /** Statistics crawler. */\n+    private final StatisticsGatheringRequestCrawler statCrawler;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param cacheProcessor Grid cache processor.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7"}, "originalPosition": 89}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48b736c4cf138d5db12978e2004c446e26e1f097", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/48b736c4cf138d5db12978e2004c446e26e1f097", "committedDate": "2021-01-18T13:30:47Z", "message": "GG-31094: minor refactoring, codestyle, statistics version in metastore and collection on caches with lost partitions."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a23eebc202da08a14cf888988d43eb62231d1189", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/a23eebc202da08a14cf888988d43eb62231d1189", "committedDate": "2021-01-18T13:33:19Z", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23afcfd0b070646af24a1572418edbec1d4b5605", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/23afcfd0b070646af24a1572418edbec1d4b5605", "committedDate": "2021-01-18T13:52:49Z", "message": "GG-31094: PR small fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "committedDate": "2021-01-19T09:40:33Z", "message": "GG-31094: tests fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/390bfd8e824301929df7b139844e3b40bd216f6d", "committedDate": "2021-01-19T09:46:53Z", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f29d66b8a36ce398400e761327f382e93ad2957", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/7f29d66b8a36ce398400e761327f382e93ad2957", "committedDate": "2021-01-19T11:26:19Z", "message": "GG-31094: licences"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe2051cb06a7d4423864c145d20b447da276320e", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/fe2051cb06a7d4423864c145d20b447da276320e", "committedDate": "2021-01-19T11:30:22Z", "message": "GG-31094: licences"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxMTAxNDU2", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-571101456", "createdAt": "2021-01-19T10:24:29Z", "commit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDoyNDoyOVrOIWH8WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMjoxNjozMVrOIWL6zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2OTcyMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Return map cache group to corrsponding stats keys.\n          \n          \n            \n                 * Return map cache group to corresponding stats keys.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560069721", "createdAt": "2021-01-19T10:24:29Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -88,13 +158,13 @@ public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws Ignite\n     }\n \n     /**\n-     * Extract groups of stats keys.\n+     * Return map cache group to corrsponding stats keys.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3Mjc2OQ==", "bodyText": "sout", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560072769", "createdAt": "2021-01-19T10:29:10Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -85,6 +85,7 @@ public IgniteStatisticsRepositoryImpl(\n             res.add(newStat);\n             store.saveLocalPartitionStatistics(key, newStat);\n         }\n+        System.out.println(statistics.size() + \" partitions saved!\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3MzkyMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Receive gathering response and math it to request, then process these couple.\n          \n          \n            \n                 * Receive gathering response and match it to request, then process these couple.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560073921", "createdAt": "2021-01-19T10:31:06Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -412,7 +421,7 @@ public void sendClearStatistics(Collection<StatisticsKeyMessage> keys) {\n     }\n \n     /**\n-     * Receive and handle statistics gathering response message as response for collection request.\n+     * Receive gathering response and math it to request, then process these couple.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDExOA==", "bodyText": "lockPool", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134118", "createdAt": "2021-01-19T12:15:06Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDg2Mg==", "bodyText": "GridTestUtils#getFieldValue(Object obj, String... fieldNames)", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134862", "createdAt": "2021-01-19T12:16:31Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringImpl.gatMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeGathLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringImpl crawler = readField(statMgr, \"statGathering\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"gatMgmtPool\");\n+        return lockPool(pool);\n+    }\n+\n+    /**\n+     * Lock specified pool with task, waiting for lock release.\n+     *\n+     * @param pool Pool to block.\n+     * @return Lock.\n+     */\n+    private Lock lockPool(IgniteThreadPoolExecutor pool) {\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Read object field value by name.\n+     *\n+     * @param obj Object to read value from.\n+     * @param field Field name.\n+     * @return Field value.\n+     * @throws Exception If case if object doesn't contains specified field.\n+     */\n+    protected <T> T readField(Object obj, String field) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d"}, "originalPosition": 155}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "committedDate": "2021-01-20T08:29:24Z", "message": "GG-31094: gathering tests, small refactorings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/33170812024f6c4d321f85287fea0b6c3abdb9e5", "committedDate": "2021-01-20T11:21:27Z", "message": "GG-31094: codestyle refactorings, batch gathering test."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "committedDate": "2021-01-20T11:45:58Z", "message": "GG-31094: checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcyMTU2NTgz", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-572156583", "createdAt": "2021-01-20T12:08:35Z", "commit": {"oid": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQxMjowODozNVrOIW7Ucw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQxMjowODozNVrOIW7Ucw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ==", "bodyText": "it's better to complete a future with this exception", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560911475", "createdAt": "2021-01-20T12:08:35Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -255,13 +261,15 @@ public void gatherLocalObjectStatisticsAsync(\n         StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n             new StatisticsGatheringContext(gatId, keysSet, partsCnt));\n \n-        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFut().isCancelled());\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFuture().isCancelled());\n     }\n \n     /** {@inheritDoc} */\n-    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n     ) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics async\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c"}, "originalPosition": 69}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1eb42d79754cf530e8ede9439c69b74635dd022f", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/1eb42d79754cf530e8ede9439c69b74635dd022f", "committedDate": "2021-01-21T08:37:47Z", "message": "GG-31094: GridTestUtils.getFieldValue usage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "committedDate": "2021-01-21T11:11:26Z", "message": "GG-31094: remove Exception from Async method, add StatisticsTarget array to the gathering future."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNDYyMzE5", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-573462319", "createdAt": "2021-01-21T15:42:48Z", "commit": {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxNTo0Mjo0OFrOIX8uBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxNTo0Mjo0OFrOIX8uBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4Mjk4Mg==", "bodyText": "it's better to check this with checkStatisticsSupport(), but slightly modify it to take param to decide wether an exception should be thrown or not (true by default)\n void checkStatisticsSupport(String op) {\n     checkStatisticsSupport(op, true)\n }\n\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\n     if (<support>)\n         return true;\n     \n     if (shouldThrow)\n         throw new Ex();\n\n     return false;\n }", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561982982", "createdAt": "2021-01-21T15:42:48Z", "author": {"login": "korlov42"}, "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -267,14 +266,23 @@ public void gatherLocalObjectStatisticsAsync(\n     /** {@inheritDoc} */\n     @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n-    ) throws IgniteCheckedException {\n-        checkSupport(\"collect statistics async\");\n+    ) {\n+\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n+            .collect(Collectors.toSet());\n \n-        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-            t -> new StatisticsKeyMessage(t.schema(), t.obj(), Arrays.asList(t.columns()))).collect(Collectors.toSet());\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        List<StatisticsGatheringFuture<Void>> res = new ArrayList<>();\n+        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNDcxMzk4", "url": "https://github.com/gridgain/gridgain/pull/1660#pullrequestreview-573471398", "createdAt": "2021-01-21T15:51:24Z", "commit": {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxNTo1MToyNFrOIX9JTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxNTo1MToyNFrOIX9JTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4OTk2Ng==", "bodyText": "BTW id=52 already reserved. Please check https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list for next feature ID. You need to reserve it first.", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561989966", "createdAt": "2021-01-21T15:51:24Z", "author": {"login": "korlov42"}, "path": "modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "diffHunk": "@@ -194,7 +194,10 @@\n     CACHE_GROUP_KEY_CHANGE(50),\n \n     /** Possibility to safe deactivation, take into account pure in memory caches with possible data loss.*/\n-    SAFE_CLUSTER_DEACTIVATION(51);\n+    SAFE_CLUSTER_DEACTIVATION(51),\n+\n+    /** Statistics collection. */\n+    STATISTICS_COLLECTION(52);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "committedDate": "2021-01-22T08:55:32Z", "message": "GG-31094: change feature number, minor fix by PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acbdccc0496377fc2b3b7d52363aea2185d33239", "author": {"user": null}, "url": "https://github.com/gridgain/gridgain/commit/acbdccc0496377fc2b3b7d52363aea2185d33239", "committedDate": "2021-01-26T16:09:51Z", "message": "GG-31094: Merge remote-tracking branch 'gridgain-ce/master' into gg-31094"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4883, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}