{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA2MDUxOTg0", "number": 4185, "title": "[RW-5045][risk=no] Hail Microarray Demo codegen", "bodyText": "Description:\nExample of generated code\n\n\nPR checklist\n\n This PR meets the Acceptance Criteria in the JIRA story\n The JIRA story has been moved to Dev Review\n This PR includes appropriate unit tests\n I have run and tested this change locally\n I have run the E2E tests on ths change against my local UI + API server with yarn test-local\n If this includes a UI change, I have taken screen recordings or screenshots of the new behavior and notified the PO and UX designer\n If this includes an API change, I have updated the appropriate Swagger definitions and notified API consumers\n If this includes a new feature flag, I have created and linked new JIRA tickets to (a) turn on the feature flag and (b) remove it later", "createdAt": "2020-10-19T14:58:21Z", "url": "https://github.com/all-of-us/workbench/pull/4185", "merged": true, "mergeCommit": {"oid": "41cd89ae77a6b281f5ed709d54ec966357bf6c35"}, "closed": true, "closedAt": "2020-10-20T19:44:54Z", "author": {"login": "ericsong"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUFMFrgH2gAyNTA2MDUxOTg0OmM2MTg1YmZmMjNlZTEyNzJjMzMxMjM3NWQ4Y2QwOTMyZWQ5YTc0MjA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdUb0YHAFqTUxMjk0NTYyNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c6185bff23ee1272c3312375d8cd0932ed9a7420", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/c6185bff23ee1272c3312375d8cd0932ed9a7420", "committedDate": "2020-10-19T14:38:27Z", "message": "add Hail codegen"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6de1325b9540e32dcf4bde52b2d584fd07ab073", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/e6de1325b9540e32dcf4bde52b2d584fd07ab073", "committedDate": "2020-10-19T14:46:53Z", "message": "revert test changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54623c35cee9a77b8e6ccd70c48f3fc9f1f8e135", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/54623c35cee9a77b8e6ccd70c48f3fc9f1f8e135", "committedDate": "2020-10-19T14:48:03Z", "message": "remove unused line"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a5b3d91ffe48c99fc05fcc5012f29b81b7f1deb", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/7a5b3d91ffe48c99fc05fcc5012f29b81b7f1deb", "committedDate": "2020-10-19T14:49:13Z", "message": "flip bool"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbe99ae106e6d713bd9624c9a80106d27e752648", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/fbe99ae106e6d713bd9624c9a80106d27e752648", "committedDate": "2020-10-19T17:56:42Z", "message": "Merge branch 'master' of github.com:all-of-us/workbench into songe/RW-5045-2"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyMDM1NTQ4", "url": "https://github.com/all-of-us/workbench/pull/4185#pullrequestreview-512035548", "createdAt": "2020-10-19T18:14:39Z", "commit": {"oid": "fbe99ae106e6d713bd9624c9a80106d27e752648"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/5d33e62b4a74cef08c417a76bf173b4bd06a63cb", "committedDate": "2020-10-19T18:43:26Z", "message": "change project id arg"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyMTQ1NzI1", "url": "https://github.com/all-of-us/workbench/pull/4185#pullrequestreview-512145725", "createdAt": "2020-10-19T20:46:03Z", "commit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQyMDo0NjowM1rOHkhAlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQyMDo0ODo1MVrOHkhGKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODA1MTYwNQ==", "bodyText": ".tsv?", "url": "https://github.com/all-of-us/workbench/pull/4185#discussion_r508051605", "createdAt": "2020-10-19T20:46:03Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -815,6 +815,58 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n             + \"head results.P2.assoc\");\n   }\n \n+  @Override\n+  public List<String> generateHailDemoCode(String qualifier) {\n+    final String phenotypeFilename = \"phenotypes_annotations_\" + qualifier + \".txt\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODA1MjA3NQ==", "bodyText": "Please spell it out in the variable name", "url": "https://github.com/all-of-us/workbench/pull/4185#discussion_r508052075", "createdAt": "2020-10-19T20:46:59Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -815,6 +815,58 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n             + \"head results.P2.assoc\");\n   }\n \n+  @Override\n+  public List<String> generateHailDemoCode(String qualifier) {\n+    final String phenotypeFilename = \"phenotypes_annotations_\" + qualifier + \".txt\";\n+    final String cohortQualifier = \"cohort_\" + qualifier;\n+    final String cohortVcfFilename = cohortQualifier + \".vcf\";\n+    final String cohortMtFilename = cohortQualifier + \".mt\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODA1MjYwNA==", "bodyText": "Why?", "url": "https://github.com/all-of-us/workbench/pull/4185#discussion_r508052604", "createdAt": "2020-10-19T20:48:01Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -815,6 +815,58 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n             + \"head results.P2.assoc\");\n   }\n \n+  @Override\n+  public List<String> generateHailDemoCode(String qualifier) {\n+    final String phenotypeFilename = \"phenotypes_annotations_\" + qualifier + \".txt\";\n+    final String cohortQualifier = \"cohort_\" + qualifier;\n+    final String cohortVcfFilename = cohortQualifier + \".vcf\";\n+    final String cohortMtFilename = cohortQualifier + \".mt\";\n+\n+    return ImmutableList.of(\n+        \"import subprocess, os\\n\"\n+            + \"import random\\n\"\n+            + \"\\n\"\n+            + \"# Creating phenotype annotations file\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    person_id = person_id\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODA1MzAzNA==", "bodyText": "If covariates is something the user should expect to be modifying, then please comment or pull out into a variable", "url": "https://github.com/all-of-us/workbench/pull/4185#discussion_r508053034", "createdAt": "2020-10-19T20:48:51Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -815,6 +815,58 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n             + \"head results.P2.assoc\");\n   }\n \n+  @Override\n+  public List<String> generateHailDemoCode(String qualifier) {\n+    final String phenotypeFilename = \"phenotypes_annotations_\" + qualifier + \".txt\";\n+    final String cohortQualifier = \"cohort_\" + qualifier;\n+    final String cohortVcfFilename = cohortQualifier + \".vcf\";\n+    final String cohortMtFilename = cohortQualifier + \".mt\";\n+\n+    return ImmutableList.of(\n+        \"import subprocess, os\\n\"\n+            + \"import random\\n\"\n+            + \"\\n\"\n+            + \"# Creating phenotype annotations file\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    person_id = person_id\\n\"\n+            + \"    phenotype_1 = random.randint(0, 2) # Change this value to what makes sense for your research by looking through the dataset(s)\\n\"\n+            + \"    phenotype_2 = random.randint(0, 2) # Change this value as well or remove if you are only processing one phenotype \\n\"\n+            + \"    phenotypes_table.append([person_id, phenotype_1, phenotype_2])\\n\"\n+            + \"\\n\"\n+            + \"cohort_phenotypes = pandas.DataFrame(phenotypes_table,columns=[\\\"sample_name\\\", \\\"phenotype1\\\", \\\"phenotype2\\\"]) \\n\"\n+            + \"cohort_phenotypes.to_csv('\"\n+            + phenotypeFilename\n+            + \"', index=False, sep='\\\\t')\\n\"\n+            + \"\\n\"\n+            + \"subprocess.run([\\\"gsutil\\\", \\\"cp\\\", \\\"\"\n+            + phenotypeFilename\n+            + \"\\\", os.environ['WORKSPACE_BUCKET']])\",\n+        \"import hail as hl\\n\"\n+            + \"import os\\n\"\n+            + \"from hail.plot import show\\n\"\n+            + \"\\n\"\n+            + \"hl.plot.output_notebook()\\n\"\n+            + \"bucket = os.environ['WORKSPACE_BUCKET']\\n\"\n+            + \"hl.import_vcf(f'{bucket}/\"\n+            + cohortVcfFilename\n+            + \"').write(f'{bucket}/\"\n+            + cohortMtFilename\n+            + \"')\\n\"\n+            + \"table = hl.import_table(f'{bucket}/\"\n+            + phenotypeFilename\n+            + \"', types={'sample_name': hl.tstr}, impute=True, key='sample_name')\\n\"\n+            + \"\\n\"\n+            + \"mt = hl.read_matrix_table(f'{bucket}/\"\n+            + cohortMtFilename\n+            + \"');\\n\"\n+            + \"mt = mt.annotate_cols(pheno = table[mt.s])\\n\"\n+            + \"\\n\"\n+            + \"gwas = hl.linear_regression_rows(y=mt.pheno.phenotype1, x=mt.GT.n_alt_alleles(), covariates=[1.0])\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d33e62b4a74cef08c417a76bf173b4bd06a63cb"}, "originalPosition": 60}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d32e360eefa1c371ebe2be044158164d952bf6c", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/1d32e360eefa1c371ebe2be044158164d952bf6c", "committedDate": "2020-10-20T15:00:18Z", "message": "code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4580de882fe131020465a6a4013c8e73b719a3f", "author": {"user": {"login": "ericsong", "name": "Eric Song"}}, "url": "https://github.com/all-of-us/workbench/commit/b4580de882fe131020465a6a4013c8e73b719a3f", "committedDate": "2020-10-20T16:13:46Z", "message": "add microarray codegen tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyOTQ1NjI1", "url": "https://github.com/all-of-us/workbench/pull/4185#pullrequestreview-512945625", "createdAt": "2020-10-20T16:57:35Z", "commit": {"oid": "b4580de882fe131020465a6a4013c8e73b719a3f"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxNjo1NzozNVrOHlIB2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxNjo1NzozNVrOHlIB2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODY5MDkwNQ==", "bodyText": "opt: if you wanted to use streams here, you could use flatMap to expand the inner arrays. Fine as currently written though.", "url": "https://github.com/all-of-us/workbench/pull/4185#discussion_r508690905", "createdAt": "2020-10-20T16:57:35Z", "author": {"login": "calbach"}, "path": "api/src/test/java/org/pmiops/workbench/api/DataSetControllerTest.java", "diffHunk": "@@ -739,4 +732,169 @@ public void testGetValuesFromDomain() {\n         .containsExactly(\n             new DomainValue().value(\"field_one\"), new DomainValue().value(\"field_two\"));\n   }\n+\n+  @Test\n+  public void exportToNotebook_microarrayCodegen_cdrCheck() {\n+    DbCdrVersion cdrVersion =\n+        cdrVersionDao.findByCdrVersionId(Long.parseLong(workspace.getCdrVersionId()));\n+    cdrVersion.setMicroarrayBigqueryDataset(null);\n+    cdrVersionDao.save(cdrVersion);\n+\n+    DataSetExportRequest request =\n+        setUpValidDataSetExportRequest().genomicsDataType(GenomicsDataTypeEnum.MICROARRAY);\n+\n+    FailedPreconditionException e =\n+        assertThrows(\n+            FailedPreconditionException.class,\n+            () ->\n+                dataSetController.exportToNotebook(\n+                    workspace.getNamespace(), WORKSPACE_NAME, request));\n+    assertThat(e)\n+        .hasMessageThat()\n+        .contains(\"The workspace CDR version does not have microarray data\");\n+  }\n+\n+  @Test\n+  public void exportToNotebook_microarrayCodegen_kernelCheck() {\n+    DataSetExportRequest request =\n+        setUpValidDataSetExportRequest()\n+            .kernelType(KernelTypeEnum.R)\n+            .genomicsDataType(GenomicsDataTypeEnum.MICROARRAY);\n+\n+    BadRequestException e =\n+        assertThrows(\n+            BadRequestException.class,\n+            () ->\n+                dataSetController.exportToNotebook(\n+                    workspace.getNamespace(), WORKSPACE_NAME, request));\n+    assertThat(e).hasMessageThat().contains(\"Genomics code generation is only supported in Python\");\n+  }\n+\n+  @Test\n+  public void exportToNotebook_microarrayCodegen_noGenomicsTool() {\n+    DataSetExportRequest request =\n+        setUpValidDataSetExportRequest()\n+            .genomicsDataType(GenomicsDataTypeEnum.MICROARRAY)\n+            .genomicsAnalysisTool(GenomicsAnalysisToolEnum.NONE);\n+\n+    dataSetController.exportToNotebook(workspace.getNamespace(), WORKSPACE_NAME, request);\n+\n+    verify(mockNotebooksService, times(1))\n+        .saveNotebook(\n+            eq(WORKSPACE_BUCKET_NAME),\n+            eq(request.getNotebookName()),\n+            notebookContentsCaptor.capture());\n+\n+    List<String> codeCells = notebookContentsToStrings(notebookContentsCaptor.getValue());\n+\n+    assertThat(codeCells.size()).isEqualTo(3);\n+    assertThat(codeCells.get(2)).contains(\"raw_array_cohort_extract.py\");\n+    assertThat(codeCells.get(2)).contains(\"gatk ArrayExtractCohort\");\n+    assertThat(codeCells.get(2)).contains(\"gsutil cp\");\n+  }\n+\n+  @Test\n+  public void exportToNotebook_microarrayCodegen_plink() {\n+    DataSetExportRequest request =\n+        setUpValidDataSetExportRequest()\n+            .genomicsDataType(GenomicsDataTypeEnum.MICROARRAY)\n+            .genomicsAnalysisTool(GenomicsAnalysisToolEnum.PLINK);\n+\n+    dataSetController.exportToNotebook(workspace.getNamespace(), WORKSPACE_NAME, request);\n+\n+    verify(mockNotebooksService, times(1))\n+        .saveNotebook(\n+            eq(WORKSPACE_BUCKET_NAME),\n+            eq(request.getNotebookName()),\n+            notebookContentsCaptor.capture());\n+\n+    List<String> codeCells = notebookContentsToStrings(notebookContentsCaptor.getValue());\n+\n+    assertThat(codeCells.size()).isEqualTo(5);\n+    assertThat(codeCells.get(2)).contains(\"gatk ArrayExtractCohort\");\n+    assertThat(codeCells.get(3)).contains(\"cohort_phenotypes.to_csv\");\n+    assertThat(codeCells.get(3)).contains(\".phe\");\n+    assertThat(codeCells.get(4)).contains(\"plink\");\n+  }\n+\n+  List<String> notebookContentsToStrings(JSONObject notebookContents) {\n+    List<String> codeCellStrings = new ArrayList<>();\n+\n+    JSONArray cells = notebookContents.getJSONArray(\"cells\");\n+    for (int i = 0; i < cells.length(); i++) {\n+      String cellString = \"\";\n+      JSONArray innerCells = cells.getJSONObject(i).getJSONArray(\"source\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4580de882fe131020465a6a4013c8e73b719a3f"}, "originalPosition": 181}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3987, "cost": 1, "resetAt": "2021-10-29T17:30:11Z"}}}