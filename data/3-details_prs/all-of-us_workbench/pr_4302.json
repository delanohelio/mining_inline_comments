{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNTczOTE3", "number": 4302, "title": "[RW-5938][risk=no] Dueling crons for Reporting", "bodyText": "We are currently maintaining two different upload to BigQuery implementations.\n\nThe default, and currently configured in all environments, is the streaming upload method. This method is fast and simple in some ways, but has a potentially deal-breaking flaw because rows can be duplicated. A unique identifier provided for each row enables \"best-effort\" deduplication.\nAn insert query-based method, using Data Manipulation Language. In this implementation we have to build query strings and interpolate values we care about. The main operational issue with this mode so far is difficulty in making surer all our queries are below the size and complexity limits for queries.  We don't have much data yet for this mode aside from local runs.\n\nThe present PR exposes two test probe cron endpoints for the two implementations which should allow us to collect some real data in the logs.\n\nPR checklist\n\n This PR meets the Acceptance Criteria in the JIRA story\n The JIRA story has been moved to Dev Review\n This PR includes appropriate unit tests\n I have run and tested this change locally\n I have run the E2E tests on ths change against my local UI + API server with yarn test-local\n If this includes a UI change, I have taken screen recordings or screenshots of the new behavior and notified the PO and UX designer\n If this includes an API change, I have updated the appropriate Swagger definitions and notified API consumers\n If this includes a new feature flag, I have created and linked new JIRA tickets to (a) turn on the feature flag and (b) remove it later", "createdAt": "2020-11-17T17:18:53Z", "url": "https://github.com/all-of-us/workbench/pull/4302", "merged": true, "mergeCommit": {"oid": "31927e2efbf101b70a59cf504597b50d93747904"}, "closed": true, "closedAt": "2020-12-01T20:57:35Z", "author": {"login": "jaycarlton"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdeJkrJAFqTUzNDg1NjY2Mw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdh_z59gFqTU0MjI2MTkyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0ODU2NjYz", "url": "https://github.com/all-of-us/workbench/pull/4302#pullrequestreview-534856663", "createdAt": "2020-11-19T21:14:24Z", "commit": {"oid": "6d1daf5dae59667af9f7f090b90baf8ec68ae0f2"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMToxNDoyNFrOH2x5eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMToxNjoxNlrOH2x94A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIwMjY4MA==", "bodyText": "Please update the comments to describe the differences between them", "url": "https://github.com/all-of-us/workbench/pull/4302#discussion_r527202680", "createdAt": "2020-11-19T21:14:24Z", "author": {"login": "jmthibault79"}, "path": "api/reporting/curl/upload-snapshot-local-query.sh", "diffHunk": "@@ -0,0 +1,6 @@\n+#!/bin/bash\n+\n+# Start hit the reporting snapshot & upload cron endpoint  locally.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d1daf5dae59667af9f7f090b90baf8ec68ae0f2"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIwMzgwOA==", "bodyText": "Add \"- streaming mode\" or other distinguisher here", "url": "https://github.com/all-of-us/workbench/pull/4302#discussion_r527203808", "createdAt": "2020-11-19T21:16:16Z", "author": {"login": "jmthibault79"}, "path": "api/src/main/resources/workbench-api.yaml", "diffHunk": "@@ -1616,7 +1616,38 @@ paths:\n           description: Internal Error\n           schema:\n             \"$ref\": \"#/definitions/ErrorResponse\"\n-\n+  \"/v1/cron/uploadReportingSnapshotStreaming\":\n+    get:\n+      tags:\n+        - offlineReporting\n+        - cron\n+      description: >\n+        Capture a reporting snapshot and beging the upload task to BigQuery reporting dataset.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d1daf5dae59667af9f7f090b90baf8ec68ae0f2"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1NzQ1MDEy", "url": "https://github.com/all-of-us/workbench/pull/4302#pullrequestreview-535745012", "createdAt": "2020-11-20T20:11:47Z", "commit": {"oid": "6d1daf5dae59667af9f7f090b90baf8ec68ae0f2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDoxMTo0N1rOH3fQdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDoxMTo0N1rOH3fQdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk0NTg0Nw==", "bodyText": "@calbach ISTR discussing this with you once. If I want the test environment to have a small change from the default, do I need to past the entire default cron here, or can I include it somehow?", "url": "https://github.com/all-of-us/workbench/pull/4302#discussion_r527945847", "createdAt": "2020-11-20T20:11:47Z", "author": {"login": "jaycarlton"}, "path": "api/src/main/webapp/WEB-INF/cron_test.yaml", "diffHunk": "@@ -0,0 +1,107 @@\n+cron:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d1daf5dae59667af9f7f090b90baf8ec68ae0f2"}, "originalPosition": 1}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "551f8c666d25cf016953764ff075d12506a58f95", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/551f8c666d25cf016953764ff075d12506a58f95", "committedDate": "2020-11-20T20:12:18Z", "message": "distinguish endpoints for shell snippets"}, "afterCommit": {"oid": "d0f09e9f876640ef3be74f43097d695b57d2b698", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/d0f09e9f876640ef3be74f43097d695b57d2b698", "committedDate": "2020-11-23T15:35:19Z", "message": "dueling cron jobs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d0f09e9f876640ef3be74f43097d695b57d2b698", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/d0f09e9f876640ef3be74f43097d695b57d2b698", "committedDate": "2020-11-23T15:35:19Z", "message": "dueling cron jobs"}, "afterCommit": {"oid": "2ea87625a035323f3baed7aa342886975d06b4e4", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/2ea87625a035323f3baed7aa342886975d06b4e4", "committedDate": "2020-11-25T16:40:44Z", "message": "update description"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b66cb0acb9b7b203024223f365e0e485dffe6e58", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/b66cb0acb9b7b203024223f365e0e485dffe6e58", "committedDate": "2020-12-01T19:46:01Z", "message": "temporary extra cron methods to test perf of streaming vs insert query upload"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2ea87625a035323f3baed7aa342886975d06b4e4", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/2ea87625a035323f3baed7aa342886975d06b4e4", "committedDate": "2020-11-25T16:40:44Z", "message": "update description"}, "afterCommit": {"oid": "b66cb0acb9b7b203024223f365e0e485dffe6e58", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/b66cb0acb9b7b203024223f365e0e485dffe6e58", "committedDate": "2020-12-01T19:46:01Z", "message": "temporary extra cron methods to test perf of streaming vs insert query upload"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMjQzNzkz", "url": "https://github.com/all-of-us/workbench/pull/4302#pullrequestreview-542243793", "createdAt": "2020-12-01T19:52:24Z", "commit": {"oid": "b66cb0acb9b7b203024223f365e0e485dffe6e58"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOTo1MjoyNFrOH89RBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMDowMDowMVrOH89iuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4MDM4OA==", "bodyText": "\"via the insert query\" or similar", "url": "https://github.com/all-of-us/workbench/pull/4302#discussion_r533680388", "createdAt": "2020-12-01T19:52:24Z", "author": {"login": "jmthibault79"}, "path": "api/src/main/resources/workbench-api.yaml", "diffHunk": "@@ -1616,7 +1616,39 @@ paths:\n           description: Internal Error\n           schema:\n             \"$ref\": \"#/definitions/ErrorResponse\"\n-\n+  \"/v1/cron/uploadReportingSnapshotStreaming\":\n+    get:\n+      tags:\n+        - offlineReporting\n+        - cron\n+      description: >\n+        Capture a reporting snapshot and begin the upload task to BigQuery reporting dataset via\n+        the streaming implementation.\n+      operationId: uploadReportingSnapshotStreaming\n+      security: []\n+      responses:\n+        204:\n+          description: No content\n+        500:\n+          description: Internal Error\n+          schema:\n+            \"$ref\": \"#/definitions/ErrorResponse\"\n+  \"/v1/cron/uploadReportingSnapshotQuery\":\n+    get:\n+      tags:\n+        - offlineReporting\n+        - cron\n+      description: >\n+        Capture a reporting snapshot and beging the upload task to BigQuery reporting dataset.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b66cb0acb9b7b203024223f365e0e485dffe6e58"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4NDkyMA==", "bodyText": "confirmed that these 2 are the only difference from the default", "url": "https://github.com/all-of-us/workbench/pull/4302#discussion_r533684920", "createdAt": "2020-12-01T20:00:01Z", "author": {"login": "jmthibault79"}, "path": "api/src/main/webapp/WEB-INF/cron_test.yaml", "diffHunk": "@@ -0,0 +1,107 @@\n+cron:\n+  - description: 'Periodic notebook runtime checks'\n+    url: /v1/cron/checkRuntimes\n+    schedule: every 3 hours\n+    timezone: UTC\n+    target: api\n+  - description: |\n+      Daily sync of compliance training status (via Moodle API). This is just a backup to the primary\n+      flow. It should catch expired compliance training, fixup compliance status independent of user\n+      navigation, and update on removal of Moodle course completion for some reason.\n+    url: /v1/cron/bulkSyncComplianceTrainingStatus\n+    schedule: every 24 hours\n+    timezone: UTC\n+    target: api\n+  - description: >\n+      Daily sync of eRA Commons linkage status (via FireCloud API). Records changes in the log,\n+      but currently does not drive any downstream processes.\n+    url: /v1/cron/bulkSyncEraCommonsStatus\n+    schedule: every 24 hours\n+    timezone: UTC\n+    target: api\n+  - description: >\n+      Update our database cache of users' two-factor authentication settings on their GSuite accounts\n+      via Google Directory Service.\n+    url: /v1/cron/bulkSyncTwoFactorAuthStatus\n+    schedule: every 24 hours\n+    timezone: UTC\n+    target: api\n+  - description: 'Daily audit of gcp resources that users have access to'\n+    url: /v1/cron/bulkAuditProjectAccess\n+    schedule: every 1 hours\n+    timezone: UTC\n+    target: api\n+  - description: 'If the AoU Billing Project buffer is not full, refill with one or more projects.'\n+    url: /v1/cron/bufferBillingProjects\n+    schedule: every 1 minutes\n+    timezone: UTC\n+    target: api\n+  - description: 'Fetch a BillingProjectBufferEntry that is in the CREATING state and check its status on Firecloud'\n+    url: /v1/cron/syncBillingProjectStatus\n+    schedule: every 1 minutes\n+    timezone: UTC\n+    target: api\n+  - description: 'Find BillingProjectBufferEntries that have failed during the creation or assignment step and set their statuses to ERROR'\n+    url: /v1/cron/cleanBillingBuffer\n+    schedule: every 1 hours\n+    timezone: UTC\n+    target: api\n+  - description: 'Find and alert users that have exceeded their free tier billing usage'\n+    url: /v1/cron/checkFreeTierBillingUsage\n+    schedule: every 30 minutes\n+    timezone: UTC\n+    target: api\n+  - description: >\n+      Find billing projects associated with deleted workspaces and transfer ownership to\n+      designated \"Garbage Collection\" Service Accounts. This legacy process works around the lack of\n+      API support for deleting these billing projects directly.\n+\n+      The Terra delete Account API is now available, and this cron job is deprecated. To be removed\n+      as part of RW-3627.\n+    url: /v1/cron/billingProjectGarbageCollection\n+    schedule: every 1 hours\n+    timezone: UTC\n+    target: api\n+  - description: >\n+      Sample all gauge metrics for OpenCensus Monitoring and record them. The one-minute interval is\n+      the highest granularity for Stackdriver Monitoring and the lowest interval for an AppEngine\n+      cron job.\n+    url: /v1/cron/monitoring/updateGaugeMetrics\n+    schedule: every 1 minutes\n+    timezone: UTC\n+    target: api\n+  - description: >\n+      Export user and workspace data to RDR.\n+      RDR export is hard-coded to 9pm CT, to align with VUMC expectations that the daily export is run at a time\n+      that is (1) after the close of normal business working hours, and (2) early enough in the evening that the\n+      entire export (and downstream data flows) can complete before start of the next business day.\n+    url: /v1/cron/exportToRdr\n+    schedule: every day 22:00\n+    timezone: America/Chicago\n+    target: api\n+  - description: >\n+      For each workspace update the attribute need_rp_prompt if it has been created 15 days/an Year earlier\n+    url: /v1/cron/updateResearchPurposeReviewPrompt\n+    schedule: every day 21:00\n+    timezone: America/Chicago\n+    target: api\n+  - description: >", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b66cb0acb9b7b203024223f365e0e485dffe6e58"}, "originalPosition": 88}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c973ba52a4e1a1aea3e8ac6f4e92d30daf13e74a", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/c973ba52a4e1a1aea3e8ac6f4e92d30daf13e74a", "committedDate": "2020-12-01T20:09:15Z", "message": "clarify comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9bd3321ca543b6b7a34c3d037669ae9b0c875488", "author": {"user": {"login": "jaycarlton", "name": "Jay Carlton"}}, "url": "https://github.com/all-of-us/workbench/commit/9bd3321ca543b6b7a34c3d037669ae9b0c875488", "committedDate": "2020-12-01T20:16:45Z", "message": "fix comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMjYxOTIx", "url": "https://github.com/all-of-us/workbench/pull/4302#pullrequestreview-542261921", "createdAt": "2020-12-01T20:17:27Z", "commit": {"oid": "9bd3321ca543b6b7a34c3d037669ae9b0c875488"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3879, "cost": 1, "resetAt": "2021-10-29T17:30:11Z"}}}