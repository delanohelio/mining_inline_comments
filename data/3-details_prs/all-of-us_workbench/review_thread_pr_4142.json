{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwNzA1NTcw", "number": 4142, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1MDoxMFrOEtKAXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xN1QwMDowMDozNFrOEutnbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg1MzA4OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1MDoxMFrOHgyoLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1MDoxMFrOHgyoLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0NTk2Ng==", "bodyText": "Is our codegen inconsistent about this key name?", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504145966", "createdAt": "2020-10-13T17:50:10Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg2MDA4OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1MjowMVrOHgysUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1MjowMVrOHgysUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0NzAyNQ==", "bodyText": "In general, different codegen notebooks should be independent, so I would put something distinctive in the filename, e.g. the dataset ID; OR this should just use a purely temporary file", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504147025", "createdAt": "2020-10-13T17:52:01Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg2OTQzOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1NDozNVrOHgyyGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1NDozNVrOHgyyGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0ODUwNg==", "bodyText": "Please leave a TODO here so the hardcoded value doesn't look like a bug: I filed RW-5735.", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504148506", "createdAt": "2020-10-13T17:54:35Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg3NTg2OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1NjowN1rOHgy13g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1NjowN1rOHgy13g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0OTQ3MA==", "bodyText": "This is not portable to duplication, code copying etc - instead use ${GOOGLE_PROJECT}", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504149470", "createdAt": "2020-10-13T17:56:07Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg4NDM4OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1ODoyM1rOHgy7LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1ODoyM1rOHgy7LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MDgyOQ==", "bodyText": "This is not portable to other CDR versions, we will eventually want an env var like WORKSPACE_CDR_MICROARRAY; I think this is fine for now but please leave a TODO and file a ticket if you don't mind", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504150829", "createdAt": "2020-10-13T17:58:23Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg4NjI4OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1ODo0OVrOHgy8Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzo1ODo0OVrOHgy8Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MTEyMw==", "bodyText": "per above, would use an identifier", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504151123", "createdAt": "2020-10-13T17:58:49Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg5MjYzOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODowMDozM1rOHgzASw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwMjoxMDoxNVrOHhuNeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjEzOQ==", "bodyText": "I'm wondering if this should be a separate code cell. Both of these steps are going to be quite slow", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504152139", "createdAt": "2020-10-13T18:00:33Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTEyMjE3MA==", "bodyText": "Decided to keep together so the user can run all of the extract stuff in 1 go", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505122170", "createdAt": "2020-10-15T02:10:15Z", "author": {"login": "ericsong"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjEzOQ=="}, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg5NzA2OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODowMTo0NFrOHgzC_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwMjoxOTowMFrOHhuWrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjgyOA==", "bodyText": "What is this project ID being used for? I'd expect the workspace project might be more appropriate", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504152828", "createdAt": "2020-10-13T18:01:44Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTEyNDUyNA==", "bodyText": "I poked around GATK and it turns out its not being used at all. I changed it to the workspace env var but we may be able to take it out entirely if GATK is refactored to just remove the argument.", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505124524", "createdAt": "2020-10-15T02:19:00Z", "author": {"login": "ericsong"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjgyOA=="}, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzg5ODI5OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODowMjowNlrOHgzDxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODowMjowNlrOHgzDxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MzAyOA==", "bodyText": "I'd probably rather take a default - what happens if you just leave this unspecified?", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504153028", "createdAt": "2020-10-13T18:02:06Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzk2OTI4OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoxNzo1MVrOHgzwyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoxNzo1MVrOHgzwyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NDU1Mg==", "bodyText": "probably should have some identifier", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504164552", "createdAt": "2020-10-13T18:17:51Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzk3NDczOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoxODo0OFrOHgz0Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQyMzowNjo1MlrOHiefxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NTQxOA==", "bodyText": "Assuming it is mounted at /genomics sort of forces us into putting it on the image, or localizing the reference fasta in the startup script.\nHave you tried just supplying a gs:// path to this flag?", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504165418", "createdAt": "2020-10-13T18:18:48Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTkxMzI4NA==", "bodyText": "Still curious about this - same for probe_info", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505913284", "createdAt": "2020-10-15T23:06:52Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NTQxOA=="}, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzk4MDMyOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMDoxOFrOHgz3dA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMDoxOFrOHgz3dA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NjI2MA==", "bodyText": "I guess plink is the default filename, but I find this pretty confusing. I would expect this to be called something like cohort.bed or similar; wdyt about specifying the output filename here?", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504166260", "createdAt": "2020-10-13T18:20:18Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"\n+            + \"    person_id = person_id\\n\"\n+            + \"    phenotype_1 = random.randint(0, 2) # Change this value to what makes sense for your research by looking through the dataset(s)\\n\"\n+            + \"    phenotype_2 = random.randint(0, 2) # Change this value as well or remove if you are only processing one phenotype \\n\"\n+            + \"    phenotypes_table.append([family_id, person_id, phenotype_1, phenotype_2])\\n\"\n+            + \"\\n\"\n+            + \"cohort_phenotypes = pandas.DataFrame(phenotypes_table) \\n\"\n+            + \"cohort_phenotypes.to_csv('phenotypes.phe', header=False, index=False, sep=' ')\",\n+        \"%%bash\\n\\n\"\n+            + \"plink --vcf-half-call m --const-fid 0 --vcf cohort.vcf\\n\"\n+            + \"plink --bfile plink --pheno phenotypes.phe --all-pheno --allow-no-sex --assoc --out results\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzk4NzcyOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMjoyNVrOHgz76w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMjoyNVrOHgz76w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NzQwMw==", "bodyText": "Comments for each of these CLIs probably make sense, e.g.\n# Covert the VCF into .bed: PLINK's binary format\n...\n\n# Run the GWAS.", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504167403", "createdAt": "2020-10-13T18:22:25Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"\n+            + \"    person_id = person_id\\n\"\n+            + \"    phenotype_1 = random.randint(0, 2) # Change this value to what makes sense for your research by looking through the dataset(s)\\n\"\n+            + \"    phenotype_2 = random.randint(0, 2) # Change this value as well or remove if you are only processing one phenotype \\n\"\n+            + \"    phenotypes_table.append([family_id, person_id, phenotype_1, phenotype_2])\\n\"\n+            + \"\\n\"\n+            + \"cohort_phenotypes = pandas.DataFrame(phenotypes_table) \\n\"\n+            + \"cohort_phenotypes.to_csv('phenotypes.phe', header=False, index=False, sep=' ')\",\n+        \"%%bash\\n\\n\"\n+            + \"plink --vcf-half-call m --const-fid 0 --vcf cohort.vcf\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Nzk5MDEyOnYy", "diffSide": "RIGHT", "path": "api/src/main/resources/workbench-api.yaml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMzowOVrOHgz9iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyMzowOVrOHgz9iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NzgxNg==", "bodyText": "It may make sense to start with an enum here for future extensibility. Like genomicsDataType: NONE, MICROARRAY (later: WHOME_GENOME)", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504167816", "createdAt": "2020-10-13T18:23:09Z", "author": {"login": "calbach"}, "path": "api/src/main/resources/workbench-api.yaml", "diffHunk": "@@ -4807,6 +4807,17 @@ definitions:\n         default: false\n       kernelType:\n         \"$ref\": \"#/definitions/KernelTypeEnum\"\n+      includeMicroarrayData:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1ODAwOTE0OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyODozOFrOHg0JhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyODozOFrOHg0JhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE3MDg4NA==", "bodyText": "This doesn't need to happen in this PR, but one eventual goal would be to make the extraction portion idempotent. Rough pseudocode version of this:\nif [[ gsutil exists $COHORT_VCF ]]; do\n    gsutil cp $COHORT_VCF cohort.vcf\nelse \n  ... # extract\n  gsutil cp cohort.vcf $COHORT_VCF\nfi\n\nThis avoids having to rerun extraction every time your runtime gets restarted.", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504170884", "createdAt": "2020-10-13T18:28:38Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1ODAxMjUxOnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyOTozNVrOHg0Llg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxODoyOTozNVrOHg0Llg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE3MTQxNA==", "bodyText": "Can you leave a Java or Python comment about family ID, and why it is hardcoded to 0?", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504171414", "createdAt": "2020-10-13T18:29:35Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2ODk1OTg1OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/api/DataSetController.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQyMzowNTo0MVrOHieeLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQyMzowNTo0MVrOHieeLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTkxMjg3OA==", "bodyText": "If it's easy to check the CDR version (for the workspace, e.g. workspace.getCdrVersion()) here - an assertion about whether this workspace has genomics data could be a nice addition as well. I'd consider that failure mode to be a 412 failed precondition since it's dependent on CDR version state.", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505912878", "createdAt": "2020-10-15T23:05:41Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/api/DataSetController.java", "diffHunk": "@@ -336,6 +338,20 @@ private void formatTimestampValues(List<DataSetPreviewValueList> valuePreviewLis\n             qualifier,\n             queriesByDomain);\n \n+    if (GenomicsDataTypeEnum.MICROARRAY.equals(dataSetExportRequest.getGenomicsDataType())) {\n+      if (!dataSetExportRequest.getKernelType().equals(KernelTypeEnum.PYTHON)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "edf87ceb2d84e2acf1f104685c279abc60bc8cad"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3NDE3MzI2OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xN1QwMDowMDozNFrOHjSnyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xN1QwMDowMDozNFrOHjSnyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc2NzMwNQ==", "bodyText": "Looking at the code - it seems we can probably skip this flag entirely - and it will read this from the table: https://github.com/broadinstitute/gatk/blob/ah_var_store/src/main/java/org/broadinstitute/hellbender/tools/variantdb/arrays/ArrayExtractCohort.java#L199-L204", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r506767305", "createdAt": "2020-10-17T00:00:34Z", "author": {"login": "calbach"}, "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -702,6 +702,119 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('\"\n+            + cohortSampleNamesFilename\n+            + \"', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            // TODO: Writing to the \"tmp\" dataset is a temporary workaround until an alternative,\n+            // RW-5735\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project ${GOOGLE_PROJECT} \\\\\\n\"\n+            // TODO: Replace hardcoded dataset reference: RW-5748\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file \"\n+            + cohortSampleNamesFilename\n+            + \" \\\\\\n\"\n+            + \"          --sample_map_outfile \"\n+            + cohortSampleMapFilename\n+            + \"\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R gs://fc-aou-cdr-synth-test-genomics/extract_resources/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O \"\n+            + cohortVcfFilename\n+            + \" \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aba0fc2d5d2aae64274e2ac7e495cb392a40815b"}, "originalPosition": 66}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3803, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}