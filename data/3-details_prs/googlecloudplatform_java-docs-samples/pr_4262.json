{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzMzY4NDQy", "number": 4262, "title": "test(bigtable_spark): update integration test, update deps and readme", "bodyText": "WIP targeting branch bigtable-spark-example", "createdAt": "2020-11-18T17:52:07Z", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262", "merged": true, "mergeCommit": {"oid": "92a9f3e75b8b2c52f1cc711d9c3d05e2bedb4999"}, "closed": true, "closedAt": "2020-11-18T19:14:16Z", "author": {"login": "kolea2"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddx5vFgH2gAyNTIzMzY4NDQyOmRjNWQ2YjU0ZGIxYjc3MjNhYmQ0MmUzNDI5ZmY4OGIyNjlkYTgwNWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABddzHKKgFqTUzMzc5MTUzOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "dc5d6b54db1b7723abd42e3429ff88b269da805a", "author": {"user": {"login": "kolea2", "name": null}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/dc5d6b54db1b7723abd42e3429ff88b269da805a", "committedDate": "2020-11-18T17:49:27Z", "message": "test(bigtable_spark): update integration test, update deps and readme"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzkxNDc0", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262#pullrequestreview-533791474", "createdAt": "2020-11-18T19:13:55Z", "commit": {"oid": "dc5d6b54db1b7723abd42e3429ff88b269da805a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxMzo1NlrOH1-EJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxMzo1NlrOH1-EJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MzQ0NQ==", "bodyText": "@kolea2 I presume there isn't an alternative yet?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262#discussion_r526353445", "createdAt": "2020-11-18T19:13:56Z", "author": {"login": "lesv"}, "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -15,44 +15,63 @@\n  */\n package example\n \n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n import org.scalatest.flatspec._\n import org.scalatest.matchers._\n \n class IntegrationTest extends AnyFlatSpec\n-    with should.Matchers {\n+  with should.Matchers {\n \n   def getOrThrowException(envName: String): String = {\n     sys.env.getOrElse(\n       envName,\n       throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n   }\n-  val projectId = getOrThrowException(\"BIGTABLE_SPARK_PROJECT_ID\")\n-  val instanceId = getOrThrowException(\"BIGTABLE_SPARK_INSTANCE_ID\")\n-  val table_wordcount = getOrThrowException(\"BIGTABLE_SPARK_WORDCOUNT_TABLE\")\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n   val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n-  val table_copytable = getOrThrowException(\"BIGTABLE_SPARK_COPYTABLE_TABLE\")\n-  val rowCount = 88\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n \n   \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n-    import org.apache.spark.{SparkConf, SparkContext}\n-    val appName = getClass.getSimpleName.replace(\"$\", \"\")\n-    val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n-    SparkContext.getOrCreate(config)\n-\n-    val wordcountArgs = Array(projectId, instanceId, table_wordcount, file)\n-    Wordcount.main(wordcountArgs)\n-    val copytableArgs = Array(projectId, instanceId, table_wordcount, table_copytable)\n-    CopyTable.main(copytableArgs)\n-\n-    val settings =\n-      BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n-    val dataClient = BigtableDataClient.create(settings)\n-    import collection.JavaConverters._\n-    val wordcountRowCount = dataClient.readRows(Query.create(table_wordcount)).iterator().asScala.length\n-    val copytableRowCount = dataClient.readRows(Query.create(table_copytable)).iterator().asScala.length\n-    wordcountRowCount should be(rowCount)\n-    wordcountRowCount should be(copytableRowCount)\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc5d6b54db1b7723abd42e3429ff88b269da805a"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzkxNTM5", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262#pullrequestreview-533791539", "createdAt": "2020-11-18T19:14:01Z", "commit": {"oid": "dc5d6b54db1b7723abd42e3429ff88b269da805a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 440, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}