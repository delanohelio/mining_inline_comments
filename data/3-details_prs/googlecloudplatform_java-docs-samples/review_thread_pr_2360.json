{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1ODMxNDgw", "number": 2360, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQyMTo0NTowNVrODmeURA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQyMTo0NTowNVrODmeURA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNjY5MTg4OnYy", "diffSide": "RIGHT", "path": "dataproc/src/main/java/InstantiateInlineWorkflow.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQyMTo0NTowNVrOFz6c1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQyMjozNzoxNFrOFz7ruA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk3OTM1MA==", "bodyText": "Is this pre-installed?\nWhy is this a useful example if it's already there?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2360#discussion_r389979350", "createdAt": "2020-03-09T21:45:05Z", "author": {"login": "lesv"}, "path": "dataproc/src/main/java/InstantiateInlineWorkflow.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// [START dataproc_instantiate_inline_workflow]\n+import com.google.api.gax.longrunning.OperationFuture;\n+import com.google.cloud.dataproc.v1.ClusterConfig;\n+import com.google.cloud.dataproc.v1.GceClusterConfig;\n+import com.google.cloud.dataproc.v1.HadoopJob;\n+import com.google.cloud.dataproc.v1.ManagedCluster;\n+import com.google.cloud.dataproc.v1.OrderedJob;\n+import com.google.cloud.dataproc.v1.RegionName;\n+import com.google.cloud.dataproc.v1.WorkflowMetadata;\n+import com.google.cloud.dataproc.v1.WorkflowTemplate;\n+import com.google.cloud.dataproc.v1.WorkflowTemplatePlacement;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceClient;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceSettings;\n+import com.google.protobuf.Empty;\n+import java.io.IOException;\n+import java.util.concurrent.ExecutionException;\n+\n+public class InstantiateInlineWorkflow {\n+\n+  public static void InstantiateInlineWorkflow() throws IOException, InterruptedException {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String projectId = \"your-project-id\";\n+    String region = \"your-project-region\";\n+    instantiateInlineWorkflow(projectId, region);\n+  }\n+\n+  public static void instantiateInlineWorkflow(String projectId, String region)\n+      throws IOException, InterruptedException {\n+    String myEndpoint = String.format(\"%s-dataproc.googleapis.com:443\", region);\n+\n+    // Configure the settings for the workflow template service client.\n+    WorkflowTemplateServiceSettings workflowTemplateServiceSettings =\n+        WorkflowTemplateServiceSettings.newBuilder().setEndpoint(myEndpoint).build();\n+\n+    // Create a workflow template service client with the configured settings. The client only\n+    // needs to be created once and can be reused for multiple requests. Using a try-with-resources\n+    // closes the client, but this can also be done manually with the .close() method.\n+    try (WorkflowTemplateServiceClient workflowTemplateServiceClient =\n+        WorkflowTemplateServiceClient.create(workflowTemplateServiceSettings)) {\n+\n+      // Configure the jobs within the workflow.\n+      HadoopJob teragenHadoopJob =\n+          HadoopJob.newBuilder()\n+              .setMainJarFileUri(\"file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f2842c462daba67b662741526ea1d869ca18804"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk4NDQ3NQ==", "bodyText": "The point we're trying to get across is how you can structure a workflow specifically with the client library and run it. We sometimes use these toy examples instead of say a PySpark example on GCS.\nI'm also referencing the canonical YAML example from the docs (which is not to say this sample couldn't be improved either).", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2360#discussion_r389984475", "createdAt": "2020-03-09T21:57:04Z", "author": {"login": "bradmiro"}, "path": "dataproc/src/main/java/InstantiateInlineWorkflow.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// [START dataproc_instantiate_inline_workflow]\n+import com.google.api.gax.longrunning.OperationFuture;\n+import com.google.cloud.dataproc.v1.ClusterConfig;\n+import com.google.cloud.dataproc.v1.GceClusterConfig;\n+import com.google.cloud.dataproc.v1.HadoopJob;\n+import com.google.cloud.dataproc.v1.ManagedCluster;\n+import com.google.cloud.dataproc.v1.OrderedJob;\n+import com.google.cloud.dataproc.v1.RegionName;\n+import com.google.cloud.dataproc.v1.WorkflowMetadata;\n+import com.google.cloud.dataproc.v1.WorkflowTemplate;\n+import com.google.cloud.dataproc.v1.WorkflowTemplatePlacement;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceClient;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceSettings;\n+import com.google.protobuf.Empty;\n+import java.io.IOException;\n+import java.util.concurrent.ExecutionException;\n+\n+public class InstantiateInlineWorkflow {\n+\n+  public static void InstantiateInlineWorkflow() throws IOException, InterruptedException {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String projectId = \"your-project-id\";\n+    String region = \"your-project-region\";\n+    instantiateInlineWorkflow(projectId, region);\n+  }\n+\n+  public static void instantiateInlineWorkflow(String projectId, String region)\n+      throws IOException, InterruptedException {\n+    String myEndpoint = String.format(\"%s-dataproc.googleapis.com:443\", region);\n+\n+    // Configure the settings for the workflow template service client.\n+    WorkflowTemplateServiceSettings workflowTemplateServiceSettings =\n+        WorkflowTemplateServiceSettings.newBuilder().setEndpoint(myEndpoint).build();\n+\n+    // Create a workflow template service client with the configured settings. The client only\n+    // needs to be created once and can be reused for multiple requests. Using a try-with-resources\n+    // closes the client, but this can also be done manually with the .close() method.\n+    try (WorkflowTemplateServiceClient workflowTemplateServiceClient =\n+        WorkflowTemplateServiceClient.create(workflowTemplateServiceSettings)) {\n+\n+      // Configure the jobs within the workflow.\n+      HadoopJob teragenHadoopJob =\n+          HadoopJob.newBuilder()\n+              .setMainJarFileUri(\"file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk3OTM1MA=="}, "originalCommit": {"oid": "3f2842c462daba67b662741526ea1d869ca18804"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk5OTU0NA==", "bodyText": "SG", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2360#discussion_r389999544", "createdAt": "2020-03-09T22:37:14Z", "author": {"login": "lesv"}, "path": "dataproc/src/main/java/InstantiateInlineWorkflow.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// [START dataproc_instantiate_inline_workflow]\n+import com.google.api.gax.longrunning.OperationFuture;\n+import com.google.cloud.dataproc.v1.ClusterConfig;\n+import com.google.cloud.dataproc.v1.GceClusterConfig;\n+import com.google.cloud.dataproc.v1.HadoopJob;\n+import com.google.cloud.dataproc.v1.ManagedCluster;\n+import com.google.cloud.dataproc.v1.OrderedJob;\n+import com.google.cloud.dataproc.v1.RegionName;\n+import com.google.cloud.dataproc.v1.WorkflowMetadata;\n+import com.google.cloud.dataproc.v1.WorkflowTemplate;\n+import com.google.cloud.dataproc.v1.WorkflowTemplatePlacement;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceClient;\n+import com.google.cloud.dataproc.v1.WorkflowTemplateServiceSettings;\n+import com.google.protobuf.Empty;\n+import java.io.IOException;\n+import java.util.concurrent.ExecutionException;\n+\n+public class InstantiateInlineWorkflow {\n+\n+  public static void InstantiateInlineWorkflow() throws IOException, InterruptedException {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String projectId = \"your-project-id\";\n+    String region = \"your-project-region\";\n+    instantiateInlineWorkflow(projectId, region);\n+  }\n+\n+  public static void instantiateInlineWorkflow(String projectId, String region)\n+      throws IOException, InterruptedException {\n+    String myEndpoint = String.format(\"%s-dataproc.googleapis.com:443\", region);\n+\n+    // Configure the settings for the workflow template service client.\n+    WorkflowTemplateServiceSettings workflowTemplateServiceSettings =\n+        WorkflowTemplateServiceSettings.newBuilder().setEndpoint(myEndpoint).build();\n+\n+    // Create a workflow template service client with the configured settings. The client only\n+    // needs to be created once and can be reused for multiple requests. Using a try-with-resources\n+    // closes the client, but this can also be done manually with the .close() method.\n+    try (WorkflowTemplateServiceClient workflowTemplateServiceClient =\n+        WorkflowTemplateServiceClient.create(workflowTemplateServiceSettings)) {\n+\n+      // Configure the jobs within the workflow.\n+      HadoopJob teragenHadoopJob =\n+          HadoopJob.newBuilder()\n+              .setMainJarFileUri(\"file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk3OTM1MA=="}, "originalCommit": {"oid": "3f2842c462daba67b662741526ea1d869ca18804"}, "originalPosition": 60}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 974, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}