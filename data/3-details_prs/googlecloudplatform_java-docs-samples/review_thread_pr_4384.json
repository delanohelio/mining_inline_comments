{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM0NjM4NTU0", "number": 4384, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOToyNTozMlrOFDGORw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozNjoxM1rOFDGgIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4NzkyMDA3OnYy", "diffSide": "RIGHT", "path": "bigtable/spark/build.sbt", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOToyNTozMlrOICljPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOToyNTozMlrOICljPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4MzI5Mw==", "bodyText": "I'd expect this to be okay as long as we're controlling not having duplicate dependencies above.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539583293", "createdAt": "2020-12-09T19:25:32Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/build.sbt", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+name := \"bigtable-spark-samples\"\n+\n+version := \"0.1\"\n+\n+// Versions to match Dataproc 1.4\n+// https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-1.4\n+scalaVersion := \"2.11.12\"\n+val sparkVersion = \"2.4.6\"\n+val bigtableVersion = \"1.16.0\"\n+val hbaseVersion = \"1.3.6\"\n+\n+libraryDependencies ++= Seq(\n+  \"org.apache.spark\" %% \"spark-sql\" % sparkVersion % Provided,\n+  \"org.apache.hbase.connectors.spark\" % \"hbase-spark\" % \"1.0.0\" % Provided,\n+  \"com.google.cloud.bigtable\" % \"bigtable-hbase-2.x-hadoop\" % bigtableVersion\n+)\n+\n+val scalatestVersion = \"3.2.0\"\n+libraryDependencies += \"org.scalactic\" %% \"scalactic\" % scalatestVersion\n+libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalatestVersion % \"test\"\n+test in assembly := {}\n+\n+val fixes = Seq(\n+  // Required by 'value org.apache.hadoop.hbase.spark.HBaseContext.dstream'\n+  \"org.apache.spark\" %% \"spark-streaming\" % sparkVersion % Provided,\n+  // hbase-server is needed because HBaseContext references org/apache/hadoop/hbase/fs/HFileSystem\n+  // hbase-client is declared to override the version of hbase-client declared by bigtable-hbase-2.x-hadoop\n+  \"org.apache.hbase\" % \"hbase-server\" % hbaseVersion,\n+  \"org.apache.hbase\" % \"hbase-client\" % hbaseVersion\n+)\n+libraryDependencies ++= fixes\n+\n+// Fix for Exception: Incompatible Jackson 2.9.2\n+// Version conflict between HBase and Spark\n+// Forcing the version to match Spark\n+dependencyOverrides += \"com.fasterxml.jackson.module\" %% \"jackson-module-scala\" % \"2.9.10\"\n+\n+// Excluding duplicates for the uber-jar\n+// There are other deps to provide necessary packages\n+excludeDependencies ++= Seq(\n+  ExclusionRule(organization = \"asm\", \"asm\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils-core\"),\n+  ExclusionRule(organization = \"org.mortbay.jetty\", \"servlet-api\")\n+)\n+\n+assemblyMergeStrategy in assembly := {\n+  case PathList(\"META-INF\", \"io.netty.versions.properties\") => MergeStrategy.first\n+  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n+  case PathList(\"mozilla\", \"public-suffix-list.txt\") => MergeStrategy.first\n+  case PathList(\"google\", xs @ _*) => xs match {\n+    case ps @ (x :: xs) if ps.last.endsWith(\".proto\") => MergeStrategy.first", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4NzkyOTczOnYy", "diffSide": "RIGHT", "path": "bigtable/spark/build.sbt", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOToyNzozOFrOIClo1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMTozNDowMFrOICqgWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NDcyNA==", "bodyText": "This might cause issues with guava, since our libraries use the most up-to-date version and spark (and especially HBase) doesn't necessarily track as close there is a chance for a diamond. It might be worth asking tomo how we might run linkage checker against an assembly and seeing if it would work.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539584724", "createdAt": "2020-12-09T19:27:38Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/build.sbt", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+name := \"bigtable-spark-samples\"\n+\n+version := \"0.1\"\n+\n+// Versions to match Dataproc 1.4\n+// https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-1.4\n+scalaVersion := \"2.11.12\"\n+val sparkVersion = \"2.4.6\"\n+val bigtableVersion = \"1.16.0\"\n+val hbaseVersion = \"1.3.6\"\n+\n+libraryDependencies ++= Seq(\n+  \"org.apache.spark\" %% \"spark-sql\" % sparkVersion % Provided,\n+  \"org.apache.hbase.connectors.spark\" % \"hbase-spark\" % \"1.0.0\" % Provided,\n+  \"com.google.cloud.bigtable\" % \"bigtable-hbase-2.x-hadoop\" % bigtableVersion\n+)\n+\n+val scalatestVersion = \"3.2.0\"\n+libraryDependencies += \"org.scalactic\" %% \"scalactic\" % scalatestVersion\n+libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalatestVersion % \"test\"\n+test in assembly := {}\n+\n+val fixes = Seq(\n+  // Required by 'value org.apache.hadoop.hbase.spark.HBaseContext.dstream'\n+  \"org.apache.spark\" %% \"spark-streaming\" % sparkVersion % Provided,\n+  // hbase-server is needed because HBaseContext references org/apache/hadoop/hbase/fs/HFileSystem\n+  // hbase-client is declared to override the version of hbase-client declared by bigtable-hbase-2.x-hadoop\n+  \"org.apache.hbase\" % \"hbase-server\" % hbaseVersion,\n+  \"org.apache.hbase\" % \"hbase-client\" % hbaseVersion\n+)\n+libraryDependencies ++= fixes\n+\n+// Fix for Exception: Incompatible Jackson 2.9.2\n+// Version conflict between HBase and Spark\n+// Forcing the version to match Spark\n+dependencyOverrides += \"com.fasterxml.jackson.module\" %% \"jackson-module-scala\" % \"2.9.10\"\n+\n+// Excluding duplicates for the uber-jar\n+// There are other deps to provide necessary packages\n+excludeDependencies ++= Seq(\n+  ExclusionRule(organization = \"asm\", \"asm\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils-core\"),\n+  ExclusionRule(organization = \"org.mortbay.jetty\", \"servlet-api\")\n+)\n+\n+assemblyMergeStrategy in assembly := {\n+  case PathList(\"META-INF\", \"io.netty.versions.properties\") => MergeStrategy.first\n+  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n+  case PathList(\"mozilla\", \"public-suffix-list.txt\") => MergeStrategy.first\n+  case PathList(\"google\", xs @ _*) => xs match {\n+    case ps @ (x :: xs) if ps.last.endsWith(\".proto\") => MergeStrategy.first\n+    case _ => MergeStrategy.deduplicate\n+  }\n+  case x =>\n+    val oldStrategy = (assemblyMergeStrategy in assembly).value\n+    oldStrategy(x)\n+    // FIXME Make sure first is OK (it's worked well so far)\n+    MergeStrategy.first", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY2NDQ3Mg==", "bodyText": "We try to keep the dependency versions in line with HBase for the adapter, so this should be ok.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539664472", "createdAt": "2020-12-09T21:34:00Z", "author": {"login": "kolea2"}, "path": "bigtable/spark/build.sbt", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+name := \"bigtable-spark-samples\"\n+\n+version := \"0.1\"\n+\n+// Versions to match Dataproc 1.4\n+// https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-1.4\n+scalaVersion := \"2.11.12\"\n+val sparkVersion = \"2.4.6\"\n+val bigtableVersion = \"1.16.0\"\n+val hbaseVersion = \"1.3.6\"\n+\n+libraryDependencies ++= Seq(\n+  \"org.apache.spark\" %% \"spark-sql\" % sparkVersion % Provided,\n+  \"org.apache.hbase.connectors.spark\" % \"hbase-spark\" % \"1.0.0\" % Provided,\n+  \"com.google.cloud.bigtable\" % \"bigtable-hbase-2.x-hadoop\" % bigtableVersion\n+)\n+\n+val scalatestVersion = \"3.2.0\"\n+libraryDependencies += \"org.scalactic\" %% \"scalactic\" % scalatestVersion\n+libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalatestVersion % \"test\"\n+test in assembly := {}\n+\n+val fixes = Seq(\n+  // Required by 'value org.apache.hadoop.hbase.spark.HBaseContext.dstream'\n+  \"org.apache.spark\" %% \"spark-streaming\" % sparkVersion % Provided,\n+  // hbase-server is needed because HBaseContext references org/apache/hadoop/hbase/fs/HFileSystem\n+  // hbase-client is declared to override the version of hbase-client declared by bigtable-hbase-2.x-hadoop\n+  \"org.apache.hbase\" % \"hbase-server\" % hbaseVersion,\n+  \"org.apache.hbase\" % \"hbase-client\" % hbaseVersion\n+)\n+libraryDependencies ++= fixes\n+\n+// Fix for Exception: Incompatible Jackson 2.9.2\n+// Version conflict between HBase and Spark\n+// Forcing the version to match Spark\n+dependencyOverrides += \"com.fasterxml.jackson.module\" %% \"jackson-module-scala\" % \"2.9.10\"\n+\n+// Excluding duplicates for the uber-jar\n+// There are other deps to provide necessary packages\n+excludeDependencies ++= Seq(\n+  ExclusionRule(organization = \"asm\", \"asm\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils-core\"),\n+  ExclusionRule(organization = \"org.mortbay.jetty\", \"servlet-api\")\n+)\n+\n+assemblyMergeStrategy in assembly := {\n+  case PathList(\"META-INF\", \"io.netty.versions.properties\") => MergeStrategy.first\n+  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n+  case PathList(\"mozilla\", \"public-suffix-list.txt\") => MergeStrategy.first\n+  case PathList(\"google\", xs @ _*) => xs match {\n+    case ps @ (x :: xs) if ps.last.endsWith(\".proto\") => MergeStrategy.first\n+    case _ => MergeStrategy.deduplicate\n+  }\n+  case x =>\n+    val oldStrategy = (assemblyMergeStrategy in assembly).value\n+    oldStrategy(x)\n+    // FIXME Make sure first is OK (it's worked well so far)\n+    MergeStrategy.first", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NDcyNA=="}, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4NzkzMzk4OnYy", "diffSide": "RIGHT", "path": "bigtable/spark/project/build.properties", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOToyODo1NFrOIClroQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNToyNTozMVrOIFV09g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NTQ0MQ==", "bodyText": "Is this tracking the same version as spark? (latest is 1.4.4 according to https://www.scala-sbt.org/download.html)", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539585441", "createdAt": "2020-12-09T19:28:54Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/project/build.properties", "diffHunk": "@@ -0,0 +1,15 @@\n+# Copyright 2020 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     https://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+sbt.version = 1.3.13", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTQxNA==", "bodyText": "I need to double check - this may have just been the latest at the time. For now, let's leave it as is.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r542471414", "createdAt": "2020-12-14T15:25:31Z", "author": {"login": "kolea2"}, "path": "bigtable/spark/project/build.properties", "diffHunk": "@@ -0,0 +1,15 @@\n+# Copyright 2020 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     https://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+sbt.version = 1.3.13", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NTQ0MQ=="}, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4Nzk0NjI4OnYy", "diffSide": "RIGHT", "path": "bigtable/spark/src/main/scala/example/CopyTable.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozMTo0MFrOIClzEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozMTo0MFrOIClzEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NzM0NA==", "bodyText": "The newline here will be kept in the output, not sure if that is intended.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539587344", "createdAt": "2020-12-09T19:31:40Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/src/main/scala/example/CopyTable.scala", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import org.apache.hadoop.hbase.spark.datasources.{HBaseSparkConf, HBaseTableCatalog}\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+\n+object CopyTable extends App {\n+\n+  val appName = this.getClass.getSimpleName.replace(\"$\", \"\")\n+  println(s\"$appName Spark application is starting up...\")\n+\n+  val (projectId, instanceId, fromTable, toTable) = parse(args)\n+  println(\n+    s\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4Nzk1MzU0OnYy", "diffSide": "RIGHT", "path": "bigtable/spark/src/main/scala/example/Wordcount.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozMzoyNVrOICl3aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozMzoyNVrOICl3aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4ODQ1Ng==", "bodyText": "Missing validation for args like there is in CopyTable", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539588456", "createdAt": "2020-12-09T19:33:25Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/src/main/scala/example/Wordcount.scala", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import com.google.cloud.bigtable.hbase.BigtableConfiguration\n+import org.apache.hadoop.hbase.client._\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable\n+import org.apache.hadoop.hbase.mapreduce.TableOutputFormat\n+import org.apache.hadoop.hbase.util.Bytes\n+import org.apache.spark.SparkContext\n+\n+object Wordcount extends App {\n+\n+  val projectId = args(0)\n+  val instanceId = args(1)\n+  val table = args(2)\n+  val file = args(3)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4Nzk2NTc3OnYy", "diffSide": "RIGHT", "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxOTozNjoxM1rOICl-og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMjoyMjowNlrOIDf-Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg==", "bodyText": "I would split each of these two tests into their own test so you can track them independently. We should be able to factor most of this code so that it's reusable by taking a function for the specific asserts.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539590306", "createdAt": "2020-12-09T19:36:13Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n+import org.scalatest.flatspec._\n+import org.scalatest.matchers._\n+\n+class IntegrationTest extends AnyFlatSpec\n+  with should.Matchers {\n+\n+  def getOrThrowException(envName: String): String = {\n+    sys.env.getOrElse(\n+      envName,\n+      throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n+  }\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n+  val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n+\n+  \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n+      SparkContext.getOrCreate(config)\n+\n+      val wordcountRequest = CreateTableRequest.of(wordcount_table_name).addFamily(\"cf\")\n+      tableClient.createTable(wordcountRequest)\n+\n+      val copytableRequest = CreateTableRequest.of(copytable_table_name).addFamily(\"cf\")\n+      tableClient.createTable(copytableRequest);\n+\n+      val wordcountArgs = Array(projectId, instanceId, wordcount_table_name, file)\n+      Wordcount.main(wordcountArgs)\n+      val copytableArgs = Array(projectId, instanceId, wordcount_table_name, copytable_table_name)\n+      CopyTable.main(copytableArgs)\n+\n+      import collection.JavaConverters._\n+      val wordcountRowCount = dataClient.readRows(Query.create(wordcount_table_name)).iterator().asScala.length\n+      val copytableRowCount = dataClient.readRows(Query.create(copytable_table_name)).iterator().asScala.length", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY3MDY1OQ==", "bodyText": "Not sure I understand, copytable depends on wordcount running first. Can you explain a bit more what you had in mind?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539670659", "createdAt": "2020-12-09T21:44:13Z", "author": {"login": "kolea2"}, "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n+import org.scalatest.flatspec._\n+import org.scalatest.matchers._\n+\n+class IntegrationTest extends AnyFlatSpec\n+  with should.Matchers {\n+\n+  def getOrThrowException(envName: String): String = {\n+    sys.env.getOrElse(\n+      envName,\n+      throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n+  }\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n+  val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n+\n+  \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n+      SparkContext.getOrCreate(config)\n+\n+      val wordcountRequest = CreateTableRequest.of(wordcount_table_name).addFamily(\"cf\")\n+      tableClient.createTable(wordcountRequest)\n+\n+      val copytableRequest = CreateTableRequest.of(copytable_table_name).addFamily(\"cf\")\n+      tableClient.createTable(copytableRequest);\n+\n+      val wordcountArgs = Array(projectId, instanceId, wordcount_table_name, file)\n+      Wordcount.main(wordcountArgs)\n+      val copytableArgs = Array(projectId, instanceId, wordcount_table_name, copytable_table_name)\n+      CopyTable.main(copytableArgs)\n+\n+      import collection.JavaConverters._\n+      val wordcountRowCount = dataClient.readRows(Query.create(wordcount_table_name)).iterator().asScala.length\n+      val copytableRowCount = dataClient.readRows(Query.create(copytable_table_name)).iterator().asScala.length", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg=="}, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MDQzMA==", "bodyText": "Apologies, I missed the assertion wordcountRowCount should be(copytableRowCount) in my read through and everything looked the same for both things.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r540540430", "createdAt": "2020-12-10T22:22:06Z", "author": {"login": "BenWhitehead"}, "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n+import org.scalatest.flatspec._\n+import org.scalatest.matchers._\n+\n+class IntegrationTest extends AnyFlatSpec\n+  with should.Matchers {\n+\n+  def getOrThrowException(envName: String): String = {\n+    sys.env.getOrElse(\n+      envName,\n+      throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n+  }\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n+  val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n+\n+  \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n+      SparkContext.getOrCreate(config)\n+\n+      val wordcountRequest = CreateTableRequest.of(wordcount_table_name).addFamily(\"cf\")\n+      tableClient.createTable(wordcountRequest)\n+\n+      val copytableRequest = CreateTableRequest.of(copytable_table_name).addFamily(\"cf\")\n+      tableClient.createTable(copytableRequest);\n+\n+      val wordcountArgs = Array(projectId, instanceId, wordcount_table_name, file)\n+      Wordcount.main(wordcountArgs)\n+      val copytableArgs = Array(projectId, instanceId, wordcount_table_name, copytable_table_name)\n+      CopyTable.main(copytableArgs)\n+\n+      import collection.JavaConverters._\n+      val wordcountRowCount = dataClient.readRows(Query.create(wordcount_table_name)).iterator().asScala.length\n+      val copytableRowCount = dataClient.readRows(Query.create(copytable_table_name)).iterator().asScala.length", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg=="}, "originalCommit": {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf"}, "originalPosition": 67}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 724, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}