{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2NDI3ODkw", "number": 2373, "title": "dataflow/flex-templates: Add Streaming BeamSQL and Kafka-to-BigQuery samples", "bodyText": "Adding samples for Flex Templates", "createdAt": "2020-03-11T00:36:59Z", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373", "merged": true, "mergeCommit": {"oid": "954553cdb1758b60187cdf7045886e5862408355"}, "closed": true, "closedAt": "2020-03-23T20:05:36Z", "author": {"login": "davidcavazos"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMcGSbgBqjMxMTY5MjA5NTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcQi74dgBqjMxNTY2Mzk0MjA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b1fbb7f7facfe9b6ca598866c3a923a2262c2766", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/b1fbb7f7facfe9b6ca598866c3a923a2262c2766", "committedDate": "2020-03-11T00:33:02Z", "message": "Added newline at EOF"}, "afterCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "committedDate": "2020-03-11T00:37:13Z", "message": "Added newline at EOF"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMTcwNzEy", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#pullrequestreview-373170712", "createdAt": "2020-03-11T22:30:17Z", "commit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMjozMDoxN1rOF1Lfnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMjo0NzowNlrOF1L2tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzE2Nw==", "bodyText": "A bit unexpected and incompatible with CloudBuild - you might wish to mention that in the README, but otherwise OK.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391307167", "createdAt": "2020-03-11T22:30:17Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODExMg==", "bodyText": "Wow that's a lot of steps, I wonder if it wouldn't be easier on users to just use a script that asks them what it needs to know?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308112", "createdAt": "2020-03-11T22:33:07Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/README.md", "diffHunk": "@@ -0,0 +1,337 @@\n+# Dataflow Flex templates - Kafka to BigQuery\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+If you are not familiar with Dataflow Flex templates, please see the\n+[Streaming Beam SQL](../streaming-beam-sql/) sample first.\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"kafka_to_bigquery\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Select the compute region and zone to use.\n+\n+    ```sh\n+    # Select your default compute/region, or default to \"us-central1\".\n+    export REGION=${\"$(gcloud config get-value compute/region)\":-\"us-central1\"}\n+\n+    # Select your default compute/zone, or default to \"$REGION-a\".\n+    # Note that the zone *must* be in $REGION.\n+    export ZONE=${\"$(gcloud config get-value compute/zone)\":-\"$REGION-a\"}\n+    ```\n+\n+1. Clone the `java-docs-samples` repository.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    ```\n+\n+1. Navigate to the sample code directory.\n+\n+    ```sh\n+    cd java-docs-samples/dataflow/flex-templates/kafka_to_bigquery\n+    ```\n+\n+## Kafka to BigQuery sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Apache Kafka](https://kafka.apache.org/), decodes them, and writes them into a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+For this, we need two parts running:\n+\n+1. A Kafka server container accessible through an external IP address.\n+   This services publishes messages to a topic.\n+\n+    * [kafka/Dockerfile](kafka/Dockerfile)\n+    * [kafka/start-kafka.sh](kafka/start-kafka.sh)\n+    * [kafka/create-topic.sh](kafka/create-topic.sh)\n+\n+2. An Apache Beam streaming pipeline running in Dataflow Flex Templates.\n+   This subscribes to a Kafka topic, consumes the messages that are published\n+   to that topic, processes them, and writes them into a BigQuery table.\n+\n+    * [Dockerfile](Dockerfile)\n+    * [KafkaToBigQuery.java](src/main/java/org/apache/beam/samples/KafkaToBigQuery.java)\n+    * [pom.xml](pom.xml)\n+    * [metadata.json](metadata.json)\n+\n+### Starting the Kafka server", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODQ2MQ==", "bodyText": "Copyright & License?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308461", "createdAt": "2020-03-11T22:33:49Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODY1Nw==", "bodyText": "Copyright & Licenses - general rule - if a human creates it, then it needs a copyright & license.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308657", "createdAt": "2020-03-11T22:34:25Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODc0Ng==", "bodyText": "Copyright & License?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308746", "createdAt": "2020-03-11T22:34:41Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/Dockerfile", "diffHunk": "@@ -0,0 +1,37 @@\n+FROM openjdk:8-jre-alpine", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTIwMw==", "bodyText": "Copyright & License?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391309203", "createdAt": "2020-03-11T22:35:55Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/create-topic.sh", "diffHunk": "@@ -0,0 +1,20 @@\n+#!/bin/sh", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTI5Mw==", "bodyText": "Copyright & License?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391309293", "createdAt": "2020-03-11T22:36:09Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/start-kafka.sh", "diffHunk": "@@ -0,0 +1,48 @@\n+#!/bin/sh\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMDI0Ng==", "bodyText": "Ideally should have Copyright & License unless whatever reading it has a problem w/ that.\n\"_Copyright\" : \"Copyright 2020 Google, LLC\",\n\"_License\":\"....\",\nIf that doesn't work, then it's ok to skip.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391310246", "createdAt": "2020-03-11T22:38:51Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/kafka_to_bigquery/metadata.json", "diffHunk": "@@ -0,0 +1,32 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTAxNQ==", "bodyText": "You might wish to mention this in the README; Copyright & License", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311015", "createdAt": "2020-03-11T22:41:01Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTI3Ng==", "bodyText": "Copyright & License", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311276", "createdAt": "2020-03-11T22:41:42Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTkxMg==", "bodyText": "So this is interesting w/ that .cloudignore above -- I presume you've verified that things work.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311912", "createdAt": "2020-03-11T22:43:40Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a\n+    [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a\n+    [Pub/Sub topic](https://cloud.google.com/pubsub/docs/admin#creating_a_topic)\n+    and a\n+    [subscription](https://cloud.google.com/pubsub/docs/admin#creating_subscriptions)\n+    to that topic.\n+    This is a streaming source of data for the sample.\n+\n+    ```sh\n+    # For simplicity we use the same topic name as the subscription name.\n+    export TOPIC=\"messages\"\n+    export SUBSCRIPTION=\"$TOPIC\"\n+\n+    gcloud pubsub topics create $TOPIC\n+    gcloud pubsub subscriptions create --topic $TOPIC $SUBSCRIPTION\n+    ```\n+\n+1. Create a\n+    [Cloud Scheduler job](https://cloud.google.com/scheduler/docs/quickstart)\n+    to publish \"positive\" and \"negative\" ratings every\n+    [1 and 2 minutes](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules).\n+    This publishes messages to the Pub/Sub source topic.\n+\n+    ```sh\n+    # Create a publisher for \"positive ratings\" that publishes 1 message per minute\n+    # If an App Engine app does not exist for the project, this step will create one.\n+    gcloud scheduler jobs create pubsub thumbs-up-publisher \\\n+      --schedule=\"* * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"positive\"}'\n+\n+    # Start the job.\n+    gcloud scheduler jobs run thumbs-up-publisher\n+\n+    # Create and run another similar publisher for \"negative ratings\" that\n+    # publishes 1 message every 2 minutes.\n+    gcloud scheduler jobs create pubsub thumbs-down-publisher \\\n+      --schedule=\"*/2 * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"negative\"}'\n+\n+    gcloud scheduler jobs run thumbs-down-publisher\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+    This is a table to write the output data.\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"streaming_beam_sql\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Clone the\n+    [`java-docs-samples` repository](https://github.com/GoogleCloudPlatform/java-docs-samples)\n+    and navigate to the code sample.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    cd java-docs-samples/dataflow/flex-templates/beam_sql\n+    ```\n+\n+## Pub/Sub to BigQuery with Beam SQL sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Pub/Sub](https://cloud.google.com/pubsub), uses\n+[Beam SQL](https://beam.apache.org/documentation/dsls/sql/overview/)\n+to transform the message data, and writes the results to a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+* [Dockerfile](Dockerfile)\n+* [StreamingBeamSQL.java](src/main/java/org/apache/beam/samples/StreamingBeamSQL.java)\n+* [pom.xml](pom.xml)\n+* [metadata.json](metadata.json)\n+\n+### Building a container image\n+\n+> <details><summary>\n+> <i>(Optional)</i> Run the Apache Beam pipeline locally for development.\n+> <i>(Click to expand)</i>\n+> </summary>\n+>\n+> ```sh\n+> mvn compile exec:java \\\n+>   -Dexec.mainClass=org.apache.beam.samples.StreamingBeamSQL \\\n+>   -Dexec.args=\"\\\n+>     --inputSubscription=$SUBSCRIPTION \\\n+>     --outputTable=$PROJECT:$DATASET.$TABLE \\\n+>     --tempLocation=gs://$BUCKET/samples/dataflow/temp\"\n+> ```\n+>\n+> </details>\n+\n+Build the Java project into an\n+[*Uber JAR* file](https://maven.apache.org/plugins/maven-shade-plugin/).\n+\n+```sh\n+# Build and package the application as an uber-jar file.\n+mvn clean package\n+\n+# (Optional) Note the size of the uber-jar file compared to the original.\n+ls -lh target/*.jar\n+```\n+\n+This *Uber JAR* file has all the dependencies embedded so it.\n+You can run this file as a standalone application with no external\n+dependencies on other libraries.\n+\n+Now, we build the\n+[Docker](https://docs.docker.com/engine/docker-overview/)\n+image for the Apache Beam pipeline.\n+We are using\n+[Cloud Build](https://cloud.google.com/cloud-build)\n+so we don't need a local installation of Docker.\n+\n+> *Note:* You can speed up subsequent builds with\n+> [Kaniko cache](https://cloud.google.com/cloud-build/docs/kaniko-cache)\n+> in Cloud Build.\n+>\n+> ```sh\n+> # (Optional) Enable to use Kaniko cache by default.\n+> gcloud config set builds/use_kaniko True\n+> ```\n+\n+Cloud Build allows you to\n+[build a Docker image using a `Dockerfile`](https://cloud.google.com/cloud-build/docs/quickstart-docker#build_using_dockerfile).\n+and saves it into\n+[Container Registry](https://cloud.google.com/container-registry/),\n+where the image is accessible to other Google Cloud products.\n+\n+```sh\n+export TEMPLATE_IMAGE=\"$PROJECT/samples/dataflow/streaming-beam-sql:latest\"\n+\n+# Build the image into Container Registry, this is roughly equivalent to:\n+#   gcloud auth configure-docker\n+#   docker image build -t $TEMPLATE_IMAGE .\n+#   docker push $TEMPLATE_IMAGE\n+gcloud builds submit --tag \"gcr.io/$TEMPLATE_IMAGE\" .\n+```", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjI3NQ==", "bodyText": "I wonder if you shouldn't just have a cleanup.sh script somewhere?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312275", "createdAt": "2020-03-11T22:44:40Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a\n+    [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a\n+    [Pub/Sub topic](https://cloud.google.com/pubsub/docs/admin#creating_a_topic)\n+    and a\n+    [subscription](https://cloud.google.com/pubsub/docs/admin#creating_subscriptions)\n+    to that topic.\n+    This is a streaming source of data for the sample.\n+\n+    ```sh\n+    # For simplicity we use the same topic name as the subscription name.\n+    export TOPIC=\"messages\"\n+    export SUBSCRIPTION=\"$TOPIC\"\n+\n+    gcloud pubsub topics create $TOPIC\n+    gcloud pubsub subscriptions create --topic $TOPIC $SUBSCRIPTION\n+    ```\n+\n+1. Create a\n+    [Cloud Scheduler job](https://cloud.google.com/scheduler/docs/quickstart)\n+    to publish \"positive\" and \"negative\" ratings every\n+    [1 and 2 minutes](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules).\n+    This publishes messages to the Pub/Sub source topic.\n+\n+    ```sh\n+    # Create a publisher for \"positive ratings\" that publishes 1 message per minute\n+    # If an App Engine app does not exist for the project, this step will create one.\n+    gcloud scheduler jobs create pubsub thumbs-up-publisher \\\n+      --schedule=\"* * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"positive\"}'\n+\n+    # Start the job.\n+    gcloud scheduler jobs run thumbs-up-publisher\n+\n+    # Create and run another similar publisher for \"negative ratings\" that\n+    # publishes 1 message every 2 minutes.\n+    gcloud scheduler jobs create pubsub thumbs-down-publisher \\\n+      --schedule=\"*/2 * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"negative\"}'\n+\n+    gcloud scheduler jobs run thumbs-down-publisher\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+    This is a table to write the output data.\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"streaming_beam_sql\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Clone the\n+    [`java-docs-samples` repository](https://github.com/GoogleCloudPlatform/java-docs-samples)\n+    and navigate to the code sample.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    cd java-docs-samples/dataflow/flex-templates/beam_sql\n+    ```\n+\n+## Pub/Sub to BigQuery with Beam SQL sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Pub/Sub](https://cloud.google.com/pubsub), uses\n+[Beam SQL](https://beam.apache.org/documentation/dsls/sql/overview/)\n+to transform the message data, and writes the results to a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+* [Dockerfile](Dockerfile)\n+* [StreamingBeamSQL.java](src/main/java/org/apache/beam/samples/StreamingBeamSQL.java)\n+* [pom.xml](pom.xml)\n+* [metadata.json](metadata.json)\n+\n+### Building a container image\n+\n+> <details><summary>\n+> <i>(Optional)</i> Run the Apache Beam pipeline locally for development.\n+> <i>(Click to expand)</i>\n+> </summary>\n+>\n+> ```sh\n+> mvn compile exec:java \\\n+>   -Dexec.mainClass=org.apache.beam.samples.StreamingBeamSQL \\\n+>   -Dexec.args=\"\\\n+>     --inputSubscription=$SUBSCRIPTION \\\n+>     --outputTable=$PROJECT:$DATASET.$TABLE \\\n+>     --tempLocation=gs://$BUCKET/samples/dataflow/temp\"\n+> ```\n+>\n+> </details>\n+\n+Build the Java project into an\n+[*Uber JAR* file](https://maven.apache.org/plugins/maven-shade-plugin/).\n+\n+```sh\n+# Build and package the application as an uber-jar file.\n+mvn clean package\n+\n+# (Optional) Note the size of the uber-jar file compared to the original.\n+ls -lh target/*.jar\n+```\n+\n+This *Uber JAR* file has all the dependencies embedded so it.\n+You can run this file as a standalone application with no external\n+dependencies on other libraries.\n+\n+Now, we build the\n+[Docker](https://docs.docker.com/engine/docker-overview/)\n+image for the Apache Beam pipeline.\n+We are using\n+[Cloud Build](https://cloud.google.com/cloud-build)\n+so we don't need a local installation of Docker.\n+\n+> *Note:* You can speed up subsequent builds with\n+> [Kaniko cache](https://cloud.google.com/cloud-build/docs/kaniko-cache)\n+> in Cloud Build.\n+>\n+> ```sh\n+> # (Optional) Enable to use Kaniko cache by default.\n+> gcloud config set builds/use_kaniko True\n+> ```\n+\n+Cloud Build allows you to\n+[build a Docker image using a `Dockerfile`](https://cloud.google.com/cloud-build/docs/quickstart-docker#build_using_dockerfile).\n+and saves it into\n+[Container Registry](https://cloud.google.com/container-registry/),\n+where the image is accessible to other Google Cloud products.\n+\n+```sh\n+export TEMPLATE_IMAGE=\"$PROJECT/samples/dataflow/streaming-beam-sql:latest\"\n+\n+# Build the image into Container Registry, this is roughly equivalent to:\n+#   gcloud auth configure-docker\n+#   docker image build -t $TEMPLATE_IMAGE .\n+#   docker push $TEMPLATE_IMAGE\n+gcloud builds submit --tag \"gcr.io/$TEMPLATE_IMAGE\" .\n+```\n+\n+Images starting with `gcr.io/PROJECT/` are saved into your project's\n+Container Registry, where the image is accessible to other Google Cloud products.\n+\n+### Creating a Flex Template\n+\n+To run a template, you need to create a *template spec* file containing all the\n+necessary information to run the job, such as the SDK information and metadata.\n+\n+The [`metadata.json`](metadata.json) file contains additional information for\n+the template such as the \"name\", \"description\", and input \"parameters\" field.\n+\n+The template file must be created in a Cloud Storage location,\n+and is used to run a new Dataflow job.\n+\n+```sh\n+export TEMPLATE_PATH=\"gs://$BUCKET/samples/dataflow/templates/streaming-beam-sql.json\"\n+\n+# Build the Flex Template.\n+gcloud beta dataflow flex-template build $TEMPLATE_PATH \\\n+  --image \"gcr://$TEMPLATE_IMAGE\" \\\n+  --sdk-language \"JAVA\" \\\n+  --metadata-file \"metadata.json\"\n+```\n+\n+The template is now available through the template file in the Cloud Storage\n+location that you specified.\n+\n+### Running a Dataflow Flex Template pipeline\n+\n+You can now run the Apache Beam pipeline in Dataflow by referring to the\n+template file and passing the template\n+[parameters](https://cloud.devsite.corp.google.com/dataflow/docs/guides/specifying-exec-params#setting-other-cloud-dataflow-pipeline-options)\n+required by the pipeline.\n+\n+```sh\n+# Parameters before the `--` are passed to the `gcloud` command.\n+# Parameters after the `--` are passed to the Beam pipeline.\n+gcloud beta dataflow flex-template run \"streaming-beam-sql-`date +%Y%m%d-%H%M%S`\" \\\n+  --template-file-gcs-location \"$TEMPLATE_PATH\" \\\n+  --parameters \"inputSubscription=$SUBSCRIPTION,outputTable=$PROJECT:$DATASET.$TABLE\"\n+```\n+\n+Check the results in BigQuery by running the following query:\n+\n+```sh\n+bq query --use_legacy_sql=false 'SELECT * FROM `'\"$PROJECT.$DATASET.$TABLE\"'`'\n+```\n+\n+While this pipeline is running, you can see new rows appended into the BigQuery\n+table every minute.\n+\n+You can manually publish more messages from the\n+[Cloud Scheduler page](https://console.cloud.google.com/cloudscheduler)\n+to see how that affects the page review scores.\n+\n+You can also publish messages directly to a topic through the\n+[Pub/Sub topics page](https://console.cloud.google.com/cloudpubsub/topic/list)\n+by selecting the topic you want to publish to,\n+and then clicking the \"Publish message\" button at the top.\n+This way you can test your pipeline with different URLs,\n+just make sure you pass valid JSON data since this sample does not do any\n+error handling for code simplicity.\n+\n+Try sending the following message and check back the BigQuery table about\n+a minute later.\n+\n+```json\n+{\"url\": \"https://cloud.google.com/bigquery/\", \"review\": \"positive\"}\n+```\n+\n+### Cleaning up\n+\n+After you've finished this tutorial, you can clean up the resources you created\n+on Google Cloud so you won't be billed for them in the future.\n+The following sections describe how to delete or turn off these resources.\n+\n+#### Clean up the Flex template resources", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA==", "bodyText": "Wow - this is long, I understand your trying to teach here, but I wonder if providing a script that does it and explains as it runs might be easier on users.  ./setup.sh", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312680", "createdAt": "2020-03-11T22:45:59Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjg2OA==", "bodyText": "Same comment about Copyright & Licenses at earlier.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312868", "createdAt": "2020-03-11T22:46:27Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/metadata.json", "diffHunk": "@@ -0,0 +1,23 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw==", "bodyText": "Why are we sending users to SNAPSHOT repositories?  That's not really good practice.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391313077", "createdAt": "2020-03-11T22:47:06Z", "author": {"login": "lesv"}, "path": "dataflow/flex-templates/streaming_beam_sql/pom.xml", "diffHunk": "@@ -0,0 +1,175 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one or more\n+    contributor license agreements.  See the NOTICE file distributed with\n+    this work for additional information regarding copyright ownership.\n+    The ASF licenses this file to You under the Apache License, Version 2.0\n+    (the \"License\"); you may not use this file except in compliance with\n+    the License.  You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" \n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+  <groupId>org.apache.beam.samples</groupId>\n+  <artifactId>streaming-beam-sql</artifactId>\n+  <version>1.0</version>\n+\n+  <properties>\n+    <maven.compiler.source>11</maven.compiler.source>\n+    <maven.compiler.target>11</maven.compiler.target>\n+    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n+\n+    <beam.version>2.19.0</beam.version>\n+\n+    <maven-enforcer-plugin.version>3.0.0-M3</maven-enforcer-plugin.version>\n+    <maven-compiler-plugin.version>3.8.1</maven-compiler-plugin.version>\n+    <maven-shade-plugin.version>3.2.1</maven-shade-plugin.version>\n+    <maven-exec-plugin.version>1.6.0</maven-exec-plugin.version>\n+    <slf4j.version>1.7.30</slf4j.version>\n+  </properties>\n+\n+  <repositories>\n+    <repository>\n+      <id>apache.snapshots</id>\n+      <name>Apache Development Snapshot Repository</name>\n+      <url>https://repository.apache.org/content/repositories/snapshots/</url>\n+      <releases>\n+        <enabled>false</enabled>\n+      </releases>\n+      <snapshots>\n+        <enabled>true</enabled>\n+      </snapshots>\n+    </repository>\n+  </repositories>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 52}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a292ef9ca976614be83fa296f2acbc252c7ad253", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/a292ef9ca976614be83fa296f2acbc252c7ad253", "committedDate": "2020-03-16T21:33:25Z", "message": "Added license"}, "afterCommit": {"oid": "046f5c3bc1034626d218ca3528ff7f9b5b927320", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/046f5c3bc1034626d218ca3528ff7f9b5b927320", "committedDate": "2020-03-16T22:17:24Z", "message": "Added license"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NTkxNTMx", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#pullrequestreview-375591531", "createdAt": "2020-03-16T21:22:10Z", "commit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMToyMjoxMFrOF3GM2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjoxNzowNVrOF3HjsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxNzU5Mw==", "bodyText": "That's a good point, I've added a note.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393317593", "createdAt": "2020-03-16T21:22:10Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzE2Nw=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxNzc0OA==", "bodyText": "Got it, I forgot about these files, adding copyright information", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393317748", "createdAt": "2020-03-16T21:22:32Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODY1Nw=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxODMzMA==", "bodyText": "Adding", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393318330", "createdAt": "2020-03-16T21:23:52Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODQ2MQ=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTQyMA==", "bodyText": "That's a good idea. I'll go ahead and do that in a moment", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319420", "createdAt": "2020-03-16T21:26:25Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/README.md", "diffHunk": "@@ -0,0 +1,337 @@\n+# Dataflow Flex templates - Kafka to BigQuery\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+If you are not familiar with Dataflow Flex templates, please see the\n+[Streaming Beam SQL](../streaming-beam-sql/) sample first.\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"kafka_to_bigquery\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Select the compute region and zone to use.\n+\n+    ```sh\n+    # Select your default compute/region, or default to \"us-central1\".\n+    export REGION=${\"$(gcloud config get-value compute/region)\":-\"us-central1\"}\n+\n+    # Select your default compute/zone, or default to \"$REGION-a\".\n+    # Note that the zone *must* be in $REGION.\n+    export ZONE=${\"$(gcloud config get-value compute/zone)\":-\"$REGION-a\"}\n+    ```\n+\n+1. Clone the `java-docs-samples` repository.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    ```\n+\n+1. Navigate to the sample code directory.\n+\n+    ```sh\n+    cd java-docs-samples/dataflow/flex-templates/kafka_to_bigquery\n+    ```\n+\n+## Kafka to BigQuery sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Apache Kafka](https://kafka.apache.org/), decodes them, and writes them into a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+For this, we need two parts running:\n+\n+1. A Kafka server container accessible through an external IP address.\n+   This services publishes messages to a topic.\n+\n+    * [kafka/Dockerfile](kafka/Dockerfile)\n+    * [kafka/start-kafka.sh](kafka/start-kafka.sh)\n+    * [kafka/create-topic.sh](kafka/create-topic.sh)\n+\n+2. An Apache Beam streaming pipeline running in Dataflow Flex Templates.\n+   This subscribes to a Kafka topic, consumes the messages that are published\n+   to that topic, processes them, and writes them into a BigQuery table.\n+\n+    * [Dockerfile](Dockerfile)\n+    * [KafkaToBigQuery.java](src/main/java/org/apache/beam/samples/KafkaToBigQuery.java)\n+    * [pom.xml](pom.xml)\n+    * [metadata.json](metadata.json)\n+\n+### Starting the Kafka server", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODExMg=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTU3OQ==", "bodyText": "Added", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319579", "createdAt": "2020-03-16T21:26:44Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/Dockerfile", "diffHunk": "@@ -0,0 +1,37 @@\n+FROM openjdk:8-jre-alpine", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODc0Ng=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTk4MA==", "bodyText": "Added", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319980", "createdAt": "2020-03-16T21:27:43Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/create-topic.sh", "diffHunk": "@@ -0,0 +1,20 @@\n+#!/bin/sh", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTIwMw=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDAzOA==", "bodyText": "Added", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320038", "createdAt": "2020-03-16T21:27:50Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/start-kafka.sh", "diffHunk": "@@ -0,0 +1,48 @@\n+#!/bin/sh\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTI5Mw=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDYwOQ==", "bodyText": "Did the same as above.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320609", "createdAt": "2020-03-16T21:29:02Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/streaming_beam_sql/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTAxNQ=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDY2Nw==", "bodyText": "Added", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320667", "createdAt": "2020-03-16T21:29:11Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/streaming_beam_sql/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTI3Ng=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMTczNw==", "bodyText": "I'm following what the Beam maven archetype creates for a new project. Is it safe to remove?", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393321737", "createdAt": "2020-03-16T21:31:39Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/streaming_beam_sql/pom.xml", "diffHunk": "@@ -0,0 +1,175 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one or more\n+    contributor license agreements.  See the NOTICE file distributed with\n+    this work for additional information regarding copyright ownership.\n+    The ASF licenses this file to You under the Apache License, Version 2.0\n+    (the \"License\"); you may not use this file except in compliance with\n+    the License.  You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" \n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+  <groupId>org.apache.beam.samples</groupId>\n+  <artifactId>streaming-beam-sql</artifactId>\n+  <version>1.0</version>\n+\n+  <properties>\n+    <maven.compiler.source>11</maven.compiler.source>\n+    <maven.compiler.target>11</maven.compiler.target>\n+    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n+\n+    <beam.version>2.19.0</beam.version>\n+\n+    <maven-enforcer-plugin.version>3.0.0-M3</maven-enforcer-plugin.version>\n+    <maven-compiler-plugin.version>3.8.1</maven-compiler-plugin.version>\n+    <maven-shade-plugin.version>3.2.1</maven-shade-plugin.version>\n+    <maven-exec-plugin.version>1.6.0</maven-exec-plugin.version>\n+    <slf4j.version>1.7.30</slf4j.version>\n+  </properties>\n+\n+  <repositories>\n+    <repository>\n+      <id>apache.snapshots</id>\n+      <name>Apache Development Snapshot Repository</name>\n+      <url>https://repository.apache.org/content/repositories/snapshots/</url>\n+      <releases>\n+        <enabled>false</enabled>\n+      </releases>\n+      <snapshots>\n+        <enabled>true</enabled>\n+      </snapshots>\n+    </repository>\n+  </repositories>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzOTgyNA==", "bodyText": "I agree, it's a lot. I played a bit with creating a script, but now I would have to handle user confirmations when creating/deleting resources and much more validation. That would also make doing the setup/cleanup harder to port to windows. I will leave the instructions in the README for simplicity for now.\nThese instructions are also present in the docs, so we would prefer to keep them as compatible as possible.", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393339824", "createdAt": "2020-03-16T22:17:05Z", "author": {"login": "davidcavazos"}, "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}, "originalCommit": {"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8"}, "originalPosition": 11}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fec6e36ea24b7a242e65fe8d2363d3c82890c540", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/fec6e36ea24b7a242e65fe8d2363d3c82890c540", "committedDate": "2020-03-17T22:14:36Z", "message": "Removed snapshots"}, "afterCommit": {"oid": "9e80e53f273a70d7fe697dcc5e5b992cec844f34", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/9e80e53f273a70d7fe697dcc5e5b992cec844f34", "committedDate": "2020-03-17T22:14:59Z", "message": "Removed snapshots"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2NDQ5NTY3", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#pullrequestreview-376449567", "createdAt": "2020-03-17T22:29:31Z", "commit": {"oid": "b1252bfe08993692bd6cf3f850dcdaa8526d251a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f02dfc31eb35ca3170a1d447f96ca30ffca0a862", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/f02dfc31eb35ca3170a1d447f96ca30ffca0a862", "committedDate": "2020-03-23T18:50:05Z", "message": "dataflow: add flex templates sample"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00e033c15062013747c7dc318f804e4ae43919dc", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/00e033c15062013747c7dc318f804e4ae43919dc", "committedDate": "2020-03-23T18:50:05Z", "message": "Improved the README instructions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01514151192cce3383bcbcc284b5e3f03a41bc60", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/01514151192cce3383bcbcc284b5e3f03a41bc60", "committedDate": "2020-03-23T18:50:05Z", "message": "Simplified command to create new pipeline"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7954d0116f5d1ea0fb53ad3ba22e9a30c39ddd9e", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/7954d0116f5d1ea0fb53ad3ba22e9a30c39ddd9e", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README and simplified files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "843aa48a29956caef18441f8b878bd5d35fa0a14", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/843aa48a29956caef18441f8b878bd5d35fa0a14", "committedDate": "2020-03-23T18:50:06Z", "message": "Add streaming-beam-sql sample"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0150d1803d5ac709f14d9d7d6fc4c7564024427", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/c0150d1803d5ac709f14d9d7d6fc4c7564024427", "committedDate": "2020-03-23T18:50:06Z", "message": "Added BeamSQL and updated README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91cf6ae89d2a07094f71115a19763305a7ec077d", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/91cf6ae89d2a07094f71115a19763305a7ec077d", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cf69d40ba09848782fd8b91a37eec7a290cb35b", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/5cf69d40ba09848782fd8b91a37eec7a290cb35b", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bcc1c31d0f06f49889e14b4bae3f8377ac413a3", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/3bcc1c31d0f06f49889e14b4bae3f8377ac413a3", "committedDate": "2020-03-23T18:50:06Z", "message": "Added newline at EOF"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "548fc56a2e2904d349e36c46b0c97225c55c458b", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/548fc56a2e2904d349e36c46b0c97225c55c458b", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21655d296edc0b75120da15d265fd2bcea4aec7d", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/21655d296edc0b75120da15d265fd2bcea4aec7d", "committedDate": "2020-03-23T18:50:06Z", "message": "Added license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b9b66e2fad380a5e4fc835c6de4cdd7e0ac467b", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0b9b66e2fad380a5e4fc835c6de4cdd7e0ac467b", "committedDate": "2020-03-23T18:50:06Z", "message": "Minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c555b831ebbaf555820ccc4537a8d7cb43ed115", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/8c555b831ebbaf555820ccc4537a8d7cb43ed115", "committedDate": "2020-03-23T18:50:06Z", "message": "Removed snapshots"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0054d68b9d41a233d5cd964fef983da80bc66370", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0054d68b9d41a233d5cd964fef983da80bc66370", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b1252bfe08993692bd6cf3f850dcdaa8526d251a", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/b1252bfe08993692bd6cf3f850dcdaa8526d251a", "committedDate": "2020-03-17T22:20:23Z", "message": "Updated README"}, "afterCommit": {"oid": "0054d68b9d41a233d5cd964fef983da80bc66370", "author": {"user": {"login": "davidcavazos", "name": "David Cavazos"}}, "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0054d68b9d41a233d5cd964fef983da80bc66370", "committedDate": "2020-03-23T18:50:06Z", "message": "Updated README"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 911, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}