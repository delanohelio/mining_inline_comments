{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczODQyNjkw", "number": 3529, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0NjowOFrOEdH2hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0OTo1N1rOEdH8TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTcyODA0OnYy", "diffSide": "RIGHT", "path": "open-metadata-implementation/adapters/open-connectors/governance-daemon-connectors/open-lineage-connectors/open-lineage-janus-connector/src/test/java/org/odpi/openmetadata/openconnectors/governancedaemonconnectors/openlineageconnectors/janusconnector/lineagegraph/OpenLineageGraphValidation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0NjowOFrOHIGhDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0NjowOFrOHIGhDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1NzQyMQ==", "bodyText": "You might want to print process.getQualifiedName() here", "url": "https://github.com/odpi/egeria/pull/3529#discussion_r478257421", "createdAt": "2020-08-27T08:46:08Z", "author": {"login": "popa-raluca"}, "path": "open-metadata-implementation/adapters/open-connectors/governance-daemon-connectors/open-lineage-connectors/open-lineage-janus-connector/src/test/java/org/odpi/openmetadata/openconnectors/governancedaemonconnectors/openlineageconnectors/janusconnector/lineagegraph/OpenLineageGraphValidation.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/* SPDX-License-Identifier: Apache-2.0 */\n+/* Copyright Contributors to the ODPi Egeria project. */\n+package org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.lineagegraph;\n+\n+import org.apache.tinkerpop.gremlin.process.traversal.dsl.graph.GraphTraversalSource;\n+import org.apache.tinkerpop.gremlin.process.traversal.dsl.graph.__;\n+import org.apache.tinkerpop.gremlin.structure.Graph;\n+import org.apache.tinkerpop.gremlin.structure.Vertex;\n+import org.janusgraph.core.JanusGraphFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.json.Json;\n+import javax.json.JsonArray;\n+import javax.json.JsonObject;\n+import javax.json.JsonReader;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Function;\n+\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_KEY_LABEL;\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_KEY_PREFIX_VERTEX_INSTANCE_PROPERTY;\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_NAME_QUALIFIED_NAME;\n+\n+/**\n+ * Based on provided information, the graph will be interrogated on assets of type Process, DataFile, RelationalColumn, TabularColumn\n+ * and RelationalColumn, and the graph structure around them will be validated. Just one parameter is necessary, path to\n+ * a json file of the following structure\n+ *\n+ * {\n+ *   \"graphConfigFile\": \"/Users/wf40wc/Developer/gremlin.properties\",\n+ *   \"processes\": [\n+ *     {\n+ *       \"qualifiedName\": \"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(transformation_project)=minimal::(dsjob)=flow2\",\n+ *       \"noOfSubprocesses\": 2\n+ *     }\n+ *   ],\n+ *   \"tables\":[\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(database)=MINIMAL::(database_schema)=DB2INST1::(database_table)=WORKPLACE\"\n+ *     }\n+ *   ],\n+ *   \"columns\":[\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(data_file_folder)=/::(data_file_folder)=data::(data_file_folder)=files::(data_file_folder)=minimal::(data_file)=locations.csv::(data_file_record)=locations::(data_file_field)=Name\"\n+ *     },\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(database)=MINIMAL::(database_schema)=DB2INST1::(database_table)=WORKPLACE::(database_column)=LOCID\"\n+ *     }\n+ *   ]\n+ * }\n+ *\n+ */\n+public class OpenLineageGraphValidation {\n+\n+    private static final Logger log = LoggerFactory.getLogger(OpenLineageGraphValidation.class);\n+\n+    private static final String VERTEX_QUALIFIED_NAME = PROPERTY_KEY_PREFIX_VERTEX_INSTANCE_PROPERTY + PROPERTY_NAME_QUALIFIED_NAME;\n+    private static final String QUALIFIED_NAME = \"qualifiedName\";\n+    private static final String PROCESS = \"Process\";\n+    private static final String RELATIONAL_TABLE = \"RelationalTable\";\n+    private static final String DATA_FILE = \"DataFile\";\n+    private static final String TABLE_DATA_FLOW = \"TableDataFlow\";\n+    private static final String TABULAR_COLUMN = \"TabularColumn\";\n+    private static final String COLUMN_DATA_FLOW = \"ColumnDataFlow\";\n+    private static final String ATTRIBUTE_FOR_SCHEMA = \"AttributeForSchema\";\n+    private static final String RELATIONAL_COLUMN = \"RelationalColumn\";\n+    private static final List<Process> PROCESSES = new ArrayList<>();\n+    private static final List<Table> TABLES = new ArrayList<>();\n+    private static final List<Column> COLUMNS = new ArrayList<>();\n+\n+    static class Process{\n+        private final String qualifiedName;\n+        private final long noOfProcesses;\n+\n+        Process(String qualifiedName, long noOfProcesses){\n+            this.qualifiedName = qualifiedName;\n+            this.noOfProcesses = noOfProcesses;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+\n+        long getNoOfProcesses() {\n+            return noOfProcesses;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Process> createProcess = processAsJsonObject ->\n+            new Process(processAsJsonObject.getString(QUALIFIED_NAME),\n+            processAsJsonObject.getJsonNumber(\"noOfSubprocesses\").longValue());\n+\n+    static class Table{\n+        private final String qualifiedName;\n+\n+        Table(String qualifiedName){\n+            this.qualifiedName = qualifiedName;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Table> createTable = tableAsJsonObject ->\n+            new Table(tableAsJsonObject.getString(QUALIFIED_NAME));\n+\n+    static class Column{\n+        private final String qualifiedName;\n+\n+        Column(String qualifiedName){\n+            this.qualifiedName = qualifiedName;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Column> createColumn = columnAsJsonObject ->\n+            new Column(columnAsJsonObject.getString(QUALIFIED_NAME));\n+\n+    private static <T, R> void addEntitiesToTarget(JsonArray entitiesAsJsonArray, Function<T, R> function, List<R> target){\n+        for(int i = 0 ; i < entitiesAsJsonArray.size() ; i++){\n+            JsonObject entityAsJsonObject = entitiesAsJsonArray.getJsonObject(i);\n+            target.add(function.apply((T) entityAsJsonObject));\n+        }\n+    }\n+\n+    private static JsonObject readJsonObjectFromFile(String arg) throws IOException {\n+        InputStream fis = new FileInputStream(arg);\n+        JsonReader jsonReader = Json.createReader(fis);\n+        JsonObject jsonObject = jsonReader.readObject();\n+        jsonReader.close();\n+        fis.close();\n+\n+        return jsonObject;\n+    }\n+\n+    public static void main(String[] args) throws Exception{\n+        JsonObject jsonObject = readJsonObjectFromFile(args[0]);\n+\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"processes\"), createProcess, PROCESSES);\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"tables\"), createTable, TABLES);\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"columns\"), createColumn, COLUMNS);\n+\n+        String graphConfigFile = jsonObject.getJsonString(\"graphConfigFile\").toString();\n+        OpenLineageGraphValidation graphValidation = new OpenLineageGraphValidation(graphConfigFile);\n+        graphValidation.validate();\n+        graphValidation.close();\n+    }\n+\n+    private GraphTraversalSource g;\n+\n+    private OpenLineageGraphValidation(String configFilePath){\n+        Graph graph = JanusGraphFactory.open(configFilePath);\n+        g = graph.traversal();\n+        log.info(\"Using graph configured by \" + configFilePath);\n+    }\n+\n+    private void close() throws Exception {\n+        g.close();\n+        g.getGraph().close();\n+    }\n+\n+    private void validate(){\n+        PROCESSES.forEach(this::validateProcess);\n+        log.info(\"Validated \" + PROCESSES.size() + \" processes\");\n+\n+        TABLES.forEach(this::validateTable);\n+        log.info(\"Validated \" + TABLES.size() + \" tables\");\n+\n+        COLUMNS.forEach(this::validateColumn);\n+        log.info(\"Validated \" + COLUMNS.size() + \" columns\");\n+    }\n+\n+    private void validateProcess(Process process){\n+        Vertex processAsVertex = g.V().has(VERTEX_QUALIFIED_NAME, process.getQualifiedName()).has(PROPERTY_KEY_LABEL, PROCESS).next();\n+\n+        assert processAsVertex != null : \"Process not found by qualified name \" + process;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9499dc0559f82ff9a55d65ccfd7a4846b1b02ae5"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTc0Mjg1OnYy", "diffSide": "RIGHT", "path": "open-metadata-implementation/adapters/open-connectors/governance-daemon-connectors/open-lineage-connectors/open-lineage-janus-connector/src/test/java/org/odpi/openmetadata/openconnectors/governancedaemonconnectors/openlineageconnectors/janusconnector/lineagegraph/OpenLineageGraphValidation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0OTo1N1rOHIGqKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0OTo1N1rOHIGqKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1OTc1NA==", "bodyText": "This check can be split into two different ones, for input/output with specific messages", "url": "https://github.com/odpi/egeria/pull/3529#discussion_r478259754", "createdAt": "2020-08-27T08:49:57Z", "author": {"login": "popa-raluca"}, "path": "open-metadata-implementation/adapters/open-connectors/governance-daemon-connectors/open-lineage-connectors/open-lineage-janus-connector/src/test/java/org/odpi/openmetadata/openconnectors/governancedaemonconnectors/openlineageconnectors/janusconnector/lineagegraph/OpenLineageGraphValidation.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/* SPDX-License-Identifier: Apache-2.0 */\n+/* Copyright Contributors to the ODPi Egeria project. */\n+package org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.lineagegraph;\n+\n+import org.apache.tinkerpop.gremlin.process.traversal.dsl.graph.GraphTraversalSource;\n+import org.apache.tinkerpop.gremlin.process.traversal.dsl.graph.__;\n+import org.apache.tinkerpop.gremlin.structure.Graph;\n+import org.apache.tinkerpop.gremlin.structure.Vertex;\n+import org.janusgraph.core.JanusGraphFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.json.Json;\n+import javax.json.JsonArray;\n+import javax.json.JsonObject;\n+import javax.json.JsonReader;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Function;\n+\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_KEY_LABEL;\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_KEY_PREFIX_VERTEX_INSTANCE_PROPERTY;\n+import static org.odpi.openmetadata.openconnectors.governancedaemonconnectors.openlineageconnectors.janusconnector.utils.GraphConstants.PROPERTY_NAME_QUALIFIED_NAME;\n+\n+/**\n+ * Based on provided information, the graph will be interrogated on assets of type Process, DataFile, RelationalColumn, TabularColumn\n+ * and RelationalColumn, and the graph structure around them will be validated. Just one parameter is necessary, path to\n+ * a json file of the following structure\n+ *\n+ * {\n+ *   \"graphConfigFile\": \"/Users/wf40wc/Developer/gremlin.properties\",\n+ *   \"processes\": [\n+ *     {\n+ *       \"qualifiedName\": \"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(transformation_project)=minimal::(dsjob)=flow2\",\n+ *       \"noOfSubprocesses\": 2\n+ *     }\n+ *   ],\n+ *   \"tables\":[\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(database)=MINIMAL::(database_schema)=DB2INST1::(database_table)=WORKPLACE\"\n+ *     }\n+ *   ],\n+ *   \"columns\":[\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(data_file_folder)=/::(data_file_folder)=data::(data_file_folder)=files::(data_file_folder)=minimal::(data_file)=locations.csv::(data_file_record)=locations::(data_file_field)=Name\"\n+ *     },\n+ *     {\n+ *       \"qualifiedName\":\"(host_(engine))=IS115.OPENMETADATA.IBMCLOUD.COM::(database)=MINIMAL::(database_schema)=DB2INST1::(database_table)=WORKPLACE::(database_column)=LOCID\"\n+ *     }\n+ *   ]\n+ * }\n+ *\n+ */\n+public class OpenLineageGraphValidation {\n+\n+    private static final Logger log = LoggerFactory.getLogger(OpenLineageGraphValidation.class);\n+\n+    private static final String VERTEX_QUALIFIED_NAME = PROPERTY_KEY_PREFIX_VERTEX_INSTANCE_PROPERTY + PROPERTY_NAME_QUALIFIED_NAME;\n+    private static final String QUALIFIED_NAME = \"qualifiedName\";\n+    private static final String PROCESS = \"Process\";\n+    private static final String RELATIONAL_TABLE = \"RelationalTable\";\n+    private static final String DATA_FILE = \"DataFile\";\n+    private static final String TABLE_DATA_FLOW = \"TableDataFlow\";\n+    private static final String TABULAR_COLUMN = \"TabularColumn\";\n+    private static final String COLUMN_DATA_FLOW = \"ColumnDataFlow\";\n+    private static final String ATTRIBUTE_FOR_SCHEMA = \"AttributeForSchema\";\n+    private static final String RELATIONAL_COLUMN = \"RelationalColumn\";\n+    private static final List<Process> PROCESSES = new ArrayList<>();\n+    private static final List<Table> TABLES = new ArrayList<>();\n+    private static final List<Column> COLUMNS = new ArrayList<>();\n+\n+    static class Process{\n+        private final String qualifiedName;\n+        private final long noOfProcesses;\n+\n+        Process(String qualifiedName, long noOfProcesses){\n+            this.qualifiedName = qualifiedName;\n+            this.noOfProcesses = noOfProcesses;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+\n+        long getNoOfProcesses() {\n+            return noOfProcesses;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Process> createProcess = processAsJsonObject ->\n+            new Process(processAsJsonObject.getString(QUALIFIED_NAME),\n+            processAsJsonObject.getJsonNumber(\"noOfSubprocesses\").longValue());\n+\n+    static class Table{\n+        private final String qualifiedName;\n+\n+        Table(String qualifiedName){\n+            this.qualifiedName = qualifiedName;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Table> createTable = tableAsJsonObject ->\n+            new Table(tableAsJsonObject.getString(QUALIFIED_NAME));\n+\n+    static class Column{\n+        private final String qualifiedName;\n+\n+        Column(String qualifiedName){\n+            this.qualifiedName = qualifiedName;\n+        }\n+\n+        String getQualifiedName() {\n+            return qualifiedName;\n+        }\n+    }\n+\n+    private static Function<JsonObject, Column> createColumn = columnAsJsonObject ->\n+            new Column(columnAsJsonObject.getString(QUALIFIED_NAME));\n+\n+    private static <T, R> void addEntitiesToTarget(JsonArray entitiesAsJsonArray, Function<T, R> function, List<R> target){\n+        for(int i = 0 ; i < entitiesAsJsonArray.size() ; i++){\n+            JsonObject entityAsJsonObject = entitiesAsJsonArray.getJsonObject(i);\n+            target.add(function.apply((T) entityAsJsonObject));\n+        }\n+    }\n+\n+    private static JsonObject readJsonObjectFromFile(String arg) throws IOException {\n+        InputStream fis = new FileInputStream(arg);\n+        JsonReader jsonReader = Json.createReader(fis);\n+        JsonObject jsonObject = jsonReader.readObject();\n+        jsonReader.close();\n+        fis.close();\n+\n+        return jsonObject;\n+    }\n+\n+    public static void main(String[] args) throws Exception{\n+        JsonObject jsonObject = readJsonObjectFromFile(args[0]);\n+\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"processes\"), createProcess, PROCESSES);\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"tables\"), createTable, TABLES);\n+        addEntitiesToTarget(jsonObject.getJsonArray(\"columns\"), createColumn, COLUMNS);\n+\n+        String graphConfigFile = jsonObject.getJsonString(\"graphConfigFile\").toString();\n+        OpenLineageGraphValidation graphValidation = new OpenLineageGraphValidation(graphConfigFile);\n+        graphValidation.validate();\n+        graphValidation.close();\n+    }\n+\n+    private GraphTraversalSource g;\n+\n+    private OpenLineageGraphValidation(String configFilePath){\n+        Graph graph = JanusGraphFactory.open(configFilePath);\n+        g = graph.traversal();\n+        log.info(\"Using graph configured by \" + configFilePath);\n+    }\n+\n+    private void close() throws Exception {\n+        g.close();\n+        g.getGraph().close();\n+    }\n+\n+    private void validate(){\n+        PROCESSES.forEach(this::validateProcess);\n+        log.info(\"Validated \" + PROCESSES.size() + \" processes\");\n+\n+        TABLES.forEach(this::validateTable);\n+        log.info(\"Validated \" + TABLES.size() + \" tables\");\n+\n+        COLUMNS.forEach(this::validateColumn);\n+        log.info(\"Validated \" + COLUMNS.size() + \" columns\");\n+    }\n+\n+    private void validateProcess(Process process){\n+        Vertex processAsVertex = g.V().has(VERTEX_QUALIFIED_NAME, process.getQualifiedName()).has(PROPERTY_KEY_LABEL, PROCESS).next();\n+\n+        assert processAsVertex != null : \"Process not found by qualified name \" + process;\n+\n+        boolean processIsOutput = g.V(processAsVertex.id()).in(TABLE_DATA_FLOW)\n+                .or(__.has(PROPERTY_KEY_LABEL, RELATIONAL_TABLE),\n+                        __.has(PROPERTY_KEY_LABEL, DATA_FILE)).hasNext();\n+\n+        boolean processIsInput = g.V(processAsVertex.id()).out(TABLE_DATA_FLOW)\n+                .or(__.has(PROPERTY_KEY_LABEL, RELATIONAL_TABLE),\n+                    __.has(PROPERTY_KEY_LABEL, DATA_FILE)).hasNext();\n+\n+        assert processIsInput && processIsOutput : \"Missing connection: \" + (processIsOutput? \"\" : \"(process is not output) \" )\n+                + (processIsInput? \"\" : \"(process is not input)\" );\n+\n+        long noOfSubprocesses = g.V(processAsVertex.id()).in(\"includedIn\").count().next();\n+        List<Vertex> subprocesses = g.V(processAsVertex.id()).in(\"includedIn\").next((int)noOfSubprocesses);\n+\n+        assert process.getNoOfProcesses() == noOfSubprocesses : \"Expected number of subprocesses are different than actual\";\n+\n+        for (Vertex subprocess : subprocesses) {\n+            boolean subprocessIsOutput = g.V(subprocess.id()).in(COLUMN_DATA_FLOW)\n+                                        .or(__.has(PROPERTY_KEY_LABEL, TABULAR_COLUMN),\n+                                            __.has(PROPERTY_KEY_LABEL, RELATIONAL_COLUMN)).hasNext();\n+            boolean subprocessIsInput = g.V(subprocess.id()).out(COLUMN_DATA_FLOW)\n+                    .or(__.has(PROPERTY_KEY_LABEL, TABULAR_COLUMN),\n+                        __.has(PROPERTY_KEY_LABEL, RELATIONAL_COLUMN)).hasNext();\n+\n+            assert subprocessIsInput && subprocessIsOutput : \"Missing connection: \" + (subprocessIsOutput? \"\" : \"(subprocess is not output) \" )\n+                    + (subprocessIsInput? \"\" : \"(subprocess is not input)\");\n+        }\n+\n+        log.debug(\"Validated process with qualifiedName \" + process.getQualifiedName());\n+    }\n+\n+    private void validateTable(Table table){\n+        Vertex tableVertex = g.V().has(VERTEX_QUALIFIED_NAME, table.getQualifiedName())\n+                .or(__.has(PROPERTY_KEY_LABEL, DATA_FILE),\n+                    __.has(PROPERTY_KEY_LABEL, RELATIONAL_TABLE)).next();\n+\n+        assert tableVertex != null : \"Table not found by qualifiedName \" + table.getQualifiedName();\n+\n+        boolean tableIsInput = g.V(tableVertex.id()).out(TABLE_DATA_FLOW).has(PROPERTY_KEY_LABEL, PROCESS).hasNext();\n+        boolean tableIsOutput = g.V(tableVertex.id()).in(TABLE_DATA_FLOW).has(PROPERTY_KEY_LABEL, PROCESS).hasNext();\n+\n+        if( tableIsInput && !tableIsOutput ){\n+            assert processHasOutput(tableVertex.id()) : \"Process missing output\";\n+        }\n+        if( !tableIsInput && tableIsOutput ){\n+            assert processHasInput(tableVertex.id()) : \"Process missing input\";\n+        }\n+        if(tableIsInput && tableIsOutput){\n+            assert processHasOutput(tableVertex.id()) && processHasInput(tableVertex.id()) : \"Process missing input and output\" ;\n+        }\n+\n+        log.debug(\"Validated table with qualifiedName \" + table.getQualifiedName());\n+    }\n+\n+    private boolean processHasOutput(Object tableId){\n+        Vertex process = g.V(tableId).out(TABLE_DATA_FLOW).has(PROPERTY_KEY_LABEL, PROCESS).next();\n+        return g.V(process.id()).out(TABLE_DATA_FLOW).or(__.has(PROPERTY_KEY_LABEL, RELATIONAL_TABLE),\n+                        __.has(PROPERTY_KEY_LABEL, DATA_FILE)).hasNext();\n+    }\n+\n+    private boolean processHasInput(Object tableId){\n+        Vertex process = g.V(tableId).in(TABLE_DATA_FLOW).has(PROPERTY_KEY_LABEL, PROCESS).next();\n+        return g.V(process.id()).in(TABLE_DATA_FLOW).or(__.has(PROPERTY_KEY_LABEL, RELATIONAL_TABLE),\n+                        __.has(PROPERTY_KEY_LABEL, DATA_FILE)).hasNext();\n+    }\n+\n+    private void validateColumn(Column column){\n+        Vertex columnAsVertex = g.V().has(VERTEX_QUALIFIED_NAME, column.getQualifiedName())\n+                .or(__.has(PROPERTY_KEY_LABEL, RELATIONAL_COLUMN),\n+                        __.has(PROPERTY_KEY_LABEL, TABULAR_COLUMN)).next();\n+\n+        assert columnAsVertex != null : \"Column not found by qualifiedName \" + column;\n+\n+        if( !g.V(columnAsVertex.id()).has(PROPERTY_KEY_LABEL, TABULAR_COLUMN).in(ATTRIBUTE_FOR_SCHEMA)\n+                .in(\"AssetSchemaType\").hasLabel(DATA_FILE).hasNext() ){\n+            // tabular columns that do not reach a DataFile are not eligible for validation\n+            return;\n+        }\n+\n+        boolean isInput = g.V(columnAsVertex.id()).out(COLUMN_DATA_FLOW).hasLabel(\"subProcess\").hasNext();\n+        boolean isOutput = g.V(columnAsVertex.id()).in(COLUMN_DATA_FLOW).hasLabel(\"subProcess\").hasNext();\n+\n+        assert isInput || isOutput : \"Column missing input and output\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9499dc0559f82ff9a55d65ccfd7a4846b1b02ae5"}, "originalPosition": 268}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2587, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}