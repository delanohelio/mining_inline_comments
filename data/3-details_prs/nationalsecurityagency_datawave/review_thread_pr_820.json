{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1NDcwMDc0", "number": 820, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODowMjoxMlrOEB27fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNDowOTowM1rOEET-hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzgzOTk2OnYy", "diffSide": "RIGHT", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/OptionsParser.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODowMjoxMlrOGd9jBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxOTo0MDo0OVrOGeBVpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA3MDI3Ng==", "bodyText": "is this really still a \"TODO\"?", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r434070276", "createdAt": "2020-06-02T18:02:12Z", "author": {"login": "ivakegg"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/OptionsParser.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package datawave.ingest;\n+\n+import datawave.ingest.config.TableConfigCache;\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import datawave.ingest.util.ConfigurationFileHelper;\n+import datawave.util.cli.PasswordConverter;\n+import org.apache.hadoop.conf.Configuration;\n+\n+public class OptionsParser {\n+    \n+    // todo: we parse these same arguments across several different classes in slightly different ways with very similar flags (e.g. zookeepers, zooKeepers,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEzMjM5MA==", "bodyText": "there are other options still to add, but to minimize scope creep, I've left the todo", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r434132390", "createdAt": "2020-06-02T19:40:49Z", "author": {"login": "hlgp"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/OptionsParser.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package datawave.ingest;\n+\n+import datawave.ingest.config.TableConfigCache;\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import datawave.ingest.util.ConfigurationFileHelper;\n+import datawave.util.cli.PasswordConverter;\n+import org.apache.hadoop.conf.Configuration;\n+\n+public class OptionsParser {\n+    \n+    // todo: we parse these same arguments across several different classes in slightly different ways with very similar flags (e.g. zookeepers, zooKeepers,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA3MDI3Ng=="}, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyOTI3Mzg0OnYy", "diffSide": "RIGHT", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMzowMDo1N1rOGhzqeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMzowMDo1N1rOGhzqeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwMjY0OQ==", "bodyText": "Should this use a try with resources, or a finally block to do the cleanup?", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438102649", "createdAt": "2020-06-10T13:00:57Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyOTI5ODYyOnYy", "diffSide": "RIGHT", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMzowNzoxMFrOGhz6dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMjowNzoxOVrOGkEY7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwNjc0Mg==", "bodyText": "I am not sure I like this logic. If for some reason there are hundreds of files here we could have problems. Would it be better to grab a sorted list of this.cacheFilePath.getName() + \".*\" and parse the number an increment? Might be a moot point but something to consider", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438106742", "createdAt": "2020-06-10T13:07:10Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {\n+            fs = FileSystem.get(cacheFilePath.toUri(), conf);\n+            tempFile = createTempFile(fs);\n+            writeCacheFile(fs, tempFile);\n+            createCacheFile(fs, tempFile);\n+        } catch (IOException e) {\n+            cleanup(fs, tempFile);\n+            \n+            log.error(\"Unable to update cache file \" + cacheFilePath + \" \" + e.getMessage());\n+        }\n+        \n+    }\n+    \n+    protected void initAccumuloHelper() {\n+        if (accumuloHelper == null) {\n+            accumuloHelper = new AccumuloHelper();\n+            accumuloHelper.setup(conf);\n+        }\n+    }\n+    \n+    public void createCacheFile(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(this.cacheFilePath, false);\n+            if (!fs.rename(tmpCacheFile, this.cacheFilePath)) {\n+                throw new IOException(\"Failed to rename temporary cache file\");\n+            }\n+            \n+        } catch (Exception e) {\n+            log.warn(\"Unable to rename \" + tmpCacheFile + \" to \" + this.cacheFilePath + \"probably because somebody else replaced it \", e);\n+            cleanup(fs, tmpCacheFile);\n+        }\n+        log.info(\"Updated \" + cacheFilePath);\n+        \n+    }\n+    \n+    protected void cleanup(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(tmpCacheFile, false);\n+        } catch (Exception e) {\n+            log.error(\"Unable to clean up \" + tmpCacheFile, e);\n+        }\n+    }\n+    \n+    protected void readCache(BufferedReader in, String delimiter) throws IOException {\n+        String line;\n+        while ((line = in.readLine()) != null) {\n+            String[] parts = StringUtils.split(line, delimiter);\n+            if (parts.length == 2) {\n+                conf.set(parts[0], parts[1]);\n+            }\n+        }\n+        in.close();\n+    }\n+    \n+    public Path createTempFile(FileSystem fs) throws IOException {\n+        int count = 1;\n+        Path tmpCacheFile = null;\n+        try {\n+            do {\n+                Path parentDirectory = this.cacheFilePath.getParent();\n+                String fileName = this.cacheFilePath.getName() + \".\" + count;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ1NTQwOQ==", "bodyText": "This has been there for a long time and, occasionally, we would see a handful of files hang around.  They should never be left around in the first place so I questioned this, too.  I found a place where a delete was not called but should have been and added it as part of this PR.  I didn't want to change the logic too much since it's mainly a refactor.  I will come back after more vetting and remove this in a separate PR.", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r440455409", "createdAt": "2020-06-15T21:23:55Z", "author": {"login": "hlgp"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {\n+            fs = FileSystem.get(cacheFilePath.toUri(), conf);\n+            tempFile = createTempFile(fs);\n+            writeCacheFile(fs, tempFile);\n+            createCacheFile(fs, tempFile);\n+        } catch (IOException e) {\n+            cleanup(fs, tempFile);\n+            \n+            log.error(\"Unable to update cache file \" + cacheFilePath + \" \" + e.getMessage());\n+        }\n+        \n+    }\n+    \n+    protected void initAccumuloHelper() {\n+        if (accumuloHelper == null) {\n+            accumuloHelper = new AccumuloHelper();\n+            accumuloHelper.setup(conf);\n+        }\n+    }\n+    \n+    public void createCacheFile(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(this.cacheFilePath, false);\n+            if (!fs.rename(tmpCacheFile, this.cacheFilePath)) {\n+                throw new IOException(\"Failed to rename temporary cache file\");\n+            }\n+            \n+        } catch (Exception e) {\n+            log.warn(\"Unable to rename \" + tmpCacheFile + \" to \" + this.cacheFilePath + \"probably because somebody else replaced it \", e);\n+            cleanup(fs, tmpCacheFile);\n+        }\n+        log.info(\"Updated \" + cacheFilePath);\n+        \n+    }\n+    \n+    protected void cleanup(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(tmpCacheFile, false);\n+        } catch (Exception e) {\n+            log.error(\"Unable to clean up \" + tmpCacheFile, e);\n+        }\n+    }\n+    \n+    protected void readCache(BufferedReader in, String delimiter) throws IOException {\n+        String line;\n+        while ((line = in.readLine()) != null) {\n+            String[] parts = StringUtils.split(line, delimiter);\n+            if (parts.length == 2) {\n+                conf.set(parts[0], parts[1]);\n+            }\n+        }\n+        in.close();\n+    }\n+    \n+    public Path createTempFile(FileSystem fs) throws IOException {\n+        int count = 1;\n+        Path tmpCacheFile = null;\n+        try {\n+            do {\n+                Path parentDirectory = this.cacheFilePath.getParent();\n+                String fileName = this.cacheFilePath.getName() + \".\" + count;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwNjc0Mg=="}, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ3MzgzNg==", "bodyText": "Ok I can accept that", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r440473836", "createdAt": "2020-06-15T22:07:19Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {\n+            fs = FileSystem.get(cacheFilePath.toUri(), conf);\n+            tempFile = createTempFile(fs);\n+            writeCacheFile(fs, tempFile);\n+            createCacheFile(fs, tempFile);\n+        } catch (IOException e) {\n+            cleanup(fs, tempFile);\n+            \n+            log.error(\"Unable to update cache file \" + cacheFilePath + \" \" + e.getMessage());\n+        }\n+        \n+    }\n+    \n+    protected void initAccumuloHelper() {\n+        if (accumuloHelper == null) {\n+            accumuloHelper = new AccumuloHelper();\n+            accumuloHelper.setup(conf);\n+        }\n+    }\n+    \n+    public void createCacheFile(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(this.cacheFilePath, false);\n+            if (!fs.rename(tmpCacheFile, this.cacheFilePath)) {\n+                throw new IOException(\"Failed to rename temporary cache file\");\n+            }\n+            \n+        } catch (Exception e) {\n+            log.warn(\"Unable to rename \" + tmpCacheFile + \" to \" + this.cacheFilePath + \"probably because somebody else replaced it \", e);\n+            cleanup(fs, tmpCacheFile);\n+        }\n+        log.info(\"Updated \" + cacheFilePath);\n+        \n+    }\n+    \n+    protected void cleanup(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(tmpCacheFile, false);\n+        } catch (Exception e) {\n+            log.error(\"Unable to clean up \" + tmpCacheFile, e);\n+        }\n+    }\n+    \n+    protected void readCache(BufferedReader in, String delimiter) throws IOException {\n+        String line;\n+        while ((line = in.readLine()) != null) {\n+            String[] parts = StringUtils.split(line, delimiter);\n+            if (parts.length == 2) {\n+                conf.set(parts[0], parts[1]);\n+            }\n+        }\n+        in.close();\n+    }\n+    \n+    public Path createTempFile(FileSystem fs) throws IOException {\n+        int count = 1;\n+        Path tmpCacheFile = null;\n+        try {\n+            do {\n+                Path parentDirectory = this.cacheFilePath.getParent();\n+                String fileName = this.cacheFilePath.getName() + \".\" + count;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwNjc0Mg=="}, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyOTU2ODE3OnYy", "diffSide": "RIGHT", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNDowODozNVrOGh2mxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNDowODozNVrOGh2mxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE1MDg1Mw==", "bodyText": "No soup for you!", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438150853", "createdAt": "2020-06-10T14:08:35Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java", "diffHunk": "@@ -14,8 +14,10 @@\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n+import com.google.common.collect.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyOTU3MDYzOnYy", "diffSide": "RIGHT", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/writer/AbstractContextWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNDowOTowM1rOGh2oUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMToxMTo0MFrOGkC6eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE1MTI1MQ==", "bodyText": "I thought you knew better. Sad panda.", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438151251", "createdAt": "2020-06-10T14:09:03Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/writer/AbstractContextWriter.java", "diffHunk": "@@ -3,10 +3,7 @@\n import com.google.common.collect.ArrayListMultimap;\n import com.google.common.collect.Multimap;\n import datawave.ingest.data.config.ingest.BaseIngestHelper;\n-import datawave.ingest.mapreduce.job.BulkIngestCounters;\n-import datawave.ingest.mapreduce.job.BulkIngestKey;\n-import datawave.ingest.mapreduce.job.ConstraintChecker;\n-import datawave.ingest.mapreduce.job.IngestJob;\n+import datawave.ingest.mapreduce.job.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ0OTY1Nw==", "bodyText": "reconfigured my IDE not to do this anymore!", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r440449657", "createdAt": "2020-06-15T21:11:40Z", "author": {"login": "hlgp"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/writer/AbstractContextWriter.java", "diffHunk": "@@ -3,10 +3,7 @@\n import com.google.common.collect.ArrayListMultimap;\n import com.google.common.collect.Multimap;\n import datawave.ingest.data.config.ingest.BaseIngestHelper;\n-import datawave.ingest.mapreduce.job.BulkIngestCounters;\n-import datawave.ingest.mapreduce.job.BulkIngestKey;\n-import datawave.ingest.mapreduce.job.ConstraintChecker;\n-import datawave.ingest.mapreduce.job.IngestJob;\n+import datawave.ingest.mapreduce.job.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE1MTI1MQ=="}, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4385, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}