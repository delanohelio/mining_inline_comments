{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1NDcwMDc0", "number": 820, "title": "Table config cache", "bodyText": "", "createdAt": "2020-05-08T23:12:29Z", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820", "merged": true, "mergeCommit": {"oid": "0fd1f262c0f9c2a13f3696c9d9630a1a7c07ab58"}, "closed": true, "closedAt": "2020-07-31T14:27:25Z", "author": {"login": "hlgp"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABca5BQ8gH2gAyNDE1NDcwMDc0OjhiMDhjMjAyMmM3ZTZjOTAyOWM4YWU2ZTQ4NzllY2FhMTM5MGYyNTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc6UsZWgH2gAyNDE1NDcwMDc0OmY2ODM2ZTI4Njc0NjhmZDJlZDBlOTcwMmZkNTQ4NGRmODU1ZDY3OTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "8b08c2022c7e6c9029c8ae6e4879ecaa1390f256", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/8b08c2022c7e6c9029c8ae6e4879ecaa1390f256", "committedDate": "2020-04-24T22:14:05Z", "message": "WIP: table configuration cache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a17c238b150a50cc8fb2d9038a6ec2bd00d2895", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/2a17c238b150a50cc8fb2d9038a6ec2bd00d2895", "committedDate": "2020-05-08T23:08:04Z", "message": "WIP: more table cache refinements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e742a6affd8dab3899f13929c95922eb08e6218", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/4e742a6affd8dab3899f13929c95922eb08e6218", "committedDate": "2020-05-08T23:15:30Z", "message": "Update IngestJob.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85e3a0f1f849a3d26b0644b0b6fb76c0c150e228", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/85e3a0f1f849a3d26b0644b0b6fb76c0c150e228", "committedDate": "2020-06-01T20:25:23Z", "message": "PR feedback: add enable flag, rename DIR to PATH"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/000084f54693f7998ad79294dec8a971bae85a81", "committedDate": "2020-06-01T20:29:55Z", "message": "Merge branch 'release/version2.9' into tableConfigCache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyOTMxODAy", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#pullrequestreview-422931802", "createdAt": "2020-06-02T18:02:12Z", "commit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "state": "DISMISSED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODowMjoxMlrOGd9jBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODowMjoxMlrOGd9jBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA3MDI3Ng==", "bodyText": "is this really still a \"TODO\"?", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r434070276", "createdAt": "2020-06-02T18:02:12Z", "author": {"login": "ivakegg"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/OptionsParser.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package datawave.ingest;\n+\n+import datawave.ingest.config.TableConfigCache;\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import datawave.ingest.util.ConfigurationFileHelper;\n+import datawave.util.cli.PasswordConverter;\n+import org.apache.hadoop.conf.Configuration;\n+\n+public class OptionsParser {\n+    \n+    // todo: we parse these same arguments across several different classes in slightly different ways with very similar flags (e.g. zookeepers, zooKeepers,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MDMzNjY5", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#pullrequestreview-428033669", "createdAt": "2020-06-10T13:08:35Z", "commit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MDI2OTcx", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#pullrequestreview-428026971", "createdAt": "2020-06-10T13:00:57Z", "commit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMzowMDo1N1rOGhzqeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNDowOTowM1rOGh2oUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwMjY0OQ==", "bodyText": "Should this use a try with resources, or a finally block to do the cleanup?", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438102649", "createdAt": "2020-06-10T13:00:57Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwNjc0Mg==", "bodyText": "I am not sure I like this logic. If for some reason there are hundreds of files here we could have problems. Would it be better to grab a sorted list of this.cacheFilePath.getName() + \".*\" and parse the number an increment? Might be a moot point but something to consider", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438106742", "createdAt": "2020-06-10T13:07:10Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/config/BaseHdfsFileCacheUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package datawave.ingest.config;\n+\n+import datawave.ingest.data.config.ingest.AccumuloHelper;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang.Validate;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+\n+public abstract class BaseHdfsFileCacheUtil {\n+    \n+    protected Path cacheFilePath;\n+    protected final Configuration conf;\n+    protected AccumuloHelper accumuloHelper;\n+    private static String delimiter = \"\\t\";\n+    \n+    private static final Logger log = Logger.getLogger(BaseHdfsFileCacheUtil.class);\n+    \n+    public BaseHdfsFileCacheUtil(Configuration conf) {\n+        Validate.notNull(conf, \"Configuration object passed in null\");\n+        this.conf = conf;\n+        setCacheFilePath(conf);\n+    }\n+    \n+    public Path getCacheFilePath() {\n+        return this.cacheFilePath;\n+    }\n+    \n+    public abstract void setCacheFilePath(Configuration conf);\n+    \n+    public void read() throws IOException {\n+        try (BufferedReader in = new BufferedReader(new InputStreamReader(FileSystem.get(this.cacheFilePath.toUri(), conf).open(this.cacheFilePath)))) {\n+            readCache(in, delimiter);\n+        } catch (IOException ex) {\n+            if (shouldRefreshCache(this.conf)) {\n+                update();\n+            } else {\n+                throw new IOException(\"Unable to read cache file at \" + this.cacheFilePath, ex);\n+            }\n+            \n+        }\n+        \n+    }\n+    \n+    public abstract void writeCacheFile(FileSystem fs, Path tempFile) throws IOException;\n+    \n+    public void update() {\n+        FileSystem fs = null;\n+        Path tempFile = null;\n+        try {\n+            fs = FileSystem.get(cacheFilePath.toUri(), conf);\n+            tempFile = createTempFile(fs);\n+            writeCacheFile(fs, tempFile);\n+            createCacheFile(fs, tempFile);\n+        } catch (IOException e) {\n+            cleanup(fs, tempFile);\n+            \n+            log.error(\"Unable to update cache file \" + cacheFilePath + \" \" + e.getMessage());\n+        }\n+        \n+    }\n+    \n+    protected void initAccumuloHelper() {\n+        if (accumuloHelper == null) {\n+            accumuloHelper = new AccumuloHelper();\n+            accumuloHelper.setup(conf);\n+        }\n+    }\n+    \n+    public void createCacheFile(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(this.cacheFilePath, false);\n+            if (!fs.rename(tmpCacheFile, this.cacheFilePath)) {\n+                throw new IOException(\"Failed to rename temporary cache file\");\n+            }\n+            \n+        } catch (Exception e) {\n+            log.warn(\"Unable to rename \" + tmpCacheFile + \" to \" + this.cacheFilePath + \"probably because somebody else replaced it \", e);\n+            cleanup(fs, tmpCacheFile);\n+        }\n+        log.info(\"Updated \" + cacheFilePath);\n+        \n+    }\n+    \n+    protected void cleanup(FileSystem fs, Path tmpCacheFile) {\n+        try {\n+            fs.delete(tmpCacheFile, false);\n+        } catch (Exception e) {\n+            log.error(\"Unable to clean up \" + tmpCacheFile, e);\n+        }\n+    }\n+    \n+    protected void readCache(BufferedReader in, String delimiter) throws IOException {\n+        String line;\n+        while ((line = in.readLine()) != null) {\n+            String[] parts = StringUtils.split(line, delimiter);\n+            if (parts.length == 2) {\n+                conf.set(parts[0], parts[1]);\n+            }\n+        }\n+        in.close();\n+    }\n+    \n+    public Path createTempFile(FileSystem fs) throws IOException {\n+        int count = 1;\n+        Path tmpCacheFile = null;\n+        try {\n+            do {\n+                Path parentDirectory = this.cacheFilePath.getParent();\n+                String fileName = this.cacheFilePath.getName() + \".\" + count;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE1MDg1Mw==", "bodyText": "No soup for you!", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438150853", "createdAt": "2020-06-10T14:08:35Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java", "diffHunk": "@@ -14,8 +14,10 @@\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n+import com.google.common.collect.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE1MTI1MQ==", "bodyText": "I thought you knew better. Sad panda.", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#discussion_r438151251", "createdAt": "2020-06-10T14:09:03Z", "author": {"login": "alerman"}, "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/writer/AbstractContextWriter.java", "diffHunk": "@@ -3,10 +3,7 @@\n import com.google.common.collect.ArrayListMultimap;\n import com.google.common.collect.Multimap;\n import datawave.ingest.data.config.ingest.BaseIngestHelper;\n-import datawave.ingest.mapreduce.job.BulkIngestCounters;\n-import datawave.ingest.mapreduce.job.BulkIngestKey;\n-import datawave.ingest.mapreduce.job.ConstraintChecker;\n-import datawave.ingest.mapreduce.job.IngestJob;\n+import datawave.ingest.mapreduce.job.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000084f54693f7998ad79294dec8a971bae85a81"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "348e7fe16c3c5f671b2c78cd4809c1f91839d743", "author": {"user": {"login": "hlgp", "name": "palindrome"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/348e7fe16c3c5f671b2c78cd4809c1f91839d743", "committedDate": "2020-06-15T18:13:53Z", "message": "remove star imports"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM1NzQxNDg0", "url": "https://github.com/NationalSecurityAgency/datawave/pull/820#pullrequestreview-435741484", "createdAt": "2020-06-23T12:43:10Z", "commit": {"oid": "348e7fe16c3c5f671b2c78cd4809c1f91839d743"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f0b7f0a5e0ff78a809b05d9de58821084779eae", "author": {"user": {"login": "ivakegg", "name": "Ivan Bella"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/4f0b7f0a5e0ff78a809b05d9de58821084779eae", "committedDate": "2020-07-29T22:06:34Z", "message": "Merge branch 'release/version2.9' into tableConfigCache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83ca330f55a592f7275c4d4f3f3cfffdb4a249af", "author": {"user": {"login": "ivakegg", "name": "Ivan Bella"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/83ca330f55a592f7275c4d4f3f3cfffdb4a249af", "committedDate": "2020-07-31T12:48:22Z", "message": "Merge branch 'release/version2.9' into tableConfigCache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6836e2867468fd2ed0e9702fd5484df855d6794", "author": {"user": {"login": "ivakegg", "name": "Ivan Bella"}}, "url": "https://github.com/NationalSecurityAgency/datawave/commit/f6836e2867468fd2ed0e9702fd5484df855d6794", "committedDate": "2020-07-31T14:00:17Z", "message": "Merge branch 'release/version2.9' into tableConfigCache"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 989, "cost": 1, "resetAt": "2021-11-01T15:33:45Z"}}}