{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0MDI3MjEz", "number": 497, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoxOTowMVrOEAQs8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMjo1Njo1MlrOEATXow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzA5MTA2OnYy", "diffSide": "RIGHT", "path": "doctest/test_docs.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoxOTowMVrOGbbqEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzoyNTowM1rOGcltNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNzg3Mg==", "bodyText": "Any chance we can pass this from command line? I'm thinking we may want to use this as sanity test in future.", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431417872", "createdAt": "2020-05-27T20:19:01Z", "author": {"login": "dai-chen"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ0NDc5NQ==", "bodyText": "Do you mean we want to connect to a remote endpoint and run doctest? I guess that's not doable for now with ./gradlew doctest. Currently, ./gradlew doctest depends on ./gradlew run which listens at localhost:9200.\nHowever, it may be doable by running this python script only while passing parameters such as the endpoint and login credentials. Need to do some research on that, such as connection with security plugin enabled may require different connection setup with extra arguments passed. Will open an issue to document this", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431444795", "createdAt": "2020-05-27T21:11:34Z", "author": {"login": "zhongnansu"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNzg3Mg=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzMTA5NQ==", "bodyText": "Never mind. I forgot that we're dependent on local cluster. We can figure out later if necessary. Thanks!", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r432631095", "createdAt": "2020-05-29T17:25:03Z", "author": {"login": "dai-chen"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNzg3Mg=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzEwMTMwOnYy", "diffSide": "RIGHT", "path": "doctest/docs/ppl/curl.rst", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoyMjozNFrOGbbwqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzoyNDowM1rOGclrAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxOTU2Mw==", "bodyText": "I assume the 3 docs added in this PR (ppl/cli/rst, ppl/curl.rst, sql/basics.rst) are more like samples? Never mind if we plan to change it to real docs exposed to customer. If not, probably we can move them to a sample folder used to show how to add doctest by CLI or curl for PPL/SQL.", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431419563", "createdAt": "2020-05-27T20:22:34Z", "author": {"login": "dai-chen"}, "path": "doctest/docs/ppl/curl.rst", "diffHunk": "@@ -0,0 +1,41 @@\n+Example\n+-------\n+\n+Test query::", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ1NjUwNA==", "bodyText": "Yeah my plan is to move it to real docs in next PR with clear documentation and examples of PPL. Still need to figure out the layout of docs. Should we add subfolder of ppl, or just add a single file for now.\nMixing sql and ppl code examples together in one doc doesn't work with doctest now, because we setup different client with different query language.", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431456504", "createdAt": "2020-05-27T21:35:57Z", "author": {"login": "zhongnansu"}, "path": "doctest/docs/ppl/curl.rst", "diffHunk": "@@ -0,0 +1,41 @@\n+Example\n+-------\n+\n+Test query::", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxOTU2Mw=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NjcxNA==", "bodyText": "Moved to sample folder under docs", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r432146714", "createdAt": "2020-05-28T21:56:45Z", "author": {"login": "zhongnansu"}, "path": "doctest/docs/ppl/curl.rst", "diffHunk": "@@ -0,0 +1,41 @@\n+Example\n+-------\n+\n+Test query::", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxOTU2Mw=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzMDUzMQ==", "bodyText": "Thanks!", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r432630531", "createdAt": "2020-05-29T17:24:03Z", "author": {"login": "dai-chen"}, "path": "doctest/docs/ppl/curl.rst", "diffHunk": "@@ -0,0 +1,41 @@\n+Example\n+-------\n+\n+Test query::", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxOTU2Mw=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzUyMzgxOnYy", "diffSide": "RIGHT", "path": "doctest/test_docs.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMjo1NTowMVrOGbf76Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMjo1Nzo0MlrOGbf_rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4Nzk3Nw==", "bodyText": "I think we didn't delete _all now, right?", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431487977", "createdAt": "2020-05-27T22:55:01Z", "author": {"login": "penghuo"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"\n+ACCOUNTS = \"accounts\"\n+EMPLOYEES = \"employees\"\n+\n+\n+class DocTestConnection(ESConnection):\n+\n+    def __init__(self, query_language=\"sql\"):\n+        super(DocTestConnection, self).__init__(endpoint=ENDPOINT, query_language=query_language)\n+        self.set_connection()\n+\n+        settings = OutputSettings(table_format=\"psql\", is_vertical=False)\n+        self.formatter = Formatter(settings)\n+\n+    def process(self, statement):\n+        data = self.execute_query(statement, use_console=False)\n+        output = self.formatter.format_output(data)\n+        output = \"\\n\".join(output)\n+\n+        click.echo(output)\n+\n+\n+def pretty_print(s):\n+    try:\n+        d = json.loads(s)\n+        print(json.dumps(d, indent=2))\n+    except json.decoder.JSONDecodeError:\n+        print(s)\n+\n+\n+sql_cmd = DocTestConnection(query_language=\"sql\")\n+ppl_cmd = DocTestConnection(query_language=\"ppl\")\n+test_data_client = Elasticsearch([ENDPOINT], verify_certs=True)\n+\n+\n+def sql_cli_transform(s):\n+    return u'sql_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def ppl_cli_transform(s):\n+    return u'ppl_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def bash_transform(s):\n+    # TODO: add ppl support, be default cli uses sql\n+    if s.startswith(\"odfesql\"):\n+        s = re.search(r\"odfesql\\s+-q\\s+\\\"(.*?)\\\"\", s).group(1)\n+        return u'cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+    return (r'pretty_print(sh(\"\"\"%s\"\"\").stdout.decode(\"utf-8\"))' % s) + '\\n'\n+\n+\n+sql_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=sql_cli_transform)\n+\n+ppl_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=ppl_cli_transform)\n+\n+bash_parser = zc.customdoctests.DocTestParser(\n+    ps1=r'sh\\$', comment_prefix='#', transform=bash_transform)\n+\n+\n+def set_up_accounts(test):\n+    set_up(test)\n+    load_file(\"accounts.json\", index_name=ACCOUNTS)\n+\n+\n+def load_file(filename, index_name):\n+    filepath = \"./test_data/\" + filename\n+\n+    # generate iterable data\n+    def load_json():\n+        with open(filepath, \"r\") as f:\n+            for line in f:\n+                yield json.loads(line)\n+\n+    # Need to enable refresh, because the load won't be visible to search immediately\n+    # https://stackoverflow.com/questions/57840161/elasticsearch-python-bulk-helper-api-with-refresh\n+    helpers.bulk(test_data_client, load_json(), stats_only=True, index=index_name, refresh='wait_for')\n+\n+\n+def set_up(test):\n+    test.globs['sql_cmd'] = sql_cmd\n+    test.globs['ppl_cmd'] = ppl_cmd\n+\n+\n+def tear_down(test):\n+    # drop leftover tables after each test\n+    # TODO: delete all will potentially also delete AES FGAC metadata index", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODk0Mg==", "bodyText": "Right, here we only delete the test indexes. Will remove the todo here", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431488942", "createdAt": "2020-05-27T22:57:42Z", "author": {"login": "zhongnansu"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"\n+ACCOUNTS = \"accounts\"\n+EMPLOYEES = \"employees\"\n+\n+\n+class DocTestConnection(ESConnection):\n+\n+    def __init__(self, query_language=\"sql\"):\n+        super(DocTestConnection, self).__init__(endpoint=ENDPOINT, query_language=query_language)\n+        self.set_connection()\n+\n+        settings = OutputSettings(table_format=\"psql\", is_vertical=False)\n+        self.formatter = Formatter(settings)\n+\n+    def process(self, statement):\n+        data = self.execute_query(statement, use_console=False)\n+        output = self.formatter.format_output(data)\n+        output = \"\\n\".join(output)\n+\n+        click.echo(output)\n+\n+\n+def pretty_print(s):\n+    try:\n+        d = json.loads(s)\n+        print(json.dumps(d, indent=2))\n+    except json.decoder.JSONDecodeError:\n+        print(s)\n+\n+\n+sql_cmd = DocTestConnection(query_language=\"sql\")\n+ppl_cmd = DocTestConnection(query_language=\"ppl\")\n+test_data_client = Elasticsearch([ENDPOINT], verify_certs=True)\n+\n+\n+def sql_cli_transform(s):\n+    return u'sql_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def ppl_cli_transform(s):\n+    return u'ppl_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def bash_transform(s):\n+    # TODO: add ppl support, be default cli uses sql\n+    if s.startswith(\"odfesql\"):\n+        s = re.search(r\"odfesql\\s+-q\\s+\\\"(.*?)\\\"\", s).group(1)\n+        return u'cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+    return (r'pretty_print(sh(\"\"\"%s\"\"\").stdout.decode(\"utf-8\"))' % s) + '\\n'\n+\n+\n+sql_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=sql_cli_transform)\n+\n+ppl_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=ppl_cli_transform)\n+\n+bash_parser = zc.customdoctests.DocTestParser(\n+    ps1=r'sh\\$', comment_prefix='#', transform=bash_transform)\n+\n+\n+def set_up_accounts(test):\n+    set_up(test)\n+    load_file(\"accounts.json\", index_name=ACCOUNTS)\n+\n+\n+def load_file(filename, index_name):\n+    filepath = \"./test_data/\" + filename\n+\n+    # generate iterable data\n+    def load_json():\n+        with open(filepath, \"r\") as f:\n+            for line in f:\n+                yield json.loads(line)\n+\n+    # Need to enable refresh, because the load won't be visible to search immediately\n+    # https://stackoverflow.com/questions/57840161/elasticsearch-python-bulk-helper-api-with-refresh\n+    helpers.bulk(test_data_client, load_json(), stats_only=True, index=index_name, refresh='wait_for')\n+\n+\n+def set_up(test):\n+    test.globs['sql_cmd'] = sql_cmd\n+    test.globs['ppl_cmd'] = ppl_cmd\n+\n+\n+def tear_down(test):\n+    # drop leftover tables after each test\n+    # TODO: delete all will potentially also delete AES FGAC metadata index", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4Nzk3Nw=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzUyODAzOnYy", "diffSide": "RIGHT", "path": "doctest/test_docs.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMjo1Njo1MlrOGbf-jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1NzozM1rOGcIKaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODY1NA==", "bodyText": "Does it require the develper change this file every time when they add different rst file?", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431488654", "createdAt": "2020-05-27T22:56:52Z", "author": {"login": "penghuo"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"\n+ACCOUNTS = \"accounts\"\n+EMPLOYEES = \"employees\"\n+\n+\n+class DocTestConnection(ESConnection):\n+\n+    def __init__(self, query_language=\"sql\"):\n+        super(DocTestConnection, self).__init__(endpoint=ENDPOINT, query_language=query_language)\n+        self.set_connection()\n+\n+        settings = OutputSettings(table_format=\"psql\", is_vertical=False)\n+        self.formatter = Formatter(settings)\n+\n+    def process(self, statement):\n+        data = self.execute_query(statement, use_console=False)\n+        output = self.formatter.format_output(data)\n+        output = \"\\n\".join(output)\n+\n+        click.echo(output)\n+\n+\n+def pretty_print(s):\n+    try:\n+        d = json.loads(s)\n+        print(json.dumps(d, indent=2))\n+    except json.decoder.JSONDecodeError:\n+        print(s)\n+\n+\n+sql_cmd = DocTestConnection(query_language=\"sql\")\n+ppl_cmd = DocTestConnection(query_language=\"ppl\")\n+test_data_client = Elasticsearch([ENDPOINT], verify_certs=True)\n+\n+\n+def sql_cli_transform(s):\n+    return u'sql_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def ppl_cli_transform(s):\n+    return u'ppl_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def bash_transform(s):\n+    # TODO: add ppl support, be default cli uses sql\n+    if s.startswith(\"odfesql\"):\n+        s = re.search(r\"odfesql\\s+-q\\s+\\\"(.*?)\\\"\", s).group(1)\n+        return u'cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+    return (r'pretty_print(sh(\"\"\"%s\"\"\").stdout.decode(\"utf-8\"))' % s) + '\\n'\n+\n+\n+sql_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=sql_cli_transform)\n+\n+ppl_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=ppl_cli_transform)\n+\n+bash_parser = zc.customdoctests.DocTestParser(\n+    ps1=r'sh\\$', comment_prefix='#', transform=bash_transform)\n+\n+\n+def set_up_accounts(test):\n+    set_up(test)\n+    load_file(\"accounts.json\", index_name=ACCOUNTS)\n+\n+\n+def load_file(filename, index_name):\n+    filepath = \"./test_data/\" + filename\n+\n+    # generate iterable data\n+    def load_json():\n+        with open(filepath, \"r\") as f:\n+            for line in f:\n+                yield json.loads(line)\n+\n+    # Need to enable refresh, because the load won't be visible to search immediately\n+    # https://stackoverflow.com/questions/57840161/elasticsearch-python-bulk-helper-api-with-refresh\n+    helpers.bulk(test_data_client, load_json(), stats_only=True, index=index_name, refresh='wait_for')\n+\n+\n+def set_up(test):\n+    test.globs['sql_cmd'] = sql_cmd\n+    test.globs['ppl_cmd'] = ppl_cmd\n+\n+\n+def tear_down(test):\n+    # drop leftover tables after each test\n+    # TODO: delete all will potentially also delete AES FGAC metadata index\n+    test_data_client.indices.delete(index=[ACCOUNTS, EMPLOYEES], ignore_unavailable=True)\n+\n+\n+docsuite = partial(doctest.DocFileSuite,\n+                   tearDown=tear_down,\n+                   parser=sql_cli_parser,\n+                   optionflags=doctest.NORMALIZE_WHITESPACE | doctest.ELLIPSIS,\n+                   encoding='utf-8')\n+\n+\n+doctest_file = partial(os.path.join, 'docs')\n+\n+\n+def doctest_files(*items):\n+    return (doctest_file(item) for item in items)\n+\n+\n+class DocTests(unittest.TestSuite):\n+    def run(self, result, debug=False):\n+        super().run(result, debug)\n+\n+\n+def load_tests(loader, suite, ignore):\n+    tests = []\n+    # docs with bash-based examples\n+    for fn in doctest_files('ppl/curl.rst'): # TODO: Add 'sql/explain.rst' after codebase migration", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ5MjgwNA==", "bodyText": "Theoretically, yes. That's because we need different setup, parser creation for docs containing different type of examples. sql, ppl or curl\nMixing sql and ppl code examples together in one doc doesn't work with doctest now, because we setup different client with different query language with CLI.", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r431492804", "createdAt": "2020-05-27T23:08:51Z", "author": {"login": "zhongnansu"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"\n+ACCOUNTS = \"accounts\"\n+EMPLOYEES = \"employees\"\n+\n+\n+class DocTestConnection(ESConnection):\n+\n+    def __init__(self, query_language=\"sql\"):\n+        super(DocTestConnection, self).__init__(endpoint=ENDPOINT, query_language=query_language)\n+        self.set_connection()\n+\n+        settings = OutputSettings(table_format=\"psql\", is_vertical=False)\n+        self.formatter = Formatter(settings)\n+\n+    def process(self, statement):\n+        data = self.execute_query(statement, use_console=False)\n+        output = self.formatter.format_output(data)\n+        output = \"\\n\".join(output)\n+\n+        click.echo(output)\n+\n+\n+def pretty_print(s):\n+    try:\n+        d = json.loads(s)\n+        print(json.dumps(d, indent=2))\n+    except json.decoder.JSONDecodeError:\n+        print(s)\n+\n+\n+sql_cmd = DocTestConnection(query_language=\"sql\")\n+ppl_cmd = DocTestConnection(query_language=\"ppl\")\n+test_data_client = Elasticsearch([ENDPOINT], verify_certs=True)\n+\n+\n+def sql_cli_transform(s):\n+    return u'sql_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def ppl_cli_transform(s):\n+    return u'ppl_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def bash_transform(s):\n+    # TODO: add ppl support, be default cli uses sql\n+    if s.startswith(\"odfesql\"):\n+        s = re.search(r\"odfesql\\s+-q\\s+\\\"(.*?)\\\"\", s).group(1)\n+        return u'cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+    return (r'pretty_print(sh(\"\"\"%s\"\"\").stdout.decode(\"utf-8\"))' % s) + '\\n'\n+\n+\n+sql_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=sql_cli_transform)\n+\n+ppl_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=ppl_cli_transform)\n+\n+bash_parser = zc.customdoctests.DocTestParser(\n+    ps1=r'sh\\$', comment_prefix='#', transform=bash_transform)\n+\n+\n+def set_up_accounts(test):\n+    set_up(test)\n+    load_file(\"accounts.json\", index_name=ACCOUNTS)\n+\n+\n+def load_file(filename, index_name):\n+    filepath = \"./test_data/\" + filename\n+\n+    # generate iterable data\n+    def load_json():\n+        with open(filepath, \"r\") as f:\n+            for line in f:\n+                yield json.loads(line)\n+\n+    # Need to enable refresh, because the load won't be visible to search immediately\n+    # https://stackoverflow.com/questions/57840161/elasticsearch-python-bulk-helper-api-with-refresh\n+    helpers.bulk(test_data_client, load_json(), stats_only=True, index=index_name, refresh='wait_for')\n+\n+\n+def set_up(test):\n+    test.globs['sql_cmd'] = sql_cmd\n+    test.globs['ppl_cmd'] = ppl_cmd\n+\n+\n+def tear_down(test):\n+    # drop leftover tables after each test\n+    # TODO: delete all will potentially also delete AES FGAC metadata index\n+    test_data_client.indices.delete(index=[ACCOUNTS, EMPLOYEES], ignore_unavailable=True)\n+\n+\n+docsuite = partial(doctest.DocFileSuite,\n+                   tearDown=tear_down,\n+                   parser=sql_cli_parser,\n+                   optionflags=doctest.NORMALIZE_WHITESPACE | doctest.ELLIPSIS,\n+                   encoding='utf-8')\n+\n+\n+doctest_file = partial(os.path.join, 'docs')\n+\n+\n+def doctest_files(*items):\n+    return (doctest_file(item) for item in items)\n+\n+\n+class DocTests(unittest.TestSuite):\n+    def run(self, result, debug=False):\n+        super().run(result, debug)\n+\n+\n+def load_tests(loader, suite, ignore):\n+    tests = []\n+    # docs with bash-based examples\n+    for fn in doctest_files('ppl/curl.rst'): # TODO: Add 'sql/explain.rst' after codebase migration", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODY1NA=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NzA0OQ==", "bodyText": "Added category.json to help user setup doctest without touching the doctest core code", "url": "https://github.com/opendistro-for-elasticsearch/sql/pull/497#discussion_r432147049", "createdAt": "2020-05-28T21:57:33Z", "author": {"login": "zhongnansu"}, "path": "doctest/test_docs.py", "diffHunk": "@@ -0,0 +1,179 @@\n+# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\").\n+# You may not use this file except in compliance with the License.\n+# A copy of the License is located at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# or in the \"license\" file accompanying this file. This file is distributed\n+# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+# express or implied. See the License for the specific language governing\n+# permissions and limitations under the License.\n+\n+import doctest\n+import os\n+import zc.customdoctests\n+import json\n+import re\n+import random\n+import subprocess\n+import unittest\n+import click\n+\n+from functools import partial\n+from odfe_sql_cli.esconnection import ESConnection\n+from odfe_sql_cli.utils import OutputSettings\n+from odfe_sql_cli.formatter import Formatter\n+from elasticsearch import Elasticsearch, helpers\n+\n+ENDPOINT = \"http://localhost:9200\"\n+ACCOUNTS = \"accounts\"\n+EMPLOYEES = \"employees\"\n+\n+\n+class DocTestConnection(ESConnection):\n+\n+    def __init__(self, query_language=\"sql\"):\n+        super(DocTestConnection, self).__init__(endpoint=ENDPOINT, query_language=query_language)\n+        self.set_connection()\n+\n+        settings = OutputSettings(table_format=\"psql\", is_vertical=False)\n+        self.formatter = Formatter(settings)\n+\n+    def process(self, statement):\n+        data = self.execute_query(statement, use_console=False)\n+        output = self.formatter.format_output(data)\n+        output = \"\\n\".join(output)\n+\n+        click.echo(output)\n+\n+\n+def pretty_print(s):\n+    try:\n+        d = json.loads(s)\n+        print(json.dumps(d, indent=2))\n+    except json.decoder.JSONDecodeError:\n+        print(s)\n+\n+\n+sql_cmd = DocTestConnection(query_language=\"sql\")\n+ppl_cmd = DocTestConnection(query_language=\"ppl\")\n+test_data_client = Elasticsearch([ENDPOINT], verify_certs=True)\n+\n+\n+def sql_cli_transform(s):\n+    return u'sql_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def ppl_cli_transform(s):\n+    return u'ppl_cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+\n+\n+def bash_transform(s):\n+    # TODO: add ppl support, be default cli uses sql\n+    if s.startswith(\"odfesql\"):\n+        s = re.search(r\"odfesql\\s+-q\\s+\\\"(.*?)\\\"\", s).group(1)\n+        return u'cmd.process({0})'.format(repr(s.strip().rstrip(';')))\n+    return (r'pretty_print(sh(\"\"\"%s\"\"\").stdout.decode(\"utf-8\"))' % s) + '\\n'\n+\n+\n+sql_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=sql_cli_transform)\n+\n+ppl_cli_parser = zc.customdoctests.DocTestParser(\n+    ps1='od>', comment_prefix='#', transform=ppl_cli_transform)\n+\n+bash_parser = zc.customdoctests.DocTestParser(\n+    ps1=r'sh\\$', comment_prefix='#', transform=bash_transform)\n+\n+\n+def set_up_accounts(test):\n+    set_up(test)\n+    load_file(\"accounts.json\", index_name=ACCOUNTS)\n+\n+\n+def load_file(filename, index_name):\n+    filepath = \"./test_data/\" + filename\n+\n+    # generate iterable data\n+    def load_json():\n+        with open(filepath, \"r\") as f:\n+            for line in f:\n+                yield json.loads(line)\n+\n+    # Need to enable refresh, because the load won't be visible to search immediately\n+    # https://stackoverflow.com/questions/57840161/elasticsearch-python-bulk-helper-api-with-refresh\n+    helpers.bulk(test_data_client, load_json(), stats_only=True, index=index_name, refresh='wait_for')\n+\n+\n+def set_up(test):\n+    test.globs['sql_cmd'] = sql_cmd\n+    test.globs['ppl_cmd'] = ppl_cmd\n+\n+\n+def tear_down(test):\n+    # drop leftover tables after each test\n+    # TODO: delete all will potentially also delete AES FGAC metadata index\n+    test_data_client.indices.delete(index=[ACCOUNTS, EMPLOYEES], ignore_unavailable=True)\n+\n+\n+docsuite = partial(doctest.DocFileSuite,\n+                   tearDown=tear_down,\n+                   parser=sql_cli_parser,\n+                   optionflags=doctest.NORMALIZE_WHITESPACE | doctest.ELLIPSIS,\n+                   encoding='utf-8')\n+\n+\n+doctest_file = partial(os.path.join, 'docs')\n+\n+\n+def doctest_files(*items):\n+    return (doctest_file(item) for item in items)\n+\n+\n+class DocTests(unittest.TestSuite):\n+    def run(self, result, debug=False):\n+        super().run(result, debug)\n+\n+\n+def load_tests(loader, suite, ignore):\n+    tests = []\n+    # docs with bash-based examples\n+    for fn in doctest_files('ppl/curl.rst'): # TODO: Add 'sql/explain.rst' after codebase migration", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODY1NA=="}, "originalCommit": {"oid": "c9b863f333a13ecb17374c00d39aa9e77e9ba051"}, "originalPosition": 143}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2101, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}