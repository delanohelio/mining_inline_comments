{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2NTc0NTEz", "number": 17267, "title": "[TA] Add analyze tasks feature support", "bodyText": "Add analyze tasks feature support\n\n Implementation\n Test, Sample, Codesnippet\n CHANGELOG\n README\n\nfixes: #17248, #17249\nAlso, it includes some small changes for healthcare tests, such as renaming the test name.\nAPI-View: https://apiview.dev/Assemblies/Review/329cfc783b474d97891a5349e705feb4?diffRevisionId=b0b403fd04f7495b9b16cd3692ee5cf7&doc=False", "createdAt": "2020-11-06T07:57:41Z", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267", "merged": true, "mergeCommit": {"oid": "8e1d365a16c67b4f786fdc5800807ea518c52896"}, "closed": true, "closedAt": "2020-11-19T16:31:41Z", "author": {"login": "mssfang"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZnLUQAH2gAyNTE2NTc0NTEzOjdiMGUyNGM0ZDMyMzkwZGQ5YzJlYWM5MDBlYWI1MWZjZjEwNDU1OWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdeFD_jgH2gAyNTE2NTc0NTEzOmI4MTllNGYwMzdmOTEyYTM5ZGJhY2MzMzc3OGRkYjE2MDZjNjYxYzM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7b0e24c4d32390dd9c2eac900eab51fcf104559a", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/7b0e24c4d32390dd9c2eac900eab51fcf104559a", "committedDate": "2020-11-05T19:04:00Z", "message": "TA-Healthcare"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "446bb428456b154a9cdabf289e717f70b8ff3abe", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/446bb428456b154a9cdabf289e717f70b8ff3abe", "committedDate": "2020-11-05T19:13:15Z", "message": "remove checkstyle supppresion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ac3e30ec450d074ab4ef8a9a23e31f9a50b1703", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/5ac3e30ec450d074ab4ef8a9a23e31f9a50b1703", "committedDate": "2020-11-05T19:42:24Z", "message": "regenerate swagger ater a new change merged in"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c03aa751db4ebf08f2f64251cc0832fc569ce4ba", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/c03aa751db4ebf08f2f64251cc0832fc569ce4ba", "committedDate": "2020-11-05T22:49:24Z", "message": "transfer to laptop"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "968acb98bda24788fd1bcbbe172665d1743a1268", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/968acb98bda24788fd1bcbbe172665d1743a1268", "committedDate": "2020-11-06T00:20:45Z", "message": "cancellation is working now"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b5dbc8f48620263b1afbee87ad4de4adb22245b", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/1b5dbc8f48620263b1afbee87ad4de4adb22245b", "committedDate": "2020-11-06T03:37:11Z", "message": "address mari's most feedbacks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53e0d0e853a6233f613ad880281f3d5ff5732530", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/53e0d0e853a6233f613ad880281f3d5ff5732530", "committedDate": "2020-11-06T03:57:19Z", "message": "replace a wrong json file for async pagination test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53654d67c99d34aa8ea0e4f0f7214691799bb4aa", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/53654d67c99d34aa8ea0e4f0f7214691799bb4aa", "committedDate": "2020-11-06T07:56:07Z", "message": "init analyze tasks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d7935025b25fc9199f11aeff615d0dd30480ea3", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/8d7935025b25fc9199f11aeff615d0dd30480ea3", "committedDate": "2020-11-06T13:55:52Z", "message": "removed xxxTaskState class and TaskStete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c7f4ce29ca0fbdf6478bcf350e53737ae7da51b", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/5c7f4ce29ca0fbdf6478bcf350e53737ae7da51b", "committedDate": "2020-11-06T14:05:23Z", "message": "add changelog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0", "committedDate": "2020-11-06T17:57:33Z", "message": "resolve conflict and updates changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1NDY2NDU1", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-525466455", "createdAt": "2020-11-06T20:16:53Z", "commit": {"oid": "8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMDoxNjo1M1rOHu8RqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMDoxNjo1M1rOHu8RqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk4NDEwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            - Added support for healthcare analysis feature, it is a long-running operation, and the cancellation supported. \n          \n          \n            \n            - Added support for analyze tasks feature, It analyzes multiple tasks, such as, entity recognition, PII entity recognition \n          \n          \n            \n            and key phrases extraction simultaneously in a list of document.\n          \n          \n            \n            - Added support for healthcare analysis feature. Tt is represented as a long-running operation. Cancellation supported. \n          \n          \n            \n            - Added support for analyze multiple tasks (such as, entity recognition, PII entity recognition \n          \n          \n            \n            and key phrases extraction) simultaneously in a list of document.\n          \n      \n    \n    \n  \n\nmaybe?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r518984105", "createdAt": "2020-11-06T20:16:53Z", "author": {"login": "maririos"}, "path": "sdk/textanalytics/azure-ai-textanalytics/CHANGELOG.md", "diffHunk": "@@ -1,7 +1,9 @@\n # Release History\n ## 5.1.0-beta.3 (Unreleased)\n **New features**\n-- Added support for Healthcare analysis, it is a long-running operation, and the cancellation supported. \n+- Added support for healthcare analysis feature, it is a long-running operation, and the cancellation supported. \n+- Added support for analyze tasks feature, It analyzes multiple tasks, such as, entity recognition, PII entity recognition \n+and key phrases extraction simultaneously in a list of document.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/37c3bf13bac035908e1da6f876575cec7ce9f622", "committedDate": "2020-11-11T08:16:15Z", "message": "resolved conflict and add more tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NDA4MzY1", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-528408365", "createdAt": "2020-11-11T17:56:46Z", "commit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNzo1Njo0NlrOHxYN1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxODowNzo0MVrOHxYmgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTAyOQ==", "bodyText": "Seeing the same jobID here too - #17234 (comment)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521539029", "createdAt": "2020-11-11T17:56:46Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -132,21 +137,22 @@\n                 (activationResponse, pollingContext) ->\n                     monoError(logger, new RuntimeException(\"Use the `beginCancelHealthcareJob` to cancel the job\")),\n                 fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getHealthcareFluxPage(resultId,\n-                    finalIncludeStatistics == null ? false : finalIncludeStatistics, context))))\n+                    finalTop, finalSkip, finalIncludeStatistics, context))))\n             );\n         } catch (RuntimeException ex) {\n             return PollerFlux.error(ex);\n         }\n     }\n \n-    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, boolean showStats, Context context) {\n+    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, Integer top, Integer skip, Boolean showStats,\n+        Context context) {\n         return new PagedFlux<>(\n-            () -> getPage(null, jobID, showStats, context),\n-            continuationToken -> getPage(continuationToken, jobID, showStats, context));\n+            () -> getPage(null, jobID, top, skip, showStats, context),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg==", "bodyText": "Why was this changed to non-primitive?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521539382", "createdAt": "2020-11-11T17:57:14Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -132,21 +137,22 @@\n                 (activationResponse, pollingContext) ->\n                     monoError(logger, new RuntimeException(\"Use the `beginCancelHealthcareJob` to cancel the job\")),\n                 fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getHealthcareFluxPage(resultId,\n-                    finalIncludeStatistics == null ? false : finalIncludeStatistics, context))))\n+                    finalTop, finalSkip, finalIncludeStatistics, context))))\n             );\n         } catch (RuntimeException ex) {\n             return PollerFlux.error(ex);\n         }\n     }\n \n-    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, boolean showStats, Context context) {\n+    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, Integer top, Integer skip, Boolean showStats,\n+        Context context) {\n         return new PagedFlux<>(\n-            () -> getPage(null, jobID, showStats, context),\n-            continuationToken -> getPage(continuationToken, jobID, showStats, context));\n+            () -> getPage(null, jobID, top, skip, showStats, context),\n+            continuationToken -> getPage(continuationToken, jobID, top, skip, showStats, context));\n     }\n \n-    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID,\n-        boolean showStats, Context context) {\n+    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID, Integer top, Integer skip,\n+        Boolean showStats, Context context) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDMxNA==", "bodyText": "Is this still a service bug?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521540314", "createdAt": "2020-11-11T17:58:51Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TestUtils.java", "diffHunk": "@@ -667,82 +685,165 @@ static RecognizeHealthcareEntitiesResult getRecognizeHealthcareEntitiesResult2()\n         return healthcareEntitiesResult;\n     }\n \n-    static AnalyzeTasksResult getExpectedAnalyzeTasksResult() {\n+    /**\n+     * RecognizeEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizeEntitiesResultCollection getRecognizeEntitiesResultCollection() {\n         // Categorized Entities\n-        IterableStream<CategorizedEntity> categorizedEntityList1 = new IterableStream<>(getCategorizedEntitiesList1());\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.\n         //TextDocumentStatistics textDocumentStatistics1 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult1 = new RecognizeEntitiesResult(\"0\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList1, null));\n-        IterableStream<CategorizedEntity> categorizedEntityList2 = new IterableStream<>(\n-            asList(\n-                new CategorizedEntity(\"Microsoft\", EntityCategory.ORGANIZATION, null, 0.0, 0),\n-                new CategorizedEntity(\"employee\", EntityCategory.PERSON_TYPE, null, 0.0, 10),\n-                new CategorizedEntity(\"859\", EntityCategory.QUANTITY, \"Number\", 0.0, 28),\n-                new CategorizedEntity(\"98\", EntityCategory.QUANTITY, \"Number\", 0.0, 32),\n-                new CategorizedEntity(\"0987\", EntityCategory.QUANTITY, \"Number\", 0.0, 35),\n-                new CategorizedEntity(\"API\", EntityCategory.SKILL, null, 0.0, 61)\n-            )\n-        );\n         //TextDocumentStatistics textDocumentStatistics2 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult2 = new RecognizeEntitiesResult(\"1\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList2, null));\n-\n-        RecognizeEntitiesResultCollection recognizeEntitiesResults = new RecognizeEntitiesResultCollection(\n-            asList(recognizeEntitiesResult1, recognizeEntitiesResult2),\n-            \"2020-04-01\", null\n+        return new RecognizeEntitiesResultCollection(\n+            asList(new RecognizeEntitiesResult(\"0\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesList1()), null)),\n+                new RecognizeEntitiesResult(\"1\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesForPiiInput()), null))\n+            ), \"2020-04-01\", null);\n             //new TextDocumentBatchStatistics(2, 2, 0, 2)\n-        );\n+    }\n \n+    /**\n+     * RecognizePiiEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizePiiEntitiesResultCollection getRecognizePiiEntitiesResultCollection() {\n         // PII\n-        PiiEntityCollection piiEntityCollection1 = new PiiEntityCollection(new IterableStream<>(new ArrayList<>()),\n-            \"I had a wonderful trip to Seattle last week.\", null);\n-        PiiEntityCollection piiEntityCollection2 = new PiiEntityCollection(new IterableStream<>(getPiiEntitiesList1()),\n-            \"********* employee with ssn *********** is using our awesome API's.\", null);\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDc1MQ==", "bodyText": "Consider adding service bugs to issues for better follow up.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521540751", "createdAt": "2020-11-11T17:59:32Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TestUtils.java", "diffHunk": "@@ -667,82 +685,165 @@ static RecognizeHealthcareEntitiesResult getRecognizeHealthcareEntitiesResult2()\n         return healthcareEntitiesResult;\n     }\n \n-    static AnalyzeTasksResult getExpectedAnalyzeTasksResult() {\n+    /**\n+     * RecognizeEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizeEntitiesResultCollection getRecognizeEntitiesResultCollection() {\n         // Categorized Entities\n-        IterableStream<CategorizedEntity> categorizedEntityList1 = new IterableStream<>(getCategorizedEntitiesList1());\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.\n         //TextDocumentStatistics textDocumentStatistics1 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult1 = new RecognizeEntitiesResult(\"0\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList1, null));\n-        IterableStream<CategorizedEntity> categorizedEntityList2 = new IterableStream<>(\n-            asList(\n-                new CategorizedEntity(\"Microsoft\", EntityCategory.ORGANIZATION, null, 0.0, 0),\n-                new CategorizedEntity(\"employee\", EntityCategory.PERSON_TYPE, null, 0.0, 10),\n-                new CategorizedEntity(\"859\", EntityCategory.QUANTITY, \"Number\", 0.0, 28),\n-                new CategorizedEntity(\"98\", EntityCategory.QUANTITY, \"Number\", 0.0, 32),\n-                new CategorizedEntity(\"0987\", EntityCategory.QUANTITY, \"Number\", 0.0, 35),\n-                new CategorizedEntity(\"API\", EntityCategory.SKILL, null, 0.0, 61)\n-            )\n-        );\n         //TextDocumentStatistics textDocumentStatistics2 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult2 = new RecognizeEntitiesResult(\"1\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList2, null));\n-\n-        RecognizeEntitiesResultCollection recognizeEntitiesResults = new RecognizeEntitiesResultCollection(\n-            asList(recognizeEntitiesResult1, recognizeEntitiesResult2),\n-            \"2020-04-01\", null\n+        return new RecognizeEntitiesResultCollection(\n+            asList(new RecognizeEntitiesResult(\"0\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesList1()), null)),\n+                new RecognizeEntitiesResult(\"1\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesForPiiInput()), null))\n+            ), \"2020-04-01\", null);\n             //new TextDocumentBatchStatistics(2, 2, 0, 2)\n-        );\n+    }\n \n+    /**\n+     * RecognizePiiEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizePiiEntitiesResultCollection getRecognizePiiEntitiesResultCollection() {\n         // PII\n-        PiiEntityCollection piiEntityCollection1 = new PiiEntityCollection(new IterableStream<>(new ArrayList<>()),\n-            \"I had a wonderful trip to Seattle last week.\", null);\n-        PiiEntityCollection piiEntityCollection2 = new PiiEntityCollection(new IterableStream<>(getPiiEntitiesList1()),\n-            \"********* employee with ssn *********** is using our awesome API's.\", null);\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDMxNA=="}, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0NTM0Nw==", "bodyText": "Is this still true?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521545347", "createdAt": "2020-11-11T18:07:41Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TextAnalyticsClientTestBase.java", "diffHunk": "@@ -741,7 +778,8 @@ static void validatePiiEntitiesResultCollection(boolean showStatistics,\n         validateTextAnalyticsResult(showStatistics, expected, actual, (expectedItem, actualItem) -> {\n             final PiiEntityCollection expectedPiiEntityCollection = expectedItem.getEntities();\n             final PiiEntityCollection actualPiiEntityCollection = actualItem.getEntities();\n-            assertEquals(expectedPiiEntityCollection.getRedactedText(), actualPiiEntityCollection.getRedactedText());\n+            //TODO: redacted text is empty, which is wrong", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 93}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "febe0be40b3f9e6888855474c84ed4ea82caa470", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/febe0be40b3f9e6888855474c84ed4ea82caa470", "committedDate": "2020-11-13T04:12:25Z", "message": "regenerate code base on swagger 5ef5a597b3f2342bfd254ed79b97b2fe160e50a1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a250604670607a86842206b1b3b410a0d3053c8", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/9a250604670607a86842206b1b3b410a0d3053c8", "committedDate": "2020-11-13T07:50:11Z", "message": "address feedbacks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee4ae09a5400778314324eb2edcfa613e394fd3e", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/ee4ae09a5400778314324eb2edcfa613e394fd3e", "committedDate": "2020-11-13T17:35:42Z", "message": "improve PLAYBACK test speed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cd58ae8ce2c449318bc4cb66638fe9cdf4cfb713", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/cd58ae8ce2c449318bc4cb66638fe9cdf4cfb713", "committedDate": "2020-11-13T22:40:17Z", "message": "checekstyle issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1c02b5396f091de61c641478522ad2fe28c96c2", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/d1c02b5396f091de61c641478522ad2fe28c96c2", "committedDate": "2020-11-17T23:13:09Z", "message": "update Analyze API endpoint"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyODkyNzU2", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-532892756", "createdAt": "2020-11-17T23:18:12Z", "commit": {"oid": "d1c02b5396f091de61c641478522ad2fe28c96c2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzoxODoxM1rOH1PcBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzoxODoxM1rOH1PcBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4OTUxMA==", "bodyText": "by default, options.getPollInterval() ==> DEFAULT_POLL_INTERVAL, so if options is null, we use the defaultValue, if options is not null we use custom polling interval if user has set it, otherwise, use the DEFAULT_POLL_INTERVAL.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525589510", "createdAt": "2020-11-17T23:18:13Z", "author": {"login": "mssfang"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -74,12 +75,17 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1c02b5396f091de61c641478522ad2fe28c96c2"}, "originalPosition": 24}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/c94420c6346fcdb35a10f7bc1c0358cb58b72228", "committedDate": "2020-11-17T23:37:05Z", "message": "add issue link to TODO lists"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTA3NTUw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-532907550", "createdAt": "2020-11-17T23:51:56Z", "commit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo1MTo1N1rOH1QNfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDoxNjowM1rOH1Qu4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjE3NA==", "bodyText": "We should keep this consistent https://github.com/Azure/azure-sdk-for-java/pull/17267/files#diff-7fbca8ee7335dc54eff4896d71e776956633f83aa352534da69dca097fefe74fR9", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525602174", "createdAt": "2020-11-17T23:51:57Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/CHANGELOG.md", "diffHunk": "@@ -1,7 +1,9 @@\n # Release History\n ## 5.1.0-beta.3 (Unreleased)\n **New features**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjgyMg==", "bodyText": "This could be better done at the central place at options level  like here - https://github.com/Azure/azure-sdk-for-java/blob/master/sdk/formrecognizer/azure-ai-formrecognizer/src/main/java/com/azure/ai/formrecognizer/models/RecognizeContentOptions.java#L60", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525602822", "createdAt": "2020-11-17T23:53:42Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -74,12 +75,17 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4OTUxMA=="}, "originalCommit": {"oid": "d1c02b5396f091de61c641478522ad2fe28c96c2"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzAzNw==", "bodyText": "nit: Do you need this comment?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525603037", "createdAt": "2020-11-17T23:54:14Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -74,12 +75,17 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();\n             }\n+            // the variable used in the lambda function has to be 'final' or 'effective final'.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNjE1OQ==", "bodyText": "I don't think from an API design it would make sense to have a potential null positional argument. If this argument could be null/ignored why not have it in the options then?\nI think I have seen Java API's wanting to expose primitives whenever possible.\n@JonathanGiles Do you know if we have a strong opinion on  this?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525606159", "createdAt": "2020-11-18T00:02:56Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -132,21 +137,22 @@\n                 (activationResponse, pollingContext) ->\n                     monoError(logger, new RuntimeException(\"Use the `beginCancelHealthcareJob` to cancel the job\")),\n                 fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getHealthcareFluxPage(resultId,\n-                    finalIncludeStatistics == null ? false : finalIncludeStatistics, context))))\n+                    finalTop, finalSkip, finalIncludeStatistics, context))))\n             );\n         } catch (RuntimeException ex) {\n             return PollerFlux.error(ex);\n         }\n     }\n \n-    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, boolean showStats, Context context) {\n+    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, Integer top, Integer skip, Boolean showStats,\n+        Context context) {\n         return new PagedFlux<>(\n-            () -> getPage(null, jobID, showStats, context),\n-            continuationToken -> getPage(continuationToken, jobID, showStats, context));\n+            () -> getPage(null, jobID, top, skip, showStats, context),\n+            continuationToken -> getPage(continuationToken, jobID, top, skip, showStats, context));\n     }\n \n-    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID,\n-        boolean showStats, Context context) {\n+    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID, Integer top, Integer skip,\n+        Boolean showStats, Context context) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg=="}, "originalCommit": {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNzIwOA==", "bodyText": "nit: Consider putting into a function instead of the redundant checks?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525607208", "createdAt": "2020-11-18T00:05:49Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -109,12 +115,16 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();\n             }\n             final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n             return new PollerFlux<>(\n-                DEFAULT_POLL_DURATION,\n+                pollInterval,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNzg4Mw==", "bodyText": "Is there a way to catch the potential exception that could be caused by the creation of UUID from string?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525607883", "createdAt": "2020-11-18T00:07:50Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -196,12 +208,13 @@\n             null);\n     }\n \n-    PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(UUID jobId, Context context) {\n+    PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n         try {\n-            Objects.requireNonNull(jobId, \"'jobId' is required and cannot be null.\");\n+            Objects.requireNonNull(healthTaskId, \"'healthTaskId' is required and cannot be null.\");\n             return new PollerFlux<>(\n-                DEFAULT_POLL_DURATION,\n-                activationOperation(service.cancelHealthJobWithResponseAsync(jobId,\n+                options == null ? DEFAULT_POLL_INTERVAL : options.getPollInterval(),\n+                activationOperation(service.cancelHealthJobWithResponseAsync(UUID.fromString(healthTaskId),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwODI1OA==", "bodyText": "Similar comments as health care async client.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525608258", "createdAt": "2020-11-18T00:09:07Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwODczMA==", "bodyText": "Can this check happen before the function call, one less code jump?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525608730", "createdAt": "2020-11-18T00:10:16Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTE1NA==", "bodyText": "Do we need a TODO here?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609154", "createdAt": "2020-11-18T00:11:23Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }\n+        return new JobManifestTasks()\n+            .setEntityRecognitionTasks(options.getEntitiesRecognitionTasks() == null ? null\n+                : options.getEntitiesRecognitionTasks().stream().map(\n+                    entitiesTask -> {\n+                        if (entitiesTask == null) {\n+                            return null;\n+                        }\n+                        final EntitiesTask entitiesTaskImpl = new EntitiesTask();\n+                        final com.azure.ai.textanalytics.models.EntitiesTaskParameters entitiesTaskParameters =\n+                            entitiesTask.getParameters();\n+                        if (entitiesTaskParameters == null) {\n+                            return entitiesTaskImpl;\n+                        }\n+                        entitiesTaskImpl.setParameters(\n+                            new EntitiesTaskParameters().setModelVersion(entitiesTaskParameters.getModelVersion()));\n+                        return entitiesTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setEntityRecognitionPiiTasks(options.getPiiEntitiesRecognitionTasks() == null ? null\n+                : options.getPiiEntitiesRecognitionTasks().stream().map(\n+                    piiEntitiesTask -> {\n+                        if (piiEntitiesTask == null) {\n+                            return null;\n+                        }\n+                        final PiiTask piiTaskImpl = new PiiTask();\n+                        final com.azure.ai.textanalytics.models.PiiTaskParameters piiTaskParameters =\n+                            piiEntitiesTask.getParameters();\n+                        if (piiTaskParameters == null) {\n+                            return piiTaskImpl;\n+                        }\n+                        piiTaskImpl.setParameters(\n+                            new PiiTaskParameters()\n+                                .setModelVersion(piiTaskParameters.getModelVersion())\n+                                .setDomain(PiiTaskParametersDomain.fromString(\n+                                    piiTaskParameters.getDomain() == null ? null\n+                                        : piiTaskParameters.getDomain().toString())));\n+                        return piiTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setKeyPhraseExtractionTasks(options.getKeyPhrasesExtractionTasks() == null ? null\n+                : options.getKeyPhrasesExtractionTasks().stream().map(\n+                    keyPhrasesTask -> {\n+                        if (keyPhrasesTask == null) {\n+                            return null;\n+                        }\n+                        final com.azure.ai.textanalytics.models.KeyPhrasesTaskParameters keyPhrasesTaskParameters\n+                            = keyPhrasesTask.getParameters();\n+                        final KeyPhrasesTask keyPhrasesTaskImpl = new KeyPhrasesTask();\n+                        if (keyPhrasesTaskParameters == null) {\n+                            return keyPhrasesTaskImpl;\n+                        }\n+                        keyPhrasesTaskImpl.setParameters(\n+                            new KeyPhrasesTaskParameters().setModelVersion(keyPhrasesTaskParameters.getModelVersion()));\n+                        return keyPhrasesTaskImpl;\n+                    }).collect(Collectors.toList()));\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<TextAnalyticsOperationResult>>\n+        activationOperation(Mono<TextAnalyticsOperationResult> operationResult) {\n+        return pollingContext -> {\n+            try {\n+                return operationResult.onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PollResponse<TextAnalyticsOperationResult>>>\n+        pollingOperation(Function<String, Mono<Response<AnalyzeJobState>>> pollingFunction) {\n+        return pollingContext -> {\n+            try {\n+                final PollResponse<TextAnalyticsOperationResult> operationResultPollResponse =\n+                    pollingContext.getLatestResponse();\n+//                final UUID resultUUID = UUID.fromString(operationResultPollResponse.getValue().getResultId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTU5Mg==", "bodyText": "Just confirming, cancelling == in progress?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609592", "createdAt": "2020-11-18T00:12:44Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }\n+        return new JobManifestTasks()\n+            .setEntityRecognitionTasks(options.getEntitiesRecognitionTasks() == null ? null\n+                : options.getEntitiesRecognitionTasks().stream().map(\n+                    entitiesTask -> {\n+                        if (entitiesTask == null) {\n+                            return null;\n+                        }\n+                        final EntitiesTask entitiesTaskImpl = new EntitiesTask();\n+                        final com.azure.ai.textanalytics.models.EntitiesTaskParameters entitiesTaskParameters =\n+                            entitiesTask.getParameters();\n+                        if (entitiesTaskParameters == null) {\n+                            return entitiesTaskImpl;\n+                        }\n+                        entitiesTaskImpl.setParameters(\n+                            new EntitiesTaskParameters().setModelVersion(entitiesTaskParameters.getModelVersion()));\n+                        return entitiesTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setEntityRecognitionPiiTasks(options.getPiiEntitiesRecognitionTasks() == null ? null\n+                : options.getPiiEntitiesRecognitionTasks().stream().map(\n+                    piiEntitiesTask -> {\n+                        if (piiEntitiesTask == null) {\n+                            return null;\n+                        }\n+                        final PiiTask piiTaskImpl = new PiiTask();\n+                        final com.azure.ai.textanalytics.models.PiiTaskParameters piiTaskParameters =\n+                            piiEntitiesTask.getParameters();\n+                        if (piiTaskParameters == null) {\n+                            return piiTaskImpl;\n+                        }\n+                        piiTaskImpl.setParameters(\n+                            new PiiTaskParameters()\n+                                .setModelVersion(piiTaskParameters.getModelVersion())\n+                                .setDomain(PiiTaskParametersDomain.fromString(\n+                                    piiTaskParameters.getDomain() == null ? null\n+                                        : piiTaskParameters.getDomain().toString())));\n+                        return piiTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setKeyPhraseExtractionTasks(options.getKeyPhrasesExtractionTasks() == null ? null\n+                : options.getKeyPhrasesExtractionTasks().stream().map(\n+                    keyPhrasesTask -> {\n+                        if (keyPhrasesTask == null) {\n+                            return null;\n+                        }\n+                        final com.azure.ai.textanalytics.models.KeyPhrasesTaskParameters keyPhrasesTaskParameters\n+                            = keyPhrasesTask.getParameters();\n+                        final KeyPhrasesTask keyPhrasesTaskImpl = new KeyPhrasesTask();\n+                        if (keyPhrasesTaskParameters == null) {\n+                            return keyPhrasesTaskImpl;\n+                        }\n+                        keyPhrasesTaskImpl.setParameters(\n+                            new KeyPhrasesTaskParameters().setModelVersion(keyPhrasesTaskParameters.getModelVersion()));\n+                        return keyPhrasesTaskImpl;\n+                    }).collect(Collectors.toList()));\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<TextAnalyticsOperationResult>>\n+        activationOperation(Mono<TextAnalyticsOperationResult> operationResult) {\n+        return pollingContext -> {\n+            try {\n+                return operationResult.onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PollResponse<TextAnalyticsOperationResult>>>\n+        pollingOperation(Function<String, Mono<Response<AnalyzeJobState>>> pollingFunction) {\n+        return pollingContext -> {\n+            try {\n+                final PollResponse<TextAnalyticsOperationResult> operationResultPollResponse =\n+                    pollingContext.getLatestResponse();\n+//                final UUID resultUUID = UUID.fromString(operationResultPollResponse.getValue().getResultId());\n+                final String resultID = operationResultPollResponse.getValue().getResultId();\n+                return pollingFunction.apply(resultID)\n+                    .flatMap(modelResponse -> processAnalyzedModelResponse(modelResponse, operationResultPollResponse))\n+                    .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PagedFlux<AnalyzeTasksResult>>>\n+        fetchingOperation(Function<String, Mono<PagedFlux<AnalyzeTasksResult>>> fetchingFunction) {\n+        return pollingContext -> {\n+            try {\n+//                final UUID resultUUID = UUID.fromString(pollingContext.getLatestResponse().getValue().getResultId());\n+                final String resultUUID = pollingContext.getLatestResponse().getValue().getResultId();\n+                return fetchingFunction.apply(resultUUID);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PagedIterable<AnalyzeTasksResult>>>\n+        fetchingOperationIterable(Function<String, Mono<PagedIterable<AnalyzeTasksResult>>> fetchingFunction) {\n+        return pollingContext -> {\n+            try {\n+//                final UUID resultUUID = UUID.fromString(pollingContext.getLatestResponse().getValue().getResultId());\n+                final String resultUUID = pollingContext.getLatestResponse().getValue().getResultId();\n+                return fetchingFunction.apply(resultUUID);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    PagedFlux<AnalyzeTasksResult> getAnalyzeOperationFluxPage(String analyzeTasksId, Integer top, Integer skip,\n+        Boolean showStats, Context context) {\n+        return new PagedFlux<>(\n+            () -> getPage(null, analyzeTasksId, top, skip, showStats, context),\n+            continuationToken -> getPage(continuationToken, analyzeTasksId, top, skip, showStats, context));\n+    }\n+\n+    Mono<PagedResponse<AnalyzeTasksResult>> getPage(String continuationToken, String analyzeTasksId, Integer top,\n+        Integer skip, Boolean showStats, Context context) {\n+        if (continuationToken != null) {\n+            final Map<String, Integer> continuationTokenMap = parseNextLink(continuationToken);\n+            final Integer topValue = continuationTokenMap.getOrDefault(\"$top\", null);\n+            final Integer skipValue = continuationTokenMap.getOrDefault(\"$skip\", null);\n+            return service.analyzeStatusWithResponseAsync(analyzeTasksId, showStats, topValue, skipValue, context)\n+                .map(this::toAnalyzeTasksPagedResponse)\n+                .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+        } else {\n+            return service.analyzeStatusWithResponseAsync(analyzeTasksId, showStats, top, skip, context)\n+                .map(this::toAnalyzeTasksPagedResponse)\n+                .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+        }\n+    }\n+\n+    private PagedResponse<AnalyzeTasksResult> toAnalyzeTasksPagedResponse(Response<AnalyzeJobState> response) {\n+        final AnalyzeJobState analyzeJobState = response.getValue();\n+        return new PagedResponseBase<Void, AnalyzeTasksResult>(\n+            response.getRequest(),\n+            response.getStatusCode(),\n+            response.getHeaders(),\n+            Arrays.asList(toAnalyzeTasks(analyzeJobState)),\n+            analyzeJobState.getNextLink(),\n+            null);\n+    }\n+\n+    private AnalyzeTasksResult toAnalyzeTasks(AnalyzeJobState analyzeJobState) {\n+        TasksStateTasks tasksStateTasks = analyzeJobState.getTasks();\n+        final List<TasksStateTasksEntityRecognitionPiiTasksItem> piiTasksItems =\n+            tasksStateTasks.getEntityRecognitionPiiTasks();\n+        final List<TasksStateTasksEntityRecognitionTasksItem> entityRecognitionTasksItems =\n+            tasksStateTasks.getEntityRecognitionTasks();\n+        final List<TasksStateTasksKeyPhraseExtractionTasksItem> keyPhraseExtractionTasks =\n+            tasksStateTasks.getKeyPhraseExtractionTasks();\n+        List<RecognizeEntitiesResultCollection> entitiesResultCollections = null;\n+        List<RecognizePiiEntitiesResultCollection> piiEntitiesResultCollections = null;\n+        List<ExtractKeyPhrasesResultCollection> keyPhrasesResultCollections = null;\n+        if (!CoreUtils.isNullOrEmpty(entityRecognitionTasksItems)) {\n+            entitiesResultCollections = entityRecognitionTasksItems.stream()\n+                .map(taskItem -> toRecognizeEntitiesResultCollectionResponse(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        if (!CoreUtils.isNullOrEmpty(piiTasksItems)) {\n+            piiEntitiesResultCollections = piiTasksItems.stream()\n+                .map(taskItem -> toRecognizePiiEntitiesResultCollection(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        if (!CoreUtils.isNullOrEmpty(keyPhraseExtractionTasks)) {\n+            keyPhrasesResultCollections = keyPhraseExtractionTasks.stream()\n+                .map(taskItem -> toExtractKeyPhrasesResultCollection(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        final AnalyzeTasksResult analyzeTasksResult = new AnalyzeTasksResult(\n+            analyzeJobState.getJobId(),\n+            analyzeJobState.getCreatedDateTime(),\n+            analyzeJobState.getLastUpdateDateTime(),\n+            toJobState(analyzeJobState.getStatus()),\n+            analyzeJobState.getDisplayName(),\n+            analyzeJobState.getExpirationDateTime());\n+        AnalyzeTasksResultPropertiesHelper.setErrors(analyzeTasksResult,\n+            analyzeJobState.getErrors().stream().map(Utility::toTextAnalyticsError).collect(Collectors.toList()));\n+        AnalyzeTasksResultPropertiesHelper.setStatistics(analyzeTasksResult,\n+            analyzeJobState.getStatistics() == null ? null : toBatchStatistics(analyzeJobState.getStatistics()));\n+        AnalyzeTasksResultPropertiesHelper.setCompleted(analyzeTasksResult, tasksStateTasks.getCompleted());\n+        AnalyzeTasksResultPropertiesHelper.setFailed(analyzeTasksResult, tasksStateTasks.getFailed());\n+        AnalyzeTasksResultPropertiesHelper.setInProgress(analyzeTasksResult, tasksStateTasks.getInProgress());\n+        AnalyzeTasksResultPropertiesHelper.setTotal(analyzeTasksResult, tasksStateTasks.getTotal());\n+        AnalyzeTasksResultPropertiesHelper.setEntityRecognitionTasks(analyzeTasksResult, entitiesResultCollections);\n+        AnalyzeTasksResultPropertiesHelper.setEntityRecognitionPiiTasks(analyzeTasksResult,\n+            piiEntitiesResultCollections);\n+        AnalyzeTasksResultPropertiesHelper.setKeyPhraseExtractionTasks(analyzeTasksResult, keyPhrasesResultCollections);\n+        return analyzeTasksResult;\n+    }\n+\n+    private Mono<PollResponse<TextAnalyticsOperationResult>> processAnalyzedModelResponse(\n+        Response<AnalyzeJobState> analyzeJobStateResponse,\n+        PollResponse<TextAnalyticsOperationResult> operationResultPollResponse) {\n+\n+        LongRunningOperationStatus status;\n+        switch (analyzeJobStateResponse.getValue().getStatus()) {\n+            case NOT_STARTED:\n+            case CANCELLING:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 358}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTk5OQ==", "bodyText": "remove", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609999", "createdAt": "2020-11-18T00:14:04Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDIzOA==", "bodyText": "This naming is too generic, should we consider renaming?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610238", "createdAt": "2020-11-18T00:14:43Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginAnalyze#Iterable-AnalyzeTasksOptions}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     *\n+     * @return A {@link PollerFlux} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedFlux} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.\n      */\n     @ServiceMethod(returns = ReturnType.COLLECTION)\n-    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(UUID jobId) {\n-        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(jobId, Context.NONE);\n+    public PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDU0Nw==", "bodyText": "There s no Job Id required in the parameters?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610547", "createdAt": "2020-11-18T00:15:34Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsClient.java", "diffHunk": "@@ -907,22 +908,55 @@ public AnalyzeSentimentResultCollection analyzeSentimentBatch(Iterable<String> d\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#UUID-Context}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions-Context}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      * @param context Additional context that is passed through the Http pipeline during the service call.\n      *\n      * @return A {@link SyncPoller} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public SyncPoller<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n+        return client.analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, context)\n+                   .getSyncPoller();\n+    }\n+\n+    // Analyze\n+\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginAnalyze#Iterable-AnalyzeTasksOptions-Context}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     *\n+     * @return A {@link SyncPoller} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedIterable} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDcyMw==", "bodyText": "Needs update/", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610723", "createdAt": "2020-11-18T00:16:03Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginAnalyze#Iterable-AnalyzeTasksOptions}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     *\n+     * @return A {@link PollerFlux} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedFlux} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTIwNDU3", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-532920457", "createdAt": "2020-11-18T00:23:36Z", "commit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDoyMzozNlrOH1Q5EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDoyMzozNlrOH1Q5EA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMzMyOA==", "bodyText": "Do we have this mentioned in the docs anywhere?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525613328", "createdAt": "2020-11-18T00:23:36Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TextAnalyticsClientTestBase.java", "diffHunk": "@@ -620,26 +665,52 @@ void healthcareLroRunner(BiConsumer<List<TextDocumentInput>, RecognizeHealthcare\n             asList(\n                 new TextDocumentInput(\"0\", HEALTHCARE_INPUTS.get(0)),\n                 new TextDocumentInput(\"1\", HEALTHCARE_INPUTS.get(1))),\n-            new RecognizeHealthcareEntityOptions().setIncludeStatistics(true));\n+            new RecognizeHealthcareEntityOptions().setIncludeStatistics(true).setPollInterval(durationTestMode));\n     }\n \n     void healthcareLroPaginationRunner(\n-        BiConsumer<List<TextDocumentInput>, RecognizeHealthcareEntityOptions> testRunner) {\n+        BiConsumer<List<TextDocumentInput>, RecognizeHealthcareEntityOptions> testRunner, int totalDocuments) {\n         List<TextDocumentInput> documents = new ArrayList<>();\n-        // Service has 20 as the default size per page. So there will be 2 remaining page in the next page link\n-        for (int i = 0; i < 22; i++) {\n+        // Service has 10 as the default size per page. So there will be 2 remaining page in the next page link", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228"}, "originalPosition": 121}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8802740487adbe907e5e94b4599c71e90b5b413c", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/8802740487adbe907e5e94b4599c71e90b5b413c", "committedDate": "2020-11-18T05:11:01Z", "message": "renaming some APIs and address feedbacks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae88549e02ddb4022762f65d83ff23e7ff497823", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/ae88549e02ddb4022762f65d83ff23e7ff497823", "committedDate": "2020-11-18T05:17:39Z", "message": "make final class if possible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "047f2b51481a51d91de56770bd5e33e272840640", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/047f2b51481a51d91de56770bd5e33e272840640", "committedDate": "2020-11-18T05:32:08Z", "message": "make HealthcareEntityCollection final class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "201e02596788d346212d0bf129459a7c388d6791", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/201e02596788d346212d0bf129459a7c388d6791", "committedDate": "2020-11-18T22:59:38Z", "message": "service already fixed the nextLink to @nextLink"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzOTcwNTI4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#pullrequestreview-533970528", "createdAt": "2020-11-18T23:42:44Z", "commit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQyMzo0Mjo0NFrOH2GxrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMDowMToyOFrOH2HM3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5NjE3Mg==", "bodyText": "Can this be put into a function to avoid repeated code?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526496172", "createdAt": "2020-11-18T23:42:44Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,393 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyzeTasks(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setTasks(getJobManifestTasks(options)).setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) ->\n+                    Mono.error(new RuntimeException(\"Cancellation is not supported.\")),\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeTasksIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setTasks(getJobManifestTasks(options)).setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5OTU0Mg==", "bodyText": "Dos needs to be updated for potential NPE.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526499542", "createdAt": "2020-11-18T23:51:45Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsClient.java", "diffHunk": "@@ -907,22 +905,52 @@ public AnalyzeSentimentResultCollection analyzeSentimentBatch(Iterable<String> d\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#UUID-Context}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelHealthcareTask#String-RecognizeHealthcareEntityOptions-Context}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      * @param context Additional context that is passed through the Http pipeline during the service call.\n      *\n      * @return A {@link SyncPoller} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n-     * @throws NullPointerException If {@code jobId} is null.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public SyncPoller<TextAnalyticsOperationResult, Void> beginCancelHealthcareTask(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n+        return client.analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, context)\n+                   .getSyncPoller();\n+    }\n+\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginAnalyzeTasks#Iterable-AnalyzeTasksOptions-Context}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     *\n+     * @return A {@link SyncPoller} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedIterable} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMTE3Mg==", "bodyText": "Just confirming, we are keeping some of the methods/mnamings as is since for this preview we just want to expose the generated methods/code as is. Correct?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526501172", "createdAt": "2020-11-18T23:56:01Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/models/AnalyzeTasksResult.java", "diffHunk": "@@ -0,0 +1,251 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.models;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+\n+import java.time.OffsetDateTime;\n+import java.util.List;\n+\n+/**\n+ * The AnalyzeTasksResult model.\n+ */\n+public final class AnalyzeTasksResult extends JobMetadata {\n+\n+    /*\n+     * The errors property.\n+     */\n+    private List<TextAnalyticsError> errors;\n+\n+    /*\n+     * if showStats=true was specified in the request this field will contain\n+     * information about the request payload.\n+     */\n+    private TextDocumentBatchStatistics statistics;\n+\n+    /*\n+     * The completed property.\n+     */\n+    private int completed;\n+\n+    /*\n+     * The failed property.\n+     */\n+    private int failed;\n+\n+    /*\n+     * The inProgress property.\n+     */\n+    private int inProgress;\n+\n+    /*\n+     * The total property.\n+     */\n+    private int total;\n+\n+    /*\n+     * The entityRecognitionTasks property.\n+     */\n+    private List<RecognizeEntitiesResultCollection> entityRecognitionTasks;\n+\n+    /*\n+     * The entityRecognitionPiiTasks property.\n+     */\n+    private List<RecognizePiiEntitiesResultCollection> entityRecognitionPiiTasks;\n+\n+    /*\n+     * The keyPhraseExtractionTasks property.\n+     */\n+    private List<ExtractKeyPhrasesResultCollection> keyPhraseExtractionTasks;\n+\n+    static {\n+        AnalyzeTasksResultPropertiesHelper.setAccessor(\n+            new AnalyzeTasksResultPropertiesHelper.AnalyzeTasksResultAccessor() {\n+                @Override\n+                public void setErrors(AnalyzeTasksResult analyzeTasksResult, List<TextAnalyticsError> errors) {\n+                    analyzeTasksResult.setErrors(errors);\n+                }\n+\n+                @Override\n+                public void setStatistics(AnalyzeTasksResult analyzeTasksResult,\n+                    TextDocumentBatchStatistics statistics) {\n+                    analyzeTasksResult.setStatistics(statistics);\n+                }\n+\n+                @Override\n+                public void setCompleted(AnalyzeTasksResult analyzeTasksResult, int completed) {\n+                    analyzeTasksResult.setCompleted(completed);\n+                }\n+\n+                @Override\n+                public void setFailed(AnalyzeTasksResult analyzeTasksResult, int failed) {\n+                    analyzeTasksResult.setFailed(failed);\n+                }\n+\n+                @Override\n+                public void setInProgress(AnalyzeTasksResult analyzeTasksResult, int inProgress) {\n+                    analyzeTasksResult.setInProgress(inProgress);\n+                }\n+\n+                @Override\n+                public void setTotal(AnalyzeTasksResult analyzeTasksResult, int total) {\n+                    analyzeTasksResult.setTotal(total);\n+                }\n+\n+                @Override\n+                public void setEntityRecognitionTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<RecognizeEntitiesResultCollection> entityRecognitionTasks) {\n+                    analyzeTasksResult.setEntityRecognitionTasks(entityRecognitionTasks);\n+                }\n+\n+                @Override\n+                public void setEntityRecognitionPiiTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<RecognizePiiEntitiesResultCollection> entityRecognitionPiiTasks) {\n+                    analyzeTasksResult.setEntityRecognitionPiiTasks(entityRecognitionPiiTasks);\n+                }\n+\n+                @Override\n+                public void setKeyPhraseExtractionTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<ExtractKeyPhrasesResultCollection> keyPhraseExtractionTasks) {\n+                    analyzeTasksResult.setKeyPhraseExtractionTasks(keyPhraseExtractionTasks);\n+                }\n+            });\n+    }\n+\n+    /**\n+     * Creates a {@link AnalyzeTasksResult} model that describes analyzed tasks result.\n+     *\n+     * @param analyzeTasksId the analyze tasks identification.\n+     * @param createdDateTime the created time of the job.\n+     * @param lastUpdateDateTime the last updated time of the job.\n+     * @param status the job status.\n+     * @param displayName the display name.\n+     * @param expirationDateTime the expiration time of the job.\n+     */\n+    public AnalyzeTasksResult(String analyzeTasksId, OffsetDateTime createdDateTime, OffsetDateTime lastUpdateDateTime,\n+        JobState status, String displayName, OffsetDateTime expirationDateTime) {\n+        super(analyzeTasksId, createdDateTime, lastUpdateDateTime, status, displayName, expirationDateTime);\n+    }\n+\n+    /**\n+     * Get the errors property: The errors property.\n+     *\n+     * @return the errors value.\n+     */\n+    public List<TextAnalyticsError> getErrors() {\n+        return this.errors;\n+    }\n+\n+    /**\n+     * Get the statistics property: if showStats=true was specified in the request this field will contain information\n+     * about the request payload.\n+     *\n+     * @return the statistics value.\n+     */\n+    public TextDocumentBatchStatistics getStatistics() {\n+        return this.statistics;\n+    }\n+\n+    /**\n+     * Get the completed property: The completed property.\n+     *\n+     * @return the completed value.\n+     */\n+    public int getCompleted() {\n+        return this.completed;\n+    }\n+\n+    /**\n+     * Get the failed property: The failed property.\n+     *\n+     * @return the failed value.\n+     */\n+    public int getFailed() {\n+        return this.failed;\n+    }\n+\n+    /**\n+     * Get the inProgress property: The inProgress property.\n+     *\n+     * @return the inProgress value.\n+     */\n+    public int getInProgress() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMjE5Mw==", "bodyText": "Should PiiTaskParameters model name be plural, ignore if genrated code exposed.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526502193", "createdAt": "2020-11-18T23:58:52Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/models/PiiTask.java", "diffHunk": "@@ -0,0 +1,35 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.models;\n+\n+import com.azure.core.annotation.Fluent;\n+\n+/** The PiiTask model. */\n+@Fluent\n+public final class PiiTask {\n+    /*\n+     * The parameters property.\n+     */\n+    private PiiTaskParameters parameters = new PiiTaskParameters();\n+\n+    /**\n+     * Get the parameters property: The parameters property.\n+     *\n+     * @return the parameters value.\n+     */\n+    public PiiTaskParameters getParameters() {\n+        return this.parameters;\n+    }\n+\n+    /**\n+     * Set the parameters property: The parameters property.\n+     *\n+     * @param parameters the parameters value to set.\n+     * @return the PiiTask object itself.\n+     */\n+    public PiiTask setParameters(PiiTaskParameters parameters) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMzEzMg==", "bodyText": "why a special foldrer for lro?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526503132", "createdAt": "2020-11-19T00:01:28Z", "author": {"login": "samvaity"}, "path": "sdk/textanalytics/azure-ai-textanalytics/src/samples/java/com/azure/ai/textanalytics/lro/AnalyzeTasks.java", "diffHunk": "@@ -0,0 +1,151 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.lro;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "201e02596788d346212d0bf129459a7c388d6791"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d52decd09201e5c05dd1de225ad86139a24f2113", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/d52decd09201e5c05dd1de225ad86139a24f2113", "committedDate": "2020-11-19T01:01:20Z", "message": "add NPE and add live test setup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "668650b09ef6dc97c2643259252dc6bde0261ae5", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/668650b09ef6dc97c2643259252dc6bde0261ae5", "committedDate": "2020-11-19T02:31:12Z", "message": "address last feedbacks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b819e4f037f912a39dbacc33778ddb1606c661c3", "author": {"user": {"login": "mssfang", "name": "Shawn Fang"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/b819e4f037f912a39dbacc33778ddb1606c661c3", "committedDate": "2020-11-19T16:08:51Z", "message": "update readme content and links"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 129, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}