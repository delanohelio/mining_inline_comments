{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxNjAxODkz", "number": 17952, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMTozODo1M1rOFCE3GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMTozODo1M1rOFCE3GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM3NzIxMTEzOnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMTozODo1M1rOIBC0vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMjoyNzoyOVrOIBD98g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk2NTc1Nw==", "bodyText": "Good point - I think it might be useful to see whether we can make that decision based on \"avg.\" document size? Like < 1 KB don't push down pruning - but for larger documents do it?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17952#discussion_r537965757", "createdAt": "2020-12-08T01:38:53Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -51,7 +51,21 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     CosmosScan(config.asScala.toMap, this.processedPredicates.get.cosmosParametrizedQuery)\n   }\n \n+  /**\n+    * Applies column pruning w.r.t. the given requiredSchema.\n+    *\n+    * Implementation should try its best to prune the unnecessary columns or nested fields, but it's\n+    * also OK to do the pruning partially, e.g., a data source may not be able to prune nested\n+    * fields, and only prune top-level columns.\n+    *\n+    * Note that, {@link Scan# readSchema ( )} implementation should take care of the column\n+    * pruning applied here.\n+    */\n   override def pruneColumns(requiredSchema: StructType): Unit = {\n-    // TODO moderakh add projection to the query\n+    // TODO moderakh: we need to decide whether do a push down or not on the projection", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "48830b5a58c04347b13ef12f36bf965aeb26583b"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk2NTg1MA==", "bodyText": "Not blocking of course...", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17952#discussion_r537965850", "createdAt": "2020-12-08T01:39:10Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -51,7 +51,21 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     CosmosScan(config.asScala.toMap, this.processedPredicates.get.cosmosParametrizedQuery)\n   }\n \n+  /**\n+    * Applies column pruning w.r.t. the given requiredSchema.\n+    *\n+    * Implementation should try its best to prune the unnecessary columns or nested fields, but it's\n+    * also OK to do the pruning partially, e.g., a data source may not be able to prune nested\n+    * fields, and only prune top-level columns.\n+    *\n+    * Note that, {@link Scan# readSchema ( )} implementation should take care of the column\n+    * pruning applied here.\n+    */\n   override def pruneColumns(requiredSchema: StructType): Unit = {\n-    // TODO moderakh add projection to the query\n+    // TODO moderakh: we need to decide whether do a push down or not on the projection", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk2NTc1Nw=="}, "originalCommit": {"oid": "48830b5a58c04347b13ef12f36bf965aeb26583b"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk4NDQ5OA==", "bodyText": "Thanks for the suggestion. good idea. I will look into this.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17952#discussion_r537984498", "createdAt": "2020-12-08T02:27:29Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -51,7 +51,21 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     CosmosScan(config.asScala.toMap, this.processedPredicates.get.cosmosParametrizedQuery)\n   }\n \n+  /**\n+    * Applies column pruning w.r.t. the given requiredSchema.\n+    *\n+    * Implementation should try its best to prune the unnecessary columns or nested fields, but it's\n+    * also OK to do the pruning partially, e.g., a data source may not be able to prune nested\n+    * fields, and only prune top-level columns.\n+    *\n+    * Note that, {@link Scan# readSchema ( )} implementation should take care of the column\n+    * pruning applied here.\n+    */\n   override def pruneColumns(requiredSchema: StructType): Unit = {\n-    // TODO moderakh add projection to the query\n+    // TODO moderakh: we need to decide whether do a push down or not on the projection", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk2NTc1Nw=="}, "originalCommit": {"oid": "48830b5a58c04347b13ef12f36bf965aeb26583b"}, "originalPosition": 16}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2632, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}