{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY2MjE4NzAx", "number": 13979, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNToyNTowMlrOEYGtlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTozMzo0NlrOEYG70A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNzExMjUyOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-changefeed/src/main/java/com/azure/storage/blob/changefeed/Changefeed.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNToyNTowMlrOHAQr-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTo1NDowOFrOHAR3Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNTQ1MA==", "bodyText": "endTime is/should be optional parameter. How do we handle that case? I.e. we should default to lastConsumable if end time is null . Also if end time is null we shouldn't populate it in the cursor.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470035450", "createdAt": "2020-08-13T15:25:02Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-changefeed/src/main/java/com/azure/storage/blob/changefeed/Changefeed.java", "diffHunk": "@@ -100,25 +116,24 @@\n     private Mono<OffsetDateTime> populateLastConsumable() {\n         /* We can keep the entire metadata file in memory since it is expected to only be a few hundred bytes. */\n         return DownloadUtils.downloadToByteArray(this.client, METADATA_SEGMENT_PATH)\n+            .flatMap(DownloadUtils::parseJson)\n             /* Parse JSON for last consumable. */\n-            .flatMap(json -> {\n-                try {\n-                    JsonNode jsonNode = MAPPER.reader().readTree(json);\n-                    this.lastConsumable = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n-                    if (this.lastConsumable.isBefore(endTime)) {\n-                        this.safeEndTime = this.lastConsumable;\n-                    }\n-                    return Mono.just(this.lastConsumable);\n-                } catch (IOException e) {\n-                    return FluxUtil.monoError(logger, new UncheckedIOException(e));\n+            .flatMap(jsonNode -> {\n+                /* Last consumable time. The latest time the changefeed can safely be read from.*/\n+                OffsetDateTime lastConsumableTime = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n+                /* Soonest time between lastConsumable and endTime. */\n+                OffsetDateTime safeEndTime = this.endTime;\n+                if (lastConsumableTime.isBefore(endTime)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA1MTI1Mw==", "bodyText": "I think ChangefeedFactory deals with this - we default to the Max time\nOffsetDateTime start = startTime == null ? OffsetDateTime.MIN : startTime;\nOffsetDateTime end = endTime == null ? OffsetDateTime.MAX : endTime;\n    return new Changefeed(this.client, start, end, null, segmentFactory);", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470051253", "createdAt": "2020-08-13T15:48:44Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-changefeed/src/main/java/com/azure/storage/blob/changefeed/Changefeed.java", "diffHunk": "@@ -100,25 +116,24 @@\n     private Mono<OffsetDateTime> populateLastConsumable() {\n         /* We can keep the entire metadata file in memory since it is expected to only be a few hundred bytes. */\n         return DownloadUtils.downloadToByteArray(this.client, METADATA_SEGMENT_PATH)\n+            .flatMap(DownloadUtils::parseJson)\n             /* Parse JSON for last consumable. */\n-            .flatMap(json -> {\n-                try {\n-                    JsonNode jsonNode = MAPPER.reader().readTree(json);\n-                    this.lastConsumable = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n-                    if (this.lastConsumable.isBefore(endTime)) {\n-                        this.safeEndTime = this.lastConsumable;\n-                    }\n-                    return Mono.just(this.lastConsumable);\n-                } catch (IOException e) {\n-                    return FluxUtil.monoError(logger, new UncheckedIOException(e));\n+            .flatMap(jsonNode -> {\n+                /* Last consumable time. The latest time the changefeed can safely be read from.*/\n+                OffsetDateTime lastConsumableTime = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n+                /* Soonest time between lastConsumable and endTime. */\n+                OffsetDateTime safeEndTime = this.endTime;\n+                if (lastConsumableTime.isBefore(endTime)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNTQ1MA=="}, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA1MTgxNg==", "bodyText": "I feel like if endTime is null, the user just wants to go forever so I don't see the issue in doing this", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470051816", "createdAt": "2020-08-13T15:49:32Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-changefeed/src/main/java/com/azure/storage/blob/changefeed/Changefeed.java", "diffHunk": "@@ -100,25 +116,24 @@\n     private Mono<OffsetDateTime> populateLastConsumable() {\n         /* We can keep the entire metadata file in memory since it is expected to only be a few hundred bytes. */\n         return DownloadUtils.downloadToByteArray(this.client, METADATA_SEGMENT_PATH)\n+            .flatMap(DownloadUtils::parseJson)\n             /* Parse JSON for last consumable. */\n-            .flatMap(json -> {\n-                try {\n-                    JsonNode jsonNode = MAPPER.reader().readTree(json);\n-                    this.lastConsumable = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n-                    if (this.lastConsumable.isBefore(endTime)) {\n-                        this.safeEndTime = this.lastConsumable;\n-                    }\n-                    return Mono.just(this.lastConsumable);\n-                } catch (IOException e) {\n-                    return FluxUtil.monoError(logger, new UncheckedIOException(e));\n+            .flatMap(jsonNode -> {\n+                /* Last consumable time. The latest time the changefeed can safely be read from.*/\n+                OffsetDateTime lastConsumableTime = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n+                /* Soonest time between lastConsumable and endTime. */\n+                OffsetDateTime safeEndTime = this.endTime;\n+                if (lastConsumableTime.isBefore(endTime)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNTQ1MA=="}, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA1NDczOQ==", "bodyText": "great. sounds good.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470054739", "createdAt": "2020-08-13T15:54:08Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-changefeed/src/main/java/com/azure/storage/blob/changefeed/Changefeed.java", "diffHunk": "@@ -100,25 +116,24 @@\n     private Mono<OffsetDateTime> populateLastConsumable() {\n         /* We can keep the entire metadata file in memory since it is expected to only be a few hundred bytes. */\n         return DownloadUtils.downloadToByteArray(this.client, METADATA_SEGMENT_PATH)\n+            .flatMap(DownloadUtils::parseJson)\n             /* Parse JSON for last consumable. */\n-            .flatMap(json -> {\n-                try {\n-                    JsonNode jsonNode = MAPPER.reader().readTree(json);\n-                    this.lastConsumable = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n-                    if (this.lastConsumable.isBefore(endTime)) {\n-                        this.safeEndTime = this.lastConsumable;\n-                    }\n-                    return Mono.just(this.lastConsumable);\n-                } catch (IOException e) {\n-                    return FluxUtil.monoError(logger, new UncheckedIOException(e));\n+            .flatMap(jsonNode -> {\n+                /* Last consumable time. The latest time the changefeed can safely be read from.*/\n+                OffsetDateTime lastConsumableTime = OffsetDateTime.parse(jsonNode.get(\"lastConsumable\").asText());\n+                /* Soonest time between lastConsumable and endTime. */\n+                OffsetDateTime safeEndTime = this.endTime;\n+                if (lastConsumableTime.isBefore(endTime)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNTQ1MA=="}, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNzE0Mjg1OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroObject.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTozMjoxNlrOHAQ-0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTo1NTowN1rOHAR50g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MDI3NQ==", "bodyText": "I'd go back to ObjectIndex. Avro doesn't know it's used in CF context. It's supposed to be general purpose parser.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470040275", "createdAt": "2020-08-13T15:32:16Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroObject.java", "diffHunk": "@@ -35,8 +42,8 @@ public long getBlockOffset() {\n     /**\n      * @return The index of the object in the block.\n      */\n-    public long getObjectBlockIndex() {\n-        return objectBlockIndex;\n+    public long getEventIndex() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA1NTM3OA==", "bodyText": "done", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470055378", "createdAt": "2020-08-13T15:55:07Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroObject.java", "diffHunk": "@@ -35,8 +42,8 @@ public long getBlockOffset() {\n     /**\n      * @return The index of the object in the block.\n      */\n-    public long getObjectBlockIndex() {\n-        return objectBlockIndex;\n+    public long getEventIndex() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MDI3NQ=="}, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNzE0ODk2OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTozMzo0NlrOHARCsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTo1NToxMVrOHAR6DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTI2Ng==", "bodyText": "maybe this should be called beginIndex or beginObjectIndex. Threshold sounds more like upper boundary.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470041266", "createdAt": "2020-08-13T15:33:46Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroParser.java", "diffHunk": "@@ -106,31 +103,26 @@ private void onFilteredHeader(Object header) {\n \n         /* On reading the header, read a block. */\n         if (!partialRead) { /* Only do this if we are reading the stream from start to finish. */\n-            onBlock(-1L);\n+            onBlock(0L);\n         }\n     }\n \n     /**\n      * Block handler.\n      *\n-     * @param index The object index after which to start aggregating events in the block.\n+     * @param threshold The object index after which to start aggregating events in the block.\n      *                         By default this is 0 to collect all objects in the block.\n      */\n-    private void onBlock(Object index) {\n+    private void onBlock(Object threshold) {\n         /* On reading the block, read another block. */\n-        AvroSchema.checkType(\"objectBlockIndex\", index, Long.class);\n-        long threshold = (Long) index;\n+        AvroSchema.checkType(\"threshold\", threshold, Long.class);\n \n-        this.blockOffset = this.state.getSourceOffset();\n-        this.objectBlockIndex = 0;\n-        AvroBlockSchema blockSchema = new AvroBlockSchema(\n+        final AvroBlockSchema blockSchema = new AvroBlockSchema(\n             this.objectType,\n+            (Long) threshold,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA1NTQzNg==", "bodyText": "done", "url": "https://github.com/Azure/azure-sdk-for-java/pull/13979#discussion_r470055436", "createdAt": "2020-08-13T15:55:11Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-internal-avro/src/main/java/com/azure/storage/internal/avro/implementation/AvroParser.java", "diffHunk": "@@ -106,31 +103,26 @@ private void onFilteredHeader(Object header) {\n \n         /* On reading the header, read a block. */\n         if (!partialRead) { /* Only do this if we are reading the stream from start to finish. */\n-            onBlock(-1L);\n+            onBlock(0L);\n         }\n     }\n \n     /**\n      * Block handler.\n      *\n-     * @param index The object index after which to start aggregating events in the block.\n+     * @param threshold The object index after which to start aggregating events in the block.\n      *                         By default this is 0 to collect all objects in the block.\n      */\n-    private void onBlock(Object index) {\n+    private void onBlock(Object threshold) {\n         /* On reading the block, read another block. */\n-        AvroSchema.checkType(\"objectBlockIndex\", index, Long.class);\n-        long threshold = (Long) index;\n+        AvroSchema.checkType(\"threshold\", threshold, Long.class);\n \n-        this.blockOffset = this.state.getSourceOffset();\n-        this.objectBlockIndex = 0;\n-        AvroBlockSchema blockSchema = new AvroBlockSchema(\n+        final AvroBlockSchema blockSchema = new AvroBlockSchema(\n             this.objectType,\n+            (Long) threshold,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTI2Ng=="}, "originalCommit": {"oid": "149da3fcaf78dde9fc1f7650ad38cd89e7e64185"}, "originalPosition": 38}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1728, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}