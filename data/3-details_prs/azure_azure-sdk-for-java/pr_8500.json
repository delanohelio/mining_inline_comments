{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgwNDg0NzA5", "number": 8500, "title": "Nio copy", "bodyText": "", "createdAt": "2020-02-26T20:20:27Z", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500", "merged": true, "mergeCommit": {"oid": "74ee16a5c8d11cb3bce1b5a41e258ceba738f0bc"}, "closed": true, "closedAt": "2020-03-06T19:51:40Z", "author": {"login": "rickle-msft"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcIMRJcAH2gAyMzgwNDg0NzA5OjJlZmUyYzExNWU3MGM0ZjA3YTY0NjdlNWZmM2VjODNhNTFlMmQ2NWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcLFhdJgFqTM3MDU4MjQzMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2efe2c115e70c4f07a6467e5ff3ec83a51e2d65d", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/2efe2c115e70c4f07a6467e5ff3ec83a51e2d65d", "committedDate": "2020-02-26T19:55:04Z", "message": "Worked on copy and some helpers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c4d256ccd316b1be5f939e2de7be7ba0f5978cf4", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/c4d256ccd316b1be5f939e2de7be7ba0f5978cf4", "committedDate": "2020-02-26T20:03:17Z", "message": "Added copy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e07f1e8e12eca5de38b463157b86bd4cc2b3177", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/2e07f1e8e12eca5de38b463157b86bd4cc2b3177", "committedDate": "2020-02-26T20:11:30Z", "message": "More tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e3ca5a5a95c3fe2c945e755ba58ee406f0e1bbc", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/4e3ca5a5a95c3fe2c945e755ba58ee406f0e1bbc", "committedDate": "2020-02-26T20:11:58Z", "message": "Cleanup and recordings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/7297ab8ac6d23abe0320a90a958976358c45e20e", "committedDate": "2020-02-26T20:12:37Z", "message": "Pom/style/resources cleanup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MjE1MzM2", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-365215336", "createdAt": "2020-02-26T20:23:47Z", "commit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoyMzo0N1rOFu65og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoyMzo0N1rOFu65og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc0Mzg0Mg==", "bodyText": "revert", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r384743842", "createdAt": "2020-02-26T20:23:47Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-common/pom.xml", "diffHunk": "@@ -41,7 +41,7 @@\n     <dependency>\n       <groupId>com.azure</groupId>\n       <artifactId>azure-core</artifactId>\n-      <version>1.2.0</version> <!-- {x-version-update;com.azure:azure-core;dependency} -->\n+      <version>1.3.0-beta.1</version> <!-- {x-version-update;com.azure:azure-core;dependency} -->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/3bf83d19a92b5aec5f890152e811949d6f3b28e1", "committedDate": "2020-02-26T21:39:53Z", "message": "Reverted core dependency"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MjQxOTY5", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-365241969", "createdAt": "2020-02-26T21:06:52Z", "commit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTowNjo1MlrOFu8N4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDowNTo0N1rOFvA3hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc2NTQxMA==", "bodyText": "I know this isnt part of this particular PR but do you think it might be useful to catch the specific Error Code as well here?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r384765410", "createdAt": "2020-02-26T21:06:52Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -261,27 +270,22 @@ public void createDirectory(Path path, FileAttribute<?>... fileAttributes) throw\n         }\n         fileAttributes = fileAttributes == null ? new FileAttribute<?>[0] : fileAttributes;\n \n-        // Get the destination for the directory and it's parent container.\n+        // Get the destination for the directory.\n         BlobClient client = ((AzurePath) path).toBlobClient();\n-        BlobContainerClient containerClient = ((AzureFileSystem) path.getFileSystem()).getBlobServiceClient()\n-            .getBlobContainerClient(client.getContainerName());\n \n-        // Determine the path for the parent directory blob. This is the parent path without the root.\n+        // Validate that we are not trying to create a root.\n         Path root = path.getRoot();\n         if (root != null && root.equals(path)) {\n             throw Utility.logError(logger, new IOException(\"Creating a root directory is not supported.\"));\n         }\n-        Path prefix = root == null ? path.getParent() : root.relativize(path).getParent();\n \n         // Check if parent exists. If it does, atomically check if a file already exists and create a new dir if not.\n-        if (checkParentDirectoryExists(containerClient, prefix)) {\n+        if (checkParentDirectoryExists(path)) {\n             try {\n                 List<FileAttribute<?>> attributeList = new ArrayList<>(Arrays.asList(fileAttributes));\n                 BlobHttpHeaders headers = Utility.extractHttpHeaders(attributeList, logger);\n                 Map<String, String> metadata = Utility.convertAttributesToMetadata(attributeList);\n-                metadata = prepareMetadataForDirectory(metadata);\n-                client.getAppendBlobClient().createWithResponse(headers, metadata,\n-                    new BlobRequestConditions().setIfNoneMatch(\"*\"), null, null);\n+                putDirectoryBlob(client, headers, metadata, new BlobRequestConditions().setIfNoneMatch(\"*\"));\n             } catch (BlobStorageException e) {\n                 if (e.getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgzOTQ5MA==", "bodyText": "Would it be helpful to a user to separate these checks so they know which is illegal?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r384839490", "createdAt": "2020-02-26T23:59:04Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -325,13 +369,184 @@ public void delete(Path path) throws IOException {\n     }\n \n     /**\n+     * As stated in the nio docs, this method is not atomic. More specifically, the checks necessary to validate the\n+     * inputs and state of the file system are not atomic with the actual copying of data. If the copy is triggered,\n+     * the copy itself is atomic and only a complete copy will ever be left at the destination.\n+     *\n+     * In addition to those in the nio javadocs, this method has the following requirements for successful completion.\n+     * {@link StandardCopyOption#COPY_ATTRIBUTES} must be passed as it is impossible not to copy blob properties;\n+     * if this option is not passed, an {@link UnsupportedOperationException} will be thrown. Neither the source nor the\n+     * destination can be a root directory; if either is a root directory, an {@link IllegalArgumentException} will be\n+     * thrown. The parent directory of the destination must at least weakly exist; if it does not, an\n+     * {@link IOException} will be thrown. The only supported option other than\n+     * {@link StandardCopyOption#COPY_ATTRIBUTES} is {@link StandardCopyOption#REPLACE_EXISTING}; the presence of any\n+     * other option will result in an {@link UnsupportedOperationException}.\n+     *\n+     * This method supports both virtual and concrete directories as both the source and destination. Unlike when\n+     * creating a directory, the existence of a virtual directory at the destination will cause this operation to fail.\n+     * This is in order to prevent the possibility of overwriting a non-empty virtual directory with a file. Still, as\n+     * mentioned above, this check is not atomic with the creation of the resultant directory.\n+     *\n      * {@inheritDoc}\n+     * @see #createDirectory(Path, FileAttribute[]) for more information about directory existence.\n      */\n     @Override\n-    public void copy(Path path, Path path1, CopyOption... copyOptions) throws IOException {\n+    public void copy(Path source, Path destination, CopyOption... copyOptions) throws IOException {\n+        // Validate instance types.\n+        if (!(source instanceof AzurePath && destination instanceof AzurePath)) {\n+            throw Utility.logError(logger, new IllegalArgumentException(\"This provider cannot operate on subtypes of \"\n+                + \"Path other than AzurePath\"));\n+        }\n+\n+        // If paths point to the same file, operation is a no-op.\n+        if (source.equals(destination)) {\n+            return;\n+        }\n+\n+        // Read and validate options.\n+        // Remove accepted options as we find them. Anything left we don't support.\n+        boolean replaceExisting = false;\n+        List<CopyOption> optionsList = new ArrayList<>(Arrays.asList(copyOptions));\n+        if (!optionsList.contains(StandardCopyOption.COPY_ATTRIBUTES)) {\n+            throw Utility.logError(logger, new UnsupportedOperationException(\"StandardCopyOption.COPY_ATTRIBUTES \"\n+                + \"must be specified as the service will always copy file attributes.\"));\n+        }\n+        optionsList.remove(StandardCopyOption.COPY_ATTRIBUTES);\n+        if (optionsList.contains(StandardCopyOption.REPLACE_EXISTING)) {\n+            replaceExisting = true;\n+            optionsList.remove(StandardCopyOption.REPLACE_EXISTING);\n+        }\n+        if (!optionsList.isEmpty()) {\n+            throw Utility.logError(logger, new UnsupportedOperationException(\"Unsupported copy option found. Only \"\n+                + \"StandardCopyOption.COPY_ATTRIBUTES and StandareCopyOption.REPLACE_EXISTING are supported.\"));\n+        }\n \n+        // Validate paths.\n+        // Copying a root directory or attempting to create/overwrite a root directory is illegal.\n+        if (source.equals(source.getRoot()) || destination.equals(destination.getRoot())) {\n+            throw Utility.logError(logger, new IllegalArgumentException(String.format(\"Neither source nor destination \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTYwNw==", "bodyText": "Is there a reason for the duration being 30 here?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r384841607", "createdAt": "2020-02-27T00:05:47Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -325,13 +369,184 @@ public void delete(Path path) throws IOException {\n     }\n \n     /**\n+     * As stated in the nio docs, this method is not atomic. More specifically, the checks necessary to validate the\n+     * inputs and state of the file system are not atomic with the actual copying of data. If the copy is triggered,\n+     * the copy itself is atomic and only a complete copy will ever be left at the destination.\n+     *\n+     * In addition to those in the nio javadocs, this method has the following requirements for successful completion.\n+     * {@link StandardCopyOption#COPY_ATTRIBUTES} must be passed as it is impossible not to copy blob properties;\n+     * if this option is not passed, an {@link UnsupportedOperationException} will be thrown. Neither the source nor the\n+     * destination can be a root directory; if either is a root directory, an {@link IllegalArgumentException} will be\n+     * thrown. The parent directory of the destination must at least weakly exist; if it does not, an\n+     * {@link IOException} will be thrown. The only supported option other than\n+     * {@link StandardCopyOption#COPY_ATTRIBUTES} is {@link StandardCopyOption#REPLACE_EXISTING}; the presence of any\n+     * other option will result in an {@link UnsupportedOperationException}.\n+     *\n+     * This method supports both virtual and concrete directories as both the source and destination. Unlike when\n+     * creating a directory, the existence of a virtual directory at the destination will cause this operation to fail.\n+     * This is in order to prevent the possibility of overwriting a non-empty virtual directory with a file. Still, as\n+     * mentioned above, this check is not atomic with the creation of the resultant directory.\n+     *\n      * {@inheritDoc}\n+     * @see #createDirectory(Path, FileAttribute[]) for more information about directory existence.\n      */\n     @Override\n-    public void copy(Path path, Path path1, CopyOption... copyOptions) throws IOException {\n+    public void copy(Path source, Path destination, CopyOption... copyOptions) throws IOException {\n+        // Validate instance types.\n+        if (!(source instanceof AzurePath && destination instanceof AzurePath)) {\n+            throw Utility.logError(logger, new IllegalArgumentException(\"This provider cannot operate on subtypes of \"\n+                + \"Path other than AzurePath\"));\n+        }\n+\n+        // If paths point to the same file, operation is a no-op.\n+        if (source.equals(destination)) {\n+            return;\n+        }\n+\n+        // Read and validate options.\n+        // Remove accepted options as we find them. Anything left we don't support.\n+        boolean replaceExisting = false;\n+        List<CopyOption> optionsList = new ArrayList<>(Arrays.asList(copyOptions));\n+        if (!optionsList.contains(StandardCopyOption.COPY_ATTRIBUTES)) {\n+            throw Utility.logError(logger, new UnsupportedOperationException(\"StandardCopyOption.COPY_ATTRIBUTES \"\n+                + \"must be specified as the service will always copy file attributes.\"));\n+        }\n+        optionsList.remove(StandardCopyOption.COPY_ATTRIBUTES);\n+        if (optionsList.contains(StandardCopyOption.REPLACE_EXISTING)) {\n+            replaceExisting = true;\n+            optionsList.remove(StandardCopyOption.REPLACE_EXISTING);\n+        }\n+        if (!optionsList.isEmpty()) {\n+            throw Utility.logError(logger, new UnsupportedOperationException(\"Unsupported copy option found. Only \"\n+                + \"StandardCopyOption.COPY_ATTRIBUTES and StandareCopyOption.REPLACE_EXISTING are supported.\"));\n+        }\n \n+        // Validate paths.\n+        // Copying a root directory or attempting to create/overwrite a root directory is illegal.\n+        if (source.equals(source.getRoot()) || destination.equals(destination.getRoot())) {\n+            throw Utility.logError(logger, new IllegalArgumentException(String.format(\"Neither source nor destination \"\n+                + \"can be just a root directory. Source: %s. Destination: %s.\", source.toString(),\n+                destination.toString())));\n+        }\n+\n+        // Build clients.\n+        BlobClient sourceBlob = ((AzurePath) source).toBlobClient();\n+        BlobClient destinationBlob = ((AzurePath) destination).toBlobClient();\n+\n+        // Check destination is not a directory with children.\n+        DirectoryStatus destinationStatus = checkDirStatus(destinationBlob);\n+        if (destinationStatus.equals(DirectoryStatus.NOT_EMPTY)) {\n+            throw Utility.logError(logger, new DirectoryNotEmptyException(destination.toString()));\n+        }\n+\n+        /*\n+        Set request conditions if we should not overwrite. We can error out here if we know something already exists,\n+        but we will also create request conditions as a safeguard against overwriting something that was created\n+        between our check and put.\n+         */\n+        BlobRequestConditions requestConditions = null;\n+        if (!replaceExisting) {\n+            if (!destinationStatus.equals(DirectoryStatus.DOES_NOT_EXIST)) {\n+                throw Utility.logError(logger, new FileAlreadyExistsException(destination.toString()));\n+            }\n+            requestConditions = new BlobRequestConditions().setIfNoneMatch(\"*\");\n+        }\n+\n+        /*\n+        More path validation\n+\n+        Check that the parent for the destination exists. We only need to perform this check if there is nothing\n+        currently at the destination, for if the destination exists, its parent at least weakly exists and we\n+        can skip a service call.\n+         */\n+        if (destinationStatus.equals(DirectoryStatus.DOES_NOT_EXIST) && !checkParentDirectoryExists(destination)) {\n+            throw Utility.logError(logger, new IOException(\"Parent directory of destination location does not exist.\"\n+                + \"The destination path is therefore invalid. Destination: \" + destination.toString()));\n+        }\n+\n+        /*\n+        Try to copy the resource at the source path.\n+\n+        There is an optimization here where we try to do the copy first and only check for a virtual directory if\n+        there's a 404. In the cases of files and concrete directories, this only requires one request. For virtual\n+        directories, however, this requires three requests: failed copy, check status, create directory. Depending on\n+        customer scenarios and how many virtual directories they copy, it could be better to check the directory status\n+        first and then do a copy or createDir, which would always be two requests for all resource types.\n+         */\n+        try {\n+            SyncPoller<BlobCopyInfo, Void> pollResponse =\n+                destinationBlob.beginCopy(sourceBlob.getBlobUrl(), null, null, null, null, requestConditions, null);\n+            pollResponse.waitForCompletion(Duration.ofSeconds(30));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7297ab8ac6d23abe0320a90a958976358c45e20e"}, "originalPosition": 270}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MzM2NzMz", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-365336733", "createdAt": "2020-02-27T00:16:20Z", "commit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDoxNjoyMFrOFvBD1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDoxNjoyMFrOFvBD1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0NDc1Ng==", "bodyText": "why dont we add this repeated stuff to the setup and create global variables?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r384844756", "createdAt": "2020-02-27T00:16:20Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/test/java/com/azure/storage/blob/nio/AzureFileSystemProviderSpec.groovy", "diffHunk": "@@ -303,15 +306,509 @@ class AzureFileSystemProviderSpec extends APISpec {\n         props.getCacheControl() == \"myControl\"\n     }\n \n+    @Unroll\n+    def \"FileSystemProvider copy source\"() {\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def containerName = rootToContainer(rootName)\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)\n+\n+        // Generate clients to resources.\n+        def containerClient = primaryBlobServiceClient\n+            .getBlobContainerClient(containerName)\n+        def sourceClient = containerClient.getBlobClient(sourceName)\n+        def destinationClient = containerClient.getBlobClient(destName)\n+        def sourceChildClient = null\n+        def destChildClient = null\n+\n+        // Create resources as necessary\n+        if (sourceIsDir) {\n+            if (!sourceIsVirtual) {\n+                fs.provider().createDirectory(sourcePath)\n+            }\n+            if (!sourceEmpty) {\n+                def sourceChildName = generateBlobName()\n+                def sourceChildPath = fs.getPath(rootName, sourceName, sourceChildName)\n+                sourceChildClient = ((AzurePath) sourceChildPath).toBlobClient().getAppendBlobClient()\n+                sourceChildClient.create()\n+                destChildClient = ((AzurePath) fs.getPath(rootName, destName, sourceChildName)).toBlobClient()\n+                    .getAppendBlobClient()\n+            }\n+        } else { // source is file\n+            sourceClient.upload(defaultInputStream.get(), defaultDataSize)\n+        }\n+\n+        when:\n+        fs.provider().copy(sourcePath, destPath, StandardCopyOption.COPY_ATTRIBUTES)\n+\n+        then:\n+        // Check the source still exists.\n+        if (!sourceIsVirtual) {\n+            assert sourceClient.exists()\n+        } else {\n+            assert ((AzureFileSystemProvider) fs.provider()).checkDirectoryExists(sourceClient)\n+        }\n+\n+        // If the source was a file, check that the destination data matches the source.\n+        if (!sourceIsDir) {\n+            def outStream = new ByteArrayOutputStream()\n+            destinationClient.download(outStream)\n+            assert ByteBuffer.wrap(outStream.toByteArray()) == defaultData\n+        } else {\n+            // Check that the destination directory is concrete.\n+            assert destinationClient.exists()\n+            assert destinationClient.getProperties().getMetadata()\n+                .containsKey(AzureFileSystemProvider.DIR_METADATA_MARKER)\n+            if (!sourceEmpty) {\n+                // Check that source child still exists and was not copied to the destination.\n+                assert sourceChildClient.exists()\n+                assert !destChildClient.exists()\n+            }\n+        }\n+\n+        where:\n+        sourceIsDir | sourceIsVirtual | sourceEmpty\n+        false       | false           | false\n+        true        | true            | false\n+        true        | false           | true\n+        true        | false           | false\n+        // Can't have an empty virtual dir\n+    }\n+\n+    @Unroll\n+    def \"FileSystemProvider copy destination\"() {\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def containerName = rootToContainer(rootName)\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)\n+\n+        // Generate clients to resources.\n+        def containerClient = primaryBlobServiceClient\n+            .getBlobContainerClient(containerName)\n+        def sourceClient = containerClient.getBlobClient(sourceName)\n+        def destinationClient = containerClient.getBlobClient(destName)\n+\n+        // Create resources as necessary\n+        sourceClient.upload(defaultInputStream.get(), defaultDataSize)\n+        if (destinationExists) {\n+            if (destinationIsDir) {\n+                fs.provider().createDirectory(destPath)\n+            } else { // source is file\n+                destinationClient.upload(new ByteArrayInputStream(getRandomByteArray(20)), 20)\n+            }\n+        }\n+\n+        when:\n+        fs.provider().copy(sourcePath, destPath, StandardCopyOption.COPY_ATTRIBUTES,\n+            StandardCopyOption.REPLACE_EXISTING)\n+\n+        then:\n+        sourceClient.exists()\n+        def outStream = new ByteArrayOutputStream()\n+        destinationClient.download(outStream)\n+        assert ByteBuffer.wrap(outStream.toByteArray()) == defaultData\n+\n+        where:\n+        destinationExists | destinationIsDir\n+        false             | false\n+        true              | false\n+        true              | true\n+        // Can't have an empty virtual directory. Copying to a nonempty directory will fail.\n+    }\n+\n+    @Unroll\n+    def \"FileSystemProvider copy non empty dest\"() {\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def containerName = rootToContainer(rootName)\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)\n+\n+        // Generate clients to resources.\n+        def containerClient = primaryBlobServiceClient\n+            .getBlobContainerClient(containerName)\n+        def sourceClient = containerClient.getBlobClient(sourceName)\n+        def destinationClient = containerClient.getBlobClient(destName)\n+        def destChildClient\n+\n+        // Create resources as necessary\n+        sourceClient.upload(new ByteArrayInputStream(getRandomByteArray(20)), 20)\n+        if (!destinationIsVirtual) {\n+            fs.provider().createDirectory(destPath)\n+        }\n+        def childName = generateBlobName()\n+        destChildClient = ((AzurePath) fs.getPath(rootName, destName, childName)).toBlobClient()\n+        destChildClient.upload(defaultInputStream.get(), defaultDataSize)\n+\n+        when:\n+        fs.provider().copy(sourcePath, destPath, StandardCopyOption.COPY_ATTRIBUTES,\n+            StandardCopyOption.REPLACE_EXISTING) // Ensure that even when trying to replace_existing, we still fail.\n+\n+        then:\n+        thrown(DirectoryNotEmptyException)\n+        ((AzureFileSystemProvider) fs.provider()).checkDirectoryExists(destinationClient)\n+\n+        where:\n+        destinationIsVirtual | _\n+        true                 | _\n+        false                | _\n+    }\n+\n+    @Unroll\n+    def \"FileSystemProvider copy replace existing fail\"() {\n+        // The success case is tested by the \"copy destination\" test.\n+        // Testing replacing a virtual directory is in the \"non empty dest\" test as there can be no empty virtual dir.\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def containerName = rootToContainer(rootName)\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)\n+\n+        // Generate clients to resources.\n+        def containerClient = primaryBlobServiceClient\n+            .getBlobContainerClient(containerName)\n+        def sourceClient = containerClient.getBlobClient(sourceName)\n+        def destinationClient = containerClient.getBlobClient(destName)\n+\n+        // Create resources as necessary\n+        sourceClient.upload(new ByteArrayInputStream(getRandomByteArray(20)), 20)\n+        if (destinationIsDir) {\n+            fs.provider().createDirectory(destPath)\n+        } else {\n+            destinationClient.upload(defaultInputStream.get(), defaultDataSize)\n+        }\n+\n+        when:\n+        fs.provider().copy(sourcePath, destPath, StandardCopyOption.COPY_ATTRIBUTES)\n+\n+        then:\n+        thrown(FileAlreadyExistsException)\n+        if (destinationIsDir) {\n+            assert ((AzureFileSystemProvider) fs.provider()).checkDirectoryExists(destinationClient)\n+        } else {\n+            def outStream = new ByteArrayOutputStream()\n+            destinationClient.download(outStream)\n+            assert ByteBuffer.wrap(outStream.toByteArray()) == defaultData\n+        }\n+\n+        where:\n+        destinationIsDir | _\n+        true             | _\n+        false            | _\n+        // No need to test virtual directories. If they exist, they aren't empty and can't be overwritten anyway.\n+        // See above.\n+    }\n+\n+    def \"FileSystemProvider copy options fail\"() {\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1"}, "originalPosition": 270}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTE3Mzc2", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-369117376", "createdAt": "2020-03-04T20:58:31Z", "commit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo1ODozMVrOFx9ZMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo1ODozMVrOFx9ZMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkzMDQxNw==", "bodyText": "Can you throw this in the file's setup method? It looks mostly the same throughout.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#discussion_r387930417", "createdAt": "2020-03-04T20:58:31Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/test/java/com/azure/storage/blob/nio/AzureFileSystemProviderSpec.groovy", "diffHunk": "@@ -303,15 +306,509 @@ class AzureFileSystemProviderSpec extends APISpec {\n         props.getCacheControl() == \"myControl\"\n     }\n \n+    @Unroll\n+    def \"FileSystemProvider copy source\"() {\n+        setup:\n+        def fs = createFS(config)\n+\n+        // Generate resource names.\n+        // Don't use default directory to ensure we honor the root.\n+        def rootName = fs.getRootDirectories().last().toString()\n+        def containerName = rootToContainer(rootName)\n+        def sourceName = generateBlobName()\n+        def sourcePath = fs.getPath(rootName, sourceName)\n+        def destName = generateBlobName()\n+        def destPath = fs.getPath(rootName, destName)\n+\n+        // Generate clients to resources.\n+        def containerClient = primaryBlobServiceClient\n+            .getBlobContainerClient(containerName)\n+        def sourceClient = containerClient.getBlobClient(sourceName)\n+        def destinationClient = containerClient.getBlobClient(destName)\n+        def sourceChildClient = null\n+        def destChildClient = null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bf83d19a92b5aec5f890152e811949d6f3b28e1"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11224f2bc546bf26c9e3986dec155cee18f8d2f1", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/11224f2bc546bf26c9e3986dec155cee18f8d2f1", "committedDate": "2020-03-06T00:42:19Z", "message": "PR feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "191337e74eb8250cef93169f43097cee82c2586e", "author": {"user": {"login": "rickle-msft", "name": "Rick Ley"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/191337e74eb8250cef93169f43097cee82c2586e", "committedDate": "2020-03-06T18:49:23Z", "message": "Checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTgxMDM4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-370581038", "createdAt": "2020-03-06T19:42:53Z", "commit": {"oid": "191337e74eb8250cef93169f43097cee82c2586e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTgyNDMw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8500#pullrequestreview-370582430", "createdAt": "2020-03-06T19:45:19Z", "commit": {"oid": "191337e74eb8250cef93169f43097cee82c2586e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1050, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}