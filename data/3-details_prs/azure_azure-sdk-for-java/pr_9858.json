{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4NDAzMjYx", "number": 9858, "title": "Cosmos CFP: fix for handling partition splits or partition not found", "bodyText": "Bug fix when handling partition splits or partition not found. The cause of the bug is a typo in the call to log the current partition information such as the partition ID.\nBug fix when syncronizing lease updates across different threads.\nAdd test case for handling partition splits.", "createdAt": "2020-04-03T21:54:13Z", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858", "merged": true, "mergeCommit": {"oid": "2b7d799ebf32b539145b8ae2aa42a97caa5f0c44"}, "closed": true, "closedAt": "2020-04-17T18:31:47Z", "author": {"login": "milismsft"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcUIGHIgH2gAyMzk4NDAzMjYxOjMyMjhmOTRmNGM4ZmVjZGRiMWUzODcyY2NiNjA2YjY4OGRhMDc0MTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcYRfcqAH2gAyMzk4NDAzMjYxOjA1ZWIwN2FmNzI2NGMzYmQyOWZkZTcxOTU2YTFkYTdlNjQ5YzI2MzM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "3228f94f4c8fecddb1e3872ccb606b688da07412", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/3228f94f4c8fecddb1e3872ccb606b688da07412", "committedDate": "2020-04-03T21:50:29Z", "message": "Bug fix when handling partition splits or partition not found.\n  The cause of the bug is a typo in the call to log the current partition information such as the partition ID.\nBug fix when syncronizing lease updates across different threads.\nAdd test case for handling partition splits."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e51cd135d58167203bfca1872e35cee76235709d", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/e51cd135d58167203bfca1872e35cee76235709d", "committedDate": "2020-04-03T21:55:28Z", "message": "Undo module related changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "120219bc1078b8b4c683d1ba676a5bfd30993457", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/120219bc1078b8b4c683d1ba676a5bfd30993457", "committedDate": "2020-04-03T21:58:06Z", "message": "Merge branch 'master' into milismsft-v4-cfp-fixSplit"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NjI5MTQ2", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-387629146", "createdAt": "2020-04-03T23:14:23Z", "commit": {"oid": "120219bc1078b8b4c683d1ba676a5bfd30993457"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89fadf09b17f3b23574394854291f44e35441347", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/89fadf09b17f3b23574394854291f44e35441347", "committedDate": "2020-04-03T23:34:25Z", "message": "disable the split test in order to rule it out as causing the CI failure. Splits are not properly handled when tests are run against the public emulator."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/cfed2526a1a897ae11832382960b93f6130d8185", "committedDate": "2020-04-04T08:29:24Z", "message": "change new test group and default timings for CFP tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4NDI4NjQ0", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-388428644", "createdAt": "2020-04-06T16:40:52Z", "commit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjo0MDo1M1rOGBgfmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjo0NzozMlrOGBgw2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNDEzNw==", "bodyText": "when a class is annotated with jackson annotation, jackson uses reflection for serialization/deserialization to json.\nreflection is expensive and that being said, If there are pre existing classes in the code which needs to be serialized/deserialized to json we should ideally use a jackson serializer rather than annotating the class with jackson annotation.\n(not necessarily in the scope of this PR, but something to be addressed outside of this PR).", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r404234137", "createdAt": "2020-04-06T16:40:53Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -63,7 +63,8 @@ public ServiceItemLease withId(String id) {\n         return this;\n     }\n \n-    @JsonIgnore\n+//    @JsonIgnore\n+    @JsonProperty(\"_etag\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNzY3MQ==", "bodyText": "partition split normally takes 10-20 min to complete. how are we ensuring that the test sees partition split completing within its life time?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r404237671", "createdAt": "2020-04-06T16:46:12Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -332,10 +315,136 @@ public void staledLeaseAcquiring() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = 50 * CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void readFeedDocumentsAfterSplit() {\n+        createdFeedCollectionForSplit = createFeedCollection(FEED_COLLECTION_THROUGHPUT_FOR_SPLIT);\n+\n+        // generate a first batch of documents\n+        setupReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        changeFeedProcessor = ChangeFeedProcessor.changeFeedProcessorBuilder()\n+            .hostName(hostName)\n+            .handleChanges(changeFeedProcessorHandler())\n+            .feedContainer(createdFeedCollectionForSplit)\n+            .leaseContainer(createdLeaseCollection)\n+            .options(new ChangeFeedProcessorOptions()\n+                .setLeasePrefix(\"TEST\")\n+                .setStartFromBeginning(true)\n+                .setMaxItemCount(10)\n+            )\n+            .build();\n+\n+        changeFeedProcessor.start().subscribeOn(Schedulers.elastic())\n+            .timeout(Duration.ofMillis(2 * CHANGE_FEED_PROCESSOR_TIMEOUT))\n+            .onErrorResume(throwable -> {\n+                log.error(\"Change feed processor did not start in the expected time\", throwable);\n+                return Mono.error(throwable);\n+            })\n+            .doOnSuccess(aVoid -> {\n+                // Wait for the feed processor to receive and process the first batch of documents.\n+                waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT);\n+            })\n+            .then(\n+                // increase throughput to force a single partition collection to go through a split\n+                createdFeedCollectionForSplit.readProvisionedThroughput().subscribeOn(Schedulers.elastic())\n+                    .flatMap(currentThroughput ->\n+                        createdFeedCollectionForSplit.replaceProvisionedThroughput(FEED_COLLECTION_THROUGHPUT).subscribeOn(Schedulers.elastic())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODIwOQ==", "bodyText": "don't catch InterruptedException if that's thrown, we can fail the test.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r404238209", "createdAt": "2020-04-06T16:47:01Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -332,10 +315,136 @@ public void staledLeaseAcquiring() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = 50 * CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void readFeedDocumentsAfterSplit() {\n+        createdFeedCollectionForSplit = createFeedCollection(FEED_COLLECTION_THROUGHPUT_FOR_SPLIT);\n+\n+        // generate a first batch of documents\n+        setupReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        changeFeedProcessor = ChangeFeedProcessor.changeFeedProcessorBuilder()\n+            .hostName(hostName)\n+            .handleChanges(changeFeedProcessorHandler())\n+            .feedContainer(createdFeedCollectionForSplit)\n+            .leaseContainer(createdLeaseCollection)\n+            .options(new ChangeFeedProcessorOptions()\n+                .setLeasePrefix(\"TEST\")\n+                .setStartFromBeginning(true)\n+                .setMaxItemCount(10)\n+            )\n+            .build();\n+\n+        changeFeedProcessor.start().subscribeOn(Schedulers.elastic())\n+            .timeout(Duration.ofMillis(2 * CHANGE_FEED_PROCESSOR_TIMEOUT))\n+            .onErrorResume(throwable -> {\n+                log.error(\"Change feed processor did not start in the expected time\", throwable);\n+                return Mono.error(throwable);\n+            })\n+            .doOnSuccess(aVoid -> {\n+                // Wait for the feed processor to receive and process the first batch of documents.\n+                waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT);\n+            })\n+            .then(\n+                // increase throughput to force a single partition collection to go through a split\n+                createdFeedCollectionForSplit.readProvisionedThroughput().subscribeOn(Schedulers.elastic())\n+                    .flatMap(currentThroughput ->\n+                        createdFeedCollectionForSplit.replaceProvisionedThroughput(FEED_COLLECTION_THROUGHPUT).subscribeOn(Schedulers.elastic())\n+                    )\n+                .then()\n+            )\n+            .subscribe();\n+\n+        // Wait for the feed processor to receive and process the first batch of documents and apply throughput change.\n+        try {\n+            Thread.sleep(4 * CHANGE_FEED_PROCESSOR_TIMEOUT);\n+        } catch (InterruptedException e) {\n+            log.error(e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODMwMw==", "bodyText": "don't catch InterruptedException if that's thrown, we can fail the test.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r404238303", "createdAt": "2020-04-06T16:47:09Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -332,10 +315,136 @@ public void staledLeaseAcquiring() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = 50 * CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void readFeedDocumentsAfterSplit() {\n+        createdFeedCollectionForSplit = createFeedCollection(FEED_COLLECTION_THROUGHPUT_FOR_SPLIT);\n+\n+        // generate a first batch of documents\n+        setupReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        changeFeedProcessor = ChangeFeedProcessor.changeFeedProcessorBuilder()\n+            .hostName(hostName)\n+            .handleChanges(changeFeedProcessorHandler())\n+            .feedContainer(createdFeedCollectionForSplit)\n+            .leaseContainer(createdLeaseCollection)\n+            .options(new ChangeFeedProcessorOptions()\n+                .setLeasePrefix(\"TEST\")\n+                .setStartFromBeginning(true)\n+                .setMaxItemCount(10)\n+            )\n+            .build();\n+\n+        changeFeedProcessor.start().subscribeOn(Schedulers.elastic())\n+            .timeout(Duration.ofMillis(2 * CHANGE_FEED_PROCESSOR_TIMEOUT))\n+            .onErrorResume(throwable -> {\n+                log.error(\"Change feed processor did not start in the expected time\", throwable);\n+                return Mono.error(throwable);\n+            })\n+            .doOnSuccess(aVoid -> {\n+                // Wait for the feed processor to receive and process the first batch of documents.\n+                waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT);\n+            })\n+            .then(\n+                // increase throughput to force a single partition collection to go through a split\n+                createdFeedCollectionForSplit.readProvisionedThroughput().subscribeOn(Schedulers.elastic())\n+                    .flatMap(currentThroughput ->\n+                        createdFeedCollectionForSplit.replaceProvisionedThroughput(FEED_COLLECTION_THROUGHPUT).subscribeOn(Schedulers.elastic())\n+                    )\n+                .then()\n+            )\n+            .subscribe();\n+\n+        // Wait for the feed processor to receive and process the first batch of documents and apply throughput change.\n+        try {\n+            Thread.sleep(4 * CHANGE_FEED_PROCESSOR_TIMEOUT);\n+        } catch (InterruptedException e) {\n+            log.error(e.getMessage());\n+        }\n+\n+        // Loop through reading the current partition count until we get a split\n+        //   This can take up to two minute or more.\n+        String partitionKeyRangesPath = extractContainerSelfLink(createdFeedCollectionForSplit);\n+        FeedOptions feedOptions = new FeedOptions();\n+        feedOptions.setRequestContinuation(null);\n+\n+        AsyncDocumentClient contextClient = getContextClient(createdDatabase);\n+        Flux.just(1).subscribeOn(Schedulers.elastic())\n+            .flatMap( value -> {\n+                log.warn(\"Reading current hroughput change.\");\n+                return contextClient.readPartitionKeyRanges(partitionKeyRangesPath, feedOptions);\n+            })\n+            .map(partitionKeyRangeFeedResponse -> {\n+                int count = partitionKeyRangeFeedResponse.getResults().size();\n+\n+                if ( count < 2) {\n+                    log.warn(\"Throughput change is pending.\");\n+                    throw new RuntimeException(\"Throughput change is not done.\");\n+                }\n+                return count;\n+            })\n+            // this will timeout approximately after 3 minutes\n+            .retry(40, throwable -> {\n+                try {\n+                    log.warn(\"Retrying...\");\n+                    Thread.sleep(CHANGE_FEED_PROCESSOR_TIMEOUT);\n+                } catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODU1NQ==", "bodyText": "here and elsewhere please. we don't need to catch this, let it get thrown", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r404238555", "createdAt": "2020-04-06T16:47:32Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -332,10 +315,136 @@ public void staledLeaseAcquiring() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = 50 * CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void readFeedDocumentsAfterSplit() {\n+        createdFeedCollectionForSplit = createFeedCollection(FEED_COLLECTION_THROUGHPUT_FOR_SPLIT);\n+\n+        // generate a first batch of documents\n+        setupReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        changeFeedProcessor = ChangeFeedProcessor.changeFeedProcessorBuilder()\n+            .hostName(hostName)\n+            .handleChanges(changeFeedProcessorHandler())\n+            .feedContainer(createdFeedCollectionForSplit)\n+            .leaseContainer(createdLeaseCollection)\n+            .options(new ChangeFeedProcessorOptions()\n+                .setLeasePrefix(\"TEST\")\n+                .setStartFromBeginning(true)\n+                .setMaxItemCount(10)\n+            )\n+            .build();\n+\n+        changeFeedProcessor.start().subscribeOn(Schedulers.elastic())\n+            .timeout(Duration.ofMillis(2 * CHANGE_FEED_PROCESSOR_TIMEOUT))\n+            .onErrorResume(throwable -> {\n+                log.error(\"Change feed processor did not start in the expected time\", throwable);\n+                return Mono.error(throwable);\n+            })\n+            .doOnSuccess(aVoid -> {\n+                // Wait for the feed processor to receive and process the first batch of documents.\n+                waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT);\n+            })\n+            .then(\n+                // increase throughput to force a single partition collection to go through a split\n+                createdFeedCollectionForSplit.readProvisionedThroughput().subscribeOn(Schedulers.elastic())\n+                    .flatMap(currentThroughput ->\n+                        createdFeedCollectionForSplit.replaceProvisionedThroughput(FEED_COLLECTION_THROUGHPUT).subscribeOn(Schedulers.elastic())\n+                    )\n+                .then()\n+            )\n+            .subscribe();\n+\n+        // Wait for the feed processor to receive and process the first batch of documents and apply throughput change.\n+        try {\n+            Thread.sleep(4 * CHANGE_FEED_PROCESSOR_TIMEOUT);\n+        } catch (InterruptedException e) {\n+            log.error(e.getMessage());\n+        }\n+\n+        // Loop through reading the current partition count until we get a split\n+        //   This can take up to two minute or more.\n+        String partitionKeyRangesPath = extractContainerSelfLink(createdFeedCollectionForSplit);\n+        FeedOptions feedOptions = new FeedOptions();\n+        feedOptions.setRequestContinuation(null);\n+\n+        AsyncDocumentClient contextClient = getContextClient(createdDatabase);\n+        Flux.just(1).subscribeOn(Schedulers.elastic())\n+            .flatMap( value -> {\n+                log.warn(\"Reading current hroughput change.\");\n+                return contextClient.readPartitionKeyRanges(partitionKeyRangesPath, feedOptions);\n+            })\n+            .map(partitionKeyRangeFeedResponse -> {\n+                int count = partitionKeyRangeFeedResponse.getResults().size();\n+\n+                if ( count < 2) {\n+                    log.warn(\"Throughput change is pending.\");\n+                    throw new RuntimeException(\"Throughput change is not done.\");\n+                }\n+                return count;\n+            })\n+            // this will timeout approximately after 3 minutes\n+            .retry(40, throwable -> {\n+                try {\n+                    log.warn(\"Retrying...\");\n+                    Thread.sleep(CHANGE_FEED_PROCESSOR_TIMEOUT);\n+                } catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODMwMw=="}, "originalCommit": {"oid": "cfed2526a1a897ae11832382960b93f6130d8185"}, "originalPosition": 212}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9706a8344d13bfe2f86a8d2e23befde72e16e738", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/9706a8344d13bfe2f86a8d2e23befde72e16e738", "committedDate": "2020-04-06T17:16:25Z", "message": "Adjust CFP tests timeouts."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NTE1NjI3", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-389515627", "createdAt": "2020-04-07T21:49:37Z", "commit": {"oid": "9706a8344d13bfe2f86a8d2e23befde72e16e738"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/29eb83a7735a3a5d54f58d6b815eafe80dcf6a48", "committedDate": "2020-04-11T07:25:47Z", "message": "Implement its own Json serializer for the Lease class."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjg5Mjk0", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-392689294", "createdAt": "2020-04-14T08:00:02Z", "commit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODowMDowMlrOGFCsmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODowMDowMlrOGFCsmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk0MDI1MQ==", "bodyText": "Please add unit test scoped to serialization.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r407940251", "createdAt": "2020-04-14T08:00:02Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -20,6 +22,7 @@\n /**\n  * Document service lease.\n  */\n+@JsonSerialize(using = ServiceItemLease.ServiceItemLeaseJsonSerializer.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjk3NDk2", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-392697496", "createdAt": "2020-04-14T08:11:22Z", "commit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxMToyMlrOGFDGaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxMToyMlrOGFDGaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk0Njg1OQ==", "bodyText": "stale code. remove", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r407946859", "createdAt": "2020-04-14T08:11:22Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -181,34 +182,17 @@ public ServiceItemLease withTimestamp(ZonedDateTime timestamp) {\n         return this;\n     }\n \n-    @JsonIgnore\n+//    @JsonIgnore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "originalPosition": 90}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjk3NTg4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-392697588", "createdAt": "2020-04-14T08:11:28Z", "commit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxMToyOFrOGFDGsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxMToyOFrOGFDGsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk0NjkyOA==", "bodyText": "ditto", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r407946928", "createdAt": "2020-04-14T08:11:28Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -181,34 +182,17 @@ public ServiceItemLease withTimestamp(ZonedDateTime timestamp) {\n         return this;\n     }\n \n-    @JsonIgnore\n+//    @JsonIgnore\n     public String getExplicitTimestamp() {\n         return this.timestamp;\n     }\n \n-    @JsonIgnore\n+//    @JsonIgnore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjk5Nzk3", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-392699797", "createdAt": "2020-04-14T08:14:25Z", "commit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxNDoyNVrOGFDN0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoxNDoyNVrOGFDN0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk0ODc1Mw==", "bodyText": "LeaseToken, ContinuationToken, Owner are Camel case, but timestamp, id, etag are not is that expected?\nalso for Owner, timestamp, ContinuationToken, LeaseToken we probably should define constants.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r407948753", "createdAt": "2020-04-14T08:14:25Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -236,4 +235,32 @@ public String toString() {\n             this.getTimestamp(),\n             UNIX_START_TIME.plusSeconds(Long.parseLong(this.getTs())));\n     }\n+\n+    @SuppressWarnings(\"serial\")\n+    static final class ServiceItemLeaseJsonSerializer extends StdSerializer<ServiceItemLease> {\n+        // this value should be incremented if changes are made to the ServiceItemLease class members\n+        private static final long serialVersionUID = 1L;\n+\n+        protected ServiceItemLeaseJsonSerializer() { this(null); }\n+\n+        protected ServiceItemLeaseJsonSerializer(Class<ServiceItemLease> t) {\n+            super(t);\n+        }\n+\n+        @Override\n+        public void serialize(ServiceItemLease lease, JsonGenerator writer, SerializerProvider serializerProvider) {\n+            try {\n+                writer.writeStartObject();\n+                writer.writeStringField(Constants.Properties.ID, lease.getId());\n+                writer.writeStringField(Constants.Properties.E_TAG, lease.getETag());\n+                writer.writeStringField(\"LeaseToken\", lease.getLeaseToken());\n+                writer.writeStringField(\"ContinuationToken\", lease.getContinuationToken());\n+                writer.writeStringField(\"timestamp\", lease.getTimestamp());\n+                writer.writeStringField(\"Owner\", lease.getOwner());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29eb83a7735a3a5d54f58d6b815eafe80dcf6a48"}, "originalPosition": 169}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ce2d3d238e26673d430d940d7e311b6d3789e6c", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/7ce2d3d238e26673d430d940d7e311b6d3789e6c", "committedDate": "2020-04-14T15:46:10Z", "message": "Clean-up and add unit test for lease serialization."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDYxMDU4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-393061058", "createdAt": "2020-04-14T15:48:03Z", "commit": {"oid": "7ce2d3d238e26673d430d940d7e311b6d3789e6c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTo0ODowM1rOGFVMNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTo0ODowM1rOGFVMNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0MzI1Mw==", "bodyText": "thank you for the test. as a code style rule we don't add \"test\" as prefix.\nPlease drop the \"test\" prefix to be consistent with other tests.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r408243253", "createdAt": "2020-04-14T15:48:03Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -424,6 +427,46 @@ public void readFeedDocumentsAfterSplit() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void testServiceItemLeaseSerialization() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ce2d3d238e26673d430d940d7e311b6d3789e6c"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDYxODM4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-393061838", "createdAt": "2020-04-14T15:48:54Z", "commit": {"oid": "7ce2d3d238e26673d430d940d7e311b6d3789e6c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTo0ODo1NFrOGFVO0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTo0ODo1NFrOGFVO0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0MzkyMA==", "bodyText": "please drop the try/catch block here. if there is a failure the failure should get thrown and the exception needs to be added to the test method signature.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r408243920", "createdAt": "2020-04-14T15:48:54Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -424,6 +427,46 @@ public void readFeedDocumentsAfterSplit() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void testServiceItemLeaseSerialization() {\n+        ZonedDateTime timeNow = ZonedDateTime.now();\n+        String timeNowValue = timeNow.toString();\n+\n+        Lease lease1 = new ServiceItemLease()\n+            .withId(\"id1\")\n+            .withLeaseToken(\"1\")\n+            .withETag(\"etag1\")\n+            .withOwner(\"Owner1\")\n+            .withContinuationToken(\"12\")\n+            .withTimestamp(timeNow)\n+            .withTs(\"122311231\");\n+\n+        Lease lease2 = new ServiceItemLease()\n+            .withId(\"id2\")\n+            .withLeaseToken(\"2\")\n+            .withETag(\"etag2\")\n+            .withContinuationToken(\"22\")\n+            .withTimestamp(timeNow)\n+            .withTs(\"122311232\");\n+\n+        ObjectMapper mapper = new ObjectMapper();\n+\n+        try {\n+            assertThat(mapper.writeValueAsString(lease1)).isEqualTo(\n+                String.format(\"%s%s%s\",\n+                    \"{\\\"id\\\":\\\"id1\\\",\\\"_etag\\\":\\\"etag1\\\",\\\"LeaseToken\\\":\\\"1\\\",\\\"ContinuationToken\\\":\\\"12\\\",\\\"timestamp\\\":\\\"\",\n+                    timeNowValue,\n+                    \"\\\",\\\"Owner\\\":\\\"Owner1\\\"}\"));\n+            assertThat(mapper.writeValueAsString(lease2)).isEqualTo(\n+                String.format(\"%s%s%s\",\n+                    \"{\\\"id\\\":\\\"id2\\\",\\\"_etag\\\":\\\"etag2\\\",\\\"LeaseToken\\\":\\\"2\\\",\\\"ContinuationToken\\\":\\\"22\\\",\\\"timestamp\\\":\\\"\",\n+                    timeNowValue,\n+                    \"\\\",\\\"Owner\\\":null}\"));\n+        } catch(Exception ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ce2d3d238e26673d430d940d7e311b6d3789e6c"}, "originalPosition": 65}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7952a341834a954266246d317f3b437f80ea1502", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/7952a341834a954266246d317f3b437f80ea1502", "committedDate": "2020-04-14T15:51:04Z", "message": "minor change to rename test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/cb9a8f6dab209235b8b2641bccc086d1b7effd57", "committedDate": "2020-04-14T15:54:35Z", "message": "update test signature and remove try/catch"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDcyOTU0", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-393072954", "createdAt": "2020-04-14T16:00:25Z", "commit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNjowMDoyNVrOGFVwNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNjowMDoyNVrOGFVwNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI1MjQ2OQ==", "bodyText": "we should add a deserializer as well. Document/CosmosItemProperties can use the custom deserializer.\nYou can take a look at PartitionKeyInternal.java as example.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r408252469", "createdAt": "2020-04-14T16:00:25Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/changefeed/ServiceItemLease.java", "diffHunk": "@@ -236,4 +234,32 @@ public String toString() {\n             this.getTimestamp(),\n             UNIX_START_TIME.plusSeconds(Long.parseLong(this.getTs())));\n     }\n+\n+    @SuppressWarnings(\"serial\")\n+    static final class ServiceItemLeaseJsonSerializer extends StdSerializer<ServiceItemLease> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57"}, "originalPosition": 167}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDc2NjIw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-393076620", "createdAt": "2020-04-14T16:04:32Z", "commit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNjowNDozMlrOGFV8AQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNjowNDozMlrOGFV8AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI1NTQ4OQ==", "bodyText": "\"simple\" test group is only invoked as integration test in the presence of a cosmosdb endpoint.\nas this is unit test, not integration test, the group needs to be \"unit\".  (groups = { \"unit\" })\nalso the unit tests should go in a separate class, e.g.,  please move the test to  the new class ServiceItemLeaseTest.java", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r408255489", "createdAt": "2020-04-14T16:04:32Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -332,10 +325,172 @@ public void staledLeaseAcquiring() {\n         receivedDocuments.clear();\n     }\n \n+    @Test(groups = { \"simple\" }, timeOut = 50 * CHANGE_FEED_PROCESSOR_TIMEOUT)\n+    public void readFeedDocumentsAfterSplit() {\n+        createdFeedCollectionForSplit = createFeedCollection(FEED_COLLECTION_THROUGHPUT_FOR_SPLIT);\n+\n+        // generate a first batch of documents\n+        setupReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        changeFeedProcessor = ChangeFeedProcessor.changeFeedProcessorBuilder()\n+            .hostName(hostName)\n+            .handleChanges(changeFeedProcessorHandler())\n+            .feedContainer(createdFeedCollectionForSplit)\n+            .leaseContainer(createdLeaseCollection)\n+            .options(new ChangeFeedProcessorOptions()\n+                .setLeasePrefix(\"TEST\")\n+                .setStartFromBeginning(true)\n+                .setMaxItemCount(10)\n+            )\n+            .build();\n+\n+        changeFeedProcessor.start().subscribeOn(Schedulers.elastic())\n+            .timeout(Duration.ofMillis(2 * CHANGE_FEED_PROCESSOR_TIMEOUT))\n+            .onErrorResume(throwable -> {\n+                log.error(\"Change feed processor did not start in the expected time\", throwable);\n+                return Mono.error(throwable);\n+            })\n+            .doOnSuccess(aVoid -> {\n+                // Wait for the feed processor to receive and process the first batch of documents.\n+                waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT);\n+            })\n+            .then(\n+                // increase throughput to force a single partition collection to go through a split\n+                createdFeedCollectionForSplit.readProvisionedThroughput().subscribeOn(Schedulers.elastic())\n+                    .flatMap(currentThroughput ->\n+                        createdFeedCollectionForSplit.replaceProvisionedThroughput(FEED_COLLECTION_THROUGHPUT).subscribeOn(Schedulers.elastic())\n+                    )\n+                .then()\n+            )\n+            .subscribe();\n+\n+        // Wait for the feed processor to receive and process the first batch of documents and apply throughput change.\n+        try {\n+            Thread.sleep(4 * CHANGE_FEED_PROCESSOR_TIMEOUT);\n+        } catch (InterruptedException e) {\n+            log.error(e.getMessage());\n+        }\n+\n+        // Loop through reading the current partition count until we get a split\n+        //   This can take up to two minute or more.\n+        String partitionKeyRangesPath = extractContainerSelfLink(createdFeedCollectionForSplit);\n+        FeedOptions feedOptions = new FeedOptions();\n+        feedOptions.setRequestContinuation(null);\n+\n+        AsyncDocumentClient contextClient = getContextClient(createdDatabase);\n+        Flux.just(1).subscribeOn(Schedulers.elastic())\n+            .flatMap( value -> {\n+                log.warn(\"Reading current hroughput change.\");\n+                return contextClient.readPartitionKeyRanges(partitionKeyRangesPath, feedOptions);\n+            })\n+            .map(partitionKeyRangeFeedResponse -> {\n+                int count = partitionKeyRangeFeedResponse.getResults().size();\n+\n+                if ( count < 2) {\n+                    log.warn(\"Throughput change is pending.\");\n+                    throw new RuntimeException(\"Throughput change is not done.\");\n+                }\n+                return count;\n+            })\n+            // this will timeout approximately after 3 minutes\n+            .retry(40, throwable -> {\n+                try {\n+                    log.warn(\"Retrying...\");\n+                    Thread.sleep(CHANGE_FEED_PROCESSOR_TIMEOUT);\n+                } catch (InterruptedException e) {\n+                    log.error(e.getMessage());\n+                }\n+                return true;\n+            })\n+            .last().block();\n+\n+        assertThat(changeFeedProcessor.isStarted()).as(\"Change Feed Processor instance is running\").isTrue();\n+\n+        // generate the second batch of documents\n+        createReadFeedDocuments(createdFeedCollectionForSplit, FEED_COUNT);\n+\n+        // Wait for the feed processor to receive and process the second batch of documents.\n+        waitToReceiveDocuments(2 * CHANGE_FEED_PROCESSOR_TIMEOUT, FEED_COUNT * 2);\n+\n+        changeFeedProcessor.stop().subscribeOn(Schedulers.elastic()).timeout(Duration.ofMillis(CHANGE_FEED_PROCESSOR_TIMEOUT)).subscribe();\n+\n+        for (CosmosItemProperties item : createdDocuments) {\n+            assertThat(receivedDocuments.containsKey(item.getId())).as(\"Document with getId: \" + item.getId()).isTrue();\n+        }\n+\n+        // Wait for the feed processor to shutdown.\n+        try {\n+            Thread.sleep(CHANGE_FEED_PROCESSOR_TIMEOUT);\n+        } catch (InterruptedException e) {\n+            log.error(e.getMessage());\n+        }\n+        receivedDocuments.clear();\n+    }\n+\n+    @Test(groups = { \"simple\" }, timeOut = CHANGE_FEED_PROCESSOR_TIMEOUT)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57"}, "originalPosition": 296}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDk0NzY0", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-393094764", "createdAt": "2020-04-14T16:26:04Z", "commit": {"oid": "cb9a8f6dab209235b8b2641bccc086d1b7effd57"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d60f1e96aa6a7f19df6a0be9d9ed81cc696e0f4f", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/d60f1e96aa6a7f19df6a0be9d9ed81cc696e0f4f", "committedDate": "2020-04-14T16:36:57Z", "message": "test refactoring..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f749df84d510947a31b17605b720086132e26c1", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/0f749df84d510947a31b17605b720086132e26c1", "committedDate": "2020-04-14T21:34:37Z", "message": "test refactoring; each test will use it's own instance of the received document map."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "269b21236e39ab80242214e518b3ee397fdf1ef1", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/269b21236e39ab80242214e518b3ee397fdf1ef1", "committedDate": "2020-04-16T00:38:30Z", "message": "Refactoring to create test related resources within each test.\nRemove try/catch on InterruptedExceptions calls."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0ff8d96b32f5d37031899c6c6534c08b4a00744", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/a0ff8d96b32f5d37031899c6c6534c08b4a00744", "committedDate": "2020-04-16T04:10:08Z", "message": "Merge branch 'master' into milismsft-v4-cfp-fixSplit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "935a1c3958070d375115593d391bf7f0c0fd6d36", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/935a1c3958070d375115593d391bf7f0c0fd6d36", "committedDate": "2020-04-16T04:19:03Z", "message": "fix merge related conflict."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MjkxODk3", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#pullrequestreview-394291897", "createdAt": "2020-04-16T04:34:22Z", "commit": {"oid": "935a1c3958070d375115593d391bf7f0c0fd6d36"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDozNDoyM1rOGGUOQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDozNDoyM1rOGGUOQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3NTk3MA==", "bodyText": "I suspect you have client leak in your test class. this might cause CI test issues later.\nthe afterClass is annotated as part of emulator test group. But your partition split test is in a different test group, i.e., simple test group. Due to that the afterClass may not get invoked for the partition split test.\nOur test pattern is to not mix different test groups in the same class for simplicity.\nDifferent test group go to different test classes, otherwise you need to be very cautious in the cleaning logic.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9858#discussion_r409275970", "createdAt": "2020-04-16T04:34:23Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos/src/test/java/com/azure/cosmos/rx/ChangeFeedProcessorTest.java", "diffHunk": "@@ -360,27 +493,18 @@ public void before_ChangeFeedProcessorTest() {\n //            log.warn(\"Database delete\", e);\n //        }\n //        createdDatabase = createDatabase(client, databaseId);\n-        createdDatabase = getSharedCosmosDatabase(client);\n     }\n \n     @AfterMethod(groups = { \"emulator\" }, timeOut = 3 * SHUTDOWN_TIMEOUT, alwaysRun = true)\n     public void afterMethod() {\n-        safeDeleteCollection(createdFeedCollection);\n-        safeDeleteCollection(createdLeaseCollection);\n-\n-        // Allow some time for the collections and the database to be deleted before exiting.\n-        try {\n-            Thread.sleep(500);\n-        } catch (Exception e){ }\n     }\n \n     @AfterClass(groups = { \"emulator\" }, timeOut = 2 * SHUTDOWN_TIMEOUT, alwaysRun = true)\n     public void afterClass() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "935a1c3958070d375115593d391bf7f0c0fd6d36"}, "originalPosition": 690}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05eb07af7264c3bd29fde71956a1da7e649c2633", "author": {"user": {"login": "milismsft", "name": "Milis"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/05eb07af7264c3bd29fde71956a1da7e649c2633", "committedDate": "2020-04-16T19:03:00Z", "message": "Add missing group for before and after related test methods"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1184, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}