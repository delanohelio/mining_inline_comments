{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2NjAyNzM1", "number": 17789, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjowODo0MVrOE9Mwxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxODozNjozMFrOE9Wbhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNjA3Njg2OnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjowODo0MVrOH5wg3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0NTo1M1rOH6DWuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNTcyNQ==", "bodyText": "Same should be true for FeedRange query option (or in old model PkRangeId) as long as retry policies are in place, correct? Simply because we would never ever push down predicates that would need the QUery magic in the client - like Group By and Order BY - Spark is much better at doing them client-side :-)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530325725", "createdAt": "2020-11-25T12:08:41Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "diffHunk": "@@ -0,0 +1,17 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.Filter\n+\n+// TODO: moderakh, thought for future optimization:\n+//  if we can identify if the user filter is a equality on cosmos partitionKeyValue\n+//  then we can set partitionKeyValue in the CosmosQueryOption\n+//  the benefit is that if the partitionKeyValue is set in the CosmosQueryOption\n+//  the antlr query parsing support can eliminate the need for query plan fetch from GW", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU2MjE0OA==", "bodyText": "AnalyzedFilter analyzes \"only\" the user specified filters pushed down by spark platform. FeedRange/PkRangeId will not be a user push down query so hence won't be captured here.\nYes, we need to capture add FeedRange/PkRangeId to the query options. That will happen elsewhere in the code where driver is submitting spark tasks:\nneed to be done here:\nhttps://github.com/Azure/azure-sdk-for-java/blob/feature/cosmos/spark30/sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScan.scala#L14-L28", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530562148", "createdAt": "2020-11-25T18:10:42Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "diffHunk": "@@ -0,0 +1,17 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.Filter\n+\n+// TODO: moderakh, thought for future optimization:\n+//  if we can identify if the user filter is a equality on cosmos partitionKeyValue\n+//  then we can set partitionKeyValue in the CosmosQueryOption\n+//  the benefit is that if the partitionKeyValue is set in the CosmosQueryOption\n+//  the antlr query parsing support can eliminate the need for query plan fetch from GW", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNTcyNQ=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU3MjU3NQ==", "bodyText": "I think query plan fetch optimization only apply to logical partition key queries, since any other feed range still needs to go to gateway for the plan. The reason for this is because if you have a pkrangeid or epkrange, then you always have a chance to encounter a split, which makes our query go from one feed range to multiple. At this point you now need client side aggregation and without a query plan you can't pull it off.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530572575", "createdAt": "2020-11-25T18:31:39Z", "author": {"login": "bchong95"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "diffHunk": "@@ -0,0 +1,17 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.Filter\n+\n+// TODO: moderakh, thought for future optimization:\n+//  if we can identify if the user filter is a equality on cosmos partitionKeyValue\n+//  then we can set partitionKeyValue in the CosmosQueryOption\n+//  the benefit is that if the partitionKeyValue is set in the CosmosQueryOption\n+//  the antlr query parsing support can eliminate the need for query plan fetch from GW", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNTcyNQ=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzNDQyNA==", "bodyText": "correct epkrange will be passed differently (as options) not through this code path.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530634424", "createdAt": "2020-11-25T20:45:53Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "diffHunk": "@@ -0,0 +1,17 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.Filter\n+\n+// TODO: moderakh, thought for future optimization:\n+//  if we can identify if the user filter is a equality on cosmos partitionKeyValue\n+//  then we can set partitionKeyValue in the CosmosQueryOption\n+//  the benefit is that if the partitionKeyValue is set in the CosmosQueryOption\n+//  the antlr query parsing support can eliminate the need for query plan fetch from GW", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNTcyNQ=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNjA4MzA3OnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxMDoyMFrOH5wkog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxMDo0MFrOH5wlTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNjY5MA==", "bodyText": "NIT: static singleton", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530326690", "createdAt": "2020-11-25T12:10:20Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -20,68 +20,35 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     with CosmosLoggingTrait {\n   logInfo(s\"Instantiated ${this.getClass.getSimpleName}\")\n \n-  var filtersToBePushDownToCosmos: Array[Filter] = Array.empty\n-  var filtersToBeEvaluatedBySpark: Array[Filter] = Array.empty\n+  var processedPredicates : Option[AnalyzedFilters] = Option.empty\n \n   /**\n     * Pushes down filters, and returns filters that need to be evaluated after scanning.\n-    * @param filters\n-    * @return filters to be evaluated after scanning\n+    * @param filters pushed down filters.\n+    * @return the filters that spark need to evaluate\n     */\n   override def pushFilters(filters: Array[Filter]): Array[Filter] = {\n-    // TODO moderakh we need to build the push down filter translation to Cosmos query\n-    // for now leave it to spark to filter\n+    processedPredicates = Option.apply(FilterAnalyzer().analyze(filters))\n \n-    // TODO: moderakh identify all the filters which are relevant to cosmos db\n-    this.filtersToBePushDownToCosmos = filters.filter(\n-      filter => filter match {\n-        case EqualTo(attribute, value) => true\n-        case _ => false\n-      }\n-    )\n-    this.filtersToBeEvaluatedBySpark = filters\n-\n-    // return all filter so spark also applies the filters\n-    filters\n+    // return the filters that spark need to evaluate\n+    this.processedPredicates.get.filtersNotSupportedByCosmos\n   }\n \n   /**\n-    * Returns the filters that are pushed to the data source via {@link #pushFilters ( Filter[ ] )}.\n-    * @return\n+    * Returns the filters that are pushed to Cosmos as query predicates\n+    * @return filters to be pushed to cosmos db.\n     */\n   override def pushedFilters: Array[Filter] = {\n-    this.filtersToBePushDownToCosmos\n+    if (this.processedPredicates.isDefined) {\n+      this.processedPredicates.get.filtersToBePushedDownToCosmos\n+    } else {\n+      Array[Filter]()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNjg2MA==", "bodyText": "Actually never mind - who knows what the caller is doing with the array :-)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530326860", "createdAt": "2020-11-25T12:10:40Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -20,68 +20,35 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     with CosmosLoggingTrait {\n   logInfo(s\"Instantiated ${this.getClass.getSimpleName}\")\n \n-  var filtersToBePushDownToCosmos: Array[Filter] = Array.empty\n-  var filtersToBeEvaluatedBySpark: Array[Filter] = Array.empty\n+  var processedPredicates : Option[AnalyzedFilters] = Option.empty\n \n   /**\n     * Pushes down filters, and returns filters that need to be evaluated after scanning.\n-    * @param filters\n-    * @return filters to be evaluated after scanning\n+    * @param filters pushed down filters.\n+    * @return the filters that spark need to evaluate\n     */\n   override def pushFilters(filters: Array[Filter]): Array[Filter] = {\n-    // TODO moderakh we need to build the push down filter translation to Cosmos query\n-    // for now leave it to spark to filter\n+    processedPredicates = Option.apply(FilterAnalyzer().analyze(filters))\n \n-    // TODO: moderakh identify all the filters which are relevant to cosmos db\n-    this.filtersToBePushDownToCosmos = filters.filter(\n-      filter => filter match {\n-        case EqualTo(attribute, value) => true\n-        case _ => false\n-      }\n-    )\n-    this.filtersToBeEvaluatedBySpark = filters\n-\n-    // return all filter so spark also applies the filters\n-    filters\n+    // return the filters that spark need to evaluate\n+    this.processedPredicates.get.filtersNotSupportedByCosmos\n   }\n \n   /**\n-    * Returns the filters that are pushed to the data source via {@link #pushFilters ( Filter[ ] )}.\n-    * @return\n+    * Returns the filters that are pushed to Cosmos as query predicates\n+    * @return filters to be pushed to cosmos db.\n     */\n   override def pushedFilters: Array[Filter] = {\n-    this.filtersToBePushDownToCosmos\n+    if (this.processedPredicates.isDefined) {\n+      this.processedPredicates.get.filtersToBePushedDownToCosmos\n+    } else {\n+      Array[Filter]()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNjY5MA=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNjA5ODYxOnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNDo1N1rOH5wuPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxODoxNjo1OVrOH5_I8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyOTE1MA==", "bodyText": "Should we really push down EndsWith and Contains? I would not push down any filters which can not be served via full fidelity indexes - just costs more RU for the additional CPU usage when scanning through the documents", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530329150", "createdAt": "2020-11-25T12:14:57Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU1NTQ1OQ==", "bodyText": "will check with Brandon on this.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530555459", "createdAt": "2020-11-25T17:57:46Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyOTE1MA=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU2NTM2Mg==", "bodyText": "I think we should push down all the filters (even if we can't serve them well from indexes). Even if spark can serve them faster and in an RU free manner doing it client side will probably cost more RUs in the long run. If we leave out a filter it causes the engine to have to return more documents, which drives up the RU cost the query. In most cases the cost of returning extra documents will outweigh the cost of scanning to prune the result set.\nIn the case of string system functions like EndsWith and Contains the operations utilize the index fairly well. We run the system function on the index postings instead of doing a full scan on the dataset. This essentially makes it so that we are running the system function once per unique field, instead of once per document. We also make sure to run these filters after other filters that are quicker to run and will prune the dataset. Eventually when we have regex indexes these filters should be blazingly fast (and cheap).", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530565362", "createdAt": "2020-11-25T18:16:59Z", "author": {"login": "bchong95"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyOTE1MA=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNjEwNzUyOnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNzoyN1rOH5wzwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0MjozNFrOH6DRjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMDU2MQ==", "bodyText": "As a ToDo I would also track adding some of the aggregates under certain conditions:\nCount, Avg, Min, Max - We need to double-check when they can be served from full fidleity index - I think (but needs to be re-validated) when either no Group By is used or exactly one Group By by logical partition key - anyway would be worthwile to have a conversation with the query team about.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530330561", "createdAt": "2020-11-25T12:17:27Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringContains(attr, value: String) =>\n+        queryBuilder.append(\"CONTAINS(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case IsNull(attr) =>\n+        queryBuilder.append(s\"IS_NULL(${canonicalCosmosFieldPath(attr)})\")\n+        true\n+\n+      case IsNotNull(attr) =>\n+        queryBuilder.append(s\"NOT(IS_NULL(${canonicalCosmosFieldPath(attr)}))\")\n+        true\n+\n+      case And(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" AND \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Or(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" OR \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Not(childFilter) =>\n+        queryBuilder.append(\"NOT(\")\n+        val isInnerCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, childFilter)\n+        queryBuilder.append(\")\")\n+        isInnerCosmosPredicate\n+\n+      case _: Filter =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMTUzMQ==", "bodyText": "Same is true for certain Order By statements - like simple query with just order by by columns supported in index - it is possible that it simply isn't worth doing this because Spark is efficient at ordering and it is too complicated to parse and decide to only push down when order by combination matches supporting indexes. But worth having a separate discussion about and making an intentional call- and adding unit test coverage to ensure we comply with the intentional decision long-term.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530331531", "createdAt": "2020-11-25T12:19:18Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringContains(attr, value: String) =>\n+        queryBuilder.append(\"CONTAINS(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case IsNull(attr) =>\n+        queryBuilder.append(s\"IS_NULL(${canonicalCosmosFieldPath(attr)})\")\n+        true\n+\n+      case IsNotNull(attr) =>\n+        queryBuilder.append(s\"NOT(IS_NULL(${canonicalCosmosFieldPath(attr)}))\")\n+        true\n+\n+      case And(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" AND \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Or(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" OR \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Not(childFilter) =>\n+        queryBuilder.append(\"NOT(\")\n+        val isInnerCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, childFilter)\n+        queryBuilder.append(\")\")\n+        isInnerCosmosPredicate\n+\n+      case _: Filter =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMDU2MQ=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzMzEwMw==", "bodyText": "These spark Filter are just predicate. I. don't see the support for count, avg, etc in the Spark Filter.\nI suspect they will be provided from a different path. Need to investigate on that.\nfor now, I added a TODO to look at where those will be pushed down.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530633103", "createdAt": "2020-11-25T20:42:34Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringContains(attr, value: String) =>\n+        queryBuilder.append(\"CONTAINS(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case IsNull(attr) =>\n+        queryBuilder.append(s\"IS_NULL(${canonicalCosmosFieldPath(attr)})\")\n+        true\n+\n+      case IsNotNull(attr) =>\n+        queryBuilder.append(s\"NOT(IS_NULL(${canonicalCosmosFieldPath(attr)}))\")\n+        true\n+\n+      case And(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" AND \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Or(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" OR \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Not(childFilter) =>\n+        queryBuilder.append(\"NOT(\")\n+        val isInnerCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, childFilter)\n+        queryBuilder.append(\")\")\n+        isInnerCosmosPredicate\n+\n+      case _: Filter =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMDU2MQ=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNzY2MDg3OnYy", "diffSide": "RIGHT", "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxODozNjozMFrOH5_uKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0NDo1N1rOH6DVMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU3NDg4OA==", "bodyText": "In the future, I think this code should leverage a DOM / AST. We have one in .net:\nhttps://github.com/Azure/azure-cosmos-dotnet-v3/tree/master/Microsoft.Azure.Cosmos/src/SqlObjects\nand maybe we should port it to Java, since spark connector, seems to be doing some heavy query manipulation.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530574888", "createdAt": "2020-11-25T18:36:30Z", "author": {"login": "bchong95"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzNDAzMg==", "bodyText": "Thanks @bchong95 for the pointer I will take a look at that. Added a TODO in the code for this.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530634032", "createdAt": "2020-11-25T20:44:57Z", "author": {"login": "moderakh"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU3NDg4OA=="}, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2822, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}