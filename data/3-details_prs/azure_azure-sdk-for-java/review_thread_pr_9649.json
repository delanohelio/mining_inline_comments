{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk0OTQ2NDE5", "number": 9649, "reviewThreads": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowNjozMFrODvMwhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzozODo0N1rODvWAsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODE4NjkyOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobAsyncClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowNjozMFrOGBfDUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMDoxMFrOGBibHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDUxNQ==", "bodyText": "This is scoped to package private shouldn't need deprecation.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404210515", "createdAt": "2020-04-06T16:06:30Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobAsyncClient.java", "diffHunk": "@@ -88,7 +88,12 @@\n      * value will be used.\n      */\n     public static final int BLOB_DEFAULT_HTBB_UPLOAD_BLOCK_SIZE = 8 * Constants.MB;\n+    /**\n+     * @deprecated Use {@link #BLOB_MAX_UPLOAD_BLOCK_SIZE_LONG}.\n+     */\n+    @Deprecated\n     static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTc1Ng==", "bodyText": "done", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404265756", "createdAt": "2020-04-06T17:30:10Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobAsyncClient.java", "diffHunk": "@@ -88,7 +88,12 @@\n      * value will be used.\n      */\n     public static final int BLOB_DEFAULT_HTBB_UPLOAD_BLOCK_SIZE = 8 * Constants.MB;\n+    /**\n+     * @deprecated Use {@link #BLOB_MAX_UPLOAD_BLOCK_SIZE_LONG}.\n+     */\n+    @Deprecated\n     static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDUxNQ=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODIwODEyOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjoxMTowNlrOGBfQXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjowMFrOGBifng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMzg1NA==", "bodyText": "Shouldn't need Long.valueOf", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404213854", "createdAt": "2020-04-06T16:11:06Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NjkxMA==", "bodyText": "I did play with valueOf in ModelHelpers. After removing I got quite legit bug report.\n\nSo I ended up reworking this code little bit.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404266910", "createdAt": "2020-04-06T17:32:00Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMzg1NA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODIwOTA0OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjoxMToyMVrOGBfQ_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjoxNFrOGBigJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxNDAxMw==", "bodyText": "Shouldn't need Integer.valueOf", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404214013", "createdAt": "2020-04-06T16:11:21Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n+                : other.getBlockSizeLong())\n+            .setNumBuffers(other.getNumBuffers() == null\n+                ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzA0NQ==", "bodyText": "reworked (see other comment)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404267045", "createdAt": "2020-04-06T17:32:14Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n+                : other.getBlockSizeLong())\n+            .setNumBuffers(other.getNumBuffers() == null\n+                ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxNDAxMw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODIwOTc5OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjoxMTozM1rOGBfReg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjoxOVrOGBigXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxNDEzOA==", "bodyText": "Shouldn't need Long.valueOf", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404214138", "createdAt": "2020-04-06T16:11:33Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n+                : other.getBlockSizeLong())\n+            .setNumBuffers(other.getNumBuffers() == null\n+                ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n+                : other.getNumBuffers())\n+            .setProgressReceiver(other.getProgressReceiver())\n+            .setMaxSingleUploadSize(other.getMaxSingleUploadSizeLong() == null\n+                ? Long.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES_LONG)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzEwMw==", "bodyText": "reworked (see other comment)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404267103", "createdAt": "2020-04-06T17:32:19Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/implementation/util/ModelHelper.java", "diffHunk": "@@ -26,15 +26,18 @@\n      * @return An object with defaults filled in for null values in the original.\n      */\n     public static ParallelTransferOptions populateAndApplyDefaults(ParallelTransferOptions other) {\n-        other = other == null ? new ParallelTransferOptions(null, null, null) : other;\n-        return new ParallelTransferOptions(\n-            other.getBlockSize() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n-                : other.getBlockSize(),\n-            other.getNumBuffers() == null ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n-                : other.getNumBuffers(),\n-            other.getProgressReceiver(),\n-            other.getMaxSingleUploadSize() == null ? Integer.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES)\n-                : other.getMaxSingleUploadSize());\n+        other = other == null ? new ParallelTransferOptions() : other;\n+        return new ParallelTransferOptions()\n+            .setBlockSize(other.getBlockSizeLong() == null\n+                ? Long.valueOf(BlobAsyncClient.BLOB_DEFAULT_UPLOAD_BLOCK_SIZE)\n+                : other.getBlockSizeLong())\n+            .setNumBuffers(other.getNumBuffers() == null\n+                ? Integer.valueOf(BlobAsyncClient.BLOB_DEFAULT_NUMBER_OF_BUFFERS)\n+                : other.getNumBuffers())\n+            .setProgressReceiver(other.getProgressReceiver())\n+            .setMaxSingleUploadSize(other.getMaxSingleUploadSizeLong() == null\n+                ? Long.valueOf(BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES_LONG)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxNDEzOA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODM0OTYzOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadBufferPool.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjo0NDowMlrOGBgn4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjozN1rOGBihJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNjI1Nw==", "bodyText": "Any reason this is no longer final?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404236257", "createdAt": "2020-04-06T16:44:02Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadBufferPool.java", "diffHunk": "@@ -37,23 +40,23 @@\n     queue will not compromise the async nature of this workflow. Fluxes themselves are internally synchronized to ensure\n     only one call to onNext happens at a time.\n      */\n-    private final BlockingQueue<ByteBuffer> buffers;\n+    private final BlockingQueue<BufferAggregator> buffers;\n \n     private final int maxBuffs;\n \n     // The number of buffs we have allocated. We can query the queue for how many are available.\n     private int numBuffs;\n \n-    private final int buffSize;\n+    private long buffSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzMwMw==", "bodyText": "my mistake. fixed.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404267303", "createdAt": "2020-04-06T17:32:37Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadBufferPool.java", "diffHunk": "@@ -37,23 +40,23 @@\n     queue will not compromise the async nature of this workflow. Fluxes themselves are internally synchronized to ensure\n     only one call to onNext happens at a time.\n      */\n-    private final BlockingQueue<ByteBuffer> buffers;\n+    private final BlockingQueue<BufferAggregator> buffers;\n \n     private final int maxBuffs;\n \n     // The number of buffs we have allocated. We can query the queue for how many are available.\n     private int numBuffs;\n \n-    private final int buffSize;\n+    private long buffSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNjI1Nw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODM3OTUwOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-file-datalake/src/main/java/com/azure/storage/file/datalake/DataLakeFileAsyncClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjo1MToyMVrOGBg6kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjo0OFrOGBihiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0MTA0MQ==", "bodyText": "Package private, shouldn't require a deprecation", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404241041", "createdAt": "2020-04-06T16:51:21Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-file-datalake/src/main/java/com/azure/storage/file/datalake/DataLakeFileAsyncClient.java", "diffHunk": "@@ -76,8 +77,14 @@\n \n     /**\n      * Indicates the maximum number of bytes that can be sent in a call to upload.\n+     * @deprecated Use {@link #MAX_APPEND_FILE_BYTES_LONG}\n      */\n+    @Deprecated\n     static final int MAX_APPEND_FILE_BYTES = 100 * Constants.MB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzQwMA==", "bodyText": "done.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404267400", "createdAt": "2020-04-06T17:32:48Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-file-datalake/src/main/java/com/azure/storage/file/datalake/DataLakeFileAsyncClient.java", "diffHunk": "@@ -76,8 +77,14 @@\n \n     /**\n      * Indicates the maximum number of bytes that can be sent in a call to upload.\n+     * @deprecated Use {@link #MAX_APPEND_FILE_BYTES_LONG}\n      */\n+    @Deprecated\n     static final int MAX_APPEND_FILE_BYTES = 100 * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0MTA0MQ=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODY0MTYwOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzo1OTowN1rOGBjggg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzoxMToyOVrOGCNvVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4MzUyMg==", "bodyText": "I think there's a constant for GB that we could use here", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404283522", "createdAt": "2020-04-06T17:59:07Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4NDU4MA==", "bodyText": "Problem is. Jumbo block is up to exactly 4000MB. 4GB is more than that.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404284580", "createdAt": "2020-04-06T18:00:49Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4MzUyMg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk3NTQ0NA==", "bodyText": "Oh I see", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404975444", "createdAt": "2020-04-07T17:11:29Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4MzUyMg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODY0Mjk1OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzo1OToyOVrOGBjhWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxODowMDo1NFrOGBjk0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4MzczNg==", "bodyText": "Can we make that 4GB", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404283736", "createdAt": "2020-04-06T17:59:29Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -313,7 +313,7 @@\n      * @param tier {@link AccessTier} for the destination blob.\n      * @param requestConditions {@link BlobRequestConditions}\n      * @return An empty response\n-     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 100MB\n+     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 4000MB", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4NDYyNQ==", "bodyText": "Problem is. Jumbo block is up to exactly 4000MB. 4GB is more than that.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404284625", "createdAt": "2020-04-06T18:00:54Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -313,7 +313,7 @@\n      * @param tier {@link AccessTier} for the destination blob.\n      * @param requestConditions {@link BlobRequestConditions}\n      * @return An empty response\n-     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 100MB\n+     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 4000MB", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI4MzczNg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTE2NTkzOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/ParallelTransferOptions.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDoyNzo1OVrOGBooQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjowNToyMlrOGBrpQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NzQyNQ==", "bodyText": "While our property must be Long to allow for a \"not set\" option, does our setter need to be? If a user is supplying a value, should we not assume it's non-null? If we use long then users can get auto-cast from int for free. However, if we believe users need to be able to set null then I suppose this isn't an option.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404367425", "createdAt": "2020-04-06T20:27:59Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/ParallelTransferOptions.java", "diffHunk": "@@ -60,35 +68,54 @@ public ParallelTransferOptions(Integer blockSize, Integer numBuffers, ProgressRe\n      * any data is sent. Must be greater than 0. May be null to accept default behavior, which is the maximum value the\n      * service accepts for uploading in a single requests and is represented by\n      * {@link BlockBlobAsyncClient#MAX_UPLOAD_BLOB_BYTES}.\n+     * @deprecated Use fluent interface to set properties instead.\n      */\n+    @Deprecated\n     public ParallelTransferOptions(Integer blockSize, Integer numBuffers, ProgressReceiver progressReceiver,\n         Integer maxSingleUploadSize) {\n-        if (blockSize != null) {\n-            StorageImplUtils.assertInBounds(\"blockSize\", blockSize, 1, BlockBlobAsyncClient.MAX_STAGE_BLOCK_BYTES);\n-        }\n-        this.blockSize = blockSize;\n-\n-        if (numBuffers != null) {\n-            StorageImplUtils.assertInBounds(\"numBuffers\", numBuffers, 2, Integer.MAX_VALUE);\n-        }\n-        this.numBuffers = numBuffers;\n-        this.progressReceiver = progressReceiver;\n-\n-        if (maxSingleUploadSize != null) {\n-            StorageImplUtils.assertInBounds(\"maxSingleUploadSize\", maxSingleUploadSize, 1,\n-                BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES);\n-        }\n-        this.maxSingleUploadSize = maxSingleUploadSize;\n+        this.setBlockSize(blockSize == null ? null : Long.valueOf(blockSize));\n+        this.setNumBuffers(numBuffers);\n+        this.setProgressReceiver(progressReceiver);\n+        this.setMaxSingleUploadSize(maxSingleUploadSize == null ? null : Long.valueOf(maxSingleUploadSize));\n     }\n \n     /**\n      * Gets the block size (chunk size) to transfer at a time.\n      * @return The block size.\n+     * @deprecated Use {@link #getBlockSizeLong()}.\n      */\n+    @Deprecated\n     public Integer getBlockSize() {\n+        return this.blockSize == null ? null : Math.toIntExact(this.blockSize);\n+    }\n+\n+    /**\n+     * Gets the block size (chunk size) to transfer at a time.\n+     * @return The block size.\n+     */\n+    public Long getBlockSizeLong() {\n         return this.blockSize;\n     }\n \n+    /**\n+     * Sets the block size (chunk size) to transfer at a time.\n+     * For upload, The block size is the size of each block that will be staged. This value also determines the number\n+     * of requests that need to be made. If block size is large, upload will make fewer network calls, but each\n+     * individual call will send more data and will therefore take longer. This parameter also determines the size\n+     * that each buffer uses when buffering is required and consequently amount of memory consumed by such methods may\n+     * be up to blockSize * numBuffers.\n+     *\n+     * @param blockSize The block size.\n+     * @return The ParallelTransferOptions object itself.\n+     */\n+    public ParallelTransferOptions setBlockSize(Long blockSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxNjgzMg==", "bodyText": "In such case I'd rather add non-null validation - but since it's optional customer should be able to \"unset\" it - end of day it just became mutable data structure. If I were customer where this thing is result of some computation (weird but possible) then I'd be quite upset about the need of if/else-ing. Besides if some of them are actually passing Integer around that could be null for some reason then autoboxing will blow up on nulls if they don't else/if correctly.\nOther thing. Usually in classes like that I used to see symmetry between getter and setter - they usually speak same type. It'd be quite non-idiomatic in Java if we do otherwise.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404416832", "createdAt": "2020-04-06T22:05:22Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/ParallelTransferOptions.java", "diffHunk": "@@ -60,35 +68,54 @@ public ParallelTransferOptions(Integer blockSize, Integer numBuffers, ProgressRe\n      * any data is sent. Must be greater than 0. May be null to accept default behavior, which is the maximum value the\n      * service accepts for uploading in a single requests and is represented by\n      * {@link BlockBlobAsyncClient#MAX_UPLOAD_BLOB_BYTES}.\n+     * @deprecated Use fluent interface to set properties instead.\n      */\n+    @Deprecated\n     public ParallelTransferOptions(Integer blockSize, Integer numBuffers, ProgressReceiver progressReceiver,\n         Integer maxSingleUploadSize) {\n-        if (blockSize != null) {\n-            StorageImplUtils.assertInBounds(\"blockSize\", blockSize, 1, BlockBlobAsyncClient.MAX_STAGE_BLOCK_BYTES);\n-        }\n-        this.blockSize = blockSize;\n-\n-        if (numBuffers != null) {\n-            StorageImplUtils.assertInBounds(\"numBuffers\", numBuffers, 2, Integer.MAX_VALUE);\n-        }\n-        this.numBuffers = numBuffers;\n-        this.progressReceiver = progressReceiver;\n-\n-        if (maxSingleUploadSize != null) {\n-            StorageImplUtils.assertInBounds(\"maxSingleUploadSize\", maxSingleUploadSize, 1,\n-                BlockBlobAsyncClient.MAX_UPLOAD_BLOB_BYTES);\n-        }\n-        this.maxSingleUploadSize = maxSingleUploadSize;\n+        this.setBlockSize(blockSize == null ? null : Long.valueOf(blockSize));\n+        this.setNumBuffers(numBuffers);\n+        this.setProgressReceiver(progressReceiver);\n+        this.setMaxSingleUploadSize(maxSingleUploadSize == null ? null : Long.valueOf(maxSingleUploadSize));\n     }\n \n     /**\n      * Gets the block size (chunk size) to transfer at a time.\n      * @return The block size.\n+     * @deprecated Use {@link #getBlockSizeLong()}.\n      */\n+    @Deprecated\n     public Integer getBlockSize() {\n+        return this.blockSize == null ? null : Math.toIntExact(this.blockSize);\n+    }\n+\n+    /**\n+     * Gets the block size (chunk size) to transfer at a time.\n+     * @return The block size.\n+     */\n+    public Long getBlockSizeLong() {\n         return this.blockSize;\n     }\n \n+    /**\n+     * Sets the block size (chunk size) to transfer at a time.\n+     * For upload, The block size is the size of each block that will be staged. This value also determines the number\n+     * of requests that need to be made. If block size is large, upload will make fewer network calls, but each\n+     * individual call will send more data and will therefore take longer. This parameter also determines the size\n+     * that each buffer uses when buffering is required and consequently amount of memory consumed by such methods may\n+     * be up to blockSize * numBuffers.\n+     *\n+     * @param blockSize The block size.\n+     * @return The ParallelTransferOptions object itself.\n+     */\n+    public ParallelTransferOptions setBlockSize(Long blockSize) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NzQyNQ=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTE3NzMwOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDozMToxMlrOGBovXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDo1Mjo0MVrOGBvIlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2OTI0NA==", "bodyText": "What is this indicating?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404369244", "createdAt": "2020-04-06T20:31:12Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODU4Mw==", "bodyText": "That's not harmful remnant of swagger generation. See swagger/readme.md change in this PR. In order to transition from int->long I had to generate two Java properties for same field in such a way that one is actually used by Jackson parser to deserialize incoming xml and other to assure backwards compatibility - then remove data binding annotations and body so that extra property doesn't take part in deserialization process.\nThis comment is remnant of this process. I didn't manage to invent right regex that could get rid of this yet. But I can try harder.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404418583", "createdAt": "2020-04-06T22:09:20Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2OTI0NA=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ3NDAwNw==", "bodyText": "removed..", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404474007", "createdAt": "2020-04-07T00:52:41Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2OTI0NA=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTIwNDUxOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDozODo1OVrOGBo__g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjowOTo0MFrOGBrwhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MzUwMg==", "bodyText": "Can someone chime in on why this setter is here in the first place? I thought this was a return type only.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404373502", "createdAt": "2020-04-06T20:38:59Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -48,22 +54,44 @@ public Block setName(String name) {\n     }\n \n     /**\n-     * Get the size property: The block size in bytes.\n+     * Get the sizeLong property: The block size in bytes.\n+     *\n+     * @return the sizeLong value.\n+     */\n+    public long getSizeLong() {\n+        return this.sizeLong;\n+    }\n+\n+    /**\n+     * Set the sizeLong property: The block size in bytes.\n+     *\n+     * @param sizeLong the sizeLong value to set.\n+     * @return the Block object itself.\n+     */\n+    public Block setSizeLong(long sizeLong) {\n+        this.sizeLong = sizeLong;\n+        return this;\n+    }\n+\n+    /**\n+     * Get the size property: The size property.\n      *\n      * @return the size value.\n+     * @deprecated Use {@link #getSizeLong()}\n      */\n-    public int getSize() {\n-        return this.size;\n+    @Deprecated  public int getSize() {\n+        return (int) this.sizeLong;\n     }\n \n     /**\n-     * Set the size property: The block size in bytes.\n+     * Set the size property: The size property.\n      *\n      * @param size the size value to set.\n+     * @deprecated Use {@link #setSizeLong(long)}\n      * @return the Block object itself.\n      */\n-    public Block setSize(int size) {\n-        this.size = size;\n+    @Deprecated public Block setSize(int size) {\n+        this.sizeLong = size;\n         return this;\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODY5NA==", "bodyText": "I believe Jackson parser needs that to deserialize XML.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404418694", "createdAt": "2020-04-06T22:09:40Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -48,22 +54,44 @@ public Block setName(String name) {\n     }\n \n     /**\n-     * Get the size property: The block size in bytes.\n+     * Get the sizeLong property: The block size in bytes.\n+     *\n+     * @return the sizeLong value.\n+     */\n+    public long getSizeLong() {\n+        return this.sizeLong;\n+    }\n+\n+    /**\n+     * Set the sizeLong property: The block size in bytes.\n+     *\n+     * @param sizeLong the sizeLong value to set.\n+     * @return the Block object itself.\n+     */\n+    public Block setSizeLong(long sizeLong) {\n+        this.sizeLong = sizeLong;\n+        return this;\n+    }\n+\n+    /**\n+     * Get the size property: The size property.\n      *\n      * @return the size value.\n+     * @deprecated Use {@link #getSizeLong()}\n      */\n-    public int getSize() {\n-        return this.size;\n+    @Deprecated  public int getSize() {\n+        return (int) this.sizeLong;\n     }\n \n     /**\n-     * Set the size property: The block size in bytes.\n+     * Set the size property: The size property.\n      *\n      * @param size the size value to set.\n+     * @deprecated Use {@link #setSizeLong(long)}\n      * @return the Block object itself.\n      */\n-    public Block setSize(int size) {\n-        this.size = size;\n+    @Deprecated public Block setSize(int size) {\n+        this.sizeLong = size;\n         return this;\n     }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MzUwMg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTIyODUxOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDo0NjoyOVrOGBpPZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyODoyMFrOGCQqGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NzQ0Nw==", "bodyText": "Hard to see in this review but what is the meaning of the value being passed in? Does it make sense for the base class constructor to get overloaded (or edited) to long? Passing max value feels weird.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404377447", "createdAt": "2020-04-06T20:46:29Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQyNTQ0Mw==", "bodyText": "It ends up being used here https://github.com/Azure/azure-sdk-for-java/blob/master/sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/StorageOutputStream.java#L54 .\nAs far as I can tell from reading inheritance tree of StorageOutputStream - this can't be changed to long because of conversion to Flux of ByteBuffers - these are constrained by int capacity - these conversions happen in subtypes.\n@gapra-msft @rickle-msft  do you guys have any context behind previously chosen value?\nI think this could be set to Math.min(Integer.MAX_VALUE, parallelTransferOptions.getBlockSizeLong()) so that it would result in ByteBuffers already trimmed nice for staging blocks (for small blocks) and largest possible ByteBuffers for jumbo blocks.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404425443", "createdAt": "2020-04-06T22:25:28Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NzQ0Nw=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4Mzc5OQ==", "bodyText": "Actually, specifically for BlockBlobOutputStream, after my changes to make it write via buffered upload, this this.writeThreshold isn't used. If you look at BlockBlobOutputStream, writeInternal is overridden and dispatchWrite is never called (it just returns an empty mono). Could you just add a note about that if you don't mind?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404983799", "createdAt": "2020-04-07T17:24:57Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NzQ0Nw=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4Mzk4MA==", "bodyText": "Basically all the write Threshold logic is handled within buffered upload", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404983980", "createdAt": "2020-04-07T17:25:17Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NzQ0Nw=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMzI1OQ==", "bodyText": "added comment per our discussion.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405023259", "createdAt": "2020-04-07T18:28:20Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NzQ0Nw=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTIzNTg5OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlockBlobAsyncClient.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDo0ODo0NFrOGBpUCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0OTo1M1rOGCPOBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3ODYzMg==", "bodyText": "Do we want to up these values to max int? I know they're deprecated but there's still a lot of room between 256MB and max int that customers can use if they want and their clamping logic would be misinformed from this.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404378632", "createdAt": "2020-04-06T20:48:44Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlockBlobAsyncClient.java", "diffHunk": "@@ -58,14 +58,28 @@\n \n     /**\n      * Indicates the maximum number of bytes that can be sent in a call to upload.\n+     * @deprecated Use {@link #MAX_STAGE_BLOCK_BYTES_LONG}\n      */\n+    @Deprecated\n     public static final int MAX_UPLOAD_BLOB_BYTES = 256 * Constants.MB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQyNzEyNw==", "bodyText": "That's a good idea. However I'd rather do that only for blocks in this PR. Bumping single upload threshold deserve own PR and testing.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404427127", "createdAt": "2020-04-06T22:29:44Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlockBlobAsyncClient.java", "diffHunk": "@@ -58,14 +58,28 @@\n \n     /**\n      * Indicates the maximum number of bytes that can be sent in a call to upload.\n+     * @deprecated Use {@link #MAX_STAGE_BLOCK_BYTES_LONG}\n      */\n+    @Deprecated\n     public static final int MAX_UPLOAD_BLOB_BYTES = 256 * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3ODYzMg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTY4Nw==", "bodyText": "Sadly. Looks like it would be considered as breaking change.\n[ERROR] java.field.constantValueChanged: field com.azure.storage.blob.specialized.BlockBlobAsyncClient.MAX_STAGE_BLOCK_BYTES: Constant field changed value from '104857600' to '2147483647'. (breaks semantic versioning)\n[ERROR] java.field.constantValueChanged: field com.azure.storage.blob.specialized.BlockBlobClient.MAX_STAGE_BLOCK_BYTES: Constant field changed value from '104857600' to '2147483647'. (breaks semantic versioning)\n[ERROR]\n[ERROR] Consult the plugin output above for suggestions on how to ignore the found problems.```", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404999687", "createdAt": "2020-04-07T17:49:53Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlockBlobAsyncClient.java", "diffHunk": "@@ -58,14 +58,28 @@\n \n     /**\n      * Indicates the maximum number of bytes that can be sent in a call to upload.\n+     * @deprecated Use {@link #MAX_STAGE_BLOCK_BYTES_LONG}\n      */\n+    @Deprecated\n     public static final int MAX_UPLOAD_BLOB_BYTES = 256 * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3ODYzMg=="}, "originalCommit": {"oid": "9095a12723f9035885e4f35be58d4abd935ff632"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTM1MDU4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMToyMjo1N1rOGBqaoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo1NDoyOFrOGBuGFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM5NjcwNQ==", "bodyText": "Can we say 4GB?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404396705", "createdAt": "2020-04-06T21:22:57Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -313,7 +313,7 @@\n      * @param tier {@link AccessTier} for the destination blob.\n      * @param requestConditions {@link BlobRequestConditions}\n      * @return An empty response\n-     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 100MB\n+     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 4000MB", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1Njk4Mg==", "bodyText": "That has been already asked. Problem is. Jumbo block is up to exactly 4000MB. 4GB is more than that.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404456982", "createdAt": "2020-04-06T23:54:28Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -313,7 +313,7 @@\n      * @param tier {@link AccessTier} for the destination blob.\n      * @param requestConditions {@link BlobRequestConditions}\n      * @return An empty response\n-     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 100MB\n+     * @throws IllegalArgumentException If {@code blockSize} is less than 0 or greater than 4000MB", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM5NjcwNQ=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTM1NDE0OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMToyMzo1NVrOGBqc0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo1NTowMlrOGBuGyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM5NzI2Nw==", "bodyText": "Should this be 4 * 1024 * MB? And should we just make it 4 * GB?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404397267", "createdAt": "2020-04-06T21:23:55Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1Njc0OQ==", "bodyText": "It is actually 4000MB and not 4096MB.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404456749", "createdAt": "2020-04-06T23:53:46Z", "author": {"login": "jaschrep-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM5NzI2Nw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NzE2MA==", "bodyText": "Jumbo block is up to exactly 4000MB.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404457160", "createdAt": "2020-04-06T23:55:02Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob-cryptography/src/main/java/com/azure/storage/blob/specialized/cryptography/EncryptedBlobAsyncClient.java", "diffHunk": "@@ -71,7 +71,7 @@\n public class EncryptedBlobAsyncClient extends BlobAsyncClient {\n \n     static final int BLOB_DEFAULT_UPLOAD_BLOCK_SIZE = 4 * Constants.MB;\n-    private static final int BLOB_MAX_UPLOAD_BLOCK_SIZE = 100 * Constants.MB;\n+    private static final long BLOB_MAX_UPLOAD_BLOCK_SIZE = 4000L * Constants.MB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM5NzI2Nw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTM4MjQ4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMTozMzoxOFrOGBqu6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMTozMzoxOFrOGBqu6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQwMTg5OA==", "bodyText": "Oh thanks :) Definitely wasn't expecting you to update nio", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404401898", "createdAt": "2020-04-06T21:33:18Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -142,7 +142,12 @@\n         // Read configurations and build client.\n         try {\n             this.blobServiceClient = this.buildBlobServiceClient(accountName, config);\n-            this.blockSize = (Integer) config.get(AZURE_STORAGE_UPLOAD_BLOCK_SIZE);\n+            Object blockSize = config.get(AZURE_STORAGE_UPLOAD_BLOCK_SIZE);\n+            if (blockSize instanceof Integer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTQ4NjY2OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjowODo1NlrOGBrvag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDo1MjoxMlrOGBvIDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQxMA==", "bodyText": "This is floating a little oddly. Did this come out of the generator?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404418410", "createdAt": "2020-04-06T22:08:56Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NzYzNA==", "bodyText": "Yes. I had to generate two bend generator to produce two properties out of one and then string.replace some parts of the code. See swagger/readme.md change in this PR.\nI didn't find good regex to get rid of this thing yet.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404457634", "createdAt": "2020-04-06T23:56:37Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQxMA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ3Mzg2OA==", "bodyText": "fixed", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404473868", "createdAt": "2020-04-07T00:52:12Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/Block.java", "diffHunk": "@@ -25,7 +25,13 @@\n      * The block size in bytes.\n      */\n     @JsonProperty(value = \"Size\", required = true)\n-    private int size;\n+    private long sizeLong;\n+\n+    /*\n+     * The size property.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQxMA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTQ5NTQ3OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjoxMjoyMFrOGBr07A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyNzozN1rOGCQodg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxOTgyMA==", "bodyText": "Why did we switch to max long?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404419820", "createdAt": "2020-04-06T22:12:20Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1ODAyOQ==", "bodyText": "I left long comment on @jaschrep-msft  comment above and tagged you as there's a question. Could you please reply there?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404458029", "createdAt": "2020-04-06T23:57:46Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxOTgyMA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjgzOA==", "bodyText": "added comment after offline discussion. This value has no real meaning for blockbloboutputstream.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405022838", "createdAt": "2020-04-07T18:27:37Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlobOutputStream.java", "diffHunk": "@@ -159,7 +159,7 @@ void commit() {\n         private BlockBlobOutputStream(final BlobAsyncClient client,\n             final ParallelTransferOptions parallelTransferOptions, final BlobHttpHeaders headers,\n             final Map<String, String> metadata, final AccessTier tier, final BlobRequestConditions requestConditions) {\n-            super(BlockBlobClient.MAX_STAGE_BLOCK_BYTES);\n+            super(Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxOTgyMA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTYyMzk4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzowMzozNVrOGBtDFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODo0NzoyM1rOGCRXPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQzOTgzMQ==", "bodyText": "Can you use closures for these inline functions?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404439831", "createdAt": "2020-04-06T23:03:35Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "diffHunk": "@@ -813,4 +833,37 @@ class APISpec extends Specification {\n             return Mono.error(new IOException())\n         }\n     }\n+\n+    class TransientFailureInjectingHttpPipelinePolicy implements HttpPipelinePolicy {\n+\n+        private ConcurrentHashMap<String, Boolean> failureTracker = new ConcurrentHashMap<>();\n+\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            def key = request.url.toString()\n+            if (failureTracker.get(key, false)) {\n+                return httpPipelineNextPolicy.process()\n+            } else {\n+                failureTracker.put(key, true)\n+                return request.getBody().flatMap(new Function<ByteBuffer, Publisher<ByteBuffer>>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzNDgxNQ==", "bodyText": "done", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405034815", "createdAt": "2020-04-07T18:47:23Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "diffHunk": "@@ -813,4 +833,37 @@ class APISpec extends Specification {\n             return Mono.error(new IOException())\n         }\n     }\n+\n+    class TransientFailureInjectingHttpPipelinePolicy implements HttpPipelinePolicy {\n+\n+        private ConcurrentHashMap<String, Boolean> failureTracker = new ConcurrentHashMap<>();\n+\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            def key = request.url.toString()\n+            if (failureTracker.get(key, false)) {\n+                return httpPipelineNextPolicy.process()\n+            } else {\n+                failureTracker.put(key, true)\n+                return request.getBody().flatMap(new Function<ByteBuffer, Publisher<ByteBuffer>>() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQzOTgzMQ=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTYyNzI3OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzowNTowN1rOGBtFDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyNzowOVrOGCQnVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0MDMzNA==", "bodyText": "Is this just to alter the data to inject the failure? In general, can you leave some notes about the intended behavior of this type?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404440334", "createdAt": "2020-04-06T23:05:07Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "diffHunk": "@@ -813,4 +833,37 @@ class APISpec extends Specification {\n             return Mono.error(new IOException())\n         }\n     }\n+\n+    class TransientFailureInjectingHttpPipelinePolicy implements HttpPipelinePolicy {\n+\n+        private ConcurrentHashMap<String, Boolean> failureTracker = new ConcurrentHashMap<>();\n+\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            def key = request.url.toString()\n+            if (failureTracker.get(key, false)) {\n+                return httpPipelineNextPolicy.process()\n+            } else {\n+                failureTracker.put(key, true)\n+                return request.getBody().flatMap(new Function<ByteBuffer, Publisher<ByteBuffer>>() {\n+                    @Override\n+                    Publisher<ByteBuffer> apply(ByteBuffer byteBuffer) {\n+                        byteBuffer.get()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1ODQ2OA==", "bodyText": "This is to make sure byteBuffers were \"touched\". I'll leave a comment.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404458468", "createdAt": "2020-04-06T23:59:07Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "diffHunk": "@@ -813,4 +833,37 @@ class APISpec extends Specification {\n             return Mono.error(new IOException())\n         }\n     }\n+\n+    class TransientFailureInjectingHttpPipelinePolicy implements HttpPipelinePolicy {\n+\n+        private ConcurrentHashMap<String, Boolean> failureTracker = new ConcurrentHashMap<>();\n+\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            def key = request.url.toString()\n+            if (failureTracker.get(key, false)) {\n+                return httpPipelineNextPolicy.process()\n+            } else {\n+                failureTracker.put(key, true)\n+                return request.getBody().flatMap(new Function<ByteBuffer, Publisher<ByteBuffer>>() {\n+                    @Override\n+                    Publisher<ByteBuffer> apply(ByteBuffer byteBuffer) {\n+                        byteBuffer.get()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0MDMzNA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjU0OA==", "bodyText": "done", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405022548", "createdAt": "2020-04-07T18:27:09Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/APISpec.groovy", "diffHunk": "@@ -813,4 +833,37 @@ class APISpec extends Specification {\n             return Mono.error(new IOException())\n         }\n     }\n+\n+    class TransientFailureInjectingHttpPipelinePolicy implements HttpPipelinePolicy {\n+\n+        private ConcurrentHashMap<String, Boolean> failureTracker = new ConcurrentHashMap<>();\n+\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            def key = request.url.toString()\n+            if (failureTracker.get(key, false)) {\n+                return httpPipelineNextPolicy.process()\n+            } else {\n+                failureTracker.put(key, true)\n+                return request.getBody().flatMap(new Function<ByteBuffer, Publisher<ByteBuffer>>() {\n+                    @Override\n+                    Publisher<ByteBuffer> apply(ByteBuffer byteBuffer) {\n+                        byteBuffer.get()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0MDMzNA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTY2NDg3OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzoyMToxOFrOGBtbbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyNzowMlrOGCQnGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0NjA2Mg==", "bodyText": "Is the only difference between this test and the last one that this one drops the payload and counts it in the pipeline? Can you leave a note about that?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404446062", "createdAt": "2020-04-06T23:21:18Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "diffHunk": "@@ -0,0 +1,244 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob\n+\n+import com.azure.core.http.HttpPipelineCallContext\n+import com.azure.core.http.HttpPipelineNextPolicy\n+import com.azure.core.http.HttpResponse\n+import com.azure.core.http.policy.HttpPipelinePolicy\n+import com.azure.core.util.Context\n+import com.azure.storage.blob.models.BlockListType\n+import com.azure.storage.blob.models.ParallelTransferOptions\n+import com.azure.storage.common.implementation.Constants\n+import com.azure.storage.common.policy.StorageSharedKeyCredentialPolicy\n+import reactor.core.publisher.Flux\n+import reactor.core.publisher.Mono\n+import spock.lang.Ignore\n+import spock.lang.Requires\n+\n+import java.nio.ByteBuffer\n+import java.nio.charset.StandardCharsets\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.function.BiFunction\n+\n+class LargeBlobTest extends APISpec {\n+\n+    long maxBlockSize =  4000L * Constants.MB\n+    BlobClient blobClient\n+    BlobAsyncClient blobAsyncClient\n+    String blobName\n+    List<Mono<Long>> putBlockPayloadSizes = Collections.synchronizedList(new ArrayList<>())\n+    AtomicLong count = new AtomicLong()\n+    boolean collectSize = true\n+\n+    def setup() {\n+        blobName = generateBlobName()\n+        def basic = cc.getBlobClient(blobName)\n+        this.blobClient = getBlobClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+        this.blobAsyncClient = getBlobAsyncClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Stage Real Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+        def client = cc.getBlobClient(blobName)\n+\n+        when:\n+        client.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        client.getBlockBlobClient().commitBlockList([blockId])\n+        def blockList = client.getBlockBlobClient().listBlocks(BlockListType.COMMITTED)\n+\n+        then:\n+        blockList.committedBlocks.size() == 1\n+        blockList.committedBlocks.get(0).getSizeLong() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Stage Large Blob\"() {\n+        given:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjQ5MQ==", "bodyText": "commented", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405022491", "createdAt": "2020-04-07T18:27:02Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "diffHunk": "@@ -0,0 +1,244 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob\n+\n+import com.azure.core.http.HttpPipelineCallContext\n+import com.azure.core.http.HttpPipelineNextPolicy\n+import com.azure.core.http.HttpResponse\n+import com.azure.core.http.policy.HttpPipelinePolicy\n+import com.azure.core.util.Context\n+import com.azure.storage.blob.models.BlockListType\n+import com.azure.storage.blob.models.ParallelTransferOptions\n+import com.azure.storage.common.implementation.Constants\n+import com.azure.storage.common.policy.StorageSharedKeyCredentialPolicy\n+import reactor.core.publisher.Flux\n+import reactor.core.publisher.Mono\n+import spock.lang.Ignore\n+import spock.lang.Requires\n+\n+import java.nio.ByteBuffer\n+import java.nio.charset.StandardCharsets\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.function.BiFunction\n+\n+class LargeBlobTest extends APISpec {\n+\n+    long maxBlockSize =  4000L * Constants.MB\n+    BlobClient blobClient\n+    BlobAsyncClient blobAsyncClient\n+    String blobName\n+    List<Mono<Long>> putBlockPayloadSizes = Collections.synchronizedList(new ArrayList<>())\n+    AtomicLong count = new AtomicLong()\n+    boolean collectSize = true\n+\n+    def setup() {\n+        blobName = generateBlobName()\n+        def basic = cc.getBlobClient(blobName)\n+        this.blobClient = getBlobClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+        this.blobAsyncClient = getBlobAsyncClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Stage Real Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+        def client = cc.getBlobClient(blobName)\n+\n+        when:\n+        client.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        client.getBlockBlobClient().commitBlockList([blockId])\n+        def blockList = client.getBlockBlobClient().listBlocks(BlockListType.COMMITTED)\n+\n+        then:\n+        blockList.committedBlocks.size() == 1\n+        blockList.committedBlocks.get(0).getSizeLong() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Stage Large Blob\"() {\n+        given:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0NjA2Mg=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTY4MjE4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzoyOTowN1rOGBtlyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTo0MjoyM1rOGCJ3Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0ODcxMw==", "bodyText": "Remove", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404448713", "createdAt": "2020-04-06T23:29:07Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "diffHunk": "@@ -0,0 +1,244 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob\n+\n+import com.azure.core.http.HttpPipelineCallContext\n+import com.azure.core.http.HttpPipelineNextPolicy\n+import com.azure.core.http.HttpResponse\n+import com.azure.core.http.policy.HttpPipelinePolicy\n+import com.azure.core.util.Context\n+import com.azure.storage.blob.models.BlockListType\n+import com.azure.storage.blob.models.ParallelTransferOptions\n+import com.azure.storage.common.implementation.Constants\n+import com.azure.storage.common.policy.StorageSharedKeyCredentialPolicy\n+import reactor.core.publisher.Flux\n+import reactor.core.publisher.Mono\n+import spock.lang.Ignore\n+import spock.lang.Requires\n+\n+import java.nio.ByteBuffer\n+import java.nio.charset.StandardCharsets\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.function.BiFunction\n+\n+class LargeBlobTest extends APISpec {\n+\n+    long maxBlockSize =  4000L * Constants.MB\n+    BlobClient blobClient\n+    BlobAsyncClient blobAsyncClient\n+    String blobName\n+    List<Mono<Long>> putBlockPayloadSizes = Collections.synchronizedList(new ArrayList<>())\n+    AtomicLong count = new AtomicLong()\n+    boolean collectSize = true\n+\n+    def setup() {\n+        blobName = generateBlobName()\n+        def basic = cc.getBlobClient(blobName)\n+        this.blobClient = getBlobClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+        this.blobAsyncClient = getBlobAsyncClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Stage Real Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+        def client = cc.getBlobClient(blobName)\n+\n+        when:\n+        client.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        client.getBlockBlobClient().commitBlockList([blockId])\n+        def blockList = client.getBlockBlobClient().listBlocks(BlockListType.COMMITTED)\n+\n+        then:\n+        blockList.committedBlocks.size() == 1\n+        blockList.committedBlocks.get(0).getSizeLong() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Stage Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+\n+        when:\n+        blobClient.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        blobClient.getBlockBlobClient().commitBlockList([blockId])\n+\n+        then:\n+        count.get() == 1\n+        putBlockPayloadSizes.size() == 1\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Large Input\"() {\n+        given:\n+        def length = maxBlockSize * 2\n+        def flux = createLargeBuffer(length)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobAsyncClient.upload(flux, parallelTransferOptions)\n+        .block()\n+\n+        then:\n+        count.get() == 2\n+        putBlockPayloadSizes.size() == 2\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+        putBlockPayloadSizes[1].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Largest Input\"() {\n+        given:\n+        collectSize = false\n+        long blocks = 50 * 1000\n+        long length = maxBlockSize * blocks\n+        def flux = createLargeBuffer(length, Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobAsyncClient.upload(flux, parallelTransferOptions)\n+            .block()\n+\n+        then:\n+        count.get() == blocks\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Large Input Sync\"() {\n+        given:\n+        long blocks = 2\n+        long length = maxBlockSize * blocks\n+        def stream = createLargeInputStream(length, Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobClient.uploadWithResponse(\n+            stream, length, parallelTransferOptions,\n+            null, null, null, null, null, Context.NONE);\n+\n+        then:\n+        count.get() == blocks\n+        putBlockPayloadSizes.size() == 2\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+        putBlockPayloadSizes[1].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Upload Largest Input Sync\"() {\n+        given:\n+        collectSize = false\n+        long blocks = 50 * 1000\n+        long length = maxBlockSize * blocks\n+        def stream = createLargeInputStream(length, 100 * Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobClient.uploadWithResponse(\n+            stream, length, parallelTransferOptions,\n+            null, null, null, null, null, Context.NONE);\n+\n+        then:\n+        count.get() == blocks\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Upload Large File\"() {\n+        given:\n+        def file = getRandomLargeFile(maxBlockSize)\n+        def client = cc.getBlobClient(blobName)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        client.uploadFromFile(file.toPath().toString(), parallelTransferOptions,\n+            null, null, null, null, null)\n+\n+        then:\n+        true\n+    }\n+\n+    private InputStream createLargeInputStream(long size) {\n+        return createLargeInputStream(size, Constants.MB)\n+    }\n+\n+    private InputStream createLargeInputStream(long size, int chunkSize) {\n+        long numberOfSubStreams = (long) (size / chunkSize)\n+        def subStreams = new Vector()\n+        def bytes = getRandomByteArray(chunkSize)\n+        for (long i = 0; i < numberOfSubStreams; i++) {\n+            subStreams.add(new ByteArrayInputStream(bytes))\n+        }\n+        return new SequenceInputStream(subStreams.elements())\n+    }\n+\n+    private Flux<ByteBuffer> createLargeBuffer(long size) {\n+        return createLargeBuffer(size, Constants.MB)\n+    }\n+\n+    private Flux<ByteBuffer> createLargeBuffer(long size, int bufferSize) {\n+        def bytes = getRandomByteArray(bufferSize)\n+        long numberOfSubBuffers = (long) (size / bufferSize)\n+        return Flux.just(ByteBuffer.wrap(bytes))\n+            .map{buffer -> buffer.duplicate()}\n+            .repeat(numberOfSubBuffers - 1)\n+    }\n+\n+    File getRandomLargeFile(long size) {\n+        File file = File.createTempFile(UUID.randomUUID().toString(), \".txt\")\n+        file.deleteOnExit()\n+        FileOutputStream fos = new FileOutputStream(file)\n+\n+        if (size > Constants.MB) {\n+            for (def i = 0; i < size / Constants.MB; i++) {\n+                def dataSize = (int) Math.min(Constants.MB, size - i * Constants.MB)\n+                fos.write(getRandomByteArray(dataSize))\n+            }\n+        } else {\n+            fos.write(getRandomByteArray((int) size))\n+        }\n+\n+        fos.close()\n+        return file\n+    }\n+\n+    private class PayloadDroppingPolicy implements HttpPipelinePolicy {\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            // Substitute large body for put block requests and collect size of original body\n+            if (request.url.getQuery() != null && request.url.getQuery().endsWith(\"comp=block\")) {\n+                if (collectSize) {\n+                    def bytesReceived = request.getBody().reduce(0L, new BiFunction<Long, ByteBuffer, Long>() {\n+                        @Override\n+                        Long apply(Long a, ByteBuffer byteBuffer) {\n+                            return a + byteBuffer.remaining()\n+                        }\n+                    })\n+                    putBlockPayloadSizes.add(bytesReceived)\n+                }\n+                def currentCount = count.incrementAndGet()\n+                println(currentCount) // TODO remove this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkxMTk1MQ==", "bodyText": "removed.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404911951", "createdAt": "2020-04-07T15:42:23Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-blob/src/test/java/com/azure/storage/blob/LargeBlobTest.groovy", "diffHunk": "@@ -0,0 +1,244 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob\n+\n+import com.azure.core.http.HttpPipelineCallContext\n+import com.azure.core.http.HttpPipelineNextPolicy\n+import com.azure.core.http.HttpResponse\n+import com.azure.core.http.policy.HttpPipelinePolicy\n+import com.azure.core.util.Context\n+import com.azure.storage.blob.models.BlockListType\n+import com.azure.storage.blob.models.ParallelTransferOptions\n+import com.azure.storage.common.implementation.Constants\n+import com.azure.storage.common.policy.StorageSharedKeyCredentialPolicy\n+import reactor.core.publisher.Flux\n+import reactor.core.publisher.Mono\n+import spock.lang.Ignore\n+import spock.lang.Requires\n+\n+import java.nio.ByteBuffer\n+import java.nio.charset.StandardCharsets\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.function.BiFunction\n+\n+class LargeBlobTest extends APISpec {\n+\n+    long maxBlockSize =  4000L * Constants.MB\n+    BlobClient blobClient\n+    BlobAsyncClient blobAsyncClient\n+    String blobName\n+    List<Mono<Long>> putBlockPayloadSizes = Collections.synchronizedList(new ArrayList<>())\n+    AtomicLong count = new AtomicLong()\n+    boolean collectSize = true\n+\n+    def setup() {\n+        blobName = generateBlobName()\n+        def basic = cc.getBlobClient(blobName)\n+        this.blobClient = getBlobClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+        this.blobAsyncClient = getBlobAsyncClient(\n+            primaryCredential,\n+            basic.getBlobUrl(),\n+            new PayloadDroppingPolicy(),\n+            // Regenerate auth header after body got substituted\n+            new StorageSharedKeyCredentialPolicy(primaryCredential)\n+        )\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Stage Real Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+        def client = cc.getBlobClient(blobName)\n+\n+        when:\n+        client.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        client.getBlockBlobClient().commitBlockList([blockId])\n+        def blockList = client.getBlockBlobClient().listBlocks(BlockListType.COMMITTED)\n+\n+        then:\n+        blockList.committedBlocks.size() == 1\n+        blockList.committedBlocks.get(0).getSizeLong() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Stage Large Blob\"() {\n+        given:\n+        def stream = createLargeInputStream(maxBlockSize)\n+        def blockId = Base64.getEncoder().encodeToString(UUID.randomUUID().toString().getBytes(StandardCharsets.UTF_8))\n+\n+        when:\n+        blobClient.getBlockBlobClient().stageBlock(blockId, stream, maxBlockSize)\n+        blobClient.getBlockBlobClient().commitBlockList([blockId])\n+\n+        then:\n+        count.get() == 1\n+        putBlockPayloadSizes.size() == 1\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Large Input\"() {\n+        given:\n+        def length = maxBlockSize * 2\n+        def flux = createLargeBuffer(length)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobAsyncClient.upload(flux, parallelTransferOptions)\n+        .block()\n+\n+        then:\n+        count.get() == 2\n+        putBlockPayloadSizes.size() == 2\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+        putBlockPayloadSizes[1].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Largest Input\"() {\n+        given:\n+        collectSize = false\n+        long blocks = 50 * 1000\n+        long length = maxBlockSize * blocks\n+        def flux = createLargeBuffer(length, Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobAsyncClient.upload(flux, parallelTransferOptions)\n+            .block()\n+\n+        then:\n+        count.get() == blocks\n+    }\n+\n+    @Requires({ liveMode() })\n+    def \"Upload Large Input Sync\"() {\n+        given:\n+        long blocks = 2\n+        long length = maxBlockSize * blocks\n+        def stream = createLargeInputStream(length, Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobClient.uploadWithResponse(\n+            stream, length, parallelTransferOptions,\n+            null, null, null, null, null, Context.NONE);\n+\n+        then:\n+        count.get() == blocks\n+        putBlockPayloadSizes.size() == 2\n+        putBlockPayloadSizes[0].block() == maxBlockSize\n+        putBlockPayloadSizes[1].block() == maxBlockSize\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Upload Largest Input Sync\"() {\n+        given:\n+        collectSize = false\n+        long blocks = 50 * 1000\n+        long length = maxBlockSize * blocks\n+        def stream = createLargeInputStream(length, 100 * Constants.MB)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        blobClient.uploadWithResponse(\n+            stream, length, parallelTransferOptions,\n+            null, null, null, null, null, Context.NONE);\n+\n+        then:\n+        count.get() == blocks\n+    }\n+\n+    @Requires({ liveMode() })\n+    @Ignore(\"Takes really long time\")\n+    def \"Upload Large File\"() {\n+        given:\n+        def file = getRandomLargeFile(maxBlockSize)\n+        def client = cc.getBlobClient(blobName)\n+        def parallelTransferOptions = new ParallelTransferOptions().setBlockSize(maxBlockSize);\n+\n+        when:\n+        client.uploadFromFile(file.toPath().toString(), parallelTransferOptions,\n+            null, null, null, null, null)\n+\n+        then:\n+        true\n+    }\n+\n+    private InputStream createLargeInputStream(long size) {\n+        return createLargeInputStream(size, Constants.MB)\n+    }\n+\n+    private InputStream createLargeInputStream(long size, int chunkSize) {\n+        long numberOfSubStreams = (long) (size / chunkSize)\n+        def subStreams = new Vector()\n+        def bytes = getRandomByteArray(chunkSize)\n+        for (long i = 0; i < numberOfSubStreams; i++) {\n+            subStreams.add(new ByteArrayInputStream(bytes))\n+        }\n+        return new SequenceInputStream(subStreams.elements())\n+    }\n+\n+    private Flux<ByteBuffer> createLargeBuffer(long size) {\n+        return createLargeBuffer(size, Constants.MB)\n+    }\n+\n+    private Flux<ByteBuffer> createLargeBuffer(long size, int bufferSize) {\n+        def bytes = getRandomByteArray(bufferSize)\n+        long numberOfSubBuffers = (long) (size / bufferSize)\n+        return Flux.just(ByteBuffer.wrap(bytes))\n+            .map{buffer -> buffer.duplicate()}\n+            .repeat(numberOfSubBuffers - 1)\n+    }\n+\n+    File getRandomLargeFile(long size) {\n+        File file = File.createTempFile(UUID.randomUUID().toString(), \".txt\")\n+        file.deleteOnExit()\n+        FileOutputStream fos = new FileOutputStream(file)\n+\n+        if (size > Constants.MB) {\n+            for (def i = 0; i < size / Constants.MB; i++) {\n+                def dataSize = (int) Math.min(Constants.MB, size - i * Constants.MB)\n+                fos.write(getRandomByteArray(dataSize))\n+            }\n+        } else {\n+            fos.write(getRandomByteArray((int) size))\n+        }\n+\n+        fos.close()\n+        return file\n+    }\n+\n+    private class PayloadDroppingPolicy implements HttpPipelinePolicy {\n+        @Override\n+        Mono<HttpResponse> process(HttpPipelineCallContext httpPipelineCallContext, HttpPipelineNextPolicy httpPipelineNextPolicy) {\n+            def request = httpPipelineCallContext.httpRequest\n+            // Substitute large body for put block requests and collect size of original body\n+            if (request.url.getQuery() != null && request.url.getQuery().endsWith(\"comp=block\")) {\n+                if (collectSize) {\n+                    def bytesReceived = request.getBody().reduce(0L, new BiFunction<Long, ByteBuffer, Long>() {\n+                        @Override\n+                        Long apply(Long a, ByteBuffer byteBuffer) {\n+                            return a + byteBuffer.remaining()\n+                        }\n+                    })\n+                    putBlockPayloadSizes.add(bytesReceived)\n+                }\n+                def currentCount = count.incrementAndGet()\n+                println(currentCount) // TODO remove this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0ODcxMw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTcwMTE0OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzozODowN1rOGBtw8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyNjo0MlrOGCQmKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MTU3MA==", "bodyText": "Can you add some comments here describing the behavior:\nThe gate will only start emitting data after the threshold has been breached once it has been flushed. Checking the state of the threshold on receiving the first buffer means we can infer what upload operation we should do.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404451570", "createdAt": "2020-04-06T23:38:07Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadUtils.java", "diffHunk": "@@ -39,72 +37,25 @@\n         ParallelTransferOptions parallelTransferOptions,\n         final Function<Flux<ByteBuffer>, Mono<Response<T>>> uploadInChunks,\n         final BiFunction<Flux<ByteBuffer>, Long, Mono<Response<T>>> uploadFull) {\n-        final long[] bufferedDataSize = {0};\n-        final LinkedList<ByteBuffer> cachedBuffers = new LinkedList<>();\n \n-        /*\n-         * Window the reactive stream until either the stream completes or the windowing size is hit. If the window\n-         * size is hit the next emission will be the pointer to the rest of the reactive steam.\n-         *\n-         * Once the windowing has completed buffer the two streams, this should create a maximum overhead of ~4MB plus\n-         * the next stream emission if the window size was hit. If there are two streams buffered use Stage Blocks and\n-         * Put Block List as the upload mechanism otherwise use Put Blob.\n-         */\n+        PayloadSizeGate gate = new PayloadSizeGate(parallelTransferOptions.getMaxSingleUploadSizeLong());\n+\n         return data\n             .filter(ByteBuffer::hasRemaining)\n-            .windowUntil(buffer -> {\n-                if (bufferedDataSize[0] > parallelTransferOptions.getMaxSingleUploadSize()) {\n-                    return false;\n+            .concatMap(gate::write)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjI1MA==", "bodyText": "added comments", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405022250", "createdAt": "2020-04-07T18:26:42Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/UploadUtils.java", "diffHunk": "@@ -39,72 +37,25 @@\n         ParallelTransferOptions parallelTransferOptions,\n         final Function<Flux<ByteBuffer>, Mono<Response<T>>> uploadInChunks,\n         final BiFunction<Flux<ByteBuffer>, Long, Mono<Response<T>>> uploadFull) {\n-        final long[] bufferedDataSize = {0};\n-        final LinkedList<ByteBuffer> cachedBuffers = new LinkedList<>();\n \n-        /*\n-         * Window the reactive stream until either the stream completes or the windowing size is hit. If the window\n-         * size is hit the next emission will be the pointer to the rest of the reactive steam.\n-         *\n-         * Once the windowing has completed buffer the two streams, this should create a maximum overhead of ~4MB plus\n-         * the next stream emission if the window size was hit. If there are two streams buffered use Stage Blocks and\n-         * Put Block List as the upload mechanism otherwise use Put Blob.\n-         */\n+        PayloadSizeGate gate = new PayloadSizeGate(parallelTransferOptions.getMaxSingleUploadSizeLong());\n+\n         return data\n             .filter(ByteBuffer::hasRemaining)\n-            .windowUntil(buffer -> {\n-                if (bufferedDataSize[0] > parallelTransferOptions.getMaxSingleUploadSize()) {\n-                    return false;\n+            .concatMap(gate::write)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MTU3MA=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTcwMjg5OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/PayloadSizeGate.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzozODo0N1rOGBtx5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoyNjoyN1rOGCQljA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MTgxMw==", "bodyText": "I think you can delete this line as there's no concept of returning buffers here.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r404451813", "createdAt": "2020-04-06T23:38:47Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/PayloadSizeGate.java", "diffHunk": "@@ -0,0 +1,99 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.common.implementation;\n+\n+import reactor.core.publisher.Flux;\n+\n+import java.nio.ByteBuffer;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides ability to measure if incoming Flux of ByteBuffers is larger than a threshold.\n+ * This answers question if volume of data in bytes is larger than threshold.\n+ *\n+ * The {@link #write(ByteBuffer)} operation buffers incoming ByteBuffers until threshold is crossed.\n+ * After that it's pass-through as fact that data volume exceeds threshold is already determined.\n+ *\n+ * It is incumbent upon the caller to return the buffers after measurement is completed. It is also the caller's", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjA5Mg==", "bodyText": "deleted", "url": "https://github.com/Azure/azure-sdk-for-java/pull/9649#discussion_r405022092", "createdAt": "2020-04-07T18:26:27Z", "author": {"login": "kasobol-msft"}, "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/implementation/PayloadSizeGate.java", "diffHunk": "@@ -0,0 +1,99 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.common.implementation;\n+\n+import reactor.core.publisher.Flux;\n+\n+import java.nio.ByteBuffer;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides ability to measure if incoming Flux of ByteBuffers is larger than a threshold.\n+ * This answers question if volume of data in bytes is larger than threshold.\n+ *\n+ * The {@link #write(ByteBuffer)} operation buffers incoming ByteBuffers until threshold is crossed.\n+ * After that it's pass-through as fact that data volume exceeds threshold is already determined.\n+ *\n+ * It is incumbent upon the caller to return the buffers after measurement is completed. It is also the caller's", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MTgxMw=="}, "originalCommit": {"oid": "661a25d42c71e0bf76f92470b3e81cbc89dc1b03"}, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2123, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}