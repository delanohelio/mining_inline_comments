{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzNDAwMzU3", "number": 11433, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxOTo1ODoxMlrOD_08Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDoxMDoyMVrOD_1Kag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjU0MjM4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/BlobParallelUploadOptions.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxOTo1ODoxMlrOGauM6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNzoxOToyMlrOGb_HBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzEzMQ==", "bodyText": "Should this be called BlockBlobParallelUploadOptions based on the description. Or is this called this since it is the property bag for BlobClient upload.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430673131", "createdAt": "2020-05-26T19:58:12Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/BlobParallelUploadOptions.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.models;\n+\n+import com.azure.core.annotation.Fluent;\n+\n+import java.util.Map;\n+\n+/**\n+ * Extended options that may be passed when uploading a Block Blob in parallel.\n+ */\n+@Fluent\n+public class BlobParallelUploadOptions {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNjQ4NQ==", "bodyText": "I was thinking the latter. I am open to either", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430706485", "createdAt": "2020-05-26T21:03:23Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/BlobParallelUploadOptions.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.models;\n+\n+import com.azure.core.annotation.Fluent;\n+\n+import java.util.Map;\n+\n+/**\n+ * Extended options that may be passed when uploading a Block Blob in parallel.\n+ */\n+@Fluent\n+public class BlobParallelUploadOptions {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzEzMQ=="}, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk5ODcyNw==", "bodyText": "Given its use in BlobClient specific operations, I think the name is good.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r431998727", "createdAt": "2020-05-28T17:19:22Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/models/BlobParallelUploadOptions.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.models;\n+\n+import com.azure.core.annotation.Fluent;\n+\n+import java.util.Map;\n+\n+/**\n+ * Extended options that may be passed when uploading a Block Blob in parallel.\n+ */\n+@Fluent\n+public class BlobParallelUploadOptions {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzEzMQ=="}, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjU0NTk4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxOTo1OToyOVrOGauPXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowOTozOVrOGawajQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3Mzc1OA==", "bodyText": "Just a thought - Ideally wouldnt this model helper code go in the getter for ParallelTransferOptions in the options bag? or would that be odd for users when they see the getter returns something different from what they set", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430673758", "createdAt": "2020-05-26T19:59:29Z", "author": {"login": "gapra-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,\n+        Duration timeout, Context context) {\n+        BlobParallelUploadOptions blobParallelUploadOptions = options == null ? new BlobParallelUploadOptions()\n+            : options;\n         final ParallelTransferOptions validatedParallelTransferOptions =\n-            ModelHelper.populateAndApplyDefaults(parallelTransferOptions);\n-        Mono<Object> upload = Mono.fromCallable(() -> {\n-            try {\n-                // BlobOutputStream will internally handle the decision for single-shot or multi-part upload.\n-                BlobOutputStream blobOutputStream = BlobOutputStream.blockBlobOutputStream(client,\n-                    validatedParallelTransferOptions, headers, metadata, tier, requestConditions, context);\n-                StorageImplUtils.copyToOutputStream(data, length, blobOutputStream);\n-                blobOutputStream.close();\n-                return null;\n-            } catch (IOException e) {\n-                Throwable cause = e.getCause();\n-                if (cause instanceof BlobStorageException) {\n-                    throw logger.logExceptionAsError((BlobStorageException) cause);\n-                } else {\n-                    throw logger.logExceptionAsError(new UncheckedIOException(e));\n-                }\n-            }\n-            // Subscribing has to happen on a different thread for the timeout to happen properly.\n-        }).subscribeOn(Schedulers.elastic());\n+            ModelHelper.populateAndApplyDefaults(blobParallelUploadOptions.getParallelTransferOptions());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwOTM4OQ==", "bodyText": "I think it'd be a little odd to manipulate values like that on what otherwise seems to be a simple struct.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430709389", "createdAt": "2020-05-26T21:09:39Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,\n+        Duration timeout, Context context) {\n+        BlobParallelUploadOptions blobParallelUploadOptions = options == null ? new BlobParallelUploadOptions()\n+            : options;\n         final ParallelTransferOptions validatedParallelTransferOptions =\n-            ModelHelper.populateAndApplyDefaults(parallelTransferOptions);\n-        Mono<Object> upload = Mono.fromCallable(() -> {\n-            try {\n-                // BlobOutputStream will internally handle the decision for single-shot or multi-part upload.\n-                BlobOutputStream blobOutputStream = BlobOutputStream.blockBlobOutputStream(client,\n-                    validatedParallelTransferOptions, headers, metadata, tier, requestConditions, context);\n-                StorageImplUtils.copyToOutputStream(data, length, blobOutputStream);\n-                blobOutputStream.close();\n-                return null;\n-            } catch (IOException e) {\n-                Throwable cause = e.getCause();\n-                if (cause instanceof BlobStorageException) {\n-                    throw logger.logExceptionAsError((BlobStorageException) cause);\n-                } else {\n-                    throw logger.logExceptionAsError(new UncheckedIOException(e));\n-                }\n-            }\n-            // Subscribing has to happen on a different thread for the timeout to happen properly.\n-        }).subscribeOn(Schedulers.elastic());\n+            ModelHelper.populateAndApplyDefaults(blobParallelUploadOptions.getParallelTransferOptions());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3Mzc1OA=="}, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjU3NTQyOnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDowOToxNlrOGauieQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowNjo0NFrOGawU8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3ODY0OQ==", "bodyText": "Should the async class have this overload added as well? I know it has an API which is similar to this but with all the options splayed out.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430678649", "createdAt": "2020-05-26T20:09:16Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzk1NA==", "bodyText": "The reason for adding this specific overload right now is to address the Snowflake issue mentioned in the description. The async equivalent and a bunch of other options bag overloads are set to come out with stg 73 (they are in the tags PR right now), so I was going to let those naturally come with 73, but I can add the async overload now if we don't want the asymmetry while we wait.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430707954", "createdAt": "2020-05-26T21:06:44Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3ODY0OQ=="}, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjU3ODk4OnYy", "diffSide": "RIGHT", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDoxMDoyMVrOGauksA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowODoyN1rOGawYUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3OTIxNg==", "bodyText": "Should a non-Response overload be added to match the async client more closely.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430679216", "createdAt": "2020-05-26T20:10:21Z", "author": {"login": "alzimmermsft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwODgxOA==", "bodyText": "So an overload that takes an options bag and returns a BlockBlobItem? I can see the value of that. I think if we go that route maybe we should deprecate the overloads that don't take an options bag.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11433#discussion_r430708818", "createdAt": "2020-05-26T21:08:27Z", "author": {"login": "rickle-msft"}, "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/BlobClient.java", "diffHunk": "@@ -169,29 +174,38 @@ public void upload(InputStream data, long length, boolean overwrite) {\n     public void uploadWithResponse(InputStream data, long length, ParallelTransferOptions parallelTransferOptions,\n         BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, BlobRequestConditions requestConditions,\n         Duration timeout, Context context) {\n+        uploadWithResponse(data, length, new BlobParallelUploadOptions()\n+            .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTier(tier)\n+        .setRequestConditions(requestConditions), timeout, context);\n+    }\n+\n+    /**\n+     * Creates a new blob, or updates the content of an existing blob.\n+     * <p>\n+     * To avoid overwriting, pass \"*\" to {@link BlobRequestConditions#setIfNoneMatch(String)}.\n+     *\n+     * @param data The data to write to the blob.\n+     * @param length The exact length of the data. It is important that this value match precisely the length of the\n+     * data provided in the {@link InputStream}.\n+     * @param options {@link BlobParallelUploadOptions}\n+     * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     */\n+    public Response<BlockBlobItem> uploadWithResponse(InputStream data, long length, BlobParallelUploadOptions options,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3OTIxNg=="}, "originalCommit": {"oid": "741dd681e5c3b8c9b47584945199915a8e061ccb"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4139, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}