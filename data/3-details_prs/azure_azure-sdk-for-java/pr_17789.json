{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2NjAyNzM1", "number": 17789, "title": "spark filter to cosmos db pushdown query", "bodyText": "spark passes the user filter predicates to DataSourceV2 implementation.\nImplementation needs to split the the filters into two sets\n\nthe set which can be pushed down to the database as predicates in a query\nthe set which cannot be pushed down (the database doesn't support) and hence has to be evaluated by the spark platform later.\n\nThis PR\n\nadds support for the above feature and also translates the supported filters into a cosmos db query predicate. see FilterAnalyzer which is the core of this PR.\nadds the unit test for the feature. FilterAnalyzerSpec", "createdAt": "2020-11-24T16:21:42Z", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789", "merged": true, "mergeCommit": {"oid": "6e2f86d25148fc58efd38918d1f88a967f3c8648"}, "closed": true, "closedAt": "2020-11-25T22:16:33Z", "author": {"login": "moderakh"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfsID_gH2gAyNTI2NjAyNzM1Ojg3M2ZiMTA2MDU5MWRhOTg1OWYyNmY5OTkxYWJhMDYwMzMwYWE5YjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdgEzXMAH2gAyNTI2NjAyNzM1OjVhNzYyMzJjODk2ZDU1NjIzMzllNzEzMWRkYTM1MWNkNTQzZTlkMGM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "873fb1060591da9859f26f9991aba060330aa9b1", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/873fb1060591da9859f26f9991aba060330aa9b1", "committedDate": "2020-11-24T16:13:31Z", "message": "spark filter to cosmos query predicate"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb906c106cbf80b853fefde9cf085ca78cbd6081", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/eb906c106cbf80b853fefde9cf085ca78cbd6081", "committedDate": "2020-11-24T16:18:34Z", "message": "spark filter to cosmos query predicate"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40e06e4a5141fba4376ab48705222ca3794c55a3", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/40e06e4a5141fba4376ab48705222ca3794c55a3", "committedDate": "2020-11-24T16:22:26Z", "message": "added missing file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37e6cf2dc40654271ddf31b5f61a7c5d1618069e", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/37e6cf2dc40654271ddf31b5f61a7c5d1618069e", "committedDate": "2020-11-24T16:25:56Z", "message": "added missing file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "461813dffe07434f9344fbf1860c37074b0c6e4d", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/461813dffe07434f9344fbf1860c37074b0c6e4d", "committedDate": "2020-11-24T17:40:28Z", "message": "updated test comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0647f7a4dd99ef0ba7d60e2e8d26a0ed7db1ed2c", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/0647f7a4dd99ef0ba7d60e2e8d26a0ed7db1ed2c", "committedDate": "2020-11-24T21:09:10Z", "message": "Merge branch 'feature/cosmos/spark30' into users/moderakh/spark-filter-to-cosmos-query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db6b7aad9b9d5067e79119423a44710146dcebf2", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/db6b7aad9b9d5067e79119423a44710146dcebf2", "committedDate": "2020-11-24T21:29:11Z", "message": "compilation error fixed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b8b7fc8a33e86afb73f1ac7be9a09d330de10a3", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/6b8b7fc8a33e86afb73f1ac7be9a09d330de10a3", "committedDate": "2020-11-25T00:45:46Z", "message": "filter analyzer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a219b21a3dfee1c66621cfdb23d1bedc8fcbfa93", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/a219b21a3dfee1c66621cfdb23d1bedc8fcbfa93", "committedDate": "2020-11-25T00:49:48Z", "message": "minor cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9111bc203074f578bbe5cc5e2c745bce107ffd75", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/9111bc203074f578bbe5cc5e2c745bce107ffd75", "committedDate": "2020-11-25T00:54:56Z", "message": "minor comment cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51a48f91ba80de41991d0efaabcc0bd3a17b6482", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/51a48f91ba80de41991d0efaabcc0bd3a17b6482", "committedDate": "2020-11-25T01:03:24Z", "message": "removed whitespace"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3d828ba4bf353e7a40192e5c1d4ba762675470c", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/c3d828ba4bf353e7a40192e5c1d4ba762675470c", "committedDate": "2020-11-25T01:06:54Z", "message": "cleanup javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "173313b85731b1b48a203aa5193e90c7a00a935a", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/173313b85731b1b48a203aa5193e90c7a00a935a", "committedDate": "2020-11-25T01:14:32Z", "message": "added comment for future optimization"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81105136e6125496d02779d6aab82f103653a5d3", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/81105136e6125496d02779d6aab82f103653a5d3", "committedDate": "2020-11-25T01:14:42Z", "message": "added comment for future optimization"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/64506af55ad5fd12e5212048f05f1f33b4fb5a1a", "committedDate": "2020-11-25T01:15:14Z", "message": "added comment for future optimization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NDMxMjMz", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538431233", "createdAt": "2020-11-25T12:08:40Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjowODo0MVrOH5wg3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjowODo0MVrOH5wg3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNTcyNQ==", "bodyText": "Same should be true for FeedRange query option (or in old model PkRangeId) as long as retry policies are in place, correct? Simply because we would never ever push down predicates that would need the QUery magic in the client - like Group By and Order BY - Spark is much better at doing them client-side :-)", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530325725", "createdAt": "2020-11-25T12:08:41Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/AnalyzedFilter.scala", "diffHunk": "@@ -0,0 +1,17 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.Filter\n+\n+// TODO: moderakh, thought for future optimization:\n+//  if we can identify if the user filter is a equality on cosmos partitionKeyValue\n+//  then we can set partitionKeyValue in the CosmosQueryOption\n+//  the benefit is that if the partitionKeyValue is set in the CosmosQueryOption\n+//  the antlr query parsing support can eliminate the need for query plan fetch from GW", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NDMyNDMw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538432430", "createdAt": "2020-11-25T12:10:20Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxMDoyMFrOH5wkog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxMDoyMFrOH5wkog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyNjY5MA==", "bodyText": "NIT: static singleton", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530326690", "createdAt": "2020-11-25T12:10:20Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/CosmosScanBuilder.scala", "diffHunk": "@@ -20,68 +20,35 @@ case class CosmosScanBuilder(config: CaseInsensitiveStringMap)\n     with CosmosLoggingTrait {\n   logInfo(s\"Instantiated ${this.getClass.getSimpleName}\")\n \n-  var filtersToBePushDownToCosmos: Array[Filter] = Array.empty\n-  var filtersToBeEvaluatedBySpark: Array[Filter] = Array.empty\n+  var processedPredicates : Option[AnalyzedFilters] = Option.empty\n \n   /**\n     * Pushes down filters, and returns filters that need to be evaluated after scanning.\n-    * @param filters\n-    * @return filters to be evaluated after scanning\n+    * @param filters pushed down filters.\n+    * @return the filters that spark need to evaluate\n     */\n   override def pushFilters(filters: Array[Filter]): Array[Filter] = {\n-    // TODO moderakh we need to build the push down filter translation to Cosmos query\n-    // for now leave it to spark to filter\n+    processedPredicates = Option.apply(FilterAnalyzer().analyze(filters))\n \n-    // TODO: moderakh identify all the filters which are relevant to cosmos db\n-    this.filtersToBePushDownToCosmos = filters.filter(\n-      filter => filter match {\n-        case EqualTo(attribute, value) => true\n-        case _ => false\n-      }\n-    )\n-    this.filtersToBeEvaluatedBySpark = filters\n-\n-    // return all filter so spark also applies the filters\n-    filters\n+    // return the filters that spark need to evaluate\n+    this.processedPredicates.get.filtersNotSupportedByCosmos\n   }\n \n   /**\n-    * Returns the filters that are pushed to the data source via {@link #pushFilters ( Filter[ ] )}.\n-    * @return\n+    * Returns the filters that are pushed to Cosmos as query predicates\n+    * @return filters to be pushed to cosmos db.\n     */\n   override def pushedFilters: Array[Filter] = {\n-    this.filtersToBePushDownToCosmos\n+    if (this.processedPredicates.isDefined) {\n+      this.processedPredicates.get.filtersToBePushedDownToCosmos\n+    } else {\n+      Array[Filter]()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NDM1NjY4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538435668", "createdAt": "2020-11-25T12:14:57Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNDo1N1rOH5wuPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNDo1N1rOH5wuPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMyOTE1MA==", "bodyText": "Should we really push down EndsWith and Contains? I would not push down any filters which can not be served via full fidelity indexes - just costs more RU for the additional CPU usage when scanning through the documents", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530329150", "createdAt": "2020-11-25T12:14:57Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 132}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NDM3NDY4", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538437468", "createdAt": "2020-11-25T12:17:27Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNzoyN1rOH5wzwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjoxNzoyN1rOH5wzwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMDU2MQ==", "bodyText": "As a ToDo I would also track adding some of the aggregates under certain conditions:\nCount, Avg, Min, Max - We need to double-check when they can be served from full fidleity index - I think (but needs to be re-validated) when either no Group By is used or exactly one Group By by logical partition key - anyway would be worthwile to have a conversation with the query team about.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530330561", "createdAt": "2020-11-25T12:17:27Z", "author": {"login": "FabianMeiswinkel"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")\n+    val list = ListBuffer[(String, Any)]()\n+\n+    val filtersToBePushedDownToCosmos = ListBuffer[Filter]()\n+    val filtersNotSupportedByCosmos = ListBuffer[Filter]()\n+\n+    val whereClauseBuilder = new StringBuilder\n+\n+    for (filter <- filters) {\n+      val filterAsCosmosPredicate = new StringBuilder()\n+      val canBePushedDownToCosmos = appendCosmosQueryPredicate(filterAsCosmosPredicate, list, filter)\n+      if (canBePushedDownToCosmos) {\n+        if (filtersToBePushedDownToCosmos.size > 0) {\n+          whereClauseBuilder.append(\" AND \")\n+        }\n+        filtersToBePushedDownToCosmos.append(filter)\n+        whereClauseBuilder.append(filterAsCosmosPredicate)\n+      } else {\n+        filtersNotSupportedByCosmos.append(filter)\n+      }\n+    }\n+\n+    if (whereClauseBuilder.length > 0) {\n+      queryBuilder.append(\" WHERE \")\n+      queryBuilder.append(whereClauseBuilder)\n+    }\n+\n+    AnalyzedFilters(\n+      CosmosParametrizedQuery(queryBuilder.toString(), list.map(f => f._1).toList, list.map(f => f._2).toList),\n+      filtersToBePushedDownToCosmos.toArray,\n+      filtersNotSupportedByCosmos.toArray)\n+  }\n+\n+  /**\n+    * Provides Json Field path prefixed by the root. For example: \"r['id']\n+    * @param sparkFilterColumnName\n+    * @return cosmosFieldpath\n+    */\n+  private def canonicalCosmosFieldPath(sparkFilterColumnName: String): String = {\n+    val result = new StringBuilder(FilterAnalyzer.rootName)\n+    sparkFilterColumnName.split('.').foreach(cNamePart => result.append(s\"['${normalizedFieldName(cNamePart)}']\"))\n+    result.toString\n+  }\n+\n+  /**\n+    * Parameter name in the parametrized query: e.g. @param1.\n+    * @param paramNumber\n+    * @return\n+    */\n+  private def paramName(paramNumber: Integer): String = {\n+    s\"@param$paramNumber\"\n+  }\n+\n+  // scalastyle:off cyclomatic.complexity\n+  // scalastyle:off method.length\n+  // scalastyle:off multiple.string.literals\n+  private def appendCosmosQueryPredicate(queryBuilder: StringBuilder,\n+                                         list: scala.collection.mutable.ListBuffer[(String, Any)],\n+                                         filter: Filter): Boolean = {\n+    val pName = paramName(list.size)\n+    filter match {\n+      case EqualTo(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case EqualNullSafe(attr, value) =>\n+        // TODO moderakh check the difference between EqualTo and EqualNullSafe\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThan(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case LessThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\"<=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case GreaterThanOrEqual(attr, value) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\">=\").append(pName)\n+        list.append((pName, value))\n+        true\n+\n+      case In(attr, values) =>\n+        queryBuilder.append(canonicalCosmosFieldPath(attr)).append(\" IN \")\n+        queryBuilder.append(\"(\")\n+        queryBuilder.append(\n+          values.map(\n+            value => {\n+              val pName = paramName(list.size)\n+              list.append((pName, value))\n+              pName\n+            }\n+          ).mkString(\",\"))\n+        queryBuilder.append(\")\")\n+        true\n+\n+      case StringStartsWith(attr, value: String) =>\n+        queryBuilder.append(\"STARTSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringEndsWith(attr, value: String) =>\n+        queryBuilder.append(\"ENDSWITH(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case StringContains(attr, value: String) =>\n+        queryBuilder.append(\"CONTAINS(\").append(canonicalCosmosFieldPath(attr)).append(pName).append(\")\")\n+        list.append((pName, value))\n+        true\n+\n+      case IsNull(attr) =>\n+        queryBuilder.append(s\"IS_NULL(${canonicalCosmosFieldPath(attr)})\")\n+        true\n+\n+      case IsNotNull(attr) =>\n+        queryBuilder.append(s\"NOT(IS_NULL(${canonicalCosmosFieldPath(attr)}))\")\n+        true\n+\n+      case And(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" AND \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Or(leftFilter, rightFilter) =>\n+        queryBuilder.append(\"(\")\n+        val isLeftCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, leftFilter)\n+        queryBuilder.append(\" OR \")\n+        val isRightCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, rightFilter)\n+        queryBuilder.append(\")\")\n+        isLeftCosmosPredicate && isRightCosmosPredicate\n+\n+      case Not(childFilter) =>\n+        queryBuilder.append(\"NOT(\")\n+        val isInnerCosmosPredicate = appendCosmosQueryPredicate(queryBuilder, list, childFilter)\n+        queryBuilder.append(\")\")\n+        isInnerCosmosPredicate\n+\n+      case _: Filter =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 168}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NDM5NTkw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538439590", "createdAt": "2020-11-25T12:20:27Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NzYyNzcw", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538762770", "createdAt": "2020-11-25T18:36:30Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxODozNjozMFrOH5_uKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxODozNjozMFrOH5_uKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU3NDg4OA==", "bodyText": "In the future, I think this code should leverage a DOM / AST. We have one in .net:\nhttps://github.com/Azure/azure-cosmos-dotnet-v3/tree/master/Microsoft.Azure.Cosmos/src/SqlObjects\nand maybe we should port it to Java, since spark connector, seems to be doing some heavy query manipulation.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#discussion_r530574888", "createdAt": "2020-11-25T18:36:30Z", "author": {"login": "bchong95"}, "path": "sdk/cosmos/azure-cosmos-spark_3-0_2-12/src/main/scala/com/azure/cosmos/spark/FilterAnalyzer.scala", "diffHunk": "@@ -0,0 +1,186 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.spark\n+\n+import com.azure.cosmos.models.CosmosParametrizedQuery\n+import org.apache.spark.sql.sources.{\n+  And, EqualNullSafe, EqualTo, Filter, GreaterThan,\n+  GreaterThanOrEqual, In, IsNotNull, IsNull, LessThan, LessThanOrEqual, Not, Or,\n+  StringContains, StringEndsWith, StringStartsWith\n+}\n+\n+import scala.collection.mutable.ListBuffer\n+\n+case class FilterAnalyzer() {\n+  def analyze(filters: Array[Filter]): AnalyzedFilters = {\n+    val queryBuilder = new StringBuilder\n+    queryBuilder.append(\"SELECT * FROM r\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NzYzNDQx", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17789#pullrequestreview-538763441", "createdAt": "2020-11-25T18:37:29Z", "commit": {"oid": "64506af55ad5fd12e5212048f05f1f33b4fb5a1a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a76232c896d5562339e7131dda351cd543e9d0c", "author": {"user": {"login": "moderakh", "name": "Mohammad Derakhshani"}}, "url": "https://github.com/Azure/azure-sdk-for-java/commit/5a76232c896d5562339e7131dda351cd543e9d0c", "committedDate": "2020-11-25T20:58:32Z", "message": "responding to comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1680, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}