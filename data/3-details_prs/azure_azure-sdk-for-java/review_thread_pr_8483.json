{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5OTE5MjY3", "number": 8483, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo0NjoxN1rODjQO-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMToxMToyNlrODjTM8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjkyNzI4OnYy", "diffSide": "LEFT", "path": "pom.data.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo0NjoxN1rOFu9eRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDowNDowNVrOFvA1bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NTk4OQ==", "bodyText": "any reason for removing cosmos in this PR?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384785989", "createdAt": "2020-02-26T21:46:17Z", "author": {"login": "srnagar"}, "path": "pom.data.xml", "diffHunk": "@@ -605,7 +605,6 @@\n   <modules>\n     <module>./sdk/batch/microsoft-azure-batch</module>\n     <module>./sdk/applicationinsights/microsoft-azure-applicationinsights-query</module>\n-    <module>./sdk/cosmos</module>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTA3MA==", "bodyText": "Cosmos data plane is removed in the repo and the builds have been failing already.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841070", "createdAt": "2020-02-27T00:04:05Z", "author": {"login": "jianghaolu"}, "path": "pom.data.xml", "diffHunk": "@@ -605,7 +605,6 @@\n   <modules>\n     <module>./sdk/batch/microsoft-azure-batch</module>\n     <module>./sdk/applicationinsights/microsoft-azure-applicationinsights-query</module>\n-    <module>./sdk/cosmos</module>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NTk4OQ=="}, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjkzODU1OnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo0OTozN1rOFu9k5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDowNTozM1rOFvA3Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NzY4NQ==", "bodyText": "This was previously marked as @Deprecated. Is this release changing it to a non-deprecated method now? There are other methods in this interface that have similar changes.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384787685", "createdAt": "2020-02-26T21:49:37Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -433,108 +282,65 @@\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @return the observable to the OcrResult object\n      */\n-    @Deprecated\n     Observable<OcrResult> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, RecognizePrintedTextInStreamOptionalParameter recognizePrintedTextInStreamOptionalParameter);\n \n+\n     /**\n-     * Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters\n-     *   into a machine-usable character stream.   Upon success, the OCR results will be returned. Upon failure, the\n-     *   error code together with an error message will be returned. The error code can be one of InvalidImageUrl,\n-     *   InvalidImageFormat, InvalidImageSize, NotSupportedImage,  NotSupportedLanguage, or InternalServerError.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n      *\n-     * @return the first stage of the recognizePrintedTextInStream call\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n+     * @return the DomainModelResults object if successful.\n      */\n-    ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithDetectOrientation recognizePrintedTextInStream();\n+    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n \n     /**\n-     * Grouping of recognizePrintedTextInStream definition stages.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n+     *\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return the observable to the DomainModelResults object\n      */\n-    interface ComputerVisionRecognizePrintedTextInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify detectOrientation.\n-         */\n-        interface WithDetectOrientation {\n-            /**\n-             * Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to\n-             *   detect the image orientation and correct it before further processing (e.g. if it's upside-down).\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withDetectOrientation(boolean detectOrientation);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible\n-             *   values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',\n-             *   'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withLanguage(OcrLanguages language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the OcrResult object if successful.\n-             */\n-            OcrResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the OcrResult object\n-             */\n-            Observable<OcrResult> executeAsync();\n-        }\n-    }\n+    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 649}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTUxOA==", "bodyText": "Added back", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841518", "createdAt": "2020-02-27T00:05:33Z", "author": {"login": "jianghaolu"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -433,108 +282,65 @@\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @return the observable to the OcrResult object\n      */\n-    @Deprecated\n     Observable<OcrResult> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, RecognizePrintedTextInStreamOptionalParameter recognizePrintedTextInStreamOptionalParameter);\n \n+\n     /**\n-     * Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters\n-     *   into a machine-usable character stream.   Upon success, the OCR results will be returned. Upon failure, the\n-     *   error code together with an error message will be returned. The error code can be one of InvalidImageUrl,\n-     *   InvalidImageFormat, InvalidImageSize, NotSupportedImage,  NotSupportedLanguage, or InternalServerError.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n      *\n-     * @return the first stage of the recognizePrintedTextInStream call\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n+     * @return the DomainModelResults object if successful.\n      */\n-    ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithDetectOrientation recognizePrintedTextInStream();\n+    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n \n     /**\n-     * Grouping of recognizePrintedTextInStream definition stages.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n+     *\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return the observable to the DomainModelResults object\n      */\n-    interface ComputerVisionRecognizePrintedTextInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify detectOrientation.\n-         */\n-        interface WithDetectOrientation {\n-            /**\n-             * Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to\n-             *   detect the image orientation and correct it before further processing (e.g. if it's upside-down).\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withDetectOrientation(boolean detectOrientation);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible\n-             *   values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',\n-             *   'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withLanguage(OcrLanguages language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the OcrResult object if successful.\n-             */\n-            OcrResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the OcrResult object\n-             */\n-            Observable<OcrResult> executeAsync();\n-        }\n-    }\n+    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NzY4NQ=="}, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 649}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4Mjk0MDAzOnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1MDowNFrOFu9l5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDowNDoxMlrOFvA1mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4Nzk0Mg==", "bodyText": "Deprecated?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384787942", "createdAt": "2020-02-26T21:50:04Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -69,344 +107,154 @@\n     Observable<Void> recognizeTextInStreamAsync(byte[] image, TextRecognitionMode mode);\n \n \n+\n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the DomainModelResults object if successful.\n+     * @return the ReadOperationResult object if successful.\n      */\n-    @Deprecated\n-    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    ReadOperationResult getReadOperationResult(String operationId);\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the DomainModelResults object\n+     * @return the observable to the ReadOperationResult object\n      */\n-    @Deprecated\n-    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    Observable<ReadOperationResult> getReadOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n      *\n-     * @return the first stage of the analyzeImageByDomainInStream call\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel analyzeImageByDomainInStream();\n+    void batchReadFile(String url);\n \n     /**\n-     * Grouping of analyzeImageByDomainInStream definition stages.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n+     *\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify model.\n-         */\n-        interface WithModel {\n-            /**\n-             * The domain-specific content to recognize.\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withModel(String model);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the DomainModelResults object if successful.\n-             */\n-            DomainModelResults execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the DomainModelResults object\n-             */\n-            Observable<DomainModelResults> executeAsync();\n-        }\n-    }\n+    Observable<Void> batchReadFileAsync(String url);\n+\n \n-    /**\n-     * The entirety of analyzeImageByDomainInStream definition.\n-     */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinition extends\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithImage,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the TagResult object if successful.\n+     * @return the TextOperationResult object if successful.\n      */\n-    @Deprecated\n-    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    TextOperationResult getTextOperationResult(String operationId);\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the TagResult object\n+     * @return the observable to the TextOperationResult object\n      */\n-    @Deprecated\n-    Observable<TagResult> tagImageInStreamAsync(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    Observable<TextOperationResult> getTextOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n      *\n-     * @return the first stage of the tagImageInStream call\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionTagImageInStreamDefinitionStages.WithImage tagImageInStream();\n+    void recognizeText(String url, TextRecognitionMode mode);\n \n     /**\n-     * Grouping of tagImageInStream definition stages.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n+     *\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionTagImageInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionTagImageInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the TagResult object if successful.\n-             */\n-            TagResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the TagResult object\n-             */\n-            Observable<TagResult> executeAsync();\n-        }\n-    }\n+    Observable<Void> recognizeTextAsync(String url, TextRecognitionMode mode);\n \n-    /**\n-     * The entirety of tagImageInStream definition.\n-     */\n-    interface ComputerVisionTagImageInStreamDefinition extends\n-        ComputerVisionTagImageInStreamDefinitionStages.WithImage,\n-        ComputerVisionTagImageInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a description of an image in human readable language with complete sentences.  The\n-     *   description is based on a collection of content tags, which are also returned by the operation. More than\n-     *   one description can be generated for each image.  Descriptions are ordered by their confidence score. All\n-     *   descriptions are in English. Two input methods are supported -- (1) Uploading an image or (2) specifying an\n-     *   image URL.A successful response will be returned in JSON.  If the request failed, the response will contain\n-     *   an error code and a message to help understand what went wrong.\n+     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n+     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n+     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n+     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag\n+     *   \"ascomycete\" may be accompanied by the hint \"fungus\".\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON. If the request failed, the response will contain an error\n+     *   code and a message to help understand what went wrong.\n      *\n      * @param image An image stream.\n-     * @param describeImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the ImageDescription object if successful.\n+     * @return the TagResult object if successful.\n      */\n-    @Deprecated\n-    ImageDescription describeImageInStream(byte[] image, DescribeImageInStreamOptionalParameter describeImageInStreamOptionalParameter);\n+    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 399}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTExNA==", "bodyText": "Added back", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841114", "createdAt": "2020-02-27T00:04:12Z", "author": {"login": "jianghaolu"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -69,344 +107,154 @@\n     Observable<Void> recognizeTextInStreamAsync(byte[] image, TextRecognitionMode mode);\n \n \n+\n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the DomainModelResults object if successful.\n+     * @return the ReadOperationResult object if successful.\n      */\n-    @Deprecated\n-    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    ReadOperationResult getReadOperationResult(String operationId);\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the DomainModelResults object\n+     * @return the observable to the ReadOperationResult object\n      */\n-    @Deprecated\n-    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    Observable<ReadOperationResult> getReadOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n      *\n-     * @return the first stage of the analyzeImageByDomainInStream call\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel analyzeImageByDomainInStream();\n+    void batchReadFile(String url);\n \n     /**\n-     * Grouping of analyzeImageByDomainInStream definition stages.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n+     *\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify model.\n-         */\n-        interface WithModel {\n-            /**\n-             * The domain-specific content to recognize.\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withModel(String model);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the DomainModelResults object if successful.\n-             */\n-            DomainModelResults execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the DomainModelResults object\n-             */\n-            Observable<DomainModelResults> executeAsync();\n-        }\n-    }\n+    Observable<Void> batchReadFileAsync(String url);\n+\n \n-    /**\n-     * The entirety of analyzeImageByDomainInStream definition.\n-     */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinition extends\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithImage,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the TagResult object if successful.\n+     * @return the TextOperationResult object if successful.\n      */\n-    @Deprecated\n-    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    TextOperationResult getTextOperationResult(String operationId);\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the TagResult object\n+     * @return the observable to the TextOperationResult object\n      */\n-    @Deprecated\n-    Observable<TagResult> tagImageInStreamAsync(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    Observable<TextOperationResult> getTextOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n      *\n-     * @return the first stage of the tagImageInStream call\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionTagImageInStreamDefinitionStages.WithImage tagImageInStream();\n+    void recognizeText(String url, TextRecognitionMode mode);\n \n     /**\n-     * Grouping of tagImageInStream definition stages.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n+     *\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionTagImageInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionTagImageInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the TagResult object if successful.\n-             */\n-            TagResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the TagResult object\n-             */\n-            Observable<TagResult> executeAsync();\n-        }\n-    }\n+    Observable<Void> recognizeTextAsync(String url, TextRecognitionMode mode);\n \n-    /**\n-     * The entirety of tagImageInStream definition.\n-     */\n-    interface ComputerVisionTagImageInStreamDefinition extends\n-        ComputerVisionTagImageInStreamDefinitionStages.WithImage,\n-        ComputerVisionTagImageInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a description of an image in human readable language with complete sentences.  The\n-     *   description is based on a collection of content tags, which are also returned by the operation. More than\n-     *   one description can be generated for each image.  Descriptions are ordered by their confidence score. All\n-     *   descriptions are in English. Two input methods are supported -- (1) Uploading an image or (2) specifying an\n-     *   image URL.A successful response will be returned in JSON.  If the request failed, the response will contain\n-     *   an error code and a message to help understand what went wrong.\n+     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n+     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n+     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n+     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag\n+     *   \"ascomycete\" may be accompanied by the hint \"fungus\".\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON. If the request failed, the response will contain an error\n+     *   code and a message to help understand what went wrong.\n      *\n      * @param image An image stream.\n-     * @param describeImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the ImageDescription object if successful.\n+     * @return the TagResult object if successful.\n      */\n-    @Deprecated\n-    ImageDescription describeImageInStream(byte[] image, DescribeImageInStreamOptionalParameter describeImageInStreamOptionalParameter);\n+    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4Nzk0Mg=="}, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 399}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4Mjk0ODE0OnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1MjozMVrOFu9qxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1MjozMVrOFu9qxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4OTE4OQ==", "bodyText": "nit: Don't need extra . here.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384789189", "createdAt": "2020-02-26T21:52:31Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -36,14 +36,14 @@\n     String userAgent();\n \n     /**\n-     * Gets Supported Cognitive Services endpoints.\n+     * Gets Supported Cognitive Services endpoints..", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4Mjk0ODY2OnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1Mjo0MFrOFu9rGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1Mjo0MFrOFu9rGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4OTI3Mw==", "bodyText": "same as above.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384789273", "createdAt": "2020-02-26T21:52:40Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -36,14 +36,14 @@\n     String userAgent();\n \n     /**\n-     * Gets Supported Cognitive Services endpoints.\n+     * Gets Supported Cognitive Services endpoints..\n      *\n      * @return the endpoint value.\n      */\n     String endpoint();\n \n     /**\n-     * Sets Supported Cognitive Services endpoints.\n+     * Sets Supported Cognitive Services endpoints..", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4Mjk2MjkyOnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionError.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1Njo0MlrOFu9znQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1Njo0MlrOFu9znQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MTQ1Mw==", "bodyText": "Is this a regression? The previous version had a specific error code type returned instead of Object.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384791453", "createdAt": "2020-02-26T21:56:42Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionError.java", "diffHunk": "@@ -11,18 +11,14 @@\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n /**\n- * The ComputerVisionError model.\n+ * Details about the API request error.\n  */\n public class ComputerVisionError {\n     /**\n-     * The error code. Possible values include: 'InvalidImageUrl',\n-     * 'InvalidImageFormat', 'InvalidImageSize', 'NotSupportedVisualFeature',\n-     * 'NotSupportedImage', 'InvalidDetails', 'NotSupportedLanguage',\n-     * 'BadArgument', 'FailedToProcess', 'Timeout', 'InternalServerError',\n-     * 'Unspecified', 'StorageException'.\n+     * The error code.\n      */\n     @JsonProperty(value = \"code\", required = true)\n-    private ComputerVisionErrorCodes code;\n+    private Object code;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4Mjk2OTgzOnYy", "diffSide": "LEFT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionErrorCodes.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTo1ODo0NlrOFu935w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMDowNTo1NVrOFvA3qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MjU1MQ==", "bodyText": "This type is deleted but ComputerVisionError has methods that return code - maybe this type should be used there? I know it's generated code but not sure if this is a swagger issue that needs to be looked into.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384792551", "createdAt": "2020-02-26T21:58:46Z", "author": {"login": "srnagar"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionErrorCodes.java", "diffHunk": "@@ -1,86 +0,0 @@\n-/**\n- * Copyright (c) Microsoft Corporation. All rights reserved.\n- * Licensed under the MIT License. See License.txt in the project root for\n- * license information.\n- *\n- * Code generated by Microsoft (R) AutoRest Code Generator.\n- */\n-\n-package com.microsoft.azure.cognitiveservices.vision.computervision.models;\n-\n-import com.fasterxml.jackson.annotation.JsonCreator;\n-import com.fasterxml.jackson.annotation.JsonValue;\n-\n-/**\n- * Defines values for ComputerVisionErrorCodes.\n- */\n-public enum ComputerVisionErrorCodes {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTY0MQ==", "bodyText": "Added \"type\": \"string\" and regenerated this.", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841641", "createdAt": "2020-02-27T00:05:55Z", "author": {"login": "jianghaolu"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionErrorCodes.java", "diffHunk": "@@ -1,86 +0,0 @@\n-/**\n- * Copyright (c) Microsoft Corporation. All rights reserved.\n- * Licensed under the MIT License. See License.txt in the project root for\n- * license information.\n- *\n- * Code generated by Microsoft (R) AutoRest Code Generator.\n- */\n-\n-package com.microsoft.azure.cognitiveservices.vision.computervision.models;\n-\n-import com.fasterxml.jackson.annotation.JsonCreator;\n-import com.fasterxml.jackson.annotation.JsonValue;\n-\n-/**\n- * Defines values for ComputerVisionErrorCodes.\n- */\n-public enum ComputerVisionErrorCodes {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MjU1MQ=="}, "originalCommit": {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MzQxMzYxOnYy", "diffSide": "RIGHT", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMToxMToyNlrOFvCEcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMToxMToyNlrOFvCEcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg2MTI5Nw==", "bodyText": "Do we care that these Javadocs aren't grammatically correct?", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384861297", "createdAt": "2020-02-27T01:11:26Z", "author": {"login": "alzimmermsft"}, "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -51,44 +51,44 @@\n     ComputerVisionClient withEndpoint(String endpoint);\n \n     /**\n-     * Gets Gets or sets the preferred language for the response..\n+     * Gets Gets or sets the preferred language for the response.\n      *\n      * @return the acceptLanguage value.\n      */\n     String acceptLanguage();\n \n     /**\n-     * Sets Gets or sets the preferred language for the response..\n+     * Sets Gets or sets the preferred language for the response.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e47982313006a1409ded6f2fbcf237625f4878f"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 346, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}