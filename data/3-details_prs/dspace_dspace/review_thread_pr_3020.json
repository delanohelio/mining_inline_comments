{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3ODM0NjQ3", "number": 3020, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTowOTo0OFrOFVuPOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQyMToyNToyNVrOFW36fQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4MzIxOTc3OnYy", "diffSide": "RIGHT", "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTowOTo0OFrOIeVW_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTowOTo0OFrOIeVW_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODY3ODE0Mw==", "bodyText": "Log4j2's parameter substitution would reduce this expensive multiple-string-concatenation expression to a compile-time constant.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r568678143", "createdAt": "2021-02-02T15:09:48Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,32 +79,59 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {\n+                    tikaParser.parse(streams.getStream(), tikaHandler, tikaMetadata, tikaContext);\n+                } catch (SAXException saxe) {\n+                    // Check if this SAXException is just a notice that this file was longer than the character limit.\n+                    // Unfortunately there is not a unique, public exception type to catch here. This error is thrown\n+                    // by Tika's WriteOutContentHandler when it encounters a document longer than the char limit\n+                    // https://github.com/apache/tika/blob/main/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java\n+                    if (saxe.getMessage().contains(\"limit has been reached\")) {\n+                        // log that we only indexed up to that configured limit\n+                        log.info(\"Full text is larger than the configured limit (discovery.solr.fulltext.charLimit).\"\n+                                     + \" Only the first \" + charLimit + \" characters were indexed.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95d0cd18e500998f2ce67372d8e0edb66629d745"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4MzM4ODQwOnYy", "diffSide": "RIGHT", "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTo0MjoxMVrOIeW_3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxODoyMDowNlrOIeeiOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcwNDk5MQ==", "bodyText": "Do we really want a hard commit after every document?  The usual advice from the Solr maintainers on committing in the client is \"don't.\"  If this method is ever used in bulk indexing, the bulk operation will be quite slow and make the top-level caches ineffective for all other users.  We should tune our autocommit settings for a good balance of indexing performance and visibility, and trust autocommit.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r568704991", "createdAt": "2021-02-02T15:42:11Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,32 +79,59 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {\n+                    tikaParser.parse(streams.getStream(), tikaHandler, tikaMetadata, tikaContext);\n+                } catch (SAXException saxe) {\n+                    // Check if this SAXException is just a notice that this file was longer than the character limit.\n+                    // Unfortunately there is not a unique, public exception type to catch here. This error is thrown\n+                    // by Tika's WriteOutContentHandler when it encounters a document longer than the char limit\n+                    // https://github.com/apache/tika/blob/main/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java\n+                    if (saxe.getMessage().contains(\"limit has been reached\")) {\n+                        // log that we only indexed up to that configured limit\n+                        log.info(\"Full text is larger than the configured limit (discovery.solr.fulltext.charLimit).\"\n+                                     + \" Only the first \" + charLimit + \" characters were indexed.\");\n+                    } else {\n+                        throw new IOException(\"Tika parsing error. Could not index full text.\", saxe);\n+                    }\n+                } catch (TikaException ex) {\n+                    throw new IOException(\"Tika parsing error. Could not index full text.\", ex);\n+                }\n \n-                //req.setParam(ExtractingParams.EXTRACT_ONLY, \"true\");\n-                for (String name : doc.getFieldNames()) {\n-                    for (Object val : doc.getFieldValues(name)) {\n-                        params.add(ExtractingParams.LITERALS_PREFIX + name, val.toString());\n+                // Write Tika metadata to \"tika_meta_*\" fields.\n+                // This metadata is not very useful right now, but we'll keep it just in case it becomes more useful.\n+                for (String name : tikaMetadata.names()) {\n+                    for (String value : tikaMetadata.getValues(name)) {\n+                        doc.addField(\"tika_meta_\" + name, value);\n                     }\n                 }\n \n-                req.setParams(params);\n-                req.setParam(ExtractingParams.UNKNOWN_FIELD_PREFIX, \"attr_\");\n-                req.setParam(ExtractingParams.MAP_PREFIX + \"content\", \"fulltext\");\n-                req.setParam(ExtractingParams.EXTRACT_FORMAT, \"text\");\n-                req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);\n-                req.process(solr);\n+                // Save (parsed) full text to \"fulltext\" field\n+                doc.addField(\"fulltext\", tikaHandler.toString());\n+\n+                // Add document & commit immediately\n+                solr.add(doc);\n+                solr.commit(true, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95d0cd18e500998f2ce67372d8e0edb66629d745"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODgyODQ3Mg==", "bodyText": "Good point.  To be honest, I debated on this one myself...I only added this in because the code it replaced was also doing a hard commit.  So, I did an exact replacement here.  That said, I'm OK with removing this in favor of autocommit.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r568828472", "createdAt": "2021-02-02T18:20:06Z", "author": {"login": "tdonohue"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,32 +79,59 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {\n+                    tikaParser.parse(streams.getStream(), tikaHandler, tikaMetadata, tikaContext);\n+                } catch (SAXException saxe) {\n+                    // Check if this SAXException is just a notice that this file was longer than the character limit.\n+                    // Unfortunately there is not a unique, public exception type to catch here. This error is thrown\n+                    // by Tika's WriteOutContentHandler when it encounters a document longer than the char limit\n+                    // https://github.com/apache/tika/blob/main/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java\n+                    if (saxe.getMessage().contains(\"limit has been reached\")) {\n+                        // log that we only indexed up to that configured limit\n+                        log.info(\"Full text is larger than the configured limit (discovery.solr.fulltext.charLimit).\"\n+                                     + \" Only the first \" + charLimit + \" characters were indexed.\");\n+                    } else {\n+                        throw new IOException(\"Tika parsing error. Could not index full text.\", saxe);\n+                    }\n+                } catch (TikaException ex) {\n+                    throw new IOException(\"Tika parsing error. Could not index full text.\", ex);\n+                }\n \n-                //req.setParam(ExtractingParams.EXTRACT_ONLY, \"true\");\n-                for (String name : doc.getFieldNames()) {\n-                    for (Object val : doc.getFieldValues(name)) {\n-                        params.add(ExtractingParams.LITERALS_PREFIX + name, val.toString());\n+                // Write Tika metadata to \"tika_meta_*\" fields.\n+                // This metadata is not very useful right now, but we'll keep it just in case it becomes more useful.\n+                for (String name : tikaMetadata.names()) {\n+                    for (String value : tikaMetadata.getValues(name)) {\n+                        doc.addField(\"tika_meta_\" + name, value);\n                     }\n                 }\n \n-                req.setParams(params);\n-                req.setParam(ExtractingParams.UNKNOWN_FIELD_PREFIX, \"attr_\");\n-                req.setParam(ExtractingParams.MAP_PREFIX + \"content\", \"fulltext\");\n-                req.setParam(ExtractingParams.EXTRACT_FORMAT, \"text\");\n-                req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);\n-                req.process(solr);\n+                // Save (parsed) full text to \"fulltext\" field\n+                doc.addField(\"fulltext\", tikaHandler.toString());\n+\n+                // Add document & commit immediately\n+                solr.add(doc);\n+                solr.commit(true, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcwNDk5MQ=="}, "originalCommit": {"oid": "95d0cd18e500998f2ce67372d8e0edb66629d745"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4MzQwNDE1OnYy", "diffSide": "RIGHT", "path": "dspace-api/src/test/java/org/dspace/solr/MockSolrServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTo0NToxN1rOIeXJzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTo0NToxN1rOIeXJzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcwNzUzNQ==", "bodyText": "Paths.get(AbstractDSpaceIntegrationTest.getDspaceDir(), \"solr\");", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r568707535", "createdAt": "2021-02-02T15:45:17Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/src/test/java/org/dspace/solr/MockSolrServer.java", "diffHunk": "@@ -159,9 +162,9 @@ public void destroy() throws Exception {\n      */\n     private static synchronized void initSolrContainer() {\n         if (container == null) {\n-            String solrDir = AbstractDSpaceIntegrationTest.getDspaceDir() + File.separator + \"solr\";\n-            log.info(\"Initializing SOLR CoreContainer with directory \" + solrDir);\n-            container = new CoreContainer(solrDir);\n+            Path solrDir = Paths.get(AbstractDSpaceIntegrationTest.getDspaceDir() + File.separator + \"solr\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95d0cd18e500998f2ce67372d8e0edb66629d745"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4MzQwODgyOnYy", "diffSide": "RIGHT", "path": "dspace-api/src/test/java/org/dspace/solr/MockSolrServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTo0NjowN1rOIeXMiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxNTo0NjowN1rOIeXMiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcwODIzNQ==", "bodyText": "Parameter substitution here.\nAlso, another string concatenation in Paths.get.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r568708235", "createdAt": "2021-02-02T15:46:07Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/src/test/java/org/dspace/solr/MockSolrServer.java", "diffHunk": "@@ -159,9 +162,9 @@ public void destroy() throws Exception {\n      */\n     private static synchronized void initSolrContainer() {\n         if (container == null) {\n-            String solrDir = AbstractDSpaceIntegrationTest.getDspaceDir() + File.separator + \"solr\";\n-            log.info(\"Initializing SOLR CoreContainer with directory \" + solrDir);\n-            container = new CoreContainer(solrDir);\n+            Path solrDir = Paths.get(AbstractDSpaceIntegrationTest.getDspaceDir() + File.separator + \"solr\");\n+            log.info(\"Initializing SOLR CoreContainer with directory \" + solrDir.toAbsolutePath().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95d0cd18e500998f2ce67372d8e0edb66629d745"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU5MDM5MzE2OnYy", "diffSide": "RIGHT", "path": "dspace-api/pom.xml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QyMjoyMjo1MlrOIfZcuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxNzoyOToxOVrOIhuS4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTc5MzcyMA==", "bodyText": "We no longer have a direct dependency on solr-cell, but we've picked up a direct dependency on tika-parsers.  I'm testing a patch to address this.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r569793720", "createdAt": "2021-02-03T22:22:52Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/pom.xml", "diffHunk": "@@ -524,133 +566,33 @@\n             <scope>test</scope>\n             <version>${solr.client.version}</version>\n             <exclusions>\n+                <!-- Newer version brought in by opencsv -->\n                 <exclusion>\n-                    <groupId>commons-cli</groupId>\n-                    <artifactId>commons-cli</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-continuation</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-deploy</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-http</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-io</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-jmx</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-rewrite</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-security</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-server</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlet</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlets</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-util</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-webapp</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-xml</artifactId>\n+                    <groupId>org.apache.commons</groupId>\n+                    <artifactId>commons-text</artifactId>\n                 </exclusion>\n             </exclusions>\n         </dependency>\n         <dependency>\n             <groupId>org.apache.solr</groupId>\n             <artifactId>solr-cell</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ac127cb792c352c220b5dbfe986f749d6fa6e2d"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA4NTg0OQ==", "bodyText": "tdonohue#11 if you think it appropriate for this PR.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r571085849", "createdAt": "2021-02-05T16:20:12Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/pom.xml", "diffHunk": "@@ -524,133 +566,33 @@\n             <scope>test</scope>\n             <version>${solr.client.version}</version>\n             <exclusions>\n+                <!-- Newer version brought in by opencsv -->\n                 <exclusion>\n-                    <groupId>commons-cli</groupId>\n-                    <artifactId>commons-cli</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-continuation</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-deploy</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-http</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-io</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-jmx</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-rewrite</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-security</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-server</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlet</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlets</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-util</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-webapp</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-xml</artifactId>\n+                    <groupId>org.apache.commons</groupId>\n+                    <artifactId>commons-text</artifactId>\n                 </exclusion>\n             </exclusions>\n         </dependency>\n         <dependency>\n             <groupId>org.apache.solr</groupId>\n             <artifactId>solr-cell</artifactId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTc5MzcyMA=="}, "originalCommit": {"oid": "2ac127cb792c352c220b5dbfe986f749d6fa6e2d"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjIzMjQxOA==", "bodyText": "Thanks @mwoodiupui : I've merged in your improvement to this PR...so solr-cell is now removed.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r572232418", "createdAt": "2021-02-08T17:29:19Z", "author": {"login": "tdonohue"}, "path": "dspace-api/pom.xml", "diffHunk": "@@ -524,133 +566,33 @@\n             <scope>test</scope>\n             <version>${solr.client.version}</version>\n             <exclusions>\n+                <!-- Newer version brought in by opencsv -->\n                 <exclusion>\n-                    <groupId>commons-cli</groupId>\n-                    <artifactId>commons-cli</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-continuation</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-deploy</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-http</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-io</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-jmx</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-rewrite</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-security</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-server</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlet</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-servlets</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-util</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-webapp</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.eclipse.jetty</groupId>\n-                    <artifactId>jetty-xml</artifactId>\n+                    <groupId>org.apache.commons</groupId>\n+                    <artifactId>commons-text</artifactId>\n                 </exclusion>\n             </exclusions>\n         </dependency>\n         <dependency>\n             <groupId>org.apache.solr</groupId>\n             <artifactId>solr-cell</artifactId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTc5MzcyMA=="}, "originalCommit": {"oid": "2ac127cb792c352c220b5dbfe986f749d6fa6e2d"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU5NTI5MDg1OnYy", "diffSide": "RIGHT", "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQyMToyNToyNVrOIgH1Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQyMjoyMDoyNVrOIgJqMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU1MzYxNQ==", "bodyText": "Do we need a finally{} clause to close streams?", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r570553615", "createdAt": "2021-02-04T21:25:25Z", "author": {"login": "mwoodiupui"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,35 +79,60 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n+            // If full text stream(s) were passed in, we'll index them as part of the SolrInputDocument\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "954a0818930660d5144e97a066ec75bbb911faa5"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU4MTMzMw==", "bodyText": "Good catch...I think it is missing.  It's not streams we need to close, but streams.getStream() which creates a new SequenceInputStream that does need to be closed.  https://github.com/DSpace/DSpace/blob/main/dspace-api/src/main/java/org/dspace/discovery/FullTextContentStreams.java#L131\nI had completely overlooked that, so I'm very glad you caught it!  I'll make sure this gets stored to a new variable & closed in a finally.", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r570581333", "createdAt": "2021-02-04T22:16:01Z", "author": {"login": "tdonohue"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,35 +79,60 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n+            // If full text stream(s) were passed in, we'll index them as part of the SolrInputDocument\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU1MzYxNQ=="}, "originalCommit": {"oid": "954a0818930660d5144e97a066ec75bbb911faa5"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU4MzYwMA==", "bodyText": "Fixed now in 48f628f.  Thanks again @mwoodiupui !", "url": "https://github.com/DSpace/DSpace/pull/3020#discussion_r570583600", "createdAt": "2021-02-04T22:20:25Z", "author": {"login": "tdonohue"}, "path": "dspace-api/src/main/java/org/dspace/discovery/indexobject/IndexFactoryImpl.java", "diffHunk": "@@ -74,35 +79,60 @@ public void writeDocument(Context context, T indexableObject, SolrInputDocument\n      * Write the document to the index under the appropriate unique identifier.\n      *\n      * @param doc     the solr document to be written to the server\n-     * @param streams list of bitstream content streams    DiscoverQueryBuilderTest.java:285\n+     * @param streams list of bitstream content streams\n      * @throws IOException A general class of exceptions produced by failed or interrupted I/O operations.\n      */\n     protected void writeDocument(SolrInputDocument doc, FullTextContentStreams streams)\n             throws IOException, SolrServerException {\n         final SolrClient solr = solrSearchCore.getSolr();\n         if (solr != null) {\n+            // If full text stream(s) were passed in, we'll index them as part of the SolrInputDocument\n             if (streams != null && !streams.isEmpty()) {\n-                ContentStreamUpdateRequest req = new ContentStreamUpdateRequest(\"/update/extract\");\n-                req.addContentStream(streams);\n-\n-                ModifiableSolrParams params = new ModifiableSolrParams();\n+                // limit full text indexing to first 100,000 characters unless configured otherwise\n+                final int charLimit = DSpaceServicesFactory.getInstance().getConfigurationService()\n+                                                           .getIntProperty(\"discovery.solr.fulltext.charLimit\",\n+                                                                           100000);\n+\n+                // Use Tika's Text parser as the streams are always from the TEXT bundle (i.e. already extracted text)\n+                // TODO: We may wish to consider using Tika to extract the text in the future.\n+                TextAndCSVParser tikaParser = new TextAndCSVParser();\n+                BodyContentHandler tikaHandler = new BodyContentHandler(charLimit);\n+                Metadata tikaMetadata = new Metadata();\n+                ParseContext tikaContext = new ParseContext();\n+\n+                // Use Apache Tika to parse the full text stream\n+                try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU1MzYxNQ=="}, "originalCommit": {"oid": "954a0818930660d5144e97a066ec75bbb911faa5"}, "originalPosition": 68}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1432, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}