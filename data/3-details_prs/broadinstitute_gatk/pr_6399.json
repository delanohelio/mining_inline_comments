{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1NDQxNTc3", "number": 6399, "title": "AH - implement changes for mitochondrial pipeline", "bodyText": "This PR converts the Mutect2Filtering engine to be allele specific. This required changes to SomaticClusteringModel and ThresholdCalculator as well as ErrorProbabilities and of course the filters themselves. There are some filters which have not yet been converted, but I am prioritizing the ones in this PR for Sarah Calvo and the mitochondria pipeline. This provides the implementation for dsp-spec-ops tickets 166, 168, 169", "createdAt": "2020-01-21T18:12:08Z", "url": "https://github.com/broadinstitute/gatk/pull/6399", "merged": true, "mergeCommit": {"oid": "3021e6924aeb84d9f3b333e5298abb1ec27d350a"}, "closed": true, "closedAt": "2020-04-22T17:41:21Z", "author": {"login": "ahaessly"}, "timelineItems": {"totalCount": 101, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcZ6KsnAH2gAyMzY1NDQxNTc3OjMzYzI5NDJiN2ZkNDRkN2M2ZDcwOTQ3ZDg2MjlkYTZmMGRkOGNjNTE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZ6KsnAH2gAyMzY1NDQxNTc3OjMzYzI5NDJiN2ZkNDRkN2M2ZDcwOTQ3ZDg2MjlkYTZmMGRkOGNjNTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "33c2942b7fd44d7c6d70947d8629da6f0dd8cc51", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/33c2942b7fd44d7c6d70947d8629da6f0dd8cc51", "committedDate": "2020-04-21T21:00:22Z", "message": "update documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f3ba57bc085a1bea8a1579c0059750db935c9080", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/f3ba57bc085a1bea8a1579c0059750db935c9080", "committedDate": "2020-01-22T14:57:05Z", "message": "Disable CNNVariantPipelineTest.testTrainingReadModel until failures are resolved. (#6331)"}, "afterCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3", "committedDate": "2020-01-22T15:06:46Z", "message": "minor changes and comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2ODY3ODk3", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-346867897", "createdAt": "2020-01-22T20:06:52Z", "commit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMDowNjo1M1rOFgpXaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTowMToyM1rOFgq1eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3NjQ4OQ==", "bodyText": "I believe you can return String.join(\",\", alleleValues)", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369776489", "createdAt": "2020-01-22T20:06:53Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/StrandBiasUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.broadinstitute.hellbender.engine.filters.VariantFilter;\n+import org.broadinstitute.hellbender.tools.walkers.annotator.AnnotationUtils;\n+import org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+public class StrandBiasUtils {\n+    public static final int FORWARD = 0;\n+    public static final int REVERSE = 1;\n+    public static final int MIN_COUNT = 2;\n+    public static final String PRINT_DELIM = \"|\";\n+    private static final List<Integer> ZERO_LIST = new ArrayList<>(Arrays.asList(0,0));\n+\n+    public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {\n+        // calculate the annotation from the likelihoods\n+        // likelihoods can come from HaplotypeCaller call to VariantAnnotatorEngine\n+        final Map<String, Object> annotations = new HashMap<>();\n+        final ReducibleAnnotationData<List<Integer>> myData = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);\n+        getStrandCountsFromLikelihoodMap(vc, likelihoods, myData, MIN_COUNT);\n+        final Map<Allele, List<Integer>> perAlleleValues = myData.getAttributeMap();\n+        final String annotationString = makeRawAnnotationString(vc.getAlleles(), perAlleleValues);\n+        annotations.put(key, annotationString);\n+        return annotations;\n+    }\n+\n+    protected static String makeRawAnnotationString(final List<Allele> vcAlleles, final Map<Allele, List<Integer>> perAlleleValues) {\n+        String annotationString = \"\";\n+        for (final Allele a : vcAlleles) {\n+            if (!annotationString.isEmpty()) {\n+                annotationString += PRINT_DELIM;\n+            }\n+            List<Integer> alleleValues = perAlleleValues.get(a);\n+            if (alleleValues == null) {\n+                alleleValues = ZERO_LIST;\n+            }\n+            annotationString += encode(alleleValues);\n+        }\n+        return annotationString;\n+    }\n+\n+    protected static String encode(List<Integer> alleleValues) {\n+        String annotationString = \"\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3ODY4MA==", "bodyText": "This method could be written as\nfinal List<String> alleleStrings = vcAlleles.stream()\n    .map(a -> perAlleleValues.getOrDefault(a, ZERO_LIST))\n    .map(encode)\n    .collect(Collectors.toList());\nreturn String.join(PRINT_DELIM, alleleStrings);", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369778680", "createdAt": "2020-01-22T20:12:00Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/StrandBiasUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.broadinstitute.hellbender.engine.filters.VariantFilter;\n+import org.broadinstitute.hellbender.tools.walkers.annotator.AnnotationUtils;\n+import org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+public class StrandBiasUtils {\n+    public static final int FORWARD = 0;\n+    public static final int REVERSE = 1;\n+    public static final int MIN_COUNT = 2;\n+    public static final String PRINT_DELIM = \"|\";\n+    private static final List<Integer> ZERO_LIST = new ArrayList<>(Arrays.asList(0,0));\n+\n+    public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {\n+        // calculate the annotation from the likelihoods\n+        // likelihoods can come from HaplotypeCaller call to VariantAnnotatorEngine\n+        final Map<String, Object> annotations = new HashMap<>();\n+        final ReducibleAnnotationData<List<Integer>> myData = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);\n+        getStrandCountsFromLikelihoodMap(vc, likelihoods, myData, MIN_COUNT);\n+        final Map<Allele, List<Integer>> perAlleleValues = myData.getAttributeMap();\n+        final String annotationString = makeRawAnnotationString(vc.getAlleles(), perAlleleValues);\n+        annotations.put(key, annotationString);\n+        return annotations;\n+    }\n+\n+    protected static String makeRawAnnotationString(final List<Allele> vcAlleles, final Map<Allele, List<Integer>> perAlleleValues) {\n+        String annotationString = \"\";\n+        for (final Allele a : vcAlleles) {\n+            if (!annotationString.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3OTM3Ng==", "bodyText": "This is already defined as AnnotationUtils.ALLELE_SPECIFIC_PRINT_DELIM", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369779376", "createdAt": "2020-01-22T20:13:36Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/StrandBiasUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.broadinstitute.hellbender.engine.filters.VariantFilter;\n+import org.broadinstitute.hellbender.tools.walkers.annotator.AnnotationUtils;\n+import org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+public class StrandBiasUtils {\n+    public static final int FORWARD = 0;\n+    public static final int REVERSE = 1;\n+    public static final int MIN_COUNT = 2;\n+    public static final String PRINT_DELIM = \"|\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4MDE5NQ==", "bodyText": "How about:\nfinal int strand = read.isReverseStrand() ? REVERSE : FORWARD;\nalleleStrandCounts.set(strand, alleleStrandCounts.get(strand) + 1);", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369780195", "createdAt": "2020-01-22T20:15:30Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/StrandBiasUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.broadinstitute.hellbender.engine.filters.VariantFilter;\n+import org.broadinstitute.hellbender.tools.walkers.annotator.AnnotationUtils;\n+import org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+public class StrandBiasUtils {\n+    public static final int FORWARD = 0;\n+    public static final int REVERSE = 1;\n+    public static final int MIN_COUNT = 2;\n+    public static final String PRINT_DELIM = \"|\";\n+    private static final List<Integer> ZERO_LIST = new ArrayList<>(Arrays.asList(0,0));\n+\n+    public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {\n+        // calculate the annotation from the likelihoods\n+        // likelihoods can come from HaplotypeCaller call to VariantAnnotatorEngine\n+        final Map<String, Object> annotations = new HashMap<>();\n+        final ReducibleAnnotationData<List<Integer>> myData = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);\n+        getStrandCountsFromLikelihoodMap(vc, likelihoods, myData, MIN_COUNT);\n+        final Map<Allele, List<Integer>> perAlleleValues = myData.getAttributeMap();\n+        final String annotationString = makeRawAnnotationString(vc.getAlleles(), perAlleleValues);\n+        annotations.put(key, annotationString);\n+        return annotations;\n+    }\n+\n+    protected static String makeRawAnnotationString(final List<Allele> vcAlleles, final Map<Allele, List<Integer>> perAlleleValues) {\n+        String annotationString = \"\";\n+        for (final Allele a : vcAlleles) {\n+            if (!annotationString.isEmpty()) {\n+                annotationString += PRINT_DELIM;\n+            }\n+            List<Integer> alleleValues = perAlleleValues.get(a);\n+            if (alleleValues == null) {\n+                alleleValues = ZERO_LIST;\n+            }\n+            annotationString += encode(alleleValues);\n+        }\n+        return annotationString;\n+    }\n+\n+    protected static String encode(List<Integer> alleleValues) {\n+        String annotationString = \"\";\n+        for (int j =0; j < alleleValues.size(); j++) {\n+            annotationString += alleleValues.get(j);\n+            if (j < alleleValues.size()-1) {\n+                annotationString += \",\";\n+            }\n+        }\n+        return annotationString;\n+    }\n+\n+\n+    /**\n+     Allocate and fill a 2x2 strand contingency table.  In the end, it'll look something like this:\n+     *             fw      rc\n+     *   allele1   #       #\n+     *   allele2   #       #\n+     * @return a 2x2 contingency table\n+     */\n+    public static void getStrandCountsFromLikelihoodMap( final VariantContext vc,\n+                                                  final AlleleLikelihoods<GATKRead, Allele> likelihoods,\n+                                                  final ReducibleAnnotationData<List<Integer>> perAlleleValues,\n+                                                  final int minCount) {\n+        if( likelihoods == null || vc == null ) {\n+            return;\n+        }\n+\n+        final Allele ref = vc.getReference();\n+        final List<Allele> allAlts = vc.getAlternateAlleles();\n+\n+        for (final String sample : likelihoods.samples()) {\n+            final ReducibleAnnotationData<List<Integer>> sampleTable = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);\n+            likelihoods.bestAllelesBreakingTies(sample).stream()\n+                    .filter(ba -> ba.isInformative())\n+                    .forEach(ba -> updateTable(ba.allele, ba.evidence, ref, allAlts, sampleTable));\n+            if (passesMinimumThreshold(sampleTable, minCount)) {\n+                combineAttributeMap(sampleTable, perAlleleValues);\n+            }\n+        }\n+    }\n+\n+    protected static void combineAttributeMap(final ReducibleAnnotationData<List<Integer>> toAdd, final ReducibleAnnotationData<List<Integer>> combined) {\n+        for (final Allele a : combined.getAlleles()) {\n+            if (toAdd.hasAttribute(a) && toAdd.getAttribute(a) != null) {\n+                if (combined.getAttribute(a) != null) {\n+                    combined.getAttribute(a).set(FORWARD, (int) combined.getAttribute(a).get(FORWARD) + (int) toAdd.getAttribute(a).get(FORWARD));\n+                    combined.getAttribute(a).set(REVERSE, (int) combined.getAttribute(a).get(REVERSE) + (int) toAdd.getAttribute(a).get(REVERSE));\n+                }\n+                else {\n+                    List<Integer> alleleData = new ArrayList<>();\n+                    alleleData.add(FORWARD, toAdd.getAttribute(a).get(FORWARD));\n+                    alleleData.add(REVERSE, toAdd.getAttribute(a).get(REVERSE));\n+                    combined.putAttribute(a,alleleData);\n+                }\n+            }\n+        }\n+    }\n+\n+    private static void updateTable(final Allele bestAllele, final GATKRead read, final Allele ref, final List<Allele> allAlts, final ReducibleAnnotationData<List<Integer>> perAlleleValues) {\n+\n+        final boolean matchesRef = bestAllele.equals(ref, true);\n+        final boolean matchesAnyAlt = allAlts.contains(bestAllele);\n+\n+        //can happen if a read's most likely allele has been removed when --max_alternate_alleles is exceeded\n+        if (!( matchesRef || matchesAnyAlt )) {\n+            return;\n+        }\n+\n+        final List<Integer> alleleStrandCounts;\n+        if (perAlleleValues.hasAttribute(bestAllele) && perAlleleValues.getAttribute(bestAllele) != null) {\n+            alleleStrandCounts = perAlleleValues.getAttribute(bestAllele);\n+        } else {\n+            alleleStrandCounts = new ArrayList<>();\n+            alleleStrandCounts.add(0,0);\n+            alleleStrandCounts.add(1,0);\n+        }\n+        final boolean isForward = !read.isReverseStrand();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4MzcwMA==", "bodyText": "As long as you're touching this code, could you put in javadoc that I should have done earlier, specifying that\n\ntumorADs are by alt allele, summed over samples\ntumor logOdds are by alt allele\nartifactProbabilities are by alelle and specifically technical artifact probabilities not including sequencing error, contamination, or germline variation\nnonSomatic probabilities are probabilitie that the variants are real but not somatic ie germline or contamination", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369783700", "createdAt": "2020-01-22T20:23:01Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java", "diffHunk": "@@ -96,11 +96,16 @@ public double probabilityOfSequencingError(final Datum datum) {\n         return clusterProbabilities(datum)[SEQUENCING_ERROR_INDEX];\n     }\n \n-    public void record(final int[] tumorADs, final double[] tumorLogOdds, final double artifactProbability, final double nonSomaticProbability, final VariantContext vc) {\n+    public void record(final int[] tumorADs, final double[] tumorLogOdds, final List<Double> artifactProbabilities, final List<Double> nonSomaticProbabilities, final VariantContext vc) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4NDY3NQ==", "bodyText": "We should skip symbolic alleles -- don't record them in the clustering model or the threshold calculator, don't involve them in any filters that learn their parameters, and don't include them in the sum of ADs here, either.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369784675", "createdAt": "2020-01-22T20:25:16Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java", "diffHunk": "@@ -96,11 +96,16 @@ public double probabilityOfSequencingError(final Datum datum) {\n         return clusterProbabilities(datum)[SEQUENCING_ERROR_INDEX];\n     }\n \n-    public void record(final int[] tumorADs, final double[] tumorLogOdds, final double artifactProbability, final double nonSomaticProbability, final VariantContext vc) {\n+    public void record(final int[] tumorADs, final double[] tumorLogOdds, final List<Double> artifactProbabilities, final List<Double> nonSomaticProbabilities, final VariantContext vc) {\n         final int totalAD = (int) MathUtils.sum(tumorADs);\n+        // TODO: david b: is it important to have data for symbolic alleles?\n+        int numAltAlleles = tumorLogOdds.length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4NTA3OQ==", "bodyText": "There could conceivably be multiple symbolic alleles (spanning deletion in GVCF mode, for example), so\nfinal int numAltAlleles = tumorLogOdds.alleles().stream().filter(a -> !a.isSymbolic()).count() is safer.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369785079", "createdAt": "2020-01-22T20:26:17Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java", "diffHunk": "@@ -96,11 +96,16 @@ public double probabilityOfSequencingError(final Datum datum) {\n         return clusterProbabilities(datum)[SEQUENCING_ERROR_INDEX];\n     }\n \n-    public void record(final int[] tumorADs, final double[] tumorLogOdds, final double artifactProbability, final double nonSomaticProbability, final VariantContext vc) {\n+    public void record(final int[] tumorADs, final double[] tumorLogOdds, final List<Double> artifactProbabilities, final List<Double> nonSomaticProbabilities, final VariantContext vc) {\n         final int totalAD = (int) MathUtils.sum(tumorADs);\n+        // TODO: david b: is it important to have data for symbolic alleles?\n+        int numAltAlleles = tumorLogOdds.length;\n+        if (vc.hasSymbolicAlleles()) {\n+            numAltAlleles--;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4NTcxMw==", "bodyText": "And we shouldn't assume that symbolic alleles are at the end, so perhaps\nfor (int i = 0; i < tumorLogOdds.length; i++) {\n   if (allele i is not symbolic) {\n      data.add. . .\n   }\n}", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369785713", "createdAt": "2020-01-22T20:27:54Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java", "diffHunk": "@@ -96,11 +96,16 @@ public double probabilityOfSequencingError(final Datum datum) {\n         return clusterProbabilities(datum)[SEQUENCING_ERROR_INDEX];\n     }\n \n-    public void record(final int[] tumorADs, final double[] tumorLogOdds, final double artifactProbability, final double nonSomaticProbability, final VariantContext vc) {\n+    public void record(final int[] tumorADs, final double[] tumorLogOdds, final List<Double> artifactProbabilities, final List<Double> nonSomaticProbabilities, final VariantContext vc) {\n         final int totalAD = (int) MathUtils.sum(tumorADs);\n+        // TODO: david b: is it important to have data for symbolic alleles?\n+        int numAltAlleles = tumorLogOdds.length;\n+        if (vc.hasSymbolicAlleles()) {\n+            numAltAlleles--;\n+        }\n         // split into one-vs-all biallelics for clustering\n-        for (int i = 0; i < tumorLogOdds.length; i++) {\n-            data.add(new Datum(tumorLogOdds[i], artifactProbability, nonSomaticProbability, tumorADs[i+1], totalAD, indelLength(vc, i)));\n+        for (int i = 0; i < numAltAlleles; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4NzAzOA==", "bodyText": "How about\nreturn vc.getAttributeAsIntList(GATKVCFConstants.MEDIAN_BASE_QUALITY_KEY, 0).stream().skip(1)  // skip ref\n   .map(qual -> qual < minMedianBaseQuality).collect(Collectors.toList());", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369787038", "createdAt": "2020-01-22T20:31:02Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/BaseQualityFilter.java", "diffHunk": "@@ -19,12 +19,10 @@ public BaseQualityFilter(final double minMedianBaseQuality) {\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n     @Override\n-    public boolean isArtifact(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n-        final List<Integer> baseQualityByAllele = vc.getAttributeAsIntList(GATKVCFConstants.MEDIAN_BASE_QUALITY_KEY, 0);\n-        final double[] tumorLods = Mutect2FilteringEngine.getTumorLogOdds(vc);\n-        final int indexOfMaxTumorLod = MathUtils.maxElementIndex(tumorLods);\n-\n-        return baseQualityByAllele.get(indexOfMaxTumorLod + 1) < minMedianBaseQuality;\n+    public List<Boolean> areAllelesArtifacts(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        List<Integer> baseQualityByAllele = vc.getAttributeAsIntList(GATKVCFConstants.MEDIAN_BASE_QUALITY_KEY, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4NzQ5Mg==", "bodyText": "Why does this need to be a method and not a static constant predicate?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369787492", "createdAt": "2020-01-22T20:32:09Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ChimericOriginalAlignmentFilter.java", "diffHunk": "@@ -16,15 +20,24 @@ public ChimericOriginalAlignmentFilter(final double maxNuMTFraction) {\n     @Override\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n+    public Predicate<Genotype> checkPreconditions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4ODMwMA==", "bodyText": "Do we still need to skip multiallelic sites?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369788300", "createdAt": "2020-01-22T20:34:17Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ChimericOriginalAlignmentFilter.java", "diffHunk": "@@ -16,15 +20,24 @@ public ChimericOriginalAlignmentFilter(final double maxNuMTFraction) {\n     @Override\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n+    public Predicate<Genotype> checkPreconditions() {\n+        return Genotype::hasAD;\n+    }\n+\n+    public List<Integer> getData(Genotype g) {\n+        return Arrays.stream(g.getAD()).boxed().collect(Collectors.toList());\n+    }\n+\n     @Override\n-    public boolean isArtifact(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n+    public List<Boolean> areAllelesArtifacts(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n         if(!vc.isBiallelic()) {\n-            return false;\n+            return Collections.emptyList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4ODg1NA==", "bodyText": "a list of the depths and posterior pairs of each sample", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369788854", "createdAt": "2020-01-22T20:35:38Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ContaminationFilter.java", "diffHunk": "@@ -31,8 +32,10 @@ public ContaminationFilter(final List<File> contaminationTables, final double co\n     public ErrorType errorType() { return ErrorType.NON_SOMATIC; }\n \n     @Override\n-    public double calculateErrorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n-        final List<ImmutablePair<Integer, Double>> depthsAndPosteriors = new ArrayList<>();\n+    public List<Double> calculateErrorProbabilityForAlleles(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        // for every alt allele, a list of the depth and posterior pair", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc4OTYzMA==", "bodyText": "The +1 offset of the comment seems not to be needed any more now that you copy the array starting at 1, right?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369789630", "createdAt": "2020-01-22T20:37:18Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ContaminationFilter.java", "diffHunk": "@@ -41,29 +44,38 @@ public double calculateErrorProbability(final VariantContext vc, final Mutect2Fi\n \n             final double contaminationFromFile = contaminationBySample.getOrDefault(tumorGenotype.getSampleName(), defaultContamination);\n             final double contamination = Math.max(0, Math.min(contaminationFromFile, 1 - EPSILON)); // handle file with contamination == 1\n-            final double[] alleleFractions = GATKProtectedVariantContextUtils.getAttributeAsDoubleArray(tumorGenotype, VCFConstants.ALLELE_FREQUENCY_KEY,\n-                    () -> new double[] {1.0}, 1.0);\n-            final int maxFractionIndex = MathUtils.maxElementIndex(alleleFractions);\n-            final int[] ADs = tumorGenotype.getAD();\n-            final int altCount = ADs[maxFractionIndex + 1];   // AD is all alleles, while AF is alts only, hence the +1 offset\n-            final int depth = (int) MathUtils.sum(ADs);\n+            final int[] ADs = tumorGenotype.getAD(); // AD is all alleles, while AF is alts only, hence the +1 offset", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc5MTc3MA==", "bodyText": "This always returns a singleton list, even if there is more than one alt allele. . .", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369791770", "createdAt": "2020-01-22T20:42:07Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/DuplicatedAltReadFilter.java", "diffHunk": "@@ -20,11 +21,11 @@ public DuplicatedAltReadFilter(final int uniqueAltReadCount) {\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n     @Override\n-    public boolean isArtifact(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n-        return vc.getAttributeAsInt(UniqueAltReadCount.KEY, 1) <= uniqueAltReadCount;\n+    public List<Boolean> areAllelesArtifacts(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc5OTAyMA==", "bodyText": "The VCF spec doesn't require it, so let's be cautious and not assume.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369799020", "createdAt": "2020-01-22T20:57:59Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ErrorProbabilities.java", "diffHunk": "@@ -3,36 +3,95 @@\n import htsjdk.variant.variantcontext.VariantContext;\n import org.broadinstitute.hellbender.engine.ReferenceContext;\n \n-import java.util.Arrays;\n-import java.util.EnumMap;\n-import java.util.List;\n-import java.util.Map;\n+import java.util.*;\n+import java.util.function.Function;\n import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static java.util.stream.Collectors.*;\n \n public final class ErrorProbabilities {\n-    private final Map<Mutect2VariantFilter, Double> probabilitiesByFilter;\n-    private final EnumMap<ErrorType, Double> probabilitiesByType;\n-    private final double errorProbability;\n+    private  LinkedHashMap<Mutect2Filter, List<Double>> alleleProbabilitiesByFilter;\n+    private final Map<ErrorType, List<Double>> probabilitiesByTypeAndAllele;\n+    private final List<Double> combinedErrorProbabilitiesByAllele;\n+    private final int numAltAlleles;\n \n \n-    public ErrorProbabilities(final List<Mutect2VariantFilter> filters, final VariantContext vc, final Mutect2FilteringEngine filteringEngine, final ReferenceContext referenceContext) {\n-        probabilitiesByFilter = filters.stream().collect(Collectors.toMap(f -> f, f -> f.errorProbability(vc, filteringEngine, referenceContext)));\n-        probabilitiesByType = Arrays.stream(ErrorType.values()).collect(Collectors.toMap(v -> v, v -> 0.0, (a,b) -> a, () -> new EnumMap<>(ErrorType.class)));\n-        filters.forEach(f -> probabilitiesByType.compute(f.errorType(), (type,prob) -> Math.max(prob, probabilitiesByFilter.get(f))));\n+    public ErrorProbabilities(final List<Mutect2Filter> filters, final VariantContext vc, final Mutect2FilteringEngine filteringEngine, final ReferenceContext referenceContext) {\n+        numAltAlleles = vc.getAlternateAlleles().size();\n+        alleleProbabilitiesByFilter = filters.stream()\n+                .collect(toMap(\n+                        Function.identity(),\n+                        f -> f.errorProbabilities(vc, filteringEngine, referenceContext),\n+                        (a, b) -> a, LinkedHashMap::new))\n+                // remove filters that were not applied. i.e. returned empty list\n+                .entrySet().stream().filter(entry -> !entry.getValue().isEmpty())\n+                .collect(toMap(Map.Entry::getKey, Map.Entry::getValue, (a, b) -> a, LinkedHashMap::new));\n \n-        // treat errors of different types as independent\n-        double trueProbability = 1;\n-        for (final double errorProb : probabilitiesByType.values()) {\n-            trueProbability *= (1 - errorProb);\n+        // if vc has symbolic allele, remove it\n+        if (vc.hasSymbolicAlleles()) {\n+            // can we assume it's the last allele?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgwMDU2OQ==", "bodyText": "Should there be an error thrown inside this block?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369800569", "createdAt": "2020-01-22T21:01:23Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ErrorProbabilities.java", "diffHunk": "@@ -3,36 +3,95 @@\n import htsjdk.variant.variantcontext.VariantContext;\n import org.broadinstitute.hellbender.engine.ReferenceContext;\n \n-import java.util.Arrays;\n-import java.util.EnumMap;\n-import java.util.List;\n-import java.util.Map;\n+import java.util.*;\n+import java.util.function.Function;\n import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static java.util.stream.Collectors.*;\n \n public final class ErrorProbabilities {\n-    private final Map<Mutect2VariantFilter, Double> probabilitiesByFilter;\n-    private final EnumMap<ErrorType, Double> probabilitiesByType;\n-    private final double errorProbability;\n+    private  LinkedHashMap<Mutect2Filter, List<Double>> alleleProbabilitiesByFilter;\n+    private final Map<ErrorType, List<Double>> probabilitiesByTypeAndAllele;\n+    private final List<Double> combinedErrorProbabilitiesByAllele;\n+    private final int numAltAlleles;\n \n \n-    public ErrorProbabilities(final List<Mutect2VariantFilter> filters, final VariantContext vc, final Mutect2FilteringEngine filteringEngine, final ReferenceContext referenceContext) {\n-        probabilitiesByFilter = filters.stream().collect(Collectors.toMap(f -> f, f -> f.errorProbability(vc, filteringEngine, referenceContext)));\n-        probabilitiesByType = Arrays.stream(ErrorType.values()).collect(Collectors.toMap(v -> v, v -> 0.0, (a,b) -> a, () -> new EnumMap<>(ErrorType.class)));\n-        filters.forEach(f -> probabilitiesByType.compute(f.errorType(), (type,prob) -> Math.max(prob, probabilitiesByFilter.get(f))));\n+    public ErrorProbabilities(final List<Mutect2Filter> filters, final VariantContext vc, final Mutect2FilteringEngine filteringEngine, final ReferenceContext referenceContext) {\n+        numAltAlleles = vc.getAlternateAlleles().size();\n+        alleleProbabilitiesByFilter = filters.stream()\n+                .collect(toMap(\n+                        Function.identity(),\n+                        f -> f.errorProbabilities(vc, filteringEngine, referenceContext),\n+                        (a, b) -> a, LinkedHashMap::new))\n+                // remove filters that were not applied. i.e. returned empty list\n+                .entrySet().stream().filter(entry -> !entry.getValue().isEmpty())\n+                .collect(toMap(Map.Entry::getKey, Map.Entry::getValue, (a, b) -> a, LinkedHashMap::new));\n \n-        // treat errors of different types as independent\n-        double trueProbability = 1;\n-        for (final double errorProb : probabilitiesByType.values()) {\n-            trueProbability *= (1 - errorProb);\n+        // if vc has symbolic allele, remove it\n+        if (vc.hasSymbolicAlleles()) {\n+            // can we assume it's the last allele?\n+            int symIndex = numAltAlleles - 1;\n+            alleleProbabilitiesByFilter.values().stream().forEach(probList -> probList.remove(symIndex));\n         }\n+        LinkedHashMap<ErrorType, List<List<Double>>> probabilitiesByAllelesForEachFilter = alleleProbabilitiesByFilter.entrySet().stream().collect(\n+                groupingBy(entry -> entry.getKey().errorType(), LinkedHashMap::new, mapping(entry -> entry.getValue(), toList())));\n+        // convert the data so we have a list of probabilities by allele instead of filter\n+        probabilitiesByAllelesForEachFilter.replaceAll((k, v) -> ErrorProbabilities.transpose(v));\n+\n+        // foreach error type, get the max probability for each allele\n+        probabilitiesByTypeAndAllele = probabilitiesByAllelesForEachFilter.entrySet().stream().collect(toMap(\n+                Map.Entry::getKey,\n+                entry -> entry.getValue().stream().map(alleleList -> alleleList.stream().max(Double::compare).orElse(0.0)).collect(Collectors.toList()),\n+                (a,b) -> a, HashMap::new));\n+\n+\n+        // treat errors of different types as independent\n+        // transpose the lists of allele probabilities, so it is now a list per allele that contains the prob for each type\n+        // combine allele-wise\n+        combinedErrorProbabilitiesByAllele = transpose(probabilitiesByTypeAndAllele.values().stream().collect(toList()))\n+                .stream().map(\n+                        alleleProbabilities -> alleleProbabilities.stream().map(p -> 1.0 - p).reduce(1.0, (a, b) -> a * b)).collect(Collectors.toList());\n+        combinedErrorProbabilitiesByAllele.replaceAll(trueProb -> Mutect2FilteringEngine.roundFinitePrecisionErrors(1.0 - trueProb));\n+    }\n+\n+    public List<Double> getCombinedErrorProbabilities() { return combinedErrorProbabilitiesByAllele; }\n+    public List<Double> getTechnicalArtifactProbabilities() { return probabilitiesByTypeAndAllele.get(ErrorType.ARTIFACT); }\n+    public List<Double> getNonSomaticProbabilities() { return probabilitiesByTypeAndAllele.get(ErrorType.NON_SOMATIC); }\n+    public Map<Mutect2Filter, List<Double>> getProbabilitiesByFilter() { return alleleProbabilitiesByFilter; }\n+\n+    // helper functions for the few operations that still differ depending on whether the filter\n+    // is per variant or allele\n+    public Map<Mutect2Filter, List<Double>> getProbabilitiesForAlleleFilters() {\n+        return getPartitionedProbabilitiesByFilter(false);\n+    }\n \n-        errorProbability = Mutect2FilteringEngine.roundFinitePrecisionErrors(1 - trueProbability);\n+    public Map<Mutect2Filter, Double> getProbabilitiesForVariantFilters() {\n+        return getPartitionedProbabilitiesByFilter(true).entrySet().stream()\n+                .filter(entry -> entry.getValue() != null && !entry.getValue().isEmpty())\n+                .collect(toMap(entry -> entry.getKey(), entry -> entry.getValue().get(0)));\n     }\n \n-    public double getErrorProbability() { return errorProbability; }\n-    public double getTechnicalArtifactProbability() { return probabilitiesByType.get(ErrorType.ARTIFACT); }\n-    public double getNonSomaticProbability() { return probabilitiesByType.get(ErrorType.NON_SOMATIC); }\n-    public Map<Mutect2VariantFilter, Double> getProbabilitiesByFilter() { return probabilitiesByFilter; }\n+    private Map<Mutect2Filter, List<Double>> getPartitionedProbabilitiesByFilter(boolean variantOnly) {\n+        Map<Boolean, LinkedHashMap<Mutect2Filter, List<Double>>> groups =\n+                alleleProbabilitiesByFilter.entrySet().stream().collect(Collectors.partitioningBy(\n+                        entry -> Mutect2VariantFilter.class.isAssignableFrom(entry.getKey().getClass()),\n+                        toMap(Map.Entry::getKey, Map.Entry::getValue, (a,b) -> a, LinkedHashMap::new)));\n+        return groups.get(variantOnly);\n+    }\n \n+    // TODO would this be useful in a util class somewhere?\n+    private static <T> List<List<T>> transpose(List<List<T>> list) {\n+        // all lists need to be the same size\n+        final int N = list.stream().mapToInt(l -> l.size()).max().orElse(-1);\n+        if (list.stream().anyMatch(l -> l.size() != N)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "959a4a2c6d5ab1a1f60f897f282cd89f9ccc6cd3"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MDMwNTg2", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-347030586", "createdAt": "2020-01-23T02:35:48Z", "commit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwMjozNTo0OFrOFgxaDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwMzoxNDo1NFrOFgx11g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkwODIzOQ==", "bodyText": "As above, why is this a method and not a constant predicate?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369908239", "createdAt": "2020-01-23T02:35:48Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/MinAlleleFractionFilter.java", "diffHunk": "@@ -18,16 +21,21 @@ public MinAlleleFractionFilter(final double minAf) {\n     @Override\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n+    public Predicate<Genotype> checkPreconditions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkwODI5Mw==", "bodyText": "final Genotype g", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369908293", "createdAt": "2020-01-23T02:36:09Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/MinAlleleFractionFilter.java", "diffHunk": "@@ -18,16 +21,21 @@ public MinAlleleFractionFilter(final double minAf) {\n     @Override\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n+    public Predicate<Genotype> checkPreconditions() {\n+        return g -> g.hasExtendedAttribute(GATKVCFConstants.ALLELE_FRACTION_KEY);\n+    }\n+\n+    public List<Double> getAltData(Genotype g) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkwODU2MA==", "bodyText": "Instead of the stream, return Doubles.asList(data).", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369908560", "createdAt": "2020-01-23T02:37:40Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/MinAlleleFractionFilter.java", "diffHunk": "@@ -18,16 +21,21 @@ public MinAlleleFractionFilter(final double minAf) {\n     @Override\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n+    public Predicate<Genotype> checkPreconditions() {\n+        return g -> g.hasExtendedAttribute(GATKVCFConstants.ALLELE_FRACTION_KEY);\n+    }\n+\n+    public List<Double> getAltData(Genotype g) {\n+        double[] data = GATKProtectedVariantContextUtils.getAttributeAsDoubleArray(g, GATKVCFConstants.ALLELE_FRACTION_KEY, () -> null, 1.0);\n+        return Arrays.stream(data).boxed().collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMTQ2OA==", "bodyText": "There should be logic to \"promote\" an allele-specific filter that applies to every allele to a site-level filter.  Also, if all alleles fail, but for different reasons, what happens to the site filter?  Apologies if those features are here and I missed them.  It looks to me like perhaps this is a side-effect of addFilterStrings, but I'm having trouble following.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369911468", "createdAt": "2020-01-23T02:53:08Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -175,28 +177,89 @@ public VariantContext applyFiltersAndAccumulateOutputStats(final VariantContext\n         final ErrorProbabilities errorProbabilities = new ErrorProbabilities(filters, vc, this, referenceContext);\n         filteringOutputStats.recordCall(errorProbabilities, getThreshold() - EPSILON);\n \n-        final boolean variantFailsFilters = errorProbabilities.getErrorProbability() > Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n-        final double maxErrorProb = errorProbabilities.getProbabilitiesByFilter().values().stream().mapToDouble(p->p).max().orElse(1);\n+        // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n+        // and probabilities close to 0 must not be filtered\n+        double errorThreshold = Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n+\n+        Map<String, Double> siteFiltersWithErrorProb = new LinkedHashMap<>();\n+\n+        // apply allele specific filters\n+        List<Iterator<String>> ASFilters =\n+                errorProbabilities.getProbabilitiesForAlleleFilters().entrySet().stream()\n+                        .filter(entry -> !entry.getValue().isEmpty())\n+                        .map(entry -> addFilterStrings(entry.getValue(), siteFiltersWithErrorProb, errorThreshold, entry.getKey().filterName())).collect(Collectors.toList());\n+\n+        List<String> orderedASFilterStrings = vc.getAlleles().stream().map(allele -> allele.isReference() || allele.isSymbolic() ?\n+                VCFConstants.EMPTY_INFO_FIELD : getMergedFilterStringForAllele(ASFilters)).collect(Collectors.toList());\n+        String finalAttrString = AnnotationUtils.encodeAnyASList(orderedASFilterStrings);\n+\n+        vcb.putAttributes(Collections.singletonMap(GATKVCFConstants.AS_FILTER_STATUS_KEY, finalAttrString));\n+\n+\n+        // compute site-only filters\n+        errorProbabilities.getProbabilitiesForVariantFilters().entrySet().stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMTc1OA==", "bodyText": "I think there should not be such an option.  MIN_REPORTABLE_ERROR_PROBABILITY is fairly low.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369911758", "createdAt": "2020-01-23T02:54:46Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -175,28 +177,89 @@ public VariantContext applyFiltersAndAccumulateOutputStats(final VariantContext\n         final ErrorProbabilities errorProbabilities = new ErrorProbabilities(filters, vc, this, referenceContext);\n         filteringOutputStats.recordCall(errorProbabilities, getThreshold() - EPSILON);\n \n-        final boolean variantFailsFilters = errorProbabilities.getErrorProbability() > Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n-        final double maxErrorProb = errorProbabilities.getProbabilitiesByFilter().values().stream().mapToDouble(p->p).max().orElse(1);\n+        // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n+        // and probabilities close to 0 must not be filtered\n+        double errorThreshold = Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n+\n+        Map<String, Double> siteFiltersWithErrorProb = new LinkedHashMap<>();\n+\n+        // apply allele specific filters\n+        List<Iterator<String>> ASFilters =\n+                errorProbabilities.getProbabilitiesForAlleleFilters().entrySet().stream()\n+                        .filter(entry -> !entry.getValue().isEmpty())\n+                        .map(entry -> addFilterStrings(entry.getValue(), siteFiltersWithErrorProb, errorThreshold, entry.getKey().filterName())).collect(Collectors.toList());\n+\n+        List<String> orderedASFilterStrings = vc.getAlleles().stream().map(allele -> allele.isReference() || allele.isSymbolic() ?\n+                VCFConstants.EMPTY_INFO_FIELD : getMergedFilterStringForAllele(ASFilters)).collect(Collectors.toList());\n+        String finalAttrString = AnnotationUtils.encodeAnyASList(orderedASFilterStrings);\n+\n+        vcb.putAttributes(Collections.singletonMap(GATKVCFConstants.AS_FILTER_STATUS_KEY, finalAttrString));\n+\n+\n+        // compute site-only filters\n+        errorProbabilities.getProbabilitiesForVariantFilters().entrySet().stream()\n+                .forEach(entry -> {\n+                    entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n+                        if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n+                            vcb.attribute(annotation, QualityUtils.errorProbToQual(entry.getValue()));\n+                        }\n+                    });\n+                    if (entry.getValue() > errorThreshold) {\n+                        siteFiltersWithErrorProb.put(entry.getKey().filterName(), entry.getValue());\n+                    }\n \n-        for (final Map.Entry<Mutect2VariantFilter, Double> entry : errorProbabilities.getProbabilitiesByFilter().entrySet()) {\n-            final double errorProbability = entry.getValue();\n+                });\n \n-            entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n-                if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n-                    vcb.attribute(annotation, QualityUtils.errorProbToQual(errorProbability));\n-                }\n-            });\n+        // TO reviewers - should there be a flag where this is skipped and all filters are in the output vcf?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMjY2NA==", "bodyText": "I think it's the correct default.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369912664", "createdAt": "2020-01-23T02:59:21Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -175,28 +177,89 @@ public VariantContext applyFiltersAndAccumulateOutputStats(final VariantContext\n         final ErrorProbabilities errorProbabilities = new ErrorProbabilities(filters, vc, this, referenceContext);\n         filteringOutputStats.recordCall(errorProbabilities, getThreshold() - EPSILON);\n \n-        final boolean variantFailsFilters = errorProbabilities.getErrorProbability() > Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n-        final double maxErrorProb = errorProbabilities.getProbabilitiesByFilter().values().stream().mapToDouble(p->p).max().orElse(1);\n+        // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n+        // and probabilities close to 0 must not be filtered\n+        double errorThreshold = Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n+\n+        Map<String, Double> siteFiltersWithErrorProb = new LinkedHashMap<>();\n+\n+        // apply allele specific filters\n+        List<Iterator<String>> ASFilters =\n+                errorProbabilities.getProbabilitiesForAlleleFilters().entrySet().stream()\n+                        .filter(entry -> !entry.getValue().isEmpty())\n+                        .map(entry -> addFilterStrings(entry.getValue(), siteFiltersWithErrorProb, errorThreshold, entry.getKey().filterName())).collect(Collectors.toList());\n+\n+        List<String> orderedASFilterStrings = vc.getAlleles().stream().map(allele -> allele.isReference() || allele.isSymbolic() ?\n+                VCFConstants.EMPTY_INFO_FIELD : getMergedFilterStringForAllele(ASFilters)).collect(Collectors.toList());\n+        String finalAttrString = AnnotationUtils.encodeAnyASList(orderedASFilterStrings);\n+\n+        vcb.putAttributes(Collections.singletonMap(GATKVCFConstants.AS_FILTER_STATUS_KEY, finalAttrString));\n+\n+\n+        // compute site-only filters\n+        errorProbabilities.getProbabilitiesForVariantFilters().entrySet().stream()\n+                .forEach(entry -> {\n+                    entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n+                        if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n+                            vcb.attribute(annotation, QualityUtils.errorProbToQual(entry.getValue()));\n+                        }\n+                    });\n+                    if (entry.getValue() > errorThreshold) {\n+                        siteFiltersWithErrorProb.put(entry.getKey().filterName(), entry.getValue());\n+                    }\n \n-        for (final Map.Entry<Mutect2VariantFilter, Double> entry : errorProbabilities.getProbabilitiesByFilter().entrySet()) {\n-            final double errorProbability = entry.getValue();\n+                });\n \n-            entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n-                if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n-                    vcb.attribute(annotation, QualityUtils.errorProbToQual(errorProbability));\n-                }\n-            });\n+        // TO reviewers - should there be a flag where this is skipped and all filters are in the output vcf?\n+        // otherwise things may seem erroneous. and should we apply this type of limit on the allele specific filters too?\n \n-            // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n-            // and probabilities close to 0 must not be filtered\n-            if (variantFailsFilters && errorProbability >= Math.min(maxErrorProb, MIN_REPORTABLE_ERROR_PROBABILITY)) {\n-                vcb.filter(entry.getKey().filterName());\n+        // this code limits the number of filters specified for any variant to the highest probability filters\n+        // this will not change the status of whether a variant is actually filtered or not\n+        final double maxErrorProb = siteFiltersWithErrorProb.values().stream().mapToDouble(p->p).max().orElse(1);\n+        siteFiltersWithErrorProb.entrySet().stream().forEach(entry -> {\n+            if (entry.getValue() >= Math.min(maxErrorProb, MIN_REPORTABLE_ERROR_PROBABILITY)) {\n+                vcb.filter(entry.getKey());\n             }\n-        }\n+        });\n \n         return vcb.make();\n     }\n \n+    /**\n+     * Creates a comma separated string of all the filters that apply to the allele. This is basically\n+     * a pivot of the data. we have filterlist -> allele -> filterName. and we want allele -> list of filterName\n+     * @param alleleSpecificFilters all of the allele specific filters with the allele filter info\n+     * @return encoded (comma separated) list of filters that apply to the allele\n+     */\n+    private String getMergedFilterStringForAllele(List<Iterator<String>> alleleSpecificFilters) {\n+        // loop through each filter and pull out the filters the specified allele\n+        List<String> results = alleleSpecificFilters.stream().map(alleleValuesIterator -> alleleValuesIterator.next()).distinct().collect(Collectors.toList());\n+        if (results.size() > 1 && results.contains(VCFConstants.PASSES_FILTERS_v4)) {\n+            results.remove(VCFConstants.PASSES_FILTERS_v4);\n+        } else if (results.isEmpty()) {\n+            results.add(VCFConstants.PASSES_FILTERS_v4);\n+        }\n+        return AnnotationUtils.encodeStringList(results);\n+    }\n+\n+    /**\n+     * For each allele, determine whether the filter should be applied. also determine if the filter should apply to the site\n+     * @param probabilities the probability computed by the filter for the allele\n+     * @param siteFiltersWithErrorProb in/out parameter that is collecting site level filters with the max error probability\n+     * @param errorThreshold the theshold to use to determine whether filter applies\n+     * @param filterName the name of the filter used in the vcf\n+     * @return Iterator of filters for an allele\n+     */\n+    private Iterator<String> addFilterStrings(List<Double> probabilities, Map<String, Double> siteFiltersWithErrorProb, double errorThreshold, String filterName) {\n+        List<String> results = probabilities.stream().map(value -> value > errorThreshold ?\n+                        filterName : VCFConstants.PASSES_FILTERS_v4).collect(Collectors.toList());\n+        if (!results.isEmpty() && results.stream().allMatch(x -> x.equals(filterName))) {\n+            // TODO is this the correct default", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMjc1NQ==", "bodyText": "What are these test gvcf comments about?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369912755", "createdAt": "2020-01-23T02:59:53Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -214,15 +277,21 @@ private void buildFiltersList(final M2FiltersArgumentCollection MTFAC) {\n         filters.add(new BaseQualityFilter(MTFAC.minMedianBaseQuality));\n         filters.add(new MappingQualityFilter(MTFAC.minMedianMappingQuality, MTFAC.longIndelLength));\n         filters.add(new DuplicatedAltReadFilter(MTFAC.uniqueAltReadCount));\n-        filters.add(new StrandArtifactFilter());\n+        filters.add(new StrandArtifactFilter());  // test gvcf", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMjg3Ng==", "bodyText": "Address the TODO", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369912876", "createdAt": "2020-01-23T03:00:33Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -234,8 +303,8 @@ private void buildFiltersList(final M2FiltersArgumentCollection MTFAC) {\n         }\n \n         if (MTFAC.mitochondria) {\n-            filters.add(new ChimericOriginalAlignmentFilter(MTFAC.maxNuMTFraction));\n-            filters.add(new PolymorphicNuMTFilter(MTFAC.medianAutosomalCoverage));\n+            filters.add(new ChimericOriginalAlignmentFilter(MTFAC.maxNuMTFraction));  // TODO convert!!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMzE2Mg==", "bodyText": "This can be achieved with Collections.nCopies()", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369913162", "createdAt": "2020-01-23T03:02:09Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2VariantFilter.java", "diffHunk": "@@ -1,56 +1,25 @@\n package org.broadinstitute.hellbender.tools.walkers.mutect.filtering;\n \n import htsjdk.variant.variantcontext.VariantContext;\n-import org.apache.commons.lang3.tuple.ImmutablePair;\n import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.utils.IndexRange;\n \n-import java.util.Comparator;\n+import java.util.ArrayList;\n import java.util.List;\n-import java.util.Optional;\n \n-public abstract class Mutect2VariantFilter {\n+public abstract class Mutect2VariantFilter extends Mutect2Filter {\n     public Mutect2VariantFilter() { }\n \n-    public double errorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n-        final double result = requiredAnnotations().stream().allMatch(vc::hasAttribute) ? calculateErrorProbability(vc, filteringEngine, referenceContext) : 0;\n-        return Mutect2FilteringEngine.roundFinitePrecisionErrors(result);\n-    }\n-\n-    protected abstract double calculateErrorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext);\n+    @Override\n+    public List<Double> errorProbabilities(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        int numAltAlleles = vc.getNAlleles() - 1;\n+        final double result = Mutect2FilteringEngine.roundFinitePrecisionErrors(requiredAnnotations().stream().allMatch(vc::hasAttribute) ?\n+                calculateErrorProbability(vc, filteringEngine, referenceContext) : 0.0);\n+        ArrayList<Double> resultList = new ArrayList<>(numAltAlleles);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxMzcxMw==", "bodyText": "Is .map(   ).reduce(0, Math::addExact) equivalent to .mapToInt(  ).sum()?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369913713", "createdAt": "2020-01-23T03:05:05Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/StrandArtifactFilter.java", "diffHunk": "@@ -43,30 +44,40 @@\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n     @Override\n-    public double calculateErrorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n-        final EStep probabilities = calculateArtifactProbabilities(vc, filteringEngine);\n-        return probabilities.forwardArtifactResponsibility + probabilities.reverseArtifactResponsibility;\n+    public List<Double> calculateErrorProbabilityForAlleles(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        final List<EStep> alleleProbs = calculateArtifactProbabilities(vc, filteringEngine);\n+        return alleleProbs.isEmpty() ? Collections.emptyList() :\n+                alleleProbs.stream().map(probabilities -> probabilities.forwardArtifactResponsibility + probabilities.reverseArtifactResponsibility).collect(Collectors.toList());\n     }\n \n-    public EStep calculateArtifactProbabilities(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n-        // {fwd ref, rev ref, fwd alt, rev alt}\n-        final int[] counts = filteringEngine.sumStrandCountsOverSamples(vc, true, false);\n-\n-        final int indelSize = Math.abs(vc.getReference().length() - vc.getAlternateAllele(0).length());\n-        if (counts[2] + counts[3] == 0 || indelSize > LONGEST_STRAND_ARTIFACT_INDEL_SIZE) {\n-            return new EStep(0, 0, counts[0] + counts[2], counts[1] + counts[3], counts[2], counts[3]);\n+    public List<EStep> calculateArtifactProbabilities(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n+        // for each allele, forward and reverse count\n+        List<List<Integer>> sbs = StrandBiasUtils.getSBsForAlleles(vc);\n+        if (sbs == null || sbs.isEmpty() || sbs.size() <= 1) {\n+            return Collections.emptyList();\n         }\n \n-\n-        return strandArtifactProbability(strandArtifactPrior, counts[0] + counts[2], counts[1] + counts[3], counts[2], counts[3], indelSize);\n-\n+        final ListIterator<Integer> indelSizeIterator = vc.getAlternateAlleles().stream().map(alt -> Math.abs(vc.getReference().length() - alt.length())).collect(Collectors.toList()).listIterator();\n+        int totalFwd = sbs.stream().map(sb -> sb.get(0)).reduce(0, Math::addExact);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNDI0NA==", "bodyText": "Incrementing an iterator as a side-effect of a lambda spooks me.  It feels like it's adhering to the letter of the law that requires variables inside a lambda to be final but violating the spirit of functional programming.  I would rather have an indel size list and have an IntStream even at the cost of an extra line altSB = altSBs.get(n).", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369914244", "createdAt": "2020-01-23T03:07:54Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/StrandArtifactFilter.java", "diffHunk": "@@ -43,30 +44,40 @@\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n     @Override\n-    public double calculateErrorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n-        final EStep probabilities = calculateArtifactProbabilities(vc, filteringEngine);\n-        return probabilities.forwardArtifactResponsibility + probabilities.reverseArtifactResponsibility;\n+    public List<Double> calculateErrorProbabilityForAlleles(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        final List<EStep> alleleProbs = calculateArtifactProbabilities(vc, filteringEngine);\n+        return alleleProbs.isEmpty() ? Collections.emptyList() :\n+                alleleProbs.stream().map(probabilities -> probabilities.forwardArtifactResponsibility + probabilities.reverseArtifactResponsibility).collect(Collectors.toList());\n     }\n \n-    public EStep calculateArtifactProbabilities(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n-        // {fwd ref, rev ref, fwd alt, rev alt}\n-        final int[] counts = filteringEngine.sumStrandCountsOverSamples(vc, true, false);\n-\n-        final int indelSize = Math.abs(vc.getReference().length() - vc.getAlternateAllele(0).length());\n-        if (counts[2] + counts[3] == 0 || indelSize > LONGEST_STRAND_ARTIFACT_INDEL_SIZE) {\n-            return new EStep(0, 0, counts[0] + counts[2], counts[1] + counts[3], counts[2], counts[3]);\n+    public List<EStep> calculateArtifactProbabilities(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n+        // for each allele, forward and reverse count\n+        List<List<Integer>> sbs = StrandBiasUtils.getSBsForAlleles(vc);\n+        if (sbs == null || sbs.isEmpty() || sbs.size() <= 1) {\n+            return Collections.emptyList();\n         }\n \n-\n-        return strandArtifactProbability(strandArtifactPrior, counts[0] + counts[2], counts[1] + counts[3], counts[2], counts[3], indelSize);\n-\n+        final ListIterator<Integer> indelSizeIterator = vc.getAlternateAlleles().stream().map(alt -> Math.abs(vc.getReference().length() - alt.length())).collect(Collectors.toList()).listIterator();\n+        int totalFwd = sbs.stream().map(sb -> sb.get(0)).reduce(0, Math::addExact);\n+        int totalRev = sbs.stream().map(sb -> sb.get(1)).reduce(0, Math::addExact);\n+        // skip the reference\n+        List<List<Integer>> altSBs = sbs.subList(1, sbs.size());\n+\n+        return altSBs.stream().map(altSB -> {\n+            final int altIndelSize = indelSizeIterator.next();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNDQzNw==", "bodyText": "Thank you.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369914437", "createdAt": "2020-01-23T03:09:02Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java", "diffHunk": "@@ -20,7 +20,7 @@\n \n     private double threshold;\n \n-    final List<Double> artifactProbabilities = new ArrayList<>();\n+    final List<Double> errorProbabilities = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNDY4Mg==", "bodyText": "Why not\nreturn new IndexRange(0, tumorLods.length).mapToDouble(i -> _____);", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369914682", "createdAt": "2020-01-23T03:10:34Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/TumorEvidenceFilter.java", "diffHunk": "@@ -4,27 +4,30 @@\n import org.broadinstitute.hellbender.engine.ReferenceContext;\n import org.broadinstitute.hellbender.tools.walkers.mutect.clustering.Datum;\n import org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel;\n+import org.broadinstitute.hellbender.utils.IndexRange;\n import org.broadinstitute.hellbender.utils.MathUtils;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n \n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Optional;\n+import java.util.*;\n \n-public class TumorEvidenceFilter extends Mutect2VariantFilter {\n+public class TumorEvidenceFilter extends Mutect2AlleleFilter {\n     @Override\n     public ErrorType errorType() { return ErrorType.SEQUENCING; }\n \n     @Override\n-    public double calculateErrorProbability(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+    protected List<Double> calculateErrorProbabilityForAlleles(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext)\n+    {\n         final double[] tumorLods = Mutect2FilteringEngine.getTumorLogOdds(vc);\n         final int[] ADs = filteringEngine.sumADsOverSamples(vc, true, false);\n-        final int maxIndex = MathUtils.maxElementIndex(tumorLods);\n-        final int altCount = ADs[maxIndex + 1];\n         final int totalCount = (int) MathUtils.sum(ADs);\n+        SomaticClusteringModel model = filteringEngine.getSomaticClusteringModel();\n \n-        return filteringEngine.getSomaticClusteringModel()\n-                .probabilityOfSequencingError(new Datum(tumorLods[maxIndex], 0, 0, altCount, totalCount, SomaticClusteringModel.indelLength(vc, maxIndex)));\n+        List<Double> altResults = new ArrayList<>();\n+        // 0 is the correct value. problem with threshold\n+        new IndexRange(0, tumorLods.length).forEach(i ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNDk2Mg==", "bodyText": "I try to keep every M2 filter name at least 8 characters and less than 16.  That way the filtering stats file and, with luck, the VCF, looks better when viewed in a terminal.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369914962", "createdAt": "2020-01-23T03:12:20Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVCFConstants.java", "diffHunk": "@@ -162,7 +162,8 @@ their names (or descriptions) depend on some threshold.  Those filters are not i\n     public final static String N_RATIO_FILTER_NAME =                           \"n_ratio\";\n     public final static String CHIMERIC_ORIGINAL_ALIGNMENT_FILTER_NAME =       \"numt_chimera\"; //mitochondria\n     public final static String ALLELE_FRACTION_FILTER_NAME =                   \"low_allele_frac\";\n-    public static final String POTENTIAL_POLYMORPHIC_NUMT_FILTER_NAME =        \"numt_novel\";\n+    public static final String POSSIBLE_NUMT_FILTER_NAME =                     \"possible_numt\";\n+    public static final String LOW_HET_FILTER_NAME =                            \"low_het\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNTE2Ng==", "bodyText": "What's the status of this comment?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369915166", "createdAt": "2020-01-23T03:13:37Z", "author": {"login": "davidbenjamin"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -532,21 +550,28 @@ public void testFilterMitochondria(File unfiltered, final double minAlleleFracti\n                 args -> args.addBooleanArgument(StandardArgumentDefinitions.DISABLE_SEQUENCE_DICT_VALIDATION_NAME, true),\n                 args -> args.addNumericArgument(M2FiltersArgumentCollection.MIN_AF_LONG_NAME, minAlleleFraction),\n                 args -> args.addNumericArgument(M2FiltersArgumentCollection.MEDIAN_AUTOSOMAL_COVERAGE_LONG_NAME, autosomalCoverage),\n+                args -> args.addNumericArgument(M2FiltersArgumentCollection.MAX_NUMT_COPIES_IN_AUTOSOME_LONG_NAME, 4.0),\n+                args -> args.addNumericArgument(M2FiltersArgumentCollection.MIN_READS_ON_EACH_STRAND_LONG_NAME, 1),\n                 args -> {\n                     intervals.stream().map(SimpleInterval::new).forEach(args::addInterval);\n                     return args;\n                 });\n \n+        // add tests for DUPLICATE", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNTMyNg==", "bodyText": "This file extension should be .vcf, not .txt", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369915326", "createdAt": "2020-01-23T03:14:43Z", "author": {"login": "davidbenjamin"}, "path": "src/test/resources/org/broadinstitute/hellbender/tools/mutect/mito/expected_LowHetNone_output.txt", "diffHunk": "@@ -0,0 +1,69 @@\n+##fileformat=VCFv4.2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNTM1MA==", "bodyText": "Ditto about .vcf", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r369915350", "createdAt": "2020-01-23T03:14:54Z", "author": {"login": "davidbenjamin"}, "path": "src/test/resources/org/broadinstitute/hellbender/tools/mutect/mito/expected_LowHetVariantWalkerIntegrationTest_output.txt", "diffHunk": "@@ -0,0 +1,69 @@\n+##fileformat=VCFv4.2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 1}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/ecdbbe7f71162e09cfdef50a4a42c22463374519", "committedDate": "2020-01-22T20:08:42Z", "message": "Merge branch 'master' into ah_SO166_morefilters"}, "afterCommit": {"oid": "194678599cdb8154383cc63f1fefb7ff2cf7ff13", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/194678599cdb8154383cc63f1fefb7ff2cf7ff13", "committedDate": "2020-01-24T15:12:27Z", "message": "changes after rebase and to test FAIL filter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MzM1NDk5", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-347335499", "createdAt": "2020-01-23T14:26:12Z", "commit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNDoyNjoxMlrOFhAAQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxODoxODozM1rOFkTvGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NzM5NA==", "bodyText": "I'm on the fence about putting this in the allelespecific subpackage.  On the one hand, it is allele-specific, but on the other hand, all those classes have interfaces and/or parent classes that this one doesn't.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r370147394", "createdAt": "2020-01-23T14:26:12Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/AS_StrandBiasMutectAnnotation.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1MzYyMg==", "bodyText": "Well, sometimes likelihoods come from Mutect2, right?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r370153622", "createdAt": "2020-01-23T14:36:37Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/StrandBiasUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+package org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.broadinstitute.hellbender.engine.filters.VariantFilter;\n+import org.broadinstitute.hellbender.tools.walkers.annotator.AnnotationUtils;\n+import org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+public class StrandBiasUtils {\n+    public static final int FORWARD = 0;\n+    public static final int REVERSE = 1;\n+    public static final int MIN_COUNT = 2;\n+    public static final String PRINT_DELIM = \"|\";\n+    private static final List<Integer> ZERO_LIST = new ArrayList<>(Arrays.asList(0,0));\n+\n+    public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {\n+        // calculate the annotation from the likelihoods\n+        // likelihoods can come from HaplotypeCaller call to VariantAnnotatorEngine", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdbbe7f71162e09cfdef50a4a42c22463374519"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzUzOTU4OQ==", "bodyText": "Does it really create a comma separated string?  Also, it looks like the only duplicate filter you're checking for is PASS, so I would call the method \"removeExtraPassFilters\" or something less general than what's there now.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r373539589", "createdAt": "2020-01-31T15:32:30Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2FilteringEngine.java", "diffHunk": "@@ -176,28 +178,105 @@ public VariantContext applyFiltersAndAccumulateOutputStats(final VariantContext\n         final ErrorProbabilities errorProbabilities = new ErrorProbabilities(filters, vc, this, referenceContext);\n         filteringOutputStats.recordCall(errorProbabilities, getThreshold() - EPSILON);\n \n-        final boolean variantFailsFilters = errorProbabilities.getErrorProbability() > Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n-        final double maxErrorProb = errorProbabilities.getProbabilitiesByFilter().values().stream().mapToDouble(p->p).max().orElse(1);\n+        // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n+        // and probabilities close to 0 must not be filtered\n+        double errorThreshold = Math.min(1 - EPSILON, Math.max(EPSILON, getThreshold()));\n+\n+        Map<String, Double> siteFiltersWithErrorProb = new LinkedHashMap<>();\n+\n+        // apply allele specific filters\n+        List<List<String>> alleleStatusByFilter =\n+                errorProbabilities.getProbabilitiesForAlleleFilters().entrySet().stream()\n+                        .filter(entry -> !entry.getValue().isEmpty())\n+                        .map(entry -> addFilterStrings(entry.getValue(), errorThreshold, entry.getKey().filterName())).collect(Collectors.toList());\n+\n+        // for each allele, merge all allele specific filters\n+//      List<Iterator<String>> ASFiltersIterator = ASFilters.stream().map(list -> list.listIterator()).collect(Collectors.toList());\n+        List<List<String>> filtersByAllele = ErrorProbabilities.transpose(alleleStatusByFilter);\n+        List<List<String>> distinctFiltersByAllele = filtersByAllele.stream().map(this::getDistinctFiltersForAllele).collect(Collectors.toList());\n+        ListIterator<String> mergedFilterStringByAllele = distinctFiltersByAllele.stream().map(AnnotationUtils::encodeStringList).collect(Collectors.toList()).listIterator();\n+\n+        List<String> orderedASFilterStrings = vc.getAlleles().stream().map(allele -> allele.isReference() || allele.isSymbolic() ?\n+                VCFConstants.EMPTY_INFO_FIELD : mergedFilterStringByAllele.next()).collect(Collectors.toList());\n+        String finalAttrString = AnnotationUtils.encodeAnyASList(orderedASFilterStrings);\n+\n+        vcb.putAttributes(Collections.singletonMap(GATKVCFConstants.AS_FILTER_STATUS_KEY, finalAttrString));\n \n-        for (final Map.Entry<Mutect2VariantFilter, Double> entry : errorProbabilities.getProbabilitiesByFilter().entrySet()) {\n-            final double errorProbability = entry.getValue();\n \n-            entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n-                if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n-                    vcb.attribute(annotation, QualityUtils.errorProbToQual(errorProbability));\n-                }\n-            });\n+        // compute site-only filters\n+        // from allele specific filters\n+         alleleStatusByFilter.stream().forEachOrdered(alleleStatusForFilter -> {\n+            if (!alleleStatusForFilter.isEmpty() && alleleStatusForFilter.stream().distinct().count() == 1 && !alleleStatusForFilter.contains(VCFConstants.PASSES_FILTERS_v4)) {\n+                siteFiltersWithErrorProb.put(alleleStatusForFilter.get(0), 1.0);\n+            }\n+        });\n \n-            // error probability must exceed threshold, and just in case threshold is bad, probabilities close to 1 must be filtered\n-            // and probabilities close to 0 must not be filtered\n-            if (variantFailsFilters && errorProbability >= Math.min(maxErrorProb, MIN_REPORTABLE_ERROR_PROBABILITY)) {\n-                vcb.filter(entry.getKey().filterName());\n+\n+        // from variant filters\n+        errorProbabilities.getProbabilitiesForVariantFilters().entrySet().stream()\n+                .forEach(entry -> {\n+                    entry.getKey().phredScaledPosteriorAnnotationName().ifPresent(annotation -> {\n+                        if (entry.getKey().requiredAnnotations().stream().allMatch(vc::hasAttribute)) {\n+                            vcb.attribute(annotation, QualityUtils.errorProbToQual(entry.getValue()));\n+                        }\n+                    });\n+                    if (entry.getValue() > errorThreshold) {\n+                        siteFiltersWithErrorProb.put(entry.getKey().filterName(), entry.getValue());\n+                    }\n+\n+                });\n+\n+        // if all alleles have been filtered out, but for different reasons, fail the site.\n+        // if the site is only ref and symbolic, no filters will be applied so don't fail\n+        if (siteFiltersWithErrorProb.isEmpty() && !distinctFiltersByAllele.stream().allMatch(List::isEmpty)) {\n+            // if any allele passed, don't fail the site\n+            if (!distinctFiltersByAllele.stream().flatMap(List::stream).anyMatch(f -> f.equals(VCFConstants.PASSES_FILTERS_v4))) {\n+                // we know the allele level filters exceeded their threshold - so set this prob to 1\n+                siteFiltersWithErrorProb.put(GATKVCFConstants.FAIL, 1.0);\n             }\n         }\n \n+        // this code limits the number of filters specified for any variant to the highest probability filters\n+        // this will not change the status of whether a variant is actually filtered or not\n+        final double maxErrorProb = siteFiltersWithErrorProb.values().stream().mapToDouble(p->p).max().orElse(1);\n+        siteFiltersWithErrorProb.entrySet().stream().forEach(entry -> {\n+            if (entry.getValue() >= Math.min(maxErrorProb, MIN_REPORTABLE_ERROR_PROBABILITY)) {\n+                vcb.filter(entry.getKey());\n+            }\n+        });\n+\n         return vcb.make();\n     }\n \n+    /**\n+     * Creates a comma separated string of all the filters that apply to the allele.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65d5e19b62f1d768ae4139cb2d13e50e97ec3b2b"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU0MjIwNw==", "bodyText": "This does have required annotations, they're just not info annotations.  How important is this check?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r373542207", "createdAt": "2020-01-31T15:37:46Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/NuMTFilter.java", "diffHunk": "@@ -0,0 +1,50 @@\n+package org.broadinstitute.hellbender.tools.walkers.mutect.filtering;\n+\n+import htsjdk.variant.variantcontext.Allele;\n+import htsjdk.variant.variantcontext.Genotype;\n+import htsjdk.variant.variantcontext.VariantContext;\n+import org.apache.commons.math3.distribution.PoissonDistribution;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+\n+public class NuMTFilter extends HardAlleleFilter {\n+    private static final double LOWER_BOUND_PROB = .01;\n+    private final int maxAltDepthCutoff;\n+\n+    public NuMTFilter(final double medianAutosomalCoverage, final double maxNuMTCopies){\n+        if (maxNuMTCopies > 0 && medianAutosomalCoverage > 0) {\n+            final PoissonDistribution autosomalCoverage = new PoissonDistribution(medianAutosomalCoverage * maxNuMTCopies / 2.0);\n+            maxAltDepthCutoff = autosomalCoverage.inverseCumulativeProbability(1 - LOWER_BOUND_PROB);\n+        } else {\n+            maxAltDepthCutoff = 0;\n+        }\n+    }\n+\n+    @Override\n+    public ErrorType errorType() { return ErrorType.NON_SOMATIC; }\n+\n+    public List<Integer> getData(Genotype g) {\n+        return Arrays.stream(g.getAD()).boxed().collect(Collectors.toList());\n+    }\n+\n+    @Override\n+    public List<Boolean> areAllelesArtifacts(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        LinkedHashMap<Allele, List<Integer>> dataByAllele = getDataByAllele(vc, Genotype::hasAD, this::getData, filteringEngine);\n+        return dataByAllele.entrySet().stream()\n+                .filter(entry -> !vc.getReference().equals(entry.getKey()))\n+                .map(entry -> entry.getValue().stream().max(Integer::compare).orElse(0) < maxAltDepthCutoff).collect(Collectors.toList());\n+    }\n+\n+    @Override\n+    public String filterName() {\n+        return GATKVCFConstants.POSSIBLE_NUMT_FILTER_NAME;\n+    }\n+\n+    @Override\n+    protected List<String> requiredAnnotations() { return Collections.emptyList(); }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65d5e19b62f1d768ae4139cb2d13e50e97ec3b2b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU0MzAzMA==", "bodyText": "Thanks for the cleanup!", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r373543030", "createdAt": "2020-01-31T15:39:20Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/StrictStrandBiasFilter.java", "diffHunk": "@@ -20,25 +21,14 @@ public StrictStrandBiasFilter(final int minReadsOnEachStrand) {\n     public ErrorType errorType() { return ErrorType.ARTIFACT; }\n \n     @Override\n-    public boolean isArtifact(final VariantContext vc, final Mutect2FilteringEngine filteringEngine) {\n-        if (minReadsOnEachStrand == 0) {\n-            return false;\n+    public List<Boolean> areAllelesArtifacts(final VariantContext vc, final Mutect2FilteringEngine filteringEngine, ReferenceContext referenceContext) {\n+        List<List<Integer>> sbs = StrandBiasUtils.getSBsForAlleles(vc);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65d5e19b62f1d768ae4139cb2d13e50e97ec3b2b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxNjQwOA==", "bodyText": "I would really much rather have these tests read in the VCs and then check the filters (and check the relevant FILTER line in the header) rather than doing an exact match, because annoying things happen like someone changes the VCF header description of something unrelated and now these tests fail.  If that's going to be a huge pain, then we can live with this.  They're very thorough, I just want to save someone a little potential pain the future.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r373616408", "createdAt": "2020-01-31T18:18:33Z", "author": {"login": "ldgauthier"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/MTLowHeteroplasmyFilterToolTest.java", "diffHunk": "@@ -0,0 +1,35 @@\n+package org.broadinstitute.hellbender.tools.walkers.mutect.filtering;\n+\n+import org.broadinstitute.hellbender.CommandLineProgramTest;\n+import org.broadinstitute.hellbender.testutils.IntegrationTestSpec;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+public class MTLowHeteroplasmyFilterToolTest extends CommandLineProgramTest {\n+    private static final File MITO_REF = new File(toolsTestDir, \"mutect/mito/Homo_sapiens_assembly38.mt_only.fasta\");\n+    private static final File NA12878_MITO_FILTERED_VCF = new File(toolsTestDir, \"mutect/mito/filtered.vcf\");\n+\n+    @Test\n+    public void testLowHetVariantWalker() throws IOException {\n+        final IntegrationTestSpec testSpec = new IntegrationTestSpec(\n+                        \" -R \" + MITO_REF.getAbsolutePath()  +\n+                        \" -V \" + NA12878_MITO_FILTERED_VCF +\n+                        \" -O %s\",\n+                Arrays.asList(toolsTestDir + \"mutect/mito/expected_LowHetVariantWalkerIntegrationTest_output.vcf\")\n+        );\n+        testSpec.executeTest(\"testLowHetVariantWalker\", this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65d5e19b62f1d768ae4139cb2d13e50e97ec3b2b"}, "originalPosition": 23}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3f2937ed806b8d4aa00cfe95e6377bf6933ea320", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/3f2937ed806b8d4aa00cfe95e6377bf6933ea320", "committedDate": "2020-02-18T21:19:35Z", "message": "add final tests"}, "afterCommit": {"oid": "f07b8091378afc3e0a260f70c478dfb0c73bdd0e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/f07b8091378afc3e0a260f70c478dfb0c73bdd0e", "committedDate": "2020-02-19T22:36:50Z", "message": "add final tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d04a16c2643a27f3a5dc5844fcb73b4a4b166cf4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d04a16c2643a27f3a5dc5844fcb73b4a4b166cf4", "committedDate": "2020-02-21T21:56:59Z", "message": "needed to update another test file"}, "afterCommit": {"oid": "d1039b477108e3c118afb27199e86812c4a7cf14", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d1039b477108e3c118afb27199e86812c4a7cf14", "committedDate": "2020-03-04T14:52:43Z", "message": "needed to update another test file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3e1539dee756750bf9bca7937a375b20d616dd12", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/3e1539dee756750bf9bca7937a375b20d616dd12", "committedDate": "2020-03-05T17:54:14Z", "message": "change count type for RPA"}, "afterCommit": {"oid": "d3aacd3d17c940fdec24648baf70fd3da58a9fe8", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d3aacd3d17c940fdec24648baf70fd3da58a9fe8", "committedDate": "2020-03-05T17:54:47Z", "message": "change count type for RPA"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dd9130f925fe6068a4f764a50b52ac3824cacccb", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/dd9130f925fe6068a4f764a50b52ac3824cacccb", "committedDate": "2020-03-23T16:38:44Z", "message": "final mods"}, "afterCommit": {"oid": "10a7c3d176040c0229e51a583f6b682d33eb45fa", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/10a7c3d176040c0229e51a583f6b682d33eb45fa", "committedDate": "2020-03-23T16:47:18Z", "message": "final mods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9133abae6e5afd5bd0a5dfcddd0532aed682fc9", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/f9133abae6e5afd5bd0a5dfcddd0532aed682fc9", "committedDate": "2020-03-25T19:18:25Z", "message": "initial impl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49875a679a2fd98af6d7e4dd28a657cbf75e8458", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/49875a679a2fd98af6d7e4dd28a657cbf75e8458", "committedDate": "2020-03-25T19:18:25Z", "message": "start impl\n\nnew refactor adding allele specific filters in mutect2\n\nfix headers\n\nAS filter status working - still need to fix site filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e94059e295619ad79ed214a09f527496cd68d3d9", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/e94059e295619ad79ed214a09f527496cd68d3d9", "committedDate": "2020-03-25T19:18:25Z", "message": "wip"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22345ad2607e53015a919e88a418375ba9477f17", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/22345ad2607e53015a919e88a418375ba9477f17", "committedDate": "2020-03-25T19:18:25Z", "message": "converted base qual and tumor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32d4ed25a7dc10690da23694125a90bd41381ef9", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/32d4ed25a7dc10690da23694125a90bd41381ef9", "committedDate": "2020-03-25T19:18:25Z", "message": "converted mapping qual filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d64edf75c0c927227b345e0f6eeaa78f0cc845d", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/1d64edf75c0c927227b345e0f6eeaa78f0cc845d", "committedDate": "2020-03-25T19:18:25Z", "message": "updated duplicate alt read filter - but need to add tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b85de2140cc2d4ea9731e84d5781138a99510be", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/8b85de2140cc2d4ea9731e84d5781138a99510be", "committedDate": "2020-03-25T19:18:25Z", "message": "undo bad delim change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27b49be53a6cf5c40e11d999498a6aa1d14899fb", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/27b49be53a6cf5c40e11d999498a6aa1d14899fb", "committedDate": "2020-03-25T19:18:25Z", "message": "update min allele fraction filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1568a0e5ba355631ee213d2467754c50aa5a257e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/1568a0e5ba355631ee213d2467754c50aa5a257e", "committedDate": "2020-03-25T19:18:25Z", "message": "update read pos filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b045c0a5f5eec8b98360e3461bcf5b2d82d701f", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/2b045c0a5f5eec8b98360e3461bcf5b2d82d701f", "committedDate": "2020-03-25T19:18:25Z", "message": "2 different get data methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "409aff292a2daf802920089d4d5559f0da8ee637", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/409aff292a2daf802920089d4d5559f0da8ee637", "committedDate": "2020-03-25T19:18:25Z", "message": "use correct filter list"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e54983c21a9c950cc0adacbc36d130ecacf087b7", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/e54983c21a9c950cc0adacbc36d130ecacf087b7", "committedDate": "2020-03-25T19:18:25Z", "message": "fix issues with filters containing data for ref"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f7891786067a0deb47d882bd6c7cce1991ab964", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/9f7891786067a0deb47d882bd6c7cce1991ab964", "committedDate": "2020-03-25T19:18:25Z", "message": "wip, doens't pass tests, fixing error prob for threshold"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e0e7d4cfcbd97d4e5095140ef84d99f8a536370", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/8e0e7d4cfcbd97d4e5095140ef84d99f8a536370", "committedDate": "2020-03-25T19:18:25Z", "message": "implement 2 pass variant walker as post processing filter step for low heteroplasmy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "660c4f9e0c3b174add645baade6d89f49214d9f1", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/660c4f9e0c3b174add645baade6d89f49214d9f1", "committedDate": "2020-03-25T19:18:25Z", "message": "wip - got error prob to compile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb2a590720f9ab088adac321ac3d7d43f83c7491", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/eb2a590720f9ab088adac321ac3d7d43f83c7491", "committedDate": "2020-03-25T19:18:25Z", "message": "wip - fixed almost all compile errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9938a541588cb95d217369d4d34979690d4c5f72", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/9938a541588cb95d217369d4d34979690d4c5f72", "committedDate": "2020-03-25T19:18:25Z", "message": "wip almost done - one more q for DB"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63c414706263af4740369dac14af815499f571bd", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/63c414706263af4740369dac14af815499f571bd", "committedDate": "2020-03-25T19:18:25Z", "message": "fixed some bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e93445385c29693b8440aa536c2dfbbd171d99ad", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/e93445385c29693b8440aa536c2dfbbd171d99ad", "committedDate": "2020-03-25T19:18:25Z", "message": "mito filter tests pass"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d756078beb068bfbae3b580b85892a15ad377ff", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/5d756078beb068bfbae3b580b85892a15ad377ff", "committedDate": "2020-03-25T19:18:25Z", "message": "add AS_SB_Table as mutect2 annotation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e3595220073cb91bc8397027b6c3643793c7807", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/1e3595220073cb91bc8397027b6c3643793c7807", "committedDate": "2020-03-25T19:18:25Z", "message": "made strict strand bias allele specific"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f347db5796c589d4e7d834fe2c1401f794016555", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/f347db5796c589d4e7d834fe2c1401f794016555", "committedDate": "2020-03-25T19:18:25Z", "message": "add test data for AS_SB_TABLE in vcf. format not compatible with annotation in gvcf"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c7efe6e8b59b998582c7a5fbb11c55fe0d7cb920", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/c7efe6e8b59b998582c7a5fbb11c55fe0d7cb920", "committedDate": "2020-03-25T19:18:25Z", "message": "convert stand artifact - bug with prior list"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4344277d6ec1a6e2a5e87b226ee976397d88da21", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/4344277d6ec1a6e2a5e87b226ee976397d88da21", "committedDate": "2020-03-25T19:18:25Z", "message": "fixed strand artifact - fix and verify tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f11171f505dd5052ed3e91cd029f2791a8835ef4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/f11171f505dd5052ed3e91cd029f2791a8835ef4", "committedDate": "2020-03-25T19:18:26Z", "message": "fix bug in strand artifact. still need tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72d87ab804cbb2242bec1b6116b3751630ae0d77", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/72d87ab804cbb2242bec1b6116b3751630ae0d77", "committedDate": "2020-03-25T19:18:26Z", "message": "strand artifact - use total from all alleles"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bf1ecfbd4148c22837d28e968cffad1e9d98583", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/6bf1ecfbd4148c22837d28e968cffad1e9d98583", "committedDate": "2020-03-25T19:18:26Z", "message": "put AS_SB_TABLE back into gvcf format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "781064acd987da270153f9ad205ad087e408821c", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/781064acd987da270153f9ad205ad087e408821c", "committedDate": "2020-03-25T19:18:26Z", "message": "fix bug in strict strand filter that was ignoring the minReadsOnEachStrand parameter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f19cc3f3db70e39b3455a0df1cc42393aa243fc", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/6f19cc3f3db70e39b3455a0df1cc42393aa243fc", "committedDate": "2020-03-25T19:18:26Z", "message": "minor changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9318c08fc0acc63ff8774dac65f30e2bb0e4952", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d9318c08fc0acc63ff8774dac65f30e2bb0e4952", "committedDate": "2020-03-25T19:18:26Z", "message": "remove generic from Mutect2AlleleFilter and make generic methods static. convert chimera filter to allele specific"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec8f63cc274899e5d1322000dfd19cbb4ecf6109", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/ec8f63cc274899e5d1322000dfd19cbb4ecf6109", "committedDate": "2020-03-25T19:18:26Z", "message": "minor changes and comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5e207a8a30fd7f78c31c3e06be9a9c4a6f01729", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/b5e207a8a30fd7f78c31c3e06be9a9c4a6f01729", "committedDate": "2020-03-25T19:18:26Z", "message": "update from PR feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03754fc224e39cbfa91afd37e7bf3c3209703a64", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/03754fc224e39cbfa91afd37e7bf3c3209703a64", "committedDate": "2020-03-25T19:18:26Z", "message": "changes after rebase and to test FAIL filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98a9dc86e3686a3f000f62dc5d51eb5f8f54e13e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/98a9dc86e3686a3f000f62dc5d51eb5f8f54e13e", "committedDate": "2020-03-25T19:18:26Z", "message": "fix issue with null value for SB annotation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8bdeeeabcdea650ab7c1b8d894129282456c464", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/c8bdeeeabcdea650ab7c1b8d894129282456c464", "committedDate": "2020-03-25T19:18:26Z", "message": "fix output files for test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb956fbb0fa11725c7604f9d04286697c6557fc5", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/fb956fbb0fa11725c7604f9d04286697c6557fc5", "committedDate": "2020-03-25T19:18:26Z", "message": "remove warnings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5de3575669fbc1719a38d5b14d6200a9250bbb34", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/5de3575669fbc1719a38d5b14d6200a9250bbb34", "committedDate": "2020-03-25T19:18:26Z", "message": "update splitting alleles to include analyzing AS_FilterStatus and setting the correct filter fields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cb9b5c09307e5783d18ff713148e7bf662672a4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/2cb9b5c09307e5783d18ff713148e7bf662672a4", "committedDate": "2020-03-25T19:18:26Z", "message": "fix extra spaces in filter list"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53d31a05ae43f99ecdbf39b43fee82132f7f79c9", "author": {"user": {"login": "ldgauthier", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/53d31a05ae43f99ecdbf39b43fee82132f7f79c9", "committedDate": "2020-03-25T19:18:26Z", "message": "Fixed AF and SB splitting; also some javadoc I should have done in the\npast and some refactoring I should have done in the past"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9446699d1197564c4205e6f42f54d8895118198e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/9446699d1197564c4205e6f42f54d8895118198e", "committedDate": "2020-03-25T19:18:26Z", "message": "fix warning, fixes from PR feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6f90067ef110a057978bdee619b5bcfa7eca379", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d6f90067ef110a057978bdee619b5bcfa7eca379", "committedDate": "2020-03-25T19:18:26Z", "message": "fix another generics issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ffecce735fd7bf927a256bb363c2f7d5e15202c7", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/ffecce735fd7bf927a256bb363c2f7d5e15202c7", "committedDate": "2020-03-25T19:18:26Z", "message": "make unique alt read count allele specific"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fc762bdc4d473e1211e5f4848dfd24d15776d6b", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/4fc762bdc4d473e1211e5f4848dfd24d15776d6b", "committedDate": "2020-03-25T19:18:26Z", "message": "fix genotypes not included in vcf"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0deea4c4bdda3faeadc2c474eea9b3a7d5c69910", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/0deea4c4bdda3faeadc2c474eea9b3a7d5c69910", "committedDate": "2020-03-25T19:18:26Z", "message": "better test for low het filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03aefbfff5251a5b00d5b09215f5a558b042785a", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/03aefbfff5251a5b00d5b09215f5a558b042785a", "committedDate": "2020-03-25T19:18:26Z", "message": "changed getRequiredAnnotations to getRequiredInfoAnnotations to be more explicit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "851a90c3a7a4ce769feebee42adf9197c38958cc", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/851a90c3a7a4ce769feebee42adf9197c38958cc", "committedDate": "2020-03-25T19:18:26Z", "message": "fix low het filter to ignore ref AF"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e59a3fe972d01c837c9788c95ad3b0c8320eed9", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/9e59a3fe972d01c837c9788c95ad3b0c8320eed9", "committedDate": "2020-03-25T19:18:26Z", "message": "remove . in AS_FilterStatus for ref, and change PASS to ."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5459d4f8d2236245e627ddd4bd897c40254467be", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/5459d4f8d2236245e627ddd4bd897c40254467be", "committedDate": "2020-03-25T19:18:26Z", "message": "fix bug in removing symbolic data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30b59dcc25b202e6ab4b1a352d0994ac9058ac36", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/30b59dcc25b202e6ab4b1a352d0994ac9058ac36", "committedDate": "2020-03-25T19:18:26Z", "message": "add test for uniq alt read count"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e702456f0b219c2ab8c551172177cc91813907f7", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/e702456f0b219c2ab8c551172177cc91813907f7", "committedDate": "2020-03-25T19:18:26Z", "message": "add final tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff2051ece7f3e4998672625a933f8bc030ae9b91", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/ff2051ece7f3e4998672625a933f8bc030ae9b91", "committedDate": "2020-03-25T19:18:26Z", "message": "fix error in LeftAlignAndTrim after rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc585dab814eb16b42568299e6607f8c4c174277", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/fc585dab814eb16b42568299e6607f8c4c174277", "committedDate": "2020-03-25T19:18:26Z", "message": "fix as splitting in left align and trim..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "343cd5f3929de9dbcf44c4cee531ae94cdc85ba2", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/343cd5f3929de9dbcf44c4cee531ae94cdc85ba2", "committedDate": "2020-03-25T19:18:26Z", "message": "updated test for split multi allelics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4697b02c148ff79da35fbbfb5b5ba9761c7317ab", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/4697b02c148ff79da35fbbfb5b5ba9761c7317ab", "committedDate": "2020-03-25T19:18:26Z", "message": "needed to update another test file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94fa473fb9fb7aecf7e59a649dfc8e7f09d9b8dc", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/94fa473fb9fb7aecf7e59a649dfc8e7f09d9b8dc", "committedDate": "2020-03-25T19:18:26Z", "message": "fix split multiallelics to work for all info fields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8091e0d013d6c3b5c78bd47d8736d8168a17d326", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/8091e0d013d6c3b5c78bd47d8736d8168a17d326", "committedDate": "2020-03-25T19:18:26Z", "message": "change count type for RPA"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30396adf4fa7175d5a5681ac49edfc7723a32fe3", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/30396adf4fa7175d5a5681ac49edfc7723a32fe3", "committedDate": "2020-03-25T19:18:26Z", "message": "make NuMTFilter its own tool. update constants for MT low het tool"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3ed2d3df39a0ea4c962f6b454a5eda6b1997c97", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/a3ed2d3df39a0ea4c962f6b454a5eda6b1997c97", "committedDate": "2020-03-25T19:18:26Z", "message": "change info field count type back to 1, since format is non-standard"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39d04a7ee10206d713963b09933a3d13237e575e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/39d04a7ee10206d713963b09933a3d13237e575e", "committedDate": "2020-03-25T19:18:26Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8205932da124b265baea203848e53ba8b78565d5", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/8205932da124b265baea203848e53ba8b78565d5", "committedDate": "2020-03-25T19:18:26Z", "message": "change allele specific filter status of . to SITE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54bd5db4e986a07e3e292ec2a8458d033daab1f8", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/54bd5db4e986a07e3e292ec2a8458d033daab1f8", "committedDate": "2020-03-25T19:18:26Z", "message": "more output for failing test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b496b85b59e14ba98a6736509e7d996e4a1d739", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/6b496b85b59e14ba98a6736509e7d996e4a1d739", "committedDate": "2020-03-25T19:18:26Z", "message": "make MT filter low het tool allele specific"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "711ae07099bbaa422c0cbc9a2b3f838ba43dfcc4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/711ae07099bbaa422c0cbc9a2b3f838ba43dfcc4", "committedDate": "2020-03-25T19:18:26Z", "message": "update the passing indicator to SITE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2068a7832f734b37011770590b05f10cad52cd92", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/2068a7832f734b37011770590b05f10cad52cd92", "committedDate": "2020-03-25T19:18:26Z", "message": "use already computed AF instead of recomputing in MT Low het tool"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ae2795ab7124373023bf3a3391062f03831c7f3", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/3ae2795ab7124373023bf3a3391062f03831c7f3", "committedDate": "2020-03-25T19:18:26Z", "message": "get tests working"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9ab22c164e3231fc73704b933726833c93d08c4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/a9ab22c164e3231fc73704b933726833c93d08c4", "committedDate": "2020-03-25T19:18:26Z", "message": "final mods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3076777e9e365eb3ad65026f217d569ac8647ab4", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/3076777e9e365eb3ad65026f217d569ac8647ab4", "committedDate": "2020-03-25T19:18:26Z", "message": "minor change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10a4ba7ead50036126e9a0b9bf75555ff09ac0a1", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/10a4ba7ead50036126e9a0b9bf75555ff09ac0a1", "committedDate": "2020-03-25T19:18:26Z", "message": "fix expected files"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "478fe6539ff5b7e8fadf08aaf8e5a137e021e429", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/478fe6539ff5b7e8fadf08aaf8e5a137e021e429", "committedDate": "2020-03-24T14:09:52Z", "message": "fix expected files"}, "afterCommit": {"oid": "10a4ba7ead50036126e9a0b9bf75555ff09ac0a1", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/10a4ba7ead50036126e9a0b9bf75555ff09ac0a1", "committedDate": "2020-03-25T19:18:26Z", "message": "fix expected files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/74fff72231f9e1094cd79010e9547da85d1db76e", "committedDate": "2020-03-25T19:47:46Z", "message": "update to lastest wdl"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNDk0OTU2", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-381494956", "createdAt": "2020-03-25T20:05:55Z", "commit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMDowNTo1NVrOF7sP_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMDozNDoyM1rOF7tOZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODEzNTI5NA==", "bodyText": "I think for the tests to work this needs to be the file name \"AlignmentPipeline.wdl\". If there's a better solution for moving things back and forth between Terra and the gatk repo though I'm all for it.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r398135294", "createdAt": "2020-03-25T20:05:55Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -1,6 +1,6 @@\n version 1.0\n \n-import \"AlignmentPipeline.wdl\" as AlignAndMarkDuplicates\n+import \"https://api.firecloud.org/ga4gh/v1/tools/mitochondria:AlignmentPipeline/versions/1/plain-WDL/descriptor\" as AlignAndMarkDuplicates", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE0MjExMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  # runtime\n          \n          \n            \n                # runtime", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r398142113", "createdAt": "2020-03-25T20:18:18Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -169,93 +202,101 @@ workflow AlignAndCall {\n       gatk_override = gatk_override,\n       m2_extra_filtering_args = m2_filter_extra_args,\n       max_alt_allele_count = 4,\n-      contamination = GetContamination.minor_level,\n-      autosomal_coverage = autosomal_coverage,\n       vaf_filter_threshold = vaf_filter_threshold,\n       blacklisted_sites = blacklisted_sites,\n       blacklisted_sites_index = blacklisted_sites_index,\n       f_score_beta = f_score_beta,\n       preemptible_tries = preemptible_tries\n+ }\n+\n+  if ( defined(autosomal_coverage) ) {\n+    call FilterNuMTs {\n+      input:\n+        filtered_vcf = FilterContamination.filtered_vcf,\n+        ref_fasta = mt_fasta,\n+        ref_fai = mt_fasta_index,\n+        ref_dict = mt_dict,\n+        autosomal_coverage = autosomal_coverage,\n+        gatk_override = gatk_override,\n+        compress = compress_output_vcf,\n+        preemptible_tries = preemptible_tries\n+    }\n   }\n \n+  File low_het_vcf = select_first([FilterNuMTs.numt_filtered_vcf, FilterContamination.filtered_vcf])\n+\n+  call FilterLowHetSites {\n+    input:\n+      filtered_vcf = low_het_vcf,\n+      ref_fasta = mt_fasta,\n+      ref_fai = mt_fasta_index,\n+      ref_dict = mt_dict,\n+      max_low_het_sites = max_low_het_sites,\n+      gatk_override = gatk_override,\n+      compress = compress_output_vcf,\n+      preemptible_tries = preemptible_tries\n+  }\n+\n+\n   output {\n     File mt_aligned_bam = AlignToMt.mt_aligned_bam\n     File mt_aligned_bai = AlignToMt.mt_aligned_bai\n     File mt_aligned_shifted_bam = AlignToShiftedMt.mt_aligned_bam\n     File mt_aligned_shifted_bai = AlignToShiftedMt.mt_aligned_bai\n-    File out_vcf = Filter.filtered_vcf\n-    File out_vcf_index = Filter.filtered_vcf_idx\n+    File out_vcf = FilterLowHetSites.final_filtered_vcf\n+    File out_vcf_index = FilterLowHetSites.final_filtered_vcf_idx\n+    File input_vcf_for_haplochecker = SplitMultiAllelicsAndRemoveNonPassSites.vcf_for_haplochecker\n     File duplicate_metrics = AlignToMt.duplicate_metrics\n     File coverage_metrics = CollectWgsMetrics.metrics\n     File theoretical_sensitivity_metrics = CollectWgsMetrics.theoretical_sensitivity\n     File contamination_metrics = GetContamination.contamination_file\n     Int mean_coverage = CollectWgsMetrics.mean_coverage\n     String major_haplogroup = GetContamination.major_hg\n-    Float contamination = GetContamination.minor_level\n+    Float contamination = FilterContamination.contamination\n   }\n }\n \n+\n task GetContamination {\n   input {\n-    File input_bam\n-    File input_bam_index\n-    File ref_fasta\n-    File ref_fasta_index\n-    Int qual = 20\n-    Int map_qual = 30\n-    Float vaf = 0.01\n+    File input_vcf\n+      # runtime", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE0MjMyNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Int? preemptible_tries}\n          \n          \n            \n                Int? preemptible_tries\n          \n          \n            \n              }", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r398142325", "createdAt": "2020-03-25T20:18:41Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -169,93 +202,101 @@ workflow AlignAndCall {\n       gatk_override = gatk_override,\n       m2_extra_filtering_args = m2_filter_extra_args,\n       max_alt_allele_count = 4,\n-      contamination = GetContamination.minor_level,\n-      autosomal_coverage = autosomal_coverage,\n       vaf_filter_threshold = vaf_filter_threshold,\n       blacklisted_sites = blacklisted_sites,\n       blacklisted_sites_index = blacklisted_sites_index,\n       f_score_beta = f_score_beta,\n       preemptible_tries = preemptible_tries\n+ }\n+\n+  if ( defined(autosomal_coverage) ) {\n+    call FilterNuMTs {\n+      input:\n+        filtered_vcf = FilterContamination.filtered_vcf,\n+        ref_fasta = mt_fasta,\n+        ref_fai = mt_fasta_index,\n+        ref_dict = mt_dict,\n+        autosomal_coverage = autosomal_coverage,\n+        gatk_override = gatk_override,\n+        compress = compress_output_vcf,\n+        preemptible_tries = preemptible_tries\n+    }\n   }\n \n+  File low_het_vcf = select_first([FilterNuMTs.numt_filtered_vcf, FilterContamination.filtered_vcf])\n+\n+  call FilterLowHetSites {\n+    input:\n+      filtered_vcf = low_het_vcf,\n+      ref_fasta = mt_fasta,\n+      ref_fai = mt_fasta_index,\n+      ref_dict = mt_dict,\n+      max_low_het_sites = max_low_het_sites,\n+      gatk_override = gatk_override,\n+      compress = compress_output_vcf,\n+      preemptible_tries = preemptible_tries\n+  }\n+\n+\n   output {\n     File mt_aligned_bam = AlignToMt.mt_aligned_bam\n     File mt_aligned_bai = AlignToMt.mt_aligned_bai\n     File mt_aligned_shifted_bam = AlignToShiftedMt.mt_aligned_bam\n     File mt_aligned_shifted_bai = AlignToShiftedMt.mt_aligned_bai\n-    File out_vcf = Filter.filtered_vcf\n-    File out_vcf_index = Filter.filtered_vcf_idx\n+    File out_vcf = FilterLowHetSites.final_filtered_vcf\n+    File out_vcf_index = FilterLowHetSites.final_filtered_vcf_idx\n+    File input_vcf_for_haplochecker = SplitMultiAllelicsAndRemoveNonPassSites.vcf_for_haplochecker\n     File duplicate_metrics = AlignToMt.duplicate_metrics\n     File coverage_metrics = CollectWgsMetrics.metrics\n     File theoretical_sensitivity_metrics = CollectWgsMetrics.theoretical_sensitivity\n     File contamination_metrics = GetContamination.contamination_file\n     Int mean_coverage = CollectWgsMetrics.mean_coverage\n     String major_haplogroup = GetContamination.major_hg\n-    Float contamination = GetContamination.minor_level\n+    Float contamination = FilterContamination.contamination\n   }\n }\n \n+\n task GetContamination {\n   input {\n-    File input_bam\n-    File input_bam_index\n-    File ref_fasta\n-    File ref_fasta_index\n-    Int qual = 20\n-    Int map_qual = 30\n-    Float vaf = 0.01\n+    File input_vcf\n+      # runtime\n+    Int? preemptible_tries}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE0NDAyNg==", "bodyText": "Do you think it's worth adding any sanity checks here to make sure this doesn't break in the future since it's relying on column order to extract the values?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r398144026", "createdAt": "2020-03-25T20:21:46Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -169,93 +202,101 @@ workflow AlignAndCall {\n       gatk_override = gatk_override,\n       m2_extra_filtering_args = m2_filter_extra_args,\n       max_alt_allele_count = 4,\n-      contamination = GetContamination.minor_level,\n-      autosomal_coverage = autosomal_coverage,\n       vaf_filter_threshold = vaf_filter_threshold,\n       blacklisted_sites = blacklisted_sites,\n       blacklisted_sites_index = blacklisted_sites_index,\n       f_score_beta = f_score_beta,\n       preemptible_tries = preemptible_tries\n+ }\n+\n+  if ( defined(autosomal_coverage) ) {\n+    call FilterNuMTs {\n+      input:\n+        filtered_vcf = FilterContamination.filtered_vcf,\n+        ref_fasta = mt_fasta,\n+        ref_fai = mt_fasta_index,\n+        ref_dict = mt_dict,\n+        autosomal_coverage = autosomal_coverage,\n+        gatk_override = gatk_override,\n+        compress = compress_output_vcf,\n+        preemptible_tries = preemptible_tries\n+    }\n   }\n \n+  File low_het_vcf = select_first([FilterNuMTs.numt_filtered_vcf, FilterContamination.filtered_vcf])\n+\n+  call FilterLowHetSites {\n+    input:\n+      filtered_vcf = low_het_vcf,\n+      ref_fasta = mt_fasta,\n+      ref_fai = mt_fasta_index,\n+      ref_dict = mt_dict,\n+      max_low_het_sites = max_low_het_sites,\n+      gatk_override = gatk_override,\n+      compress = compress_output_vcf,\n+      preemptible_tries = preemptible_tries\n+  }\n+\n+\n   output {\n     File mt_aligned_bam = AlignToMt.mt_aligned_bam\n     File mt_aligned_bai = AlignToMt.mt_aligned_bai\n     File mt_aligned_shifted_bam = AlignToShiftedMt.mt_aligned_bam\n     File mt_aligned_shifted_bai = AlignToShiftedMt.mt_aligned_bai\n-    File out_vcf = Filter.filtered_vcf\n-    File out_vcf_index = Filter.filtered_vcf_idx\n+    File out_vcf = FilterLowHetSites.final_filtered_vcf\n+    File out_vcf_index = FilterLowHetSites.final_filtered_vcf_idx\n+    File input_vcf_for_haplochecker = SplitMultiAllelicsAndRemoveNonPassSites.vcf_for_haplochecker\n     File duplicate_metrics = AlignToMt.duplicate_metrics\n     File coverage_metrics = CollectWgsMetrics.metrics\n     File theoretical_sensitivity_metrics = CollectWgsMetrics.theoretical_sensitivity\n     File contamination_metrics = GetContamination.contamination_file\n     Int mean_coverage = CollectWgsMetrics.mean_coverage\n     String major_haplogroup = GetContamination.major_hg\n-    Float contamination = GetContamination.minor_level\n+    Float contamination = FilterContamination.contamination\n   }\n }\n \n+\n task GetContamination {\n   input {\n-    File input_bam\n-    File input_bam_index\n-    File ref_fasta\n-    File ref_fasta_index\n-    Int qual = 20\n-    Int map_qual = 30\n-    Float vaf = 0.01\n+    File input_vcf\n+      # runtime\n+    Int? preemptible_tries}\n \n-    # runtime\n-    Int? preemptible_tries\n-  }\n-\n-  String basename = basename(input_bam, \".bam\")\n-  Float ref_size = size(ref_fasta, \"GB\") + size(ref_fasta_index, \"GB\")\n-  Int disk_size = ceil(size(input_bam, \"GB\") + ref_size) + 20\n+  Int disk_size = ceil(size(input_vcf, \"GB\")) + 20\n \n   meta {\n-    description: \"Uses Haplochecker to estimate levels of contamination in mitochondria\"\n+    description: \"Uses new Haplochecker to estimate levels of contamination in mitochondria\"\n   }\n   parameter_meta {\n-    input_bam: \"Bam aligned to chrM\"\n-    ref_fasta: \"chrM reference\"\n+    input_vcf: \"Filtered and split multi-allelic sites VCF for mitochondria\"\n   }\n-  command {\n+  command <<<\n   set -e\n-\n-  java -jar /usr/mtdnaserver/mitolib.jar haplochecker \\\n-    --in ~{input_bam} \\\n-    --ref ~{ref_fasta} \\\n-    --out haplochecker_out \\\n-    --QUAL ~{qual} \\\n-    --MAPQ ~{map_qual} \\\n-    --VAF ~{vaf}\n-\n-python3 <<CODE\n-\n-import csv\n-\n-with open(\"haplochecker_out/~{basename}.contamination.txt\") as output:\n-    reader = csv.DictReader(output, delimiter='\\t')\n-    for row in reader:\n-        print(row[\"MajorHG\"], file=open(\"major_hg.txt\", 'w'))\n-        print(row[\"MajorLevel\"], file=open(\"major_level.txt\", 'w'))\n-        print(row[\"MinorHG\"], file=open(\"minor_hg.txt\", 'w'))\n-        print(row[\"MinorLevel\"], file=open(\"minor_level.txt\", 'w'))\n-CODE\n-  }\n+  PARENT_DIR=\"$(dirname \"~{input_vcf}\")\"\n+  java -jar /usr/mtdnaserver/haplocheckCLI.jar \"${PARENT_DIR}\"\n+\n+  sed 's/\\\"//g' output > output-noquotes\n+  grep -v \"SampleID\" output-noquotes > output-data\n+  awk '{print $2}' output-data > contamination.txt\n+  awk '{print $6}' output-data > major_hg.txt\n+  awk '{print $8}' output-data > minor_hg.txt\n+  awk '{print $14}' output-data > mean_het_major.txt\n+  awk '{print $15}' output-data > mean_het_minor.txt", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE1MTI2OA==", "bodyText": "I'm confused, I thought we got rid of the \"genotyping-mode\" argument in later versions not the other way around. Can you try running this with a gga_vcf just to make sure it doesn't throw a user error? I don't think we're testing this argument in the WDL tests, but you could also add it there (it's left out now because it's an optional parameter).", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r398151268", "createdAt": "2020-03-25T20:34:23Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -417,7 +458,9 @@ task M2 {\n       gatk --java-options \"-Xmx~{command_mem}m\" Mutect2 \\\n         -R ~{ref_fasta} \\\n         -I ~{input_bam} \\\n-        ~{\"--alleles \" + gga_vcf} \\\n+        ~{\"--genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles \" + gga_vcf} \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74fff72231f9e1094cd79010e9547da85d1db76e"}, "originalPosition": 284}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "272f6b892f61456ca8cc83cd51820732eb6c0611", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/272f6b892f61456ca8cc83cd51820732eb6c0611", "committedDate": "2020-03-30T19:16:57Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35ab2849b737c1353a53f1dfb11928359832b8bb", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/35ab2849b737c1353a53f1dfb11928359832b8bb", "committedDate": "2020-03-31T14:45:57Z", "message": "updating wdl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0dfab1da9c821ca70dc6b5c1f17a58d131c234c9", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/0dfab1da9c821ca70dc6b5c1f17a58d131c234c9", "committedDate": "2020-04-01T17:58:47Z", "message": "fix bug that removes existing filters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b8f2118dca98f17e09c856b395b7703b14a9e33", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/9b8f2118dca98f17e09c856b395b7703b14a9e33", "committedDate": "2020-04-01T18:10:23Z", "message": "add one more test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b43c103c4366214fd4c2a2125f985485e75f82d", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/3b43c103c4366214fd4c2a2125f985485e75f82d", "committedDate": "2020-04-01T21:19:30Z", "message": "fix overwrite of filter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8191f3c3f24f6148459295e5597796f26b411f07", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/8191f3c3f24f6148459295e5597796f26b411f07", "committedDate": "2020-04-02T18:14:45Z", "message": "add missing test files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54b7fc11d85d1500317278dcb77e844633a4f65a", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/54b7fc11d85d1500317278dcb77e844633a4f65a", "committedDate": "2020-04-03T16:48:45Z", "message": "should fix wdl tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37c8c81e6284f6ccbf3495892ac4be47d712d8d3", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/37c8c81e6284f6ccbf3495892ac4be47d712d8d3", "committedDate": "2020-04-03T18:26:55Z", "message": "fix wdl tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dcd0885944bbc7528ab7b9703091b5370afe76a", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/4dcd0885944bbc7528ab7b9703091b5370afe76a", "committedDate": "2020-04-03T20:11:33Z", "message": "fix path"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6b12294d6784347df60894c3112f9c64b03d1ed", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/d6b12294d6784347df60894c3112f9c64b03d1ed", "committedDate": "2020-04-06T17:37:36Z", "message": "fix path again"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e60ed86feb7657a54b65db5fd528fa9f0f725e10", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/e60ed86feb7657a54b65db5fd528fa9f0f725e10", "committedDate": "2020-04-06T20:25:55Z", "message": "remove blacklisted shifted"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/717d87fab4fb938aa44737019f62a4ae7fed1172", "committedDate": "2020-04-07T19:33:00Z", "message": "add error checking for contam file format"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMDQxODAx", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-390041801", "createdAt": "2020-04-08T14:42:35Z", "commit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNDo0MjozNVrOGCyh4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNDo0MjozNVrOGCyh4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTU3ODIwOQ==", "bodyText": "I'm not sure what the solution here is, but does keeping this as the default version mean that we'll have to keep updating it when there are new releases? That's the way it already was, so it's not necessarily a problem, I just want to remember that once this PR is merged and released we should go back and update this default.", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r405578209", "createdAt": "2020-04-08T14:42:35Z", "author": {"login": "meganshand"}, "path": "scripts/mitochondria_m2_wdl/AlignAndCall.wdl", "diffHunk": "@@ -470,7 +498,7 @@ task M2 {\n         --max-mnp-distance 0\n   >>>\n   runtime {\n-      docker: \"us.gcr.io/broad-gatk/gatk:4.1.1.0\"\n+      docker: select_first([gatk_docker_override, \"us.gcr.io/broad-gatk/gatk:4.1.1.0\"])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172"}, "originalPosition": 155}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMDQyNjYx", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-390042661", "createdAt": "2020-04-08T14:43:31Z", "commit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxODI1MzE0", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-391825314", "createdAt": "2020-04-12T06:16:12Z", "commit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwNjoxNjoxMlrOGESnUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwNjoxNjoxMlrOGESnUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1MjQ2Ng==", "bodyText": "Can you go directly compute symbolic indices via new IndexRange(0, vc.getNAlleles()).filter(n -> vc.getAllele(n).isSymbolic());?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r407152466", "createdAt": "2020-04-12T06:16:12Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java", "diffHunk": "@@ -88,19 +89,33 @@ public SomaticClusteringModel(final M2FiltersArgumentCollection MTFAC, final Lis\n         logClusterWeights = new double[] {Math.log1p(INITIAL_HIGH_AF_WEIGHT), Math.log(INITIAL_HIGH_AF_WEIGHT)};\n     }\n \n-    public void record(final int[] tumorADs, final double[] tumorLogOdds, final double artifactProbability, final double nonSomaticProbability, final VariantContext vc) {\n-        // things that are definitely not somatic don't need to go in the somatic clustering model\n-        if (artifactProbability > OBVIOUS_ARTIFACT_PROBABILITY_THRESHOLD) {\n-            obviousArtifactCount.increment();\n-            return;\n-        } else if (nonSomaticProbability > OBVIOUS_ARTIFACT_PROBABILITY_THRESHOLD) {\n-            return;\n-        }\n-\n+    /**\n+     * Adds data to the model for every alternate allele\n+     * @param tumorADs for all alleles, summed over samples\n+     * @param tumorLogOdds for alt alleles only\n+     * @param artifactProbabilities by alt allele, specifically technical artifact probabilities not including sequencing error, contamination, or germline variation\n+     * @param nonSomaticProbabilities by alt allele, probabilities that the variants are real but not somatic ie germline or contamination\n+     * @param vc the variant context the data apply to\n+     */\n+    public void record(int[] tumorADs, final double[] tumorLogOdds, final List<Double> artifactProbabilities, final List<Double> nonSomaticProbabilities, final VariantContext vc) {\n+        // set tumorAD to 0 for symbolic alleles so it won't contribute to overall AD\n+        List<Allele> symbolicAlleles = vc.getAlternateAlleles().stream().filter(allele -> allele.isSymbolic()).collect(Collectors.toList());\n+        // convert allele index to alt allele index\n+        List<Integer> symIndexes = vc.getAlleleIndices(symbolicAlleles).stream().map(i -> i-1).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "717d87fab4fb938aa44737019f62a4ae7fed1172"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69cca57628a66e36324ca4062b40c98c80e5a728", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/69cca57628a66e36324ca4062b40c98c80e5a728", "committedDate": "2020-04-14T14:47:27Z", "message": "minor refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f51ba1037f969405a808501f567c22c0b8957b9c", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/f51ba1037f969405a808501f567c22c0b8957b9c", "committedDate": "2020-04-15T13:26:06Z", "message": "update example inputs to use broad public bucket for refs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59f3dc9a2fc244fe4f0e7e64ee69055d79bc0018", "author": {"user": {"login": "ahaessly", "name": "Andrea Haessly"}}, "url": "https://github.com/broadinstitute/gatk/commit/59f3dc9a2fc244fe4f0e7e64ee69055d79bc0018", "committedDate": "2020-04-16T19:52:33Z", "message": "doc updates"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3NTY5NDU2", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-397569456", "createdAt": "2020-04-21T18:31:53Z", "commit": {"oid": "59f3dc9a2fc244fe4f0e7e64ee69055d79bc0018"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxODozMTo1M1rOGJSmvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxODozMTo1M1rOGJSmvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM5NTE5OA==", "bodyText": "\"a list with one element for each allele\"?", "url": "https://github.com/broadinstitute/gatk/pull/6399#discussion_r412395198", "createdAt": "2020-04-21T18:31:53Z", "author": {"login": "ldgauthier"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/Mutect2AlleleFilter.java", "diffHunk": "@@ -73,7 +73,7 @@\n \n \n     /**\n-     *\n+     * Returns a list for each alternate allele which is the probability that the allele should be filtered out.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59f3dc9a2fc244fe4f0e7e64ee69055d79bc0018"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3NTcxODM1", "url": "https://github.com/broadinstitute/gatk/pull/6399#pullrequestreview-397571835", "createdAt": "2020-04-21T18:35:11Z", "commit": {"oid": "59f3dc9a2fc244fe4f0e7e64ee69055d79bc0018"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2878, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}