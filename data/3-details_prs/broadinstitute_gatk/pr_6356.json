{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwMTczODky", "number": 6356, "title": "Collect split read and paired end evidence files for GATK-SV pipeline", "bodyText": "This PR creates a tool for generating split read and paired end SV evidence files from an input WGS CRAM or BAM file for use in the GATK-SV pipeline.\nThis tool emulates the behavior of svtk collect-pesr, which is the tool used in the current version of the pipeline.\nBriefly, it creates two tab-delimited, tabix-able output files. The first stores information about discordant read pairs -- the positions and orientations of a read and its mate, for each read pair marked \"not properly paired\" in the input file. Records are reported only for the upstream read in the pair. The second file contains the locations of all soft clips in the input file, including the coordinate and \"direction\" (right or left clipping) and the count of the number of reads clipped at that position and direction.\nThe integration test expected results file was generated using svtk collect-pesr to help ensure that the results are identical. We hope to eventually replace this component of the SV pipeline with this GATK tool.", "createdAt": "2020-01-07T21:09:24Z", "url": "https://github.com/broadinstitute/gatk/pull/6356", "merged": true, "mergeCommit": {"oid": "9bca5119e996886ee85ef6c890eba79ec5d6cfb1"}, "closed": true, "closedAt": "2020-01-16T16:35:36Z", "author": {"login": "cwhelan"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb5FM0EAFqTM0MTMyMTQxNA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABb6sUQUgH2gAyMzYwMTczODkyOjMzMzA4MWRhYWMyZWQyZGZmNGRlNjRkYWJlNDQ1NGFiZDMxMjI1YTg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMzIxNDE0", "url": "https://github.com/broadinstitute/gatk/pull/6356#pullrequestreview-341321414", "createdAt": "2020-01-10T17:45:47Z", "commit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "state": "APPROVED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo0NTo0OFrOFcbXog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMToxMDoyNFrOFcgKig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1Mjg2Ng==", "bodyText": "Could phrase it this way too: direction: side of read that is clipped (\"left\" or \"right\"). I initially found the use of left and right confusing. If we end up sticking with this data format it might make more sense to use strand labels (left = -, right = +) which also use fewer characters.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365352866", "createdAt": "2020-01-10T17:45:48Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg==", "bodyText": "When we migrated GATK4 tools, Geraldine discouraged the use of any \"non-standard\" short arguments (eg -I, -O, -R) because they are hard to interpret at a glance and could end up conflicting across different tools. I tend to agree, although the PE and SR files may become common for us. I'd suggest using -PE and -SR as those shouldn't cause any conflicts and follow the upper-case convention.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356192", "createdAt": "2020-01-10T17:54:25Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjQ2Ng==", "bodyText": "Also do we have a place for defining SV arguments? I think at the very least you should have them as public constants.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356466", "createdAt": "2020-01-10T17:55:05Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjcxNg==", "bodyText": "I think this can be final", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356716", "createdAt": "2020-01-10T17:55:45Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODAyMw==", "bodyText": "Can you do this by overriding getDefaultReadFilters()? That way we have the option of customizing them", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365358023", "createdAt": "2020-01-10T17:59:06Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQxNzA5Ng==", "bodyText": "Adds to split read counts list the new prevClippedReadEndPos... (nothing is actually returned)", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365417096", "createdAt": "2020-01-10T20:27:03Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw==", "bodyText": "Could replace getBestAvailableSequenceDictionary () with sequenceDictionary", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421833", "createdAt": "2020-01-10T20:41:17Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTk5MQ==", "bodyText": "Could replace samSequenceDictionary with sequenceDictionary?", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421991", "createdAt": "2020-01-10T20:41:47Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyODMwMg==", "bodyText": "What's this for?", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365428302", "createdAt": "2020-01-10T21:00:33Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read\n+     */\n+    @VisibleForTesting\n+    public void countSplitRead(final GATKRead read, final PriorityQueue<SplitPos> splitCounts, final OutputStreamWriter srWriter) {\n+        final SplitPos splitPosition = getSplitPosition(read);\n+        final int readStart = read.getStart();\n+        if (splitPosition.direction == POSITION.MIDDLE) {\n+            return;\n+        }\n+        if (currentChrom == null) {\n+            currentChrom = read.getContig();\n+        } else if (!currentChrom.equals(read.getContig())) {\n+            flushSplitCounts(splitPos -> true, srWriter, splitCounts);\n+            currentChrom = read.getContig();\n+        } else {\n+            flushSplitCounts(sp -> (sp.pos < readStart - 1), srWriter, splitCounts);\n+        }\n+\n+        splitCounts.add(splitPosition);\n+    }\n+\n+    private void flushSplitCounts(final Predicate<SplitPos> flushablePosition, final OutputStreamWriter srWriter, final PriorityQueue<SplitPos> splitCounts) {\n+\n+        while (splitCounts.size() > 0 && flushablePosition.test(splitCounts.peek())) {\n+            SplitPos pos = splitCounts.poll();\n+            int countAtPos = 1;\n+            while (splitCounts.size() > 0 && splitCounts.peek().equals(pos)) {\n+                countAtPos++;\n+                splitCounts.poll();\n+            }\n+            try {\n+                srWriter.write(currentChrom + \"\\t\" + (pos.pos - 1) + \"\\t\" + pos.direction.getDescription() + \"\\t\" + countAtPos + \"\\t\" + sampleName + \"\\n\");\n+            } catch (IOException e) {\n+                throw new GATKException(\"Could not write to sr file\", e);\n+            }\n+        }\n+    }\n+\n+    private SplitPos getSplitPosition(GATKRead read) {\n+        if (read.getCigar().getFirstCigarElement().getOperator() == CigarOperator.M) {\n+            final int matchLength = read.getCigar().getCigarElements().stream().filter(e -> e.getOperator().consumesReferenceBases()).mapToInt(CigarElement::getLength).sum();\n+            return new SplitPos(read.getStart() + matchLength, POSITION.RIGHT);\n+        } else if (read.getCigar().getLastCigarElement().getOperator() == CigarOperator.M) {\n+            return new SplitPos(read.getStart(), POSITION.LEFT);\n+        }\n+\n+        return new SplitPos(-1, POSITION.MIDDLE);\n+    }\n+\n+    private boolean isSoftClipped(final GATKRead read) {\n+        final CigarOperator firstOperator = read.getCigar().getFirstCigarElement().getOperator();\n+        final CigarOperator lastOperator = read.getCigar().getLastCigarElement().getOperator();\n+        return (firstOperator == CigarOperator.SOFT_CLIP && lastOperator != CigarOperator.SOFT_CLIP) ||\n+                (firstOperator != CigarOperator.SOFT_CLIP && lastOperator == CigarOperator.SOFT_CLIP);\n+    }\n+\n+    @Override\n+    public Object onTraversalSuccess() {\n+        flushSplitCounts(splitPos -> true, srWriter, splitPosBuffer);\n+        flushDiscordantReadPairs();\n+        return null;\n+    }\n+\n+    @Override\n+    public void closeTool() {\n+        super.closeTool();\n+        try {\n+            peWriter.close();\n+            srWriter.close();\n+        } catch (IOException e) {\n+            throw new GATKException(\"error closing output file\", e);\n+        }\n+    }\n+\n+    enum POSITION {\n+        LEFT (\"left\"),\n+        MIDDLE (\"middle\"),\n+        RIGHT (\"right\");\n+\n+        private String description;\n+\n+        POSITION(final String description) {\n+            this.description = description;\n+        }\n+\n+        public String getDescription() {\n+            return description;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMDg4MQ==", "bodyText": "This is so cool", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365430881", "createdAt": "2020-01-10T21:08:30Z", "author": {"login": "mwalker174"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollectionUnitTest.java", "diffHunk": "@@ -0,0 +1,128 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import htsjdk.samtools.SAMFileHeader;\n+import org.broadinstitute.hellbender.GATKBaseTest;\n+import org.broadinstitute.hellbender.utils.read.ArtificialReadUtils;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import java.io.OutputStreamWriter;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.PriorityQueue;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+public class PairedEndAndSplitReadEvidenceCollectionUnitTest extends GATKBaseTest {\n+\n+    @Test\n+    public void testGetReportableDiscordantReadPair() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+\n+        // read pair on different contigs\n+        final GATKRead discRPDiffContigsFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 0, 1000, 150);\n+        discRPDiffContigsFirst.setMatePosition(header.getSequence(1).getSequenceName(), 9000);\n+        final GATKRead discRPDiffContigsSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 1, 9000, 150);\n+        discRPDiffContigsSecond.setMatePosition(header.getSequence(0).getSequenceName(), 1000);\n+\n+        // read pair on same contig\n+        final GATKRead discRPSameContigFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 500, 150);\n+        discRPSameContigFirst.setMatePosition(header.getSequence(1).getSequenceName(), 5000);\n+        final GATKRead discRPSameContigSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 5000, 150);\n+        discRPSameContigSecond.setMatePosition(header.getSequence(1).getSequenceName(), 500);\n+\n+        // read pair on same contig, same start position\n+        final GATKRead discRPSameContigSameStartFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartFirst.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+        final GATKRead discRPSameContigSameStartSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartSecond.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+\n+        final HashSet<String> observedDiscordantNamesAtThisLocus = new HashSet<>();\n+\n+        final PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+\n+        PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNotNull(reportableDiscordantReadPair);\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPDiffContigsFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigSameStartFirst);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.contains(discRPSameContigSameStartFirst.getName()));\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.isEmpty());\n+\n+    }\n+\n+    private void assertDiscordantReadInfo(final PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair, final GATKRead gatkRead) {\n+        Assert.assertEquals(reportableDiscordantReadPair.getName(), gatkRead.getName());\n+        Assert.assertEquals(reportableDiscordantReadPair.getContig(), gatkRead.getContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getStart(), gatkRead.getStart());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateContig(), gatkRead.getMateContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateStart(), gatkRead.getMateStart());\n+    }\n+\n+    @Test\n+    public void testCountSplitRead() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+        final GATKRead rightClip = ArtificialReadUtils.createArtificialRead(header, \"rightClip\", 0, 1000, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"100M51S\");\n+\n+        final OutputStreamWriter mockSrWriter = Mockito.mock(OutputStreamWriter.class);\n+\n+        PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+        final PriorityQueue<PairedEndAndSplitReadEvidenceCollection.SplitPos> splitCounts = new PriorityQueue<>(new PairedEndAndSplitReadEvidenceCollection.SplitPosComparator());\n+        tool.sampleName = \"sample\";\n+\n+        tool.countSplitRead(rightClip, splitCounts, mockSrWriter);\n+        Map<PairedEndAndSplitReadEvidenceCollection.SplitPos, Long> counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead rightClip2 = ArtificialReadUtils.createArtificialRead(header, \"rightClip2\", 0, 1050, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"50M101S\");\n+        tool.countSplitRead(rightClip2, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClip = ArtificialReadUtils.createArtificialRead(header, \"leftClip\", 0, 1100, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClip, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClipDownstream = ArtificialReadUtils.createArtificialRead(header, \"leftClipDownstream\", 0, 1600, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClipDownstream, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1600, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"left\" + \"\\t\" + 1 + \"\\t\" + \"sample\" + \"\\n\");\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"right\" + \"\\t\" + 2 + \"\\t\" + \"sample\" + \"\\n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMTQzNA==", "bodyText": "Can you make a class out of this? Could be useful in the future", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365431434", "createdAt": "2020-01-10T21:10:24Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 175}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "committedDate": "2020-01-07T21:01:22Z", "message": "clean up and add some documentation"}, "afterCommit": {"oid": "0b36d11974f13aab0af41feae91ebc45860f4a3f", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/0b36d11974f13aab0af41feae91ebc45860f4a3f", "committedDate": "2020-01-15T18:57:47Z", "message": "address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd3b3966b6457558abf1365b9b709a1fe6c3ee03", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/bd3b3966b6457558abf1365b9b709a1fe6c3ee03", "committedDate": "2020-01-15T18:57:47Z", "message": "prototype port of PESR collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ee8ef3d4fb7b60dd90cc885f0343bced36163da", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/7ee8ef3d4fb7b60dd90cc885f0343bced36163da", "committedDate": "2020-01-15T18:57:47Z", "message": "fix discordant read comparator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "401a5fbadc8b3383d07f61e788b5eee37b76254a", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/401a5fbadc8b3383d07f61e788b5eee37b76254a", "committedDate": "2020-01-15T18:57:47Z", "message": "minor bug fix to pesr collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27c02b50cba8a105db9b8359dd34902dfba52965", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/27c02b50cba8a105db9b8359dd34902dfba52965", "committedDate": "2020-01-15T18:57:47Z", "message": "use an intermediate discordant read object to save memory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ef7a582e044c50fe4a490305e02f4f329bf92f2", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/4ef7a582e044c50fe4a490305e02f4f329bf92f2", "committedDate": "2020-01-15T18:57:47Z", "message": "fix sorting and flushing bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e38b8c946f0001e5e9d3ccc26cb024f9603700e", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/8e38b8c946f0001e5e9d3ccc26cb024f9603700e", "committedDate": "2020-01-15T18:57:47Z", "message": "memory improvements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8783becd6eba7b27e7db57a6ff9c0aa3c72e5761", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/8783becd6eba7b27e7db57a6ff9c0aa3c72e5761", "committedDate": "2020-01-15T18:57:47Z", "message": "switch to list + sort"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d91bb1b5e8c86a5c174555ba183c0905346a713", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/6d91bb1b5e8c86a5c174555ba183c0905346a713", "committedDate": "2020-01-15T18:57:47Z", "message": "fix some bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "215e14b0b75e615a0ac3aaac61ca57ede6f41185", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/215e14b0b75e615a0ac3aaac61ca57ede6f41185", "committedDate": "2020-01-15T18:57:47Z", "message": "make some instance variables private"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3eb8956a30034ff0396842246e4c65327c34e54", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/c3eb8956a30034ff0396842246e4c65327c34e54", "committedDate": "2020-01-15T18:57:47Z", "message": "fix bad bai index"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e076c0532848a08cf5d66f59a4c61a851797f8a8", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/e076c0532848a08cf5d66f59a4c61a851797f8a8", "committedDate": "2020-01-15T18:57:47Z", "message": "stubs for tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39f513382e64107300d3640c0e3d4a3289873dc2", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/39f513382e64107300d3640c0e3d4a3289873dc2", "committedDate": "2020-01-15T18:57:47Z", "message": "fix test stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31f708084b9d5e45bd79236ea7ff11441090bfb9", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/31f708084b9d5e45bd79236ea7ff11441090bfb9", "committedDate": "2020-01-15T18:57:47Z", "message": "start adding unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b22cc719d25bfdef4c762fd61dbeebbd38e35076", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/b22cc719d25bfdef4c762fd61dbeebbd38e35076", "committedDate": "2020-01-15T18:57:47Z", "message": "add unit test and integration test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "886e28edef29769839009e620176779f4c84a64e", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/886e28edef29769839009e620176779f4c84a64e", "committedDate": "2020-01-15T18:57:47Z", "message": "refactor and add test cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c8f7de2755b993e16400279ba42d7f4558e5e05", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/5c8f7de2755b993e16400279ba42d7f4558e5e05", "committedDate": "2020-01-15T18:57:47Z", "message": "clean up and add some documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b36d11974f13aab0af41feae91ebc45860f4a3f", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/0b36d11974f13aab0af41feae91ebc45860f4a3f", "committedDate": "2020-01-15T18:57:47Z", "message": "address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "333081daac2ed2dff4de64dabe4454abd31225a8", "author": {"user": {"login": "cwhelan", "name": null}}, "url": "https://github.com/broadinstitute/gatk/commit/333081daac2ed2dff4de64dabe4454abd31225a8", "committedDate": "2020-01-15T21:20:29Z", "message": "add the beta tool marker"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2903, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}