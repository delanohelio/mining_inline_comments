{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzOTQ2Njcz", "number": 6618, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozODowNlrOEAP8QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo0MTozMFrOEAQAYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Njk2NjQwOnYy", "diffSide": "RIGHT", "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozODowNlrOGbaaBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoxNjo0NlrOGbblqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NzM4MQ==", "bodyText": "I sort of which java had lightweight type aliases so we could rename this locally to HdfsPath and avoid these nasty fully specified names...", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431397381", "createdAt": "2020-05-27T19:38:06Z", "author": {"login": "lbergelson"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNjc0Ng==", "bodyText": "Yeah, I frequently wish Java had type aliases.", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431416746", "createdAt": "2020-05-27T20:16:46Z", "author": {"login": "cmnbroad"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NzM4MQ=="}, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Njk3MDY3OnYy", "diffSide": "RIGHT", "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozOToyOVrOGbacsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoxNzoxNVrOGbbmog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA2NA==", "bodyText": "nitpick, i'm a booster for argBuilder.addInput and .addOutput, but it doesn't matter at all", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431398064", "createdAt": "2020-05-27T19:39:29Z", "author": {"login": "lbergelson"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");\n+            final org.apache.hadoop.fs.Path refHDFSIndexPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta.fai\");\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testCram.getURI()), cramHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRef.getURI()), refHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefDict.getURI()), refHDFSDictPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefIndex.getURI()), refHDFSIndexPath);\n+\n+            // run PrintReadsSpark and print the contents of the HDFS cram test file to an output HDFS cram\n+            final GATKPathSpecifier outputHDFSPath = new GATKPathSpecifier(workingDirectory + \"testCramOnHDFSOut.cram\");\n+            final ArgumentsBuilder argBuilder = new ArgumentsBuilder();\n+            argBuilder.add(\"input\", cramHDFSPath.toUri().toString())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNjk5NA==", "bodyText": "I keep forgetting about those. Easy enough to change though.", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431416994", "createdAt": "2020-05-27T20:17:15Z", "author": {"login": "cmnbroad"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");\n+            final org.apache.hadoop.fs.Path refHDFSIndexPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta.fai\");\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testCram.getURI()), cramHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRef.getURI()), refHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefDict.getURI()), refHDFSDictPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefIndex.getURI()), refHDFSIndexPath);\n+\n+            // run PrintReadsSpark and print the contents of the HDFS cram test file to an output HDFS cram\n+            final GATKPathSpecifier outputHDFSPath = new GATKPathSpecifier(workingDirectory + \"testCramOnHDFSOut.cram\");\n+            final ArgumentsBuilder argBuilder = new ArgumentsBuilder();\n+            argBuilder.add(\"input\", cramHDFSPath.toUri().toString())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA2NA=="}, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Njk3Njk5OnYy", "diffSide": "RIGHT", "path": "src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark/count_reads.fasta", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo0MTozMFrOGbagrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo0MTozMFrOGbagrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5OTA4Ng==", "bodyText": "I love this tiny reference :). it's so cute!", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431399086", "createdAt": "2020-05-27T19:41:30Z", "author": {"login": "lbergelson"}, "path": "src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark/count_reads.fasta", "diffHunk": "@@ -0,0 +1,40 @@\n+>chr1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 1}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 916, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}