{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxMjkyMjY2", "number": 7003, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODoyOTowNlrOFUMejw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODozNDowMFrOFUMl3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2NzIwMjcxOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODoyOTowNlrOIcFOHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yM1QxOToxNTozMVrOIqY1Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxNjU3Mg==", "bodyText": "Could you specify what equation this is constructing by putting the tex in javadoc?", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r566316572", "createdAt": "2021-01-28T18:29:06Z", "author": {"login": "fleharty"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTMxNzk5MQ==", "bodyText": "done", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r581317991", "createdAt": "2021-02-23T19:15:31Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxNjU3Mg=="}, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2NzIxMTU5OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODozMToxOVrOIcFT7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yM1QxOToyOToxN1rOIqZbHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxODA2MA==", "bodyText": "standard error of 0.05\nCould you make this clearer?", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r566318060", "createdAt": "2021-01-28T18:31:19Z", "author": {"login": "fleharty"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();\n+        final double coeff2 = homs.stream().mapToDouble(ps ->\n+                oppositeAlleleFrequency.applyAsDouble(ps)*(1 - oppositeAlleleFrequency.applyAsDouble(ps)) * MathUtils.square(ps.getTotalCount())\n+        ).sum();\n+\n+        final DoubleUnaryOperator errorFunc = c -> homs.isEmpty() ? 1 : Math.sqrt(coeff1*c*(1-c) + coeff2*c*c) / totalDepthWeightedByOppositeFrequency;\n+\n+        // we're going to binary search to find the largest contamination whose expected standard error brings it within range of\n+        // our estimate.  That is, suppose we estimate a contamination of 0.03 and the standard error of 0.05 is 0.02.  Then 0.05 is", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTMyNzY0NA==", "bodyText": "done", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r581327644", "createdAt": "2021-02-23T19:29:17Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();\n+        final double coeff2 = homs.stream().mapToDouble(ps ->\n+                oppositeAlleleFrequency.applyAsDouble(ps)*(1 - oppositeAlleleFrequency.applyAsDouble(ps)) * MathUtils.square(ps.getTotalCount())\n+        ).sum();\n+\n+        final DoubleUnaryOperator errorFunc = c -> homs.isEmpty() ? 1 : Math.sqrt(coeff1*c*(1-c) + coeff2*c*c) / totalDepthWeightedByOppositeFrequency;\n+\n+        // we're going to binary search to find the largest contamination whose expected standard error brings it within range of\n+        // our estimate.  That is, suppose we estimate a contamination of 0.03 and the standard error of 0.05 is 0.02.  Then 0.05 is", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxODA2MA=="}, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2NzIyMTQyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODozNDowMFrOIcFaNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNFQwNTowMzozOFrOIqrncA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxOTY2OA==", "bodyText": "Could you either find a standard binary search, or generalize this in MathUtils?\nIf you add it in MathUtils, create a simple test for it.", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r566319668", "createdAt": "2021-01-28T18:34:00Z", "author": {"login": "fleharty"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();\n+        final double coeff2 = homs.stream().mapToDouble(ps ->\n+                oppositeAlleleFrequency.applyAsDouble(ps)*(1 - oppositeAlleleFrequency.applyAsDouble(ps)) * MathUtils.square(ps.getTotalCount())\n+        ).sum();\n+\n+        final DoubleUnaryOperator errorFunc = c -> homs.isEmpty() ? 1 : Math.sqrt(coeff1*c*(1-c) + coeff2*c*c) / totalDepthWeightedByOppositeFrequency;\n+\n+        // we're going to binary search to find the largest contamination whose expected standard error brings it within range of\n+        // our estimate.  That is, suppose we estimate a contamination of 0.03 and the standard error of 0.05 is 0.02.  Then 0.05 is\n+        // the upper end of our 1-sigma confidence interval.\n+        // this binary search is far from optimized (in fact we could solve this explicitly with a messy closed-form solution)\n+        // but it converges to a precision of 1e-6 in 20 iterations of the square root of a linear function.  This is fast enough.\n+        double top = 1.0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTYyNTcxMg==", "bodyText": "done", "url": "https://github.com/broadinstitute/gatk/pull/7003#discussion_r581625712", "createdAt": "2021-02-24T05:03:38Z", "author": {"login": "davidbenjamin"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java", "diffHunk": "@@ -160,15 +162,49 @@ public ContaminationModel(List<PileupSummary> sites) {\n                 .mapToDouble(ps -> ps.getTotalCount() * oppositeAlleleFrequency.applyAsDouble(ps))\n                 .sum();\n \n-        final double contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+        final double contaminationEstimate = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency;\n+\n+        final double coeff1 = homs.stream().mapToDouble(ps -> oppositeAlleleFrequency.applyAsDouble(ps) * ps.getTotalCount()).sum();\n+        final double coeff2 = homs.stream().mapToDouble(ps ->\n+                oppositeAlleleFrequency.applyAsDouble(ps)*(1 - oppositeAlleleFrequency.applyAsDouble(ps)) * MathUtils.square(ps.getTotalCount())\n+        ).sum();\n+\n+        final DoubleUnaryOperator errorFunc = c -> homs.isEmpty() ? 1 : Math.sqrt(coeff1*c*(1-c) + coeff2*c*c) / totalDepthWeightedByOppositeFrequency;\n+\n+        // we're going to binary search to find the largest contamination whose expected standard error brings it within range of\n+        // our estimate.  That is, suppose we estimate a contamination of 0.03 and the standard error of 0.05 is 0.02.  Then 0.05 is\n+        // the upper end of our 1-sigma confidence interval.\n+        // this binary search is far from optimized (in fact we could solve this explicitly with a messy closed-form solution)\n+        // but it converges to a precision of 1e-6 in 20 iterations of the square root of a linear function.  This is fast enough.\n+        double top = 1.0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMxOTY2OA=="}, "originalCommit": {"oid": "c442c900bbda61ea215574f56e7a3e417e6b860a"}, "originalPosition": 35}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 772, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}