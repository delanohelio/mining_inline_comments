{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzOTQ2Njcz", "number": 6618, "title": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS.", "bodyText": "This just adds a test to verify that with the issues causing #2382 (which included both the issues fixed by #6517 ,and some other issues) are all fixed now.", "createdAt": "2020-05-27T15:48:22Z", "url": "https://github.com/broadinstitute/gatk/pull/6618", "merged": true, "mergeCommit": {"oid": "6a6227f8fcba78b4ece67c7d36a554a8adc99c5d"}, "closed": true, "closedAt": "2020-06-09T12:22:39Z", "author": {"login": "cmnbroad"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcleoROgFqTQxOTU1MDM2Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcpP5XsgBqjM0MTk4NzgzNjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NTUwMzYy", "url": "https://github.com/broadinstitute/gatk/pull/6618#pullrequestreview-419550362", "createdAt": "2020-05-27T19:38:06Z", "commit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozODowNlrOGbaaBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo0MTozMFrOGbagrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NzM4MQ==", "bodyText": "I sort of which java had lightweight type aliases so we could rename this locally to HdfsPath and avoid these nasty fully specified names...", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431397381", "createdAt": "2020-05-27T19:38:06Z", "author": {"login": "lbergelson"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA2NA==", "bodyText": "nitpick, i'm a booster for argBuilder.addInput and .addOutput, but it doesn't matter at all", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431398064", "createdAt": "2020-05-27T19:39:29Z", "author": {"login": "lbergelson"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");\n+            final org.apache.hadoop.fs.Path refHDFSIndexPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta.fai\");\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testCram.getURI()), cramHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRef.getURI()), refHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefDict.getURI()), refHDFSDictPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefIndex.getURI()), refHDFSIndexPath);\n+\n+            // run PrintReadsSpark and print the contents of the HDFS cram test file to an output HDFS cram\n+            final GATKPathSpecifier outputHDFSPath = new GATKPathSpecifier(workingDirectory + \"testCramOnHDFSOut.cram\");\n+            final ArgumentsBuilder argBuilder = new ArgumentsBuilder();\n+            argBuilder.add(\"input\", cramHDFSPath.toUri().toString())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5OTA4Ng==", "bodyText": "I love this tiny reference :). it's so cute!", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431399086", "createdAt": "2020-05-27T19:41:30Z", "author": {"login": "lbergelson"}, "path": "src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark/count_reads.fasta", "diffHunk": "@@ -0,0 +1,40 @@\n+>chr1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b01459a630e7658559c9356c3c83d25bfb1a3b9"}, "originalPosition": 1}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d17cb07983e1ddba59aee713fc6e805aa7653672", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/d17cb07983e1ddba59aee713fc6e805aa7653672", "committedDate": "2020-05-27T20:22:46Z", "message": "Code review comments."}, "afterCommit": {"oid": "c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "committedDate": "2020-06-08T12:27:36Z", "message": "Code review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30b426b062cb759c0e231cc89e1f613b4866bbf4", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/30b426b062cb759c0e231cc89e1f613b4866bbf4", "committedDate": "2020-06-08T12:47:42Z", "message": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "committedDate": "2020-06-08T12:27:36Z", "message": "Code review comments."}, "afterCommit": {"oid": "30b426b062cb759c0e231cc89e1f613b4866bbf4", "author": {"user": {"login": "cmnbroad", "name": "Chris Norman"}}, "url": "https://github.com/broadinstitute/gatk/commit/30b426b062cb759c0e231cc89e1f613b4866bbf4", "committedDate": "2020-06-08T12:47:42Z", "message": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2597, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}