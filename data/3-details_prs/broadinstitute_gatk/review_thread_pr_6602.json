{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3NDIwNTIx", "number": 6602, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDoxMTo1N1rOEKhxuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQyMDowNDoyMFrOEKpPHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDc0NjE2OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDoxMTo1N1rOGrnp9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDoxMTo1N1rOGrnp9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM5MTY2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n          \n          \n            \n             * <p>Reads can be either from spliced or unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448391668", "createdAt": "2020-07-01T14:11:57Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDg0NzE2OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDozNTozNVrOGropYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDozNTozNVrOGropYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQwNzkwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *         --spliced true\n          \n          \n            \n             *         --spliced false", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448407904", "createdAt": "2020-07-01T14:35:35Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDg1MTUwOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDozNjoyNlrOGrosBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNDowMjoyNlrOGsOS2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQwODU4MQ==", "bodyText": "I'm not sure I understand what \"earliest\" and \"latest\" read means here.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448408581", "createdAt": "2020-07-01T14:36:26Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAyNDczMA==", "bodyText": "changed to describe via 5'/3', so hopefully clearer.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449024730", "createdAt": "2020-07-02T14:02:26Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQwODU4MQ=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDg3NDgyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDo0MTozOFrOGro6Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDo0MTozOFrOGro6Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQxMjIzMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n          \n          \n            \n             * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equal weight can be given to each grouping feature,", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448412230", "createdAt": "2020-07-01T14:41:38Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDg5MDU4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNDo0NToxNFrOGrpEGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNDowMzoyN1rOGsOVfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQxNDc0NA==", "bodyText": "Does Multi-mapping here mean a secondary alignment (both reads with MQ0)?", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448414744", "createdAt": "2020-07-01T14:45:14Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAyNTQwNg==", "bodyText": "yes", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449025406", "createdAt": "2020-07-02T14:03:27Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQxNDc0NA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTYyMzc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODowNjo1M1rOGrwRFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNDoxNDozNFrOGsOzgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMjc1OQ==", "bodyText": "Does properlyPaired not cover the rest of these checks?", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448532759", "createdAt": "2020-07-01T18:06:53Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 456}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAzMzA4OA==", "bodyText": "In practicality probably yes, but \"properlyPaired\" is not particularly strongly specified (the spec says this is \"each segment properly aligned according to the aligner\").  In general I want to trust the aligner's decision about what this means, but the logic I use later on fails if either the mate is unmapped or the read and mate are on different contigs.  So on the technical possibility that the aligner could choose to mark an alignment as properlyPaired when either of those conditions are true, I want to explicitly check them here.  I will remove the strand checks though, in light of @barkasn 's comment that it is protocol dependent.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449033088", "createdAt": "2020-07-02T14:14:34Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMjc1OQ=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 456}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTY1NDkwOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODoxNzoxNlrOGrwlIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDoxNDo0NlrOGsbuTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNzg4OA==", "bodyText": "Can you add a comment somewhere here to mention that this should only be called on one of the reads in a pair.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448537888", "createdAt": "2020-07-01T18:17:16Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 480}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAzNTU0OQ==", "bodyText": "I think it actually could be called on an unpaired read, and in fact is called on reads which are not in good pairs.  All the logic which relies on a mate sits inside an inGoodPair check.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449035549", "createdAt": "2020-07-02T14:18:12Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNzg4OA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 480}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE0ODA1Mw==", "bodyText": "I think it would be helpful to have a comment here that if a read is paired it should only be called on one read (otherwise you'd be double counting).", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449148053", "createdAt": "2020-07-02T16:51:25Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNzg4OA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 480}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI0NDc1MA==", "bodyText": "done", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449244750", "createdAt": "2020-07-02T20:14:46Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNzg4OA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 480}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTcwNzI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODozNDoyNFrOGrxGJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNjo1NjoyOFrOGsV_YQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0NjM0MA==", "bodyText": "Why do you want to include reverse reads that are not in good pairs here?", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448546340", "createdAt": "2020-07-01T18:34:24Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;\n+                    }\n+                }\n+            }\n+            return getMergedIntervals(alignmentIntervals);\n+\n+        } else {\n+            if (read.isUnmapped()) {\n+                return Collections.emptyList();\n+            }\n+\n+            final boolean inGoodPair = inGoodPair(read, minimumMappingQuality);\n+\n+            final int start = inGoodPair? Math.min(read.getStart(), read.getMateStart()) : read.getStart();\n+            final int end = inGoodPair? start + Math.abs(read.getFragmentLength()) - 1 : read.getEnd();\n+            return Collections.singletonList(new Interval(read.getContig(), start, end));\n+        }\n+\n+\n+    }\n+\n+    @Override\n+    public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {\n+        if ((!read.isReverseStrand() || !inGoodPair(read, mappingQualityFilter.minMappingQualityScore))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 526}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTA0MTI4NQ==", "bodyText": "The idea is that for good pairs, we only need to look at one of the reads, since we can get its mate information from it.  However, for non good pairs, we want to consider each read separately.  For example if we are using unspliced data and the two reads aligned 10000 bases away from each other, and is thus marked as not properly paired, we don't want to consider that a fragment that is 10000 bases long and thus covers every gene between the two alignments.\nI suppose it would also be reasonable (as I think is your point), to just ignore all data that isn't properly paired on the assumption that something funny has happened with those reads, and so they shouldn't be trusted.  So I will add an option to use \"non good pair\" data or not.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449041285", "createdAt": "2020-07-02T14:26:06Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;\n+                    }\n+                }\n+            }\n+            return getMergedIntervals(alignmentIntervals);\n+\n+        } else {\n+            if (read.isUnmapped()) {\n+                return Collections.emptyList();\n+            }\n+\n+            final boolean inGoodPair = inGoodPair(read, minimumMappingQuality);\n+\n+            final int start = inGoodPair? Math.min(read.getStart(), read.getMateStart()) : read.getStart();\n+            final int end = inGoodPair? start + Math.abs(read.getFragmentLength()) - 1 : read.getEnd();\n+            return Collections.singletonList(new Interval(read.getContig(), start, end));\n+        }\n+\n+\n+    }\n+\n+    @Override\n+    public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {\n+        if ((!read.isReverseStrand() || !inGoodPair(read, mappingQualityFilter.minMappingQualityScore))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0NjM0MA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 526}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE0OTU5MQ==", "bodyText": "I don't think you necessarily need to add that option. It's hard to say without looking at data if you should be ignoring \"non good\" pairs completely or not, so I'd wait until someone asks for that specific use case (unless you've already done it because I've commented here too late \ud83d\ude03).", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449149591", "createdAt": "2020-07-02T16:54:22Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;\n+                    }\n+                }\n+            }\n+            return getMergedIntervals(alignmentIntervals);\n+\n+        } else {\n+            if (read.isUnmapped()) {\n+                return Collections.emptyList();\n+            }\n+\n+            final boolean inGoodPair = inGoodPair(read, minimumMappingQuality);\n+\n+            final int start = inGoodPair? Math.min(read.getStart(), read.getMateStart()) : read.getStart();\n+            final int end = inGoodPair? start + Math.abs(read.getFragmentLength()) - 1 : read.getEnd();\n+            return Collections.singletonList(new Interval(read.getContig(), start, end));\n+        }\n+\n+\n+    }\n+\n+    @Override\n+    public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {\n+        if ((!read.isReverseStrand() || !inGoodPair(read, mappingQualityFilter.minMappingQualityScore))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0NjM0MA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 526}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE1MDgxNw==", "bodyText": "Yeah, I was also just realizing as I was thinking about how to implement it that the effect can mostly be achieved through standard command line read-filters, so I'm going to leave as-is for now.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449150817", "createdAt": "2020-07-02T16:56:28Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;\n+                    }\n+                }\n+            }\n+            return getMergedIntervals(alignmentIntervals);\n+\n+        } else {\n+            if (read.isUnmapped()) {\n+                return Collections.emptyList();\n+            }\n+\n+            final boolean inGoodPair = inGoodPair(read, minimumMappingQuality);\n+\n+            final int start = inGoodPair? Math.min(read.getStart(), read.getMateStart()) : read.getStart();\n+            final int end = inGoodPair? start + Math.abs(read.getFragmentLength()) - 1 : read.getEnd();\n+            return Collections.singletonList(new Interval(read.getContig(), start, end));\n+        }\n+\n+\n+    }\n+\n+    @Override\n+    public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {\n+        if ((!read.isReverseStrand() || !inGoodPair(read, mappingQualityFilter.minMappingQualityScore))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0NjM0MA=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 526}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTcyNzQ2OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODo0MDo0MFrOGrxSjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDozNDozNVrOGscPjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0OTUxNg==", "bodyText": "Can you add here what you're counting to get gene expression?", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448549516", "createdAt": "2020-07-01T18:40:40Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI0NTM2Mw==", "bodyText": "Do you mean just specify that this is counting fragments?", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449245363", "createdAt": "2020-07-02T20:16:11Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0OTUxNg=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MzI2MQ==", "bodyText": "yeah, I think that would be helpful.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449253261", "createdAt": "2020-07-02T20:34:35Z", "author": {"login": "meganshand"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU0OTUxNg=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTc1MzAyOnYy", "diffSide": "RIGHT", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluationIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODo0OTowOFrOGrxiyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDozNTozNFrOGscRHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU1MzY3Mg==", "bodyText": "This feels dangerous. We used to have methods for updating all the md5 checks in GATK3 and I thought we were moving away from this style test in GATK4. Are there examples of this kind of quick update for other GATK4 integration tests? (What I remember happening in GATK3 was that you'd end up with so many tests changing that you'd run the script to update them and not actually look at the diff for hundreds of changed files.)", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448553672", "createdAt": "2020-07-01T18:49:08Z", "author": {"login": "meganshand"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,156 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import org.broadinstitute.hellbender.CommandLineProgramTest;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class GeneExpressionEvaluationIntegrationTest extends CommandLineProgramTest {\n+\n+    // If true, update the expected outputs in tests that assert a match vs. prior output,\n+    // instead of actually running the tests. Can be used with \"./gradlew test -Dtest.single=GeneExpressionEvaluationIntegrationTest\"\n+    // to update all of the exact-match tests at once. After you do this, you should look at the\n+    // diffs in the new expected outputs in git to confirm that they are consistent with expectations.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NDY0Ng==", "bodyText": "I stole this from HaplotypeCallerIntegrationTest, but I'm not sure it's used anywhere else.  I agree it's probably better to make people work a little harder to update expected test results, so will remove this.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449184646", "createdAt": "2020-07-02T18:00:50Z", "author": {"login": "kachulis"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,156 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import org.broadinstitute.hellbender.CommandLineProgramTest;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class GeneExpressionEvaluationIntegrationTest extends CommandLineProgramTest {\n+\n+    // If true, update the expected outputs in tests that assert a match vs. prior output,\n+    // instead of actually running the tests. Can be used with \"./gradlew test -Dtest.single=GeneExpressionEvaluationIntegrationTest\"\n+    // to update all of the exact-match tests at once. After you do this, you should look at the\n+    // diffs in the new expected outputs in git to confirm that they are consistent with expectations.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU1MzY3Mg=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MzY2Mw==", "bodyText": "Really? I mean, if it's already in HC then it's probably fine. It certainly makes it easier, and it doesn't become a problem until you have hundreds of tests.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449253663", "createdAt": "2020-07-02T20:35:34Z", "author": {"login": "meganshand"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,156 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import org.broadinstitute.hellbender.CommandLineProgramTest;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class GeneExpressionEvaluationIntegrationTest extends CommandLineProgramTest {\n+\n+    // If true, update the expected outputs in tests that assert a match vs. prior output,\n+    // instead of actually running the tests. Can be used with \"./gradlew test -Dtest.single=GeneExpressionEvaluationIntegrationTest\"\n+    // to update all of the exact-match tests at once. After you do this, you should look at the\n+    // diffs in the new expected outputs in git to confirm that they are consistent with expectations.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU1MzY3Mg=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTk2NzM1OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQyMDowNDowMFrOGrzpDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDoyNzo0OVrOGscECQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4ODA0Ng==", "bodyText": "This doesn't seem like its used", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448588046", "createdAt": "2020-07-01T20:04:00Z", "author": {"login": "barkasn"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MDMxMw==", "bodyText": "good catch!", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449250313", "createdAt": "2020-07-02T20:27:49Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.\n+ * A \"good pair\" is defined as:\n+ *  <li>Both reads are mapped</li>\n+ *  <li>Properly paired flag is set</li>\n+ *  <li>Both reads are on same contig</li>\n+ *  <li>Reads are on opposite strands</li>\n+ *  <li>Mapping quality of both reads is at least minimum-mapping-quality</li>\n+ *  <li>Reads are inward-facing</li>\n+ *</p>\n+ *\n+ * <p>Reads can be either from spliced are unspliced RNA.  If from spliced RNA, alignment blocks of reads are taken as their coverage.  \n+ * If from unspliced RNA, the entire region from the start of the earliest read to the end of the latest read is taken as the fragment\n+ * coverage.  Splice status is set through the command line.  By default, splice status is taken to be \"spliced.\" </p>\n+ * <p>\n+ *     <h3>For spliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * <p>\n+ *     <h3>For unspliced RNA</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --spliced true\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>Gene expression is aggregated over \"groupingType\" features, and overlap of fragments with features is determined by \"overlapType\" features.  By default,\n+ * \"groupingType\" is genes, and \"overlapType\" is exons.  Additional grouping_types and overlap_types can be used as well.</p>\n+ * <p>\n+ *     <h3>Use gene and pseudogene as grouping types</h3>\n+ *     <p>\n+ *     gatk GeneExpressionEvaluation\n+ *     -I input.bam\n+ *     -G geneAnnotations.gff3\n+ *     -O output.tsv\n+ *     --grouping-type gene\n+ *     --grouping-type pseudogene\n+ *     </p>\n+ * </p>\n+ * \n+ * <p>The transcription read is by default read1, however this can be changed to read2.  The transcription read determines whether a fragment is sense or antisense.  \n+ * If the transcription read is on the same strand as the feature, the fragment is sense, if on the opposite strand, the fragment is antisense.\n+ * </p>\n+ * <p>\n+ *     <h3>Set transcription read to read2</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --transcription-read R2\n+ *         \n+ * </p>\n+ *\n+ * <p>Multi-overlapping fragments (fragment alignments which overlap multiple grouping features) can be handled in two ways.  Equals weight can be given to each grouping feature,\n+ * in which case each is given weight 1/N, for N overlapping grouping features.\n+ * </p>\n+ * <p>\n+ *     <h3>Equal weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>Multi-overlapping fragments can also have weight distributed according to how much of the fragment overlaps each feature.  In this case, each grouping feature is given an unnormalized weight corresponding\n+ * to the fraction of the fragment that overlaps its overlapping features.  A \"non-overlapping\" option is also given an unnormalized weight corresponding the the fraction of the fragment that overlaps no features.\n+ * Final weights for each feature are found by normalizing by the sum of unnormalized weights.  This is the default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Proportional weight for multi-overlapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-overlap-method PROPORTIONAL\n+ *     </p>\n+ * </p>\n+ *\n+ * <p>Multi-mapping fragments (fragments whose reads map to multiple locations) can also be handled in two ways.  They can be ignored, in which case only fragments with a single mapping are counted.\n+ * This is default behavior.\n+ * </p>\n+ * <p>\n+ *     <h3>Ignore multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method IGNORE\n+ *     </p>\n+ * </p>\n+ * <p>Multi-mapping fragments can alternatively have their weight distributed equally between the different alignments.  If run in this setting, minimum-mapping-quality will be set to 0,\n+ * regardless of its value on the command line.\n+ * </p>\n+ * <p>\n+ *     <h3>Equally weight each alignment of multi-mapping fragments</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *         --multi-map-method EQUAL\n+ *     </p>\n+ * </p>\n+ * <p>The number of mapping for a particular fragment is extracted via the NH tag.</p>\n+ * <p>Currently this tool only works on a single sample BAM.  If a readgroup header line indicates multiple samples in the same BAM, the tool will throw an exception.</p>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat \" +\n+                \"(https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features, \" +\n+                \"and expression (labeled as sense) for all unstranded grouping features.\",\n+        oneLineSummary = \"Evaluate gene expression from RNA-seq reads aligned to genome.\",\n+        programGroup = CoverageAnalysisProgramGroup.class\n+)\n+@DocumentedFeature\n+public final class GeneExpressionEvaluation extends ReadWalker {\n+\n+    @Argument(\n+            doc = \"Output file for gene expression.\",\n+            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME,\n+            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME\n+    )\n+    private File outputCountsFile = null;\n+\n+    @Argument(doc=\"Gff3 file containing feature annotations\", shortName = \"G\", fullName = \"gff-file\")\n+    private FeatureInput<Gff3Feature> gffFile;\n+\n+    @Argument(doc=\"Feature types to group by\", fullName = \"grouping-type\")\n+    private Set<String> groupingType = new HashSet<>(Collections.singleton(\"gene\"));\n+\n+    @Argument(doc=\"Feature overlap types\", fullName = \"overlap-type\")\n+    private Set<String> overlapType = new HashSet<>(Collections.singleton(\"exon\"));\n+\n+    @Argument(doc=\"Whether to label features by ID or Name\", fullName = \"feature-label-key\")\n+    private FeatureLabelType featureLabelKey = FeatureLabelType.NAME;\n+\n+    @Argument(doc = \"Which read corresponds to the transcription strand\", fullName = \"transcription-read\")\n+    private TrancriptionRead trancriptionRead = TrancriptionRead.R1;\n+\n+    @Argument(doc = \"How to distribute weight of alignments which overlap multiple features\", fullName = \"multi-overlap-method\")\n+    private MultiOverlapMethod multiOverlapMethod = MultiOverlapMethod.PROPORTIONAL;\n+\n+    @Argument(doc = \"How to distribute weight of reads with multiple alignments\", fullName = \"multi-map-method\")\n+    private MultiMapMethod multiMapMethod = MultiMapMethod.IGNORE;\n+\n+    @Argument(doc = \"Whether the rna is spliced.  If spliced, alignments must be from a splice aware aligner (such as star).  If unspliced, alignments must be from a non-splicing aligner (such as bwa). \")\n+    private boolean spliced = true;\n+\n+    final private Map<Gff3BaseData, Coverage> featureCounts = new LinkedHashMap<>();\n+\n+    final private OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector = new OverlapDetector<>(0,0);\n+\n+    private String sampleName = null;\n+\n+    final MappingQualityReadFilter mappingQualityFilter = new MappingQualityReadFilter();\n+\n+    enum FeatureLabelType {\n+        NAME(\"Name\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getName();\n+            }\n+        },\n+        ID(\"ID\") {\n+            @Override\n+            String getValue(final Gff3BaseData baseData) {\n+                return baseData.getId();\n+            }\n+        };\n+\n+        String key;\n+        FeatureLabelType(final String key) {\n+            this.key = key;\n+        }\n+        String getKey() {\n+            return key;\n+        }\n+        abstract String getValue(final Gff3BaseData baseData);\n+\n+    }\n+\n+    enum MultiOverlapMethod {\n+\n+        EQUAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final Set<Gff3BaseData> overlappingFeatures = alignmentIntervals.stream().flatMap(i -> featureOverlapDetector.getOverlaps(i).stream().map(Pair::getLeft)).collect(Collectors.toSet());\n+                final int nOverlappingFeatures = overlappingFeatures.size();\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Gff3BaseData feature : overlappingFeatures) {\n+                    weights.put(feature, (float)1.0/nOverlappingFeatures);\n+                }\n+                return weights;\n+            }\n+        },\n+\n+        PROPORTIONAL {\n+            @Override\n+            Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector) {\n+                final List<Interval> mergedAlignmentIntervals = getMergedIntervals(alignmentIntervals);\n+\n+                final int basesOnReference = mergedAlignmentIntervals.stream().map(Interval::getLengthOnReference).reduce(0, Integer::sum);\n+                int totalCoveredBases = 0;\n+                float summedUnNormalizedWeights = 0;\n+                final Map<Gff3BaseData, Float> weights = new LinkedHashMap<>();\n+                for (final Interval alignmentInterval : mergedAlignmentIntervals) {\n+                    final Set<Pair<Gff3BaseData,Interval>> overlaps = featureOverlapDetector.getOverlaps(alignmentInterval);\n+                    final Map<Gff3BaseData, List<Interval>> overlappingIntervalsByFeature = new LinkedHashMap<>();\n+                    final List<Interval> allOverlappingIntervals = new ArrayList<>();\n+                    for (Pair<Gff3BaseData, Interval> overlap : overlaps) {\n+                        final List<Interval> overlappingIntervals = overlappingIntervalsByFeature.computeIfAbsent(overlap.getLeft(), f -> new ArrayList<>());\n+                        overlappingIntervals.add(overlap.getRight());\n+                        allOverlappingIntervals.add(overlap.getRight());\n+                    }\n+\n+                    final List<Interval> allOverlappingIntervalsMerged = getMergedIntervals(allOverlappingIntervals);\n+                    totalCoveredBases += allOverlappingIntervalsMerged.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum);\n+                    for (Map.Entry<Gff3BaseData, List<Interval>> overlap : overlappingIntervalsByFeature.entrySet()) {\n+                        final List<Interval> mergedOverlapIntervals = getMergedIntervals(overlap.getValue());\n+                        final float weight = (float)mergedOverlapIntervals.stream().map(alignmentInterval::getIntersectionLength).reduce(0,Integer::sum)/basesOnReference;\n+                        weights.compute(overlap.getKey(), (k,v) -> v == null? weight : v + weight);\n+                        summedUnNormalizedWeights += weight;\n+                    }\n+                }\n+\n+                summedUnNormalizedWeights += 1.0 - (float)totalCoveredBases/basesOnReference;\n+\n+                final float normalizationFactor = (float)1.0/summedUnNormalizedWeights;\n+\n+                for (final Gff3BaseData feature : weights.keySet()) {\n+                    weights.compute(feature, (k,v) -> v*normalizationFactor);\n+                }\n+\n+                return weights;\n+            }\n+        };\n+\n+        abstract Map<Gff3BaseData, Float> getWeights(final List<Interval> alignmentIntervals, final OverlapDetector<Pair<Gff3BaseData, Interval>> featureOverlapDetector);\n+    }\n+\n+    enum MultiMapMethod {\n+        IGNORE {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    return Collections.emptyMap();\n+                }\n+            }\n+        },\n+        EQUAL {\n+            @Override\n+            protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+                if (nHits == 1) {\n+                    return previousWeights;\n+                } else {\n+                    final Map<Gff3BaseData, Float> newWeights = new HashMap<>(previousWeights.size());\n+                    for (final Map.Entry<Gff3BaseData, Float> entry : previousWeights.entrySet()) {\n+                        newWeights.put(entry.getKey(), entry.getValue()/(float)nHits);\n+                    }\n+                    return newWeights;\n+                }\n+            }\n+        };\n+\n+        Map<Gff3BaseData, Float> getWeights(final int nHits, final Map<Gff3BaseData, Float> previousWeights) {\n+            if (nHits < 1) {\n+                throw new GATKException(\"nHits = \" + nHits + \", cannot be less than 1\");\n+            }\n+\n+            return getWeightsForMethod(nHits, previousWeights);\n+        }\n+\n+        abstract protected Map<Gff3BaseData, Float> getWeightsForMethod(final int nHits, final Map<Gff3BaseData, Float> previousWeights);\n+\n+    }\n+\n+    @Override\n+    public List<ReadFilter> getDefaultReadFilters() {\n+        final List<ReadFilter> readFilters = new ArrayList<>();\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_START);\n+        readFilters.add(ReadFilterLibrary.VALID_ALIGNMENT_END);\n+        readFilters.add(new AlignmentAgreesWithHeaderReadFilter(getHeaderForReads()));\n+        readFilters.add(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS);\n+        readFilters.add(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH);\n+        readFilters.add(ReadFilterLibrary.SEQ_IS_STORED);\n+        readFilters.add(ReadFilterLibrary.MAPPED);\n+        readFilters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);\n+        readFilters.add(ReadFilterLibrary.NOT_DUPLICATE);\n+        readFilters.add(mappingQualityFilter);\n+        return readFilters;\n+    }\n+\n+    @Override\n+    public void onTraversalStart() {\n+        validateOutputFile(outputCountsFile);\n+        if(multiMapMethod == MultiMapMethod.EQUAL) {\n+            mappingQualityFilter.minMappingQualityScore = 0;\n+        }\n+        final SAMSequenceDictionary dict = getBestAvailableSequenceDictionary();\n+        final SAMFileHeader header = getHeaderForReads();\n+        for (final SAMReadGroupRecord readGroupRecord : header.getReadGroups()) {\n+            if (sampleName == null) {\n+                sampleName = readGroupRecord.getSample();\n+            } else {\n+                if (!sampleName.equals(readGroupRecord.getSample())) {\n+                    throw new GATKException(\"Cannot run GeneExpressionEvaluation on multi-sample bam.\");\n+                }\n+            }\n+        }\n+        if (dict == null) {\n+            throw new GATKException(\"sequence dictionary must be specified (\" + StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME + \").\");\n+        }\n+\n+        logger.info(\"collecting list of features\");\n+        final List<SimpleInterval> allIntervals = hasUserSuppliedIntervals()? getTraversalIntervals() : IntervalUtils.getAllIntervalsForReference(dict);\n+        for (final SimpleInterval interval : allIntervals) {\n+            final List<Gff3Feature> contigFeatures = features.getFeatures(gffFile, interval);\n+            logger.info(\"collecting features in \" + interval.getContig() + \":\" + interval.getStart() + \"-\" + interval.getEnd());\n+            for (final Gff3Feature feature : contigFeatures) {\n+                if (groupingType.contains(feature.getType())) {\n+                    final List<Interval> overlappingFeatures = feature.getDescendents().stream().filter(f -> overlapType.contains(f.getType())).map(f -> new Interval(f.getContig(), f.getStart(), f.getEnd())).collect(Collectors.toList());\n+                    final Gff3BaseData shrunkGroupingBaseData = shrinkBaseData(feature.getBaseData());\n+                    addGroupingFeature(shrunkGroupingBaseData, overlappingFeatures);\n+                }\n+            }\n+        }\n+\n+        logger.info(\"Collecting read counts...\");\n+    }\n+\n+    private void validateOutputFile(final File file) {\n+        if (file.exists()) {\n+            if (!Files.isWritable(file.toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        } else {\n+            if (!Files.isWritable(file.getParentFile().toPath())) {\n+                throw new UserException.CouldNotCreateOutputFile(file, \" is not writable\");\n+            }\n+        }\n+    }\n+\n+    private Gff3BaseData shrinkBaseData(final Gff3BaseData baseData) {\n+        //remove all but featureLabelKey attributes\n+        final Map<String, List<String>> shrunkAttributes = baseData.getAttributes().entrySet().stream().filter(e -> e.getKey().equals(featureLabelKey.getKey())).collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue));\n+        return new Gff3BaseData(baseData.getContig(), baseData.getSource(), baseData.getType(), baseData.getStart(), baseData.getEnd(), baseData.getScore(), baseData.getStrand(), baseData.getPhase(), shrunkAttributes);\n+    }\n+\n+    private void addGroupingFeature(final Gff3BaseData groupingBaseData, final List<Interval> overlappingFeatures) {\n+        final String geneLabel = featureLabelKey.getValue(groupingBaseData);\n+        if (geneLabel == null) {\n+            throw new UserException(\"no geneid field \" + featureLabelKey + \" found in feature at \" + groupingBaseData.getContig() + \":\" + groupingBaseData.getStart() + \"-\" + groupingBaseData.getEnd());\n+        }\n+\n+        featureCounts.put(groupingBaseData, new Coverage(0, 0));\n+        for (final Interval overlappingFeature : overlappingFeatures) {\n+            featureOverlapDetector.addLhs(Pair.of(groupingBaseData, overlappingFeature), overlappingFeature);\n+        }\n+    }\n+\n+\n+    static boolean inGoodPair(final GATKRead read, int minimumMappingQuality) {\n+\n+        boolean ret = !read.mateIsUnmapped() && read.isProperlyPaired() && read.getContig().equals(read.getMateContig()) &&\n+                read.isReverseStrand() != read.mateIsReverseStrand();\n+\n+        if (ret) {\n+            if (!read.hasAttribute(SAMTag.MQ.toString())) {\n+                throw new GATKException(\"Mate quality must be included.  Consider running FixMateInformation.\");\n+            }\n+            ret = ret && read.getAttributeAsInteger(SAMTag.MQ.toString()) >= minimumMappingQuality;\n+        }\n+\n+        if (ret) {\n+            if (read.isReverseStrand()) {\n+                ret = ret && read.getEnd() >= read.getMateStart();\n+            } else {\n+                if (!read.hasAttribute(SAMTag.MC.toString())) {\n+                    throw new GATKException(\"Mate cigar must be present.  Consider running FixMateInformation.\");\n+                }\n+                final Cigar mateCigar = TextCigarCodec.decode(read.getAttributeAsString(SAMTag.MC.toString()));\n+                ret = ret && read.getStart() <= read.getMateStart() + mateCigar.getReferenceLength();\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    static List<Interval> getAlignmentIntervals(final GATKRead read, final boolean spliced, final int minimumMappingQuality) {\n+\n+        if (spliced) {\n+            final List<Interval> alignmentIntervals = new ArrayList<>();\n+\n+            final List<AlignmentBlock> readAlignmentBlocks = SAMUtils.getAlignmentBlocks(read.getCigar(), read.getStart(), \"read cigar\");\n+\n+            for( final AlignmentBlock block : readAlignmentBlocks) {\n+                alignmentIntervals.add(new Interval(read.getContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1));\n+            }\n+\n+            boolean overlapsMate = false;\n+            if (inGoodPair(read, minimumMappingQuality)) {\n+                final String mateCigarString = read.getAttributeAsString(SAMTag.MC.toString());\n+                if(mateCigarString == null) {\n+                    throw new GATKException(\"Mate cigar must be present if using spliced reads\");\n+                }\n+                final List<AlignmentBlock> mateAlignmentBlocks = SAMUtils.getAlignmentBlocks(TextCigarCodec.decode(mateCigarString), read.getMateStart(), \"mate cigar\");\n+                for( final AlignmentBlock block : mateAlignmentBlocks) {\n+                    final Interval alignmentBlockInterval = new Interval(read.getMateContig(), block.getReferenceStart(), block.getReferenceStart()+block.getLength() - 1);\n+                    alignmentIntervals.add(alignmentBlockInterval);\n+\n+                    if (!overlapsMate && read.overlaps(alignmentBlockInterval)) {\n+                        overlapsMate = true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4ODA0Ng=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 503}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTk2ODMwOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQyMDowNDoyMFrOGrzpow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDozMjoyMVrOGscLqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4ODE5NQ==", "bodyText": "Consider adding a fragment mate size distance cutoff for this. Document that you currently rely on the aligner", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r448588195", "createdAt": "2020-07-01T20:04:20Z", "author": {"login": "barkasn"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MjI2Ng==", "bodyText": "Added documentation.  I want to avoid a simple fragment size cutoff since it can be easily thwarted by different protocols or splicing.  And I believe most aligners handle fragment sizes in a more sophisticated manner when setting the properly paired flag.", "url": "https://github.com/broadinstitute/gatk/pull/6602#discussion_r449252266", "createdAt": "2020-07-02T20:32:21Z", "author": {"login": "kachulis"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/rnaseq/GeneExpressionEvaluation.java", "diffHunk": "@@ -0,0 +1,667 @@\n+package org.broadinstitute.hellbender.tools.walkers.rnaseq;\n+\n+import htsjdk.samtools.AlignmentBlock;\n+import htsjdk.samtools.Cigar;\n+import htsjdk.samtools.SAMFileHeader;\n+import htsjdk.samtools.SAMReadGroupRecord;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.SAMTag;\n+import htsjdk.samtools.SAMUtils;\n+import htsjdk.samtools.TextCigarCodec;\n+import htsjdk.samtools.util.Interval;\n+import htsjdk.samtools.util.IntervalList;\n+import htsjdk.samtools.util.OverlapDetector;\n+import htsjdk.tribble.annotation.Strand;\n+import htsjdk.tribble.gff.Gff3BaseData;\n+import htsjdk.tribble.gff.Gff3Feature;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.barclay.help.DocumentedFeature;\n+import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n+import org.broadinstitute.hellbender.cmdline.programgroups.CoverageAnalysisProgramGroup;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.engine.filters.AlignmentAgreesWithHeaderReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.MappingQualityReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilter;\n+import org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+\n+import org.broadinstitute.hellbender.utils.IntervalUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import org.broadinstitute.hellbender.utils.tsv.DataLine;\n+import org.broadinstitute.hellbender.utils.tsv.TableColumnCollection;\n+import org.broadinstitute.hellbender.utils.tsv.TableReader;\n+import org.broadinstitute.hellbender.utils.tsv.TableWriter;\n+\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Evaluate gene expression from RNA-seq reads aligned to genome.\n+ *\n+ * <p>This tool evaluates gene expression from RNA-seq reads aligned to genome.  Features to evaluate expression over are defined in an input annotation file in gff3 fomat\n+ * (https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).  Output is a tsv listing sense and antisense expression for all stranded grouping features,\n+ * and expression (labeled as sense) for all unstranded grouping features.\n+ * </p>\n+ * \n+ * <p>\n+ *     <h3>Input</h3>\n+ *     <ul>\n+ *     <li>BAM file of RNA-seq reads</li>\n+ *     <li>Gff3 file of feature annotations</li>\n+ *     </ul>\n+ * </p>\n+ * <p>\n+ *     <h3>Output</h3>\n+ *     TSV file of gene expression\n+ * </p>\n+ *\n+ * <p>\n+ *     <h3>Usage Examples</h3>\n+ *     <p>\n+ *         gatk GeneExpressionEvaluation\n+ *         -I input.bam\n+ *         -G geneAnnotations.gff3\n+ *         -O output.tsv\n+ *     </p>\n+ * </p>\n+ * \n+ *<p>Reads are assumed to be paired-end.  Reads which are in a \"good pair\" are counted once together as a single fragment.  Reads which are not in a \"good pair\" are each counted separately.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4ODE5NQ=="}, "originalCommit": {"oid": "e968371a450b95f2e16b082b45e5a448c70ed414"}, "originalPosition": 79}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 898, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}