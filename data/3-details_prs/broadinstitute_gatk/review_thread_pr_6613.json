{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIwODk2NjM5", "number": 6613, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDoxNzo1NFrOD-YIrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDoxNzo1NFrOD-YIrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NzMzNzQyOnYy", "diffSide": "RIGHT", "path": "src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDoxNzo1NFrOGYcUww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDoxNzo1NFrOGYcUww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI4MzA3NQ==", "bodyText": "Actually, despite our back and forth on Slack, I'm not convinced there's a good argument either way for\ntt.switch(tt.eq(mu_den_sjk, 0.0), 0.0, mu_num_sjk / mu_den_sjk)\nvs.\ntt.switch(tt.eq(mu_den_sjk, 0.0), 1.0, mu_num_sjk / mu_den_sjk).\nIn the first, we heavily penalize the k = 0 case by saying the Poisson rate is eps_mapping * n_s, whereas the likelihood is flat and the Poisson rate is n_s for k > 0.  In the second, the likelihood is flat and the Poisson rate is n_s for all k.\nTo me, it seems strange to treat k = 0 specially.  So I think I might actually favor the second.  But in either case, in practice (where k = 0 is already heavily penalized by the prior), inference is completely determined by the prior, since mean bias and ploidy cancel out of the likelihood.\nAnd in any case, we should check behavior with some simple tests to make sure we've got things straight!", "url": "https://github.com/broadinstitute/gatk/pull/6613#discussion_r428283075", "createdAt": "2020-05-20T20:17:54Z", "author": {"login": "samuelklee"}, "path": "src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py", "diffHunk": "@@ -252,7 +252,10 @@ def __init__(self,\n                       * ploidy_k.dimshuffle('x', 'x', 0))\n         mu_den_sjk = gamma_rest_sj.dimshuffle(0, 1, 'x') + mu_num_sjk\n         eps_mapping_j = eps_mapping * t_j / tt.sum(t_j)  # average number of reads erroneously mapped to contig j\n-        mu_sjk = ((1.0 - eps_mapping) * (mu_num_sjk / mu_den_sjk)\n+\n+        # the switch is required for a single contig edge case\n+        mu_ratio_sjk = tt.switch(tt.eq(mu_den_sjk, 0.0), 0.0, mu_num_sjk / mu_den_sjk)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c922071a8753e6a3b22f4e0c196d7d251f15227"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 913, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}