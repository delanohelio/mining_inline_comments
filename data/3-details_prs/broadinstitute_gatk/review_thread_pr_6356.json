{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwMTczODky", "number": 6356, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo0NTo0OFrODXOZvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMToxMDoyNFrODXRZ8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1Njc5ODA0OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo0NTo0OFrOFcbXog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODozMDo0NlrOFeCL-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1Mjg2Ng==", "bodyText": "Could phrase it this way too: direction: side of read that is clipped (\"left\" or \"right\"). I initially found the use of left and right confusing. If we end up sticking with this data format it might make more sense to use strand labels (left = -, right = +) which also use fewer characters.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365352866", "createdAt": "2020-01-10T17:45:48Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzAzNzQzMg==", "bodyText": "Done, I agree that it would be better to eventually convert to using +/- or some other one-character indicator in the file format.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367037432", "createdAt": "2020-01-15T18:30:46Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1Mjg2Ng=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjgxODgzOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo1NDoyNVrOFcbkoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODozNDoxM1rOFeCSMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg==", "bodyText": "When we migrated GATK4 tools, Geraldine discouraged the use of any \"non-standard\" short arguments (eg -I, -O, -R) because they are hard to interpret at a glance and could end up conflicting across different tools. I tend to agree, although the PE and SR files may become common for us. I'd suggest using -PE and -SR as those shouldn't cause any conflicts and follow the upper-case convention.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356192", "createdAt": "2020-01-10T17:54:25Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjQ2Ng==", "bodyText": "Also do we have a place for defining SV arguments? I think at the very least you should have them as public constants.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356466", "createdAt": "2020-01-10T17:55:05Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzAzOTAyNg==", "bodyText": "Changed to -PE and -SR, and moved argument strings to public static constants.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367039026", "createdAt": "2020-01-15T18:34:13Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjgyMjIzOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo1NTo0NVrOFcbmrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODozNzo0NlrOFeCY4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjcxNg==", "bodyText": "I think this can be final", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356716", "createdAt": "2020-01-10T17:55:45Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MDczOA==", "bodyText": "Done, and made splitPosBuffer and discordantPairs final as well by move initialization from onTraversalStart.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367040738", "createdAt": "2020-01-15T18:37:46Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjcxNg=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjgzMDcxOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNzo1OTowNlrOFcbrxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0MToyMVrOFeCe1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODAyMw==", "bodyText": "Can you do this by overriding getDefaultReadFilters()? That way we have the option of customizing them", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365358023", "createdAt": "2020-01-10T17:59:06Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MjI2Mg==", "bodyText": "Done.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367042262", "createdAt": "2020-01-15T18:41:21Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODAyMw=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzIwMTMyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMDoyNzowM1rOFcfSiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0MzoyMFrOFeCiPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQxNzA5Ng==", "bodyText": "Adds to split read counts list the new prevClippedReadEndPos... (nothing is actually returned)", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365417096", "createdAt": "2020-01-10T20:27:03Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzEzNA==", "bodyText": "Done", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043134", "createdAt": "2020-01-15T18:43:20Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQxNzA5Ng=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzIzMDQyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMDo0MToxN1rOFcflCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0NDo0NFrOFeCklg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw==", "bodyText": "Could replace getBestAvailableSequenceDictionary () with sequenceDictionary", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421833", "createdAt": "2020-01-10T20:41:17Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzUzMA==", "bodyText": "Done", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043530", "createdAt": "2020-01-15T18:44:15Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzczNA==", "bodyText": "Done", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043734", "createdAt": "2020-01-15T18:44:44Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzIzMTUwOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMDo0MTo0N1rOFcflpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0NzoxMFrOFeCo4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTk5MQ==", "bodyText": "Could replace samSequenceDictionary with sequenceDictionary?", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421991", "createdAt": "2020-01-10T20:41:47Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDgzMg==", "bodyText": "This is this way for ease of testing so I might leave it as is..", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367044832", "createdAt": "2020-01-15T18:47:10Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTk5MQ=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzI3MTE0OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMTowMDozM1rOFcf-Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0ODo0NVrOFeCrrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyODMwMg==", "bodyText": "What's this for?", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365428302", "createdAt": "2020-01-10T21:00:33Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read\n+     */\n+    @VisibleForTesting\n+    public void countSplitRead(final GATKRead read, final PriorityQueue<SplitPos> splitCounts, final OutputStreamWriter srWriter) {\n+        final SplitPos splitPosition = getSplitPosition(read);\n+        final int readStart = read.getStart();\n+        if (splitPosition.direction == POSITION.MIDDLE) {\n+            return;\n+        }\n+        if (currentChrom == null) {\n+            currentChrom = read.getContig();\n+        } else if (!currentChrom.equals(read.getContig())) {\n+            flushSplitCounts(splitPos -> true, srWriter, splitCounts);\n+            currentChrom = read.getContig();\n+        } else {\n+            flushSplitCounts(sp -> (sp.pos < readStart - 1), srWriter, splitCounts);\n+        }\n+\n+        splitCounts.add(splitPosition);\n+    }\n+\n+    private void flushSplitCounts(final Predicate<SplitPos> flushablePosition, final OutputStreamWriter srWriter, final PriorityQueue<SplitPos> splitCounts) {\n+\n+        while (splitCounts.size() > 0 && flushablePosition.test(splitCounts.peek())) {\n+            SplitPos pos = splitCounts.poll();\n+            int countAtPos = 1;\n+            while (splitCounts.size() > 0 && splitCounts.peek().equals(pos)) {\n+                countAtPos++;\n+                splitCounts.poll();\n+            }\n+            try {\n+                srWriter.write(currentChrom + \"\\t\" + (pos.pos - 1) + \"\\t\" + pos.direction.getDescription() + \"\\t\" + countAtPos + \"\\t\" + sampleName + \"\\n\");\n+            } catch (IOException e) {\n+                throw new GATKException(\"Could not write to sr file\", e);\n+            }\n+        }\n+    }\n+\n+    private SplitPos getSplitPosition(GATKRead read) {\n+        if (read.getCigar().getFirstCigarElement().getOperator() == CigarOperator.M) {\n+            final int matchLength = read.getCigar().getCigarElements().stream().filter(e -> e.getOperator().consumesReferenceBases()).mapToInt(CigarElement::getLength).sum();\n+            return new SplitPos(read.getStart() + matchLength, POSITION.RIGHT);\n+        } else if (read.getCigar().getLastCigarElement().getOperator() == CigarOperator.M) {\n+            return new SplitPos(read.getStart(), POSITION.LEFT);\n+        }\n+\n+        return new SplitPos(-1, POSITION.MIDDLE);\n+    }\n+\n+    private boolean isSoftClipped(final GATKRead read) {\n+        final CigarOperator firstOperator = read.getCigar().getFirstCigarElement().getOperator();\n+        final CigarOperator lastOperator = read.getCigar().getLastCigarElement().getOperator();\n+        return (firstOperator == CigarOperator.SOFT_CLIP && lastOperator != CigarOperator.SOFT_CLIP) ||\n+                (firstOperator != CigarOperator.SOFT_CLIP && lastOperator == CigarOperator.SOFT_CLIP);\n+    }\n+\n+    @Override\n+    public Object onTraversalSuccess() {\n+        flushSplitCounts(splitPos -> true, srWriter, splitPosBuffer);\n+        flushDiscordantReadPairs();\n+        return null;\n+    }\n+\n+    @Override\n+    public void closeTool() {\n+        super.closeTool();\n+        try {\n+            peWriter.close();\n+            srWriter.close();\n+        } catch (IOException e) {\n+            throw new GATKException(\"error closing output file\", e);\n+        }\n+    }\n+\n+    enum POSITION {\n+        LEFT (\"left\"),\n+        MIDDLE (\"middle\"),\n+        RIGHT (\"right\");\n+\n+        private String description;\n+\n+        POSITION(final String description) {\n+            this.description = description;\n+        }\n+\n+        public String getDescription() {\n+            return description;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NTU1MA==", "bodyText": "Just to store the string that will actually make it into the file VS the name of the enum element. In this case it's just \"left\" vs LEFT, etc..", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367045550", "createdAt": "2020-01-15T18:48:45Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read\n+     */\n+    @VisibleForTesting\n+    public void countSplitRead(final GATKRead read, final PriorityQueue<SplitPos> splitCounts, final OutputStreamWriter srWriter) {\n+        final SplitPos splitPosition = getSplitPosition(read);\n+        final int readStart = read.getStart();\n+        if (splitPosition.direction == POSITION.MIDDLE) {\n+            return;\n+        }\n+        if (currentChrom == null) {\n+            currentChrom = read.getContig();\n+        } else if (!currentChrom.equals(read.getContig())) {\n+            flushSplitCounts(splitPos -> true, srWriter, splitCounts);\n+            currentChrom = read.getContig();\n+        } else {\n+            flushSplitCounts(sp -> (sp.pos < readStart - 1), srWriter, splitCounts);\n+        }\n+\n+        splitCounts.add(splitPosition);\n+    }\n+\n+    private void flushSplitCounts(final Predicate<SplitPos> flushablePosition, final OutputStreamWriter srWriter, final PriorityQueue<SplitPos> splitCounts) {\n+\n+        while (splitCounts.size() > 0 && flushablePosition.test(splitCounts.peek())) {\n+            SplitPos pos = splitCounts.poll();\n+            int countAtPos = 1;\n+            while (splitCounts.size() > 0 && splitCounts.peek().equals(pos)) {\n+                countAtPos++;\n+                splitCounts.poll();\n+            }\n+            try {\n+                srWriter.write(currentChrom + \"\\t\" + (pos.pos - 1) + \"\\t\" + pos.direction.getDescription() + \"\\t\" + countAtPos + \"\\t\" + sampleName + \"\\n\");\n+            } catch (IOException e) {\n+                throw new GATKException(\"Could not write to sr file\", e);\n+            }\n+        }\n+    }\n+\n+    private SplitPos getSplitPosition(GATKRead read) {\n+        if (read.getCigar().getFirstCigarElement().getOperator() == CigarOperator.M) {\n+            final int matchLength = read.getCigar().getCigarElements().stream().filter(e -> e.getOperator().consumesReferenceBases()).mapToInt(CigarElement::getLength).sum();\n+            return new SplitPos(read.getStart() + matchLength, POSITION.RIGHT);\n+        } else if (read.getCigar().getLastCigarElement().getOperator() == CigarOperator.M) {\n+            return new SplitPos(read.getStart(), POSITION.LEFT);\n+        }\n+\n+        return new SplitPos(-1, POSITION.MIDDLE);\n+    }\n+\n+    private boolean isSoftClipped(final GATKRead read) {\n+        final CigarOperator firstOperator = read.getCigar().getFirstCigarElement().getOperator();\n+        final CigarOperator lastOperator = read.getCigar().getLastCigarElement().getOperator();\n+        return (firstOperator == CigarOperator.SOFT_CLIP && lastOperator != CigarOperator.SOFT_CLIP) ||\n+                (firstOperator != CigarOperator.SOFT_CLIP && lastOperator == CigarOperator.SOFT_CLIP);\n+    }\n+\n+    @Override\n+    public Object onTraversalSuccess() {\n+        flushSplitCounts(splitPos -> true, srWriter, splitPosBuffer);\n+        flushDiscordantReadPairs();\n+        return null;\n+    }\n+\n+    @Override\n+    public void closeTool() {\n+        super.closeTool();\n+        try {\n+            peWriter.close();\n+            srWriter.close();\n+        } catch (IOException e) {\n+            throw new GATKException(\"error closing output file\", e);\n+        }\n+    }\n+\n+    enum POSITION {\n+        LEFT (\"left\"),\n+        MIDDLE (\"middle\"),\n+        RIGHT (\"right\");\n+\n+        private String description;\n+\n+        POSITION(final String description) {\n+            this.description = description;\n+        }\n+\n+        public String getDescription() {\n+            return description;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyODMwMg=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 289}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzI4NjYzOnYy", "diffSide": "RIGHT", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollectionUnitTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMTowODozMFrOFcgIYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo0OTowMVrOFeCsRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMDg4MQ==", "bodyText": "This is so cool", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365430881", "createdAt": "2020-01-10T21:08:30Z", "author": {"login": "mwalker174"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollectionUnitTest.java", "diffHunk": "@@ -0,0 +1,128 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import htsjdk.samtools.SAMFileHeader;\n+import org.broadinstitute.hellbender.GATKBaseTest;\n+import org.broadinstitute.hellbender.utils.read.ArtificialReadUtils;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import java.io.OutputStreamWriter;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.PriorityQueue;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+public class PairedEndAndSplitReadEvidenceCollectionUnitTest extends GATKBaseTest {\n+\n+    @Test\n+    public void testGetReportableDiscordantReadPair() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+\n+        // read pair on different contigs\n+        final GATKRead discRPDiffContigsFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 0, 1000, 150);\n+        discRPDiffContigsFirst.setMatePosition(header.getSequence(1).getSequenceName(), 9000);\n+        final GATKRead discRPDiffContigsSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 1, 9000, 150);\n+        discRPDiffContigsSecond.setMatePosition(header.getSequence(0).getSequenceName(), 1000);\n+\n+        // read pair on same contig\n+        final GATKRead discRPSameContigFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 500, 150);\n+        discRPSameContigFirst.setMatePosition(header.getSequence(1).getSequenceName(), 5000);\n+        final GATKRead discRPSameContigSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 5000, 150);\n+        discRPSameContigSecond.setMatePosition(header.getSequence(1).getSequenceName(), 500);\n+\n+        // read pair on same contig, same start position\n+        final GATKRead discRPSameContigSameStartFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartFirst.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+        final GATKRead discRPSameContigSameStartSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartSecond.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+\n+        final HashSet<String> observedDiscordantNamesAtThisLocus = new HashSet<>();\n+\n+        final PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+\n+        PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNotNull(reportableDiscordantReadPair);\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPDiffContigsFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigSameStartFirst);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.contains(discRPSameContigSameStartFirst.getName()));\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.isEmpty());\n+\n+    }\n+\n+    private void assertDiscordantReadInfo(final PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair, final GATKRead gatkRead) {\n+        Assert.assertEquals(reportableDiscordantReadPair.getName(), gatkRead.getName());\n+        Assert.assertEquals(reportableDiscordantReadPair.getContig(), gatkRead.getContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getStart(), gatkRead.getStart());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateContig(), gatkRead.getMateContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateStart(), gatkRead.getMateStart());\n+    }\n+\n+    @Test\n+    public void testCountSplitRead() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+        final GATKRead rightClip = ArtificialReadUtils.createArtificialRead(header, \"rightClip\", 0, 1000, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"100M51S\");\n+\n+        final OutputStreamWriter mockSrWriter = Mockito.mock(OutputStreamWriter.class);\n+\n+        PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+        final PriorityQueue<PairedEndAndSplitReadEvidenceCollection.SplitPos> splitCounts = new PriorityQueue<>(new PairedEndAndSplitReadEvidenceCollection.SplitPosComparator());\n+        tool.sampleName = \"sample\";\n+\n+        tool.countSplitRead(rightClip, splitCounts, mockSrWriter);\n+        Map<PairedEndAndSplitReadEvidenceCollection.SplitPos, Long> counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead rightClip2 = ArtificialReadUtils.createArtificialRead(header, \"rightClip2\", 0, 1050, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"50M101S\");\n+        tool.countSplitRead(rightClip2, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClip = ArtificialReadUtils.createArtificialRead(header, \"leftClip\", 0, 1100, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClip, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClipDownstream = ArtificialReadUtils.createArtificialRead(header, \"leftClipDownstream\", 0, 1600, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClipDownstream, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1600, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"left\" + \"\\t\" + 1 + \"\\t\" + \"sample\" + \"\\n\");\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"right\" + \"\\t\" + 2 + \"\\t\" + \"sample\" + \"\\n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NTcwMw==", "bodyText": "I love Mockito", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367045703", "createdAt": "2020-01-15T18:49:01Z", "author": {"login": "cwhelan"}, "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollectionUnitTest.java", "diffHunk": "@@ -0,0 +1,128 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import htsjdk.samtools.SAMFileHeader;\n+import org.broadinstitute.hellbender.GATKBaseTest;\n+import org.broadinstitute.hellbender.utils.read.ArtificialReadUtils;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import java.io.OutputStreamWriter;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.PriorityQueue;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+public class PairedEndAndSplitReadEvidenceCollectionUnitTest extends GATKBaseTest {\n+\n+    @Test\n+    public void testGetReportableDiscordantReadPair() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+\n+        // read pair on different contigs\n+        final GATKRead discRPDiffContigsFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 0, 1000, 150);\n+        discRPDiffContigsFirst.setMatePosition(header.getSequence(1).getSequenceName(), 9000);\n+        final GATKRead discRPDiffContigsSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 1, 9000, 150);\n+        discRPDiffContigsSecond.setMatePosition(header.getSequence(0).getSequenceName(), 1000);\n+\n+        // read pair on same contig\n+        final GATKRead discRPSameContigFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 500, 150);\n+        discRPSameContigFirst.setMatePosition(header.getSequence(1).getSequenceName(), 5000);\n+        final GATKRead discRPSameContigSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 5000, 150);\n+        discRPSameContigSecond.setMatePosition(header.getSequence(1).getSequenceName(), 500);\n+\n+        // read pair on same contig, same start position\n+        final GATKRead discRPSameContigSameStartFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartFirst.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+        final GATKRead discRPSameContigSameStartSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartSecond.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+\n+        final HashSet<String> observedDiscordantNamesAtThisLocus = new HashSet<>();\n+\n+        final PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+\n+        PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNotNull(reportableDiscordantReadPair);\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPDiffContigsFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigSameStartFirst);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.contains(discRPSameContigSameStartFirst.getName()));\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.isEmpty());\n+\n+    }\n+\n+    private void assertDiscordantReadInfo(final PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair, final GATKRead gatkRead) {\n+        Assert.assertEquals(reportableDiscordantReadPair.getName(), gatkRead.getName());\n+        Assert.assertEquals(reportableDiscordantReadPair.getContig(), gatkRead.getContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getStart(), gatkRead.getStart());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateContig(), gatkRead.getMateContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateStart(), gatkRead.getMateStart());\n+    }\n+\n+    @Test\n+    public void testCountSplitRead() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+        final GATKRead rightClip = ArtificialReadUtils.createArtificialRead(header, \"rightClip\", 0, 1000, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"100M51S\");\n+\n+        final OutputStreamWriter mockSrWriter = Mockito.mock(OutputStreamWriter.class);\n+\n+        PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+        final PriorityQueue<PairedEndAndSplitReadEvidenceCollection.SplitPos> splitCounts = new PriorityQueue<>(new PairedEndAndSplitReadEvidenceCollection.SplitPosComparator());\n+        tool.sampleName = \"sample\";\n+\n+        tool.countSplitRead(rightClip, splitCounts, mockSrWriter);\n+        Map<PairedEndAndSplitReadEvidenceCollection.SplitPos, Long> counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead rightClip2 = ArtificialReadUtils.createArtificialRead(header, \"rightClip2\", 0, 1050, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"50M101S\");\n+        tool.countSplitRead(rightClip2, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClip = ArtificialReadUtils.createArtificialRead(header, \"leftClip\", 0, 1100, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClip, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClipDownstream = ArtificialReadUtils.createArtificialRead(header, \"leftClipDownstream\", 0, 1600, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClipDownstream, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1600, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"left\" + \"\\t\" + 1 + \"\\t\" + \"sample\" + \"\\n\");\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"right\" + \"\\t\" + 2 + \"\\t\" + \"sample\" + \"\\n\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMDg4MQ=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzI5MDA4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMToxMDoyNFrOFcgKig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo1NToxOFrOFeC3Ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMTQzNA==", "bodyText": "Can you make a class out of this? Could be useful in the future", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365431434", "createdAt": "2020-01-10T21:10:24Z", "author": {"login": "mwalker174"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0ODUzOQ==", "bodyText": "Wrapped this up in a static inner class for now.", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367048539", "createdAt": "2020-01-15T18:55:18Z", "author": {"login": "cwhelan"}, "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMTQzNA=="}, "originalCommit": {"oid": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851"}, "originalPosition": 175}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1215, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}