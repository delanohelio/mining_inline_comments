{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA0MTg3NzA1", "number": 4303, "title": "DB-9924 NSDS v2 Streaming Performance", "bodyText": "", "createdAt": "2020-10-15T15:23:48Z", "url": "https://github.com/splicemachine/spliceengine/pull/4303", "merged": true, "mergeCommit": {"oid": "0c877548f302a90ac16d76f823c61b675a803dab"}, "closed": true, "closedAt": "2020-10-30T09:53:17Z", "author": {"login": "jpanko1"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc8ZgXZgH2gAyNTA0MTg3NzA1OjUwM2IwN2M3MjA5NmNlOWRhMmIyYjE5OWI2MGYyMGQ3Y2NmNjdmMmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdXbcGCgFqTUyMDE5NzAxNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "503b07c72096ce9da2b2b199b60f20d7ccf67f2d", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/503b07c72096ce9da2b2b199b60f20d7ccf67f2d", "committedDate": "2020-08-07T00:44:31Z", "message": "DB-9924 Performance tuning."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a32d004fe21667a20bc7feaa45c597626807cd95", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/a32d004fe21667a20bc7feaa45c597626807cd95", "committedDate": "2020-08-07T00:46:47Z", "message": "DB-9924 Shutting down Zookeeper last helps Kafka restart reliably more often."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4954ab5e846469a054bca0b02d18634f5f1687c", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/d4954ab5e846469a054bca0b02d18634f5f1687c", "committedDate": "2020-08-07T00:52:21Z", "message": "DB-9924 Enable kafka topic creation with num partitions and replication factor. Random partition assignment when sending data to Kafka."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e67ce530cd65e189a224ab5693e2ef172c74d1d8", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/e67ce530cd65e189a224ab5693e2ef172c74d1d8", "committedDate": "2020-08-15T00:31:26Z", "message": "DB-9924 Added sleep to ensure topics are created and ready."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bad6f2d865739646547280930e769bd60983b52", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/3bad6f2d865739646547280930e769bd60983b52", "committedDate": "2020-08-15T00:34:10Z", "message": "DB-9924 Changed random partition assignment to default in kafka producer."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b559ee23f37fb504fb37af8733497b312332ae7", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/9b559ee23f37fb504fb37af8733497b312332ae7", "committedDate": "2020-09-09T19:14:58Z", "message": "DB-9924 Latest NSDS updates."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09d48fbc73d8073239ed81a381c1c462980f52c9", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/09d48fbc73d8073239ed81a381c1c462980f52c9", "committedDate": "2020-09-16T16:40:02Z", "message": "DB-9924 Latest NSDS updates."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b7781042b1eac3978e035a3ff61e7ccd522f2bb", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/1b7781042b1eac3978e035a3ff61e7ccd522f2bb", "committedDate": "2020-09-17T16:29:09Z", "message": "DB-9924 Added end of batch marker when passing data from nsds to the DB."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29c861da0263fdf28b8efba4f5b26b51ca22bf59", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/29c861da0263fdf28b8efba4f5b26b51ca22bf59", "committedDate": "2020-09-18T14:37:03Z", "message": "DB-9924 Latest update for NSDS."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6460c6705de54874f07b4923f04e39bb58d91f7f", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/6460c6705de54874f07b4923f04e39bb58d91f7f", "committedDate": "2020-09-24T17:39:57Z", "message": "DB-9924 NSDS v2 latest updates."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87597157af221ac7613a1472913352239fecaf10", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/87597157af221ac7613a1472913352239fecaf10", "committedDate": "2020-10-15T08:40:41Z", "message": "DB-9924 NSDS v2 Added kryo serialization."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8304c61d5723be2181b8b20a48b9a393032cc40", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/e8304c61d5723be2181b8b20a48b9a393032cc40", "committedDate": "2020-10-15T09:10:02Z", "message": "DB-9924 NSDS v2 Added kryo serialization."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e668872b8a18b12903a04f001db83cd3e75898ef", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/e668872b8a18b12903a04f001db83cd3e75898ef", "committedDate": "2020-10-15T10:41:54Z", "message": "Merge branch 'master' into DB-9924"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/08e8c53eea34e7b7116af18293f24fe0f59d75db", "committedDate": "2020-10-15T11:02:08Z", "message": "DB-9924 NSDS v2 copy latest updates to spark3.0"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEwODUzNDUx", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-510853451", "createdAt": "2020-10-17T00:07:23Z", "commit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xN1QwMDowNzoyM1rOHjSr0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xN1QwMDowNzoyM1rOHjSr0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc2ODMzOA==", "bodyText": "Is this our naming convention for kafka partition?", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r506768338", "createdAt": "2020-10-17T00:07:23Z", "author": {"login": "jyuanca"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkDataSetProcessor.java", "diffHunk": "@@ -1268,13 +1268,29 @@ public void decrementOpDepth() {\n         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n         props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ExternalizableDeserializer.class.getName());\n \n-        KafkaConsumer<Integer, Externalizable> consumer = new KafkaConsumer<Integer, Externalizable>(props);\n-        List ps = consumer.partitionsFor(topicName);\n-        List<Integer> partitions = new ArrayList<>(ps.size());\n-        for (int i = 0; i < ps.size(); ++i) {\n-            partitions.add(i);\n+        List<Integer> partitions;\n+        String topicName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyNDkzMTUw", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-512493150", "createdAt": "2020-10-20T09:09:27Z", "commit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyNDk5NTYx", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-512499561", "createdAt": "2020-10-20T09:16:08Z", "commit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQwOToxNjowOFrOHkyrOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQwOTozNTozMlrOHkze-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM0MTA0OQ==", "bodyText": "What happens when we reach 10 retries? It looks like we silently drop data.", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r508341049", "createdAt": "2020-10-20T09:16:08Z", "author": {"login": "dgomezferro"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/KafkaReadFunction.java", "diffHunk": "@@ -67,59 +69,99 @@ public KafkaReadFunction(OperationContext context, String topicName, String boot\n         props.put(ConsumerConfig.CLIENT_ID_CONFIG, consumer_id);\n \n         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n-        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ExternalizableDeserializer.class.getName());\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n         props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        \n+        // MAX_POLL_RECORDS_CONFIG helped performance in standalone with lower values (default == 500).\n+        //  With high values, it spent too much time retrieving records from Kafka.\n+        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, \"100\");\n+//        props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, \"10485760\"); // 10% of max == 5242880, default == 1048576\n \n-        KafkaConsumer<Integer, Externalizable> consumer = new KafkaConsumer<Integer, Externalizable>(props);\n+        KafkaConsumer<Integer, byte[]> consumer = new KafkaConsumer<Integer, byte[]>(props);\n         consumer.assign(Arrays.asList(new TopicPartition(topicName, partition)));\n \n+        KryoSerialization kryo = new KryoSerialization();\n+        kryo.init();\n+\n         return new Iterator<ExecRow>() {\n-            Iterator<ConsumerRecord<Integer, Externalizable>> it = null;\n-            \n-            Predicate<ConsumerRecords<Integer, Externalizable>> noRecords = records ->\n+            Iterator<ConsumerRecord<Integer, byte[]>> it = null;\n+            Message prevMessage = new Message();\n+\n+            Predicate<ConsumerRecords<Integer, byte[]>> noRecords = records ->\n                 records == null || records.isEmpty();\n             \n-            private ConsumerRecords<Integer, Externalizable> kafkaRecords(int maxAttempts) throws TaskKilledException {\n+            long totalCount = 0L;\n+            int maxRetries = 10;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM0NTQzMw==", "bodyText": "Serializing ValueRows directly with Kryo still has quite a bit of overhead (we are serializing the schema with each row, for instance). I opened https://splicemachine.atlassian.net/browse/DB-10543 to track this improvement", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r508345433", "createdAt": "2020-10-20T09:22:32Z", "author": {"login": "dgomezferro"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/KafkaReadFunction.java", "diffHunk": "@@ -67,59 +69,99 @@ public KafkaReadFunction(OperationContext context, String topicName, String boot\n         props.put(ConsumerConfig.CLIENT_ID_CONFIG, consumer_id);\n \n         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n-        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ExternalizableDeserializer.class.getName());\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n         props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        \n+        // MAX_POLL_RECORDS_CONFIG helped performance in standalone with lower values (default == 500).\n+        //  With high values, it spent too much time retrieving records from Kafka.\n+        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, \"100\");\n+//        props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, \"10485760\"); // 10% of max == 5242880, default == 1048576\n \n-        KafkaConsumer<Integer, Externalizable> consumer = new KafkaConsumer<Integer, Externalizable>(props);\n+        KafkaConsumer<Integer, byte[]> consumer = new KafkaConsumer<Integer, byte[]>(props);\n         consumer.assign(Arrays.asList(new TopicPartition(topicName, partition)));\n \n+        KryoSerialization kryo = new KryoSerialization();\n+        kryo.init();\n+\n         return new Iterator<ExecRow>() {\n-            Iterator<ConsumerRecord<Integer, Externalizable>> it = null;\n-            \n-            Predicate<ConsumerRecords<Integer, Externalizable>> noRecords = records ->\n+            Iterator<ConsumerRecord<Integer, byte[]>> it = null;\n+            Message prevMessage = new Message();\n+\n+            Predicate<ConsumerRecords<Integer, byte[]>> noRecords = records ->\n                 records == null || records.isEmpty();\n             \n-            private ConsumerRecords<Integer, Externalizable> kafkaRecords(int maxAttempts) throws TaskKilledException {\n+            long totalCount = 0L;\n+            int maxRetries = 10;\n+            int retries = 0;\n+            final Duration shortTimeout = java.time.Duration.ofMillis(500L);\n+            final Duration longTimeout = java.time.Duration.ofMinutes(1L);\n+            \n+            private ConsumerRecords<Integer, byte[]> kafkaRecords(int maxAttempts, Duration timeout) throws TaskKilledException {\n                 int attempt = 1;\n-                ConsumerRecords<Integer, Externalizable> records = null;\n+                ConsumerRecords<Integer, byte[]> records = null;\n                 do {\n-                    records = consumer.poll(java.time.Duration.ofMillis(1000));\n+                    records = consumer.poll(timeout);\n                     if (TaskContext.get().isInterrupted()) {\n-                        consumer.close();\n+                        LOG.warn( id+\" KRF.call kafkaRecords Spark TaskContext Interrupted\");\n+                        //consumer.close();\n                         throw new TaskKilledException();\n                     }\n                 } while( noRecords.test(records) && attempt++ < maxAttempts );\n                 \n                 return records;\n             }\n             \n-            private boolean hasMoreRecords(int maxAttempts) throws TaskKilledException {\n-                ConsumerRecords<Integer, Externalizable> records = kafkaRecords(maxAttempts);\n+            private boolean hasMoreRecords(int maxAttempts, Duration timeout) throws TaskKilledException {\n+                ConsumerRecords<Integer, byte[]> records = kafkaRecords(maxAttempts, timeout);\n                 if( noRecords.test(records) ) {\n-                    consumer.close();\n+                    if( !prevMessage.last() && retries < maxRetries ) {\n+                        retries++;\n+                        Duration retryTimeout = longTimeout;\n+                        LOG.warn( id+\" KRF.call Missed rcds, got \"+totalCount+\" retry \"+retries+\" for up to \"+retryTimeout );\n+                        return hasMoreRecords(\n+                            maxAttempts,\n+                            retryTimeout\n+                        );\n+                    }\n+                    //consumer.close();\n+                    if( !prevMessage.last() ) {\n+                        LOG.error(id + \" KRF.call Didn't get full batch after \" + retries + \" retries, got \" + totalCount + \" records\");\n+                    }\n                     return false;\n                 } else {\n+                    int ct = records.count();\n+                    totalCount += ct;\n+                    LOG.trace( id+\" KRF.call p \"+partition+\" t \"+topicName+\" records \"+ct );\n+                    retries = 0;\n+                    \n                     it = records.iterator();\n                     return it.hasNext();\n                 }\n             }\n-\n+            \n             @Override\n             public boolean hasNext() {\n-                if (it == null) {\n-                    return hasMoreRecords(60);\n-                }\n-                if (it.hasNext()) {\n-                    return true;\n+                boolean more = false;\n+                \n+                if (it != null && it.hasNext()) {\n+                    more = true;\n+                } else if (!prevMessage.last()) {\n+                    more = hasMoreRecords(1, shortTimeout);\n                 }\n-                else {\n-                    return hasMoreRecords(1);\n+\n+                if (!more) {\n+                    consumer.close();\n+                    kryo.close();\n                 }\n+\n+                return more;\n             }\n \n             @Override\n             public ExecRow next() {\n-                return (ExecRow)it.next().value();\n+                Message m = (Message)kryo.deserialize( it.next().value() );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM0NjYwMA==", "bodyText": "remove", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r508346600", "createdAt": "2020-10-20T09:24:14Z", "author": {"login": "dgomezferro"}, "path": "splice_spark2/src/main/scala/com/splicemachine/nsds/kafka/KafkaAdmin.scala", "diffHunk": "@@ -17,28 +17,37 @@ package com.splicemachine.nsds.kafka\n \n import java.util.Properties\n import java.util.concurrent.TimeUnit\n-import org.apache.kafka.clients.admin.AdminClient\n-import org.apache.kafka.clients.admin.AdminClientConfig\n+\n+import org.apache.kafka.clients.admin.{AdminClient, AdminClientConfig, NewTopic}\n import org.apache.kafka.common.KafkaFuture\n+\n import scala.collection.JavaConverters._\n \n-class KafkaAdmin(kafkaServers: String) {\n+@SerialVersionUID(20200722241L)\n+class KafkaAdmin(kafkaServers: String) extends Serializable {\n   val props = new Properties()\n   props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers)\n   val admin = AdminClient.create( props )\n   \n+  def createTopics(topicNames: collection.mutable.Set[String], numParitions: Int, repFactor: Short): Unit = {\n+    admin.createTopics(\n+      topicNames.map(new NewTopic(_,numParitions,repFactor)).asJava\n+    ).all.get\n+//    Thread.sleep(1000)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM1MDgzMg==", "bodyText": "We shouldn't print to console, use Debugging output instead", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r508350832", "createdAt": "2020-10-20T09:30:19Z", "author": {"login": "dgomezferro"}, "path": "splice_spark2/src/main/spark2.2/com/splicemachine/spark2/splicemachine/SplicemachineContext.scala", "diffHunk": "@@ -489,68 +552,269 @@ class SplicemachineContext(options: Map[String, String]) extends Serializable {\n    * @param schema\n    * @param schemaTableName\n    */\n-  def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String): Unit = insert(rdd, schema, schemaTableName, Map[String,String]())\n+  def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String): Long = insert(rdd, schema, schemaTableName, Map[String,String]())\n \n   private[this] def columnList(schema: StructType): String = SpliceJDBCUtil.listColumns(schema.fieldNames)\n   private[this] def schemaString(schema: StructType): String = SpliceJDBCUtil.schemaWithoutNullableString(schema, url).replace(\"\\\"\",\"\")\n \n-  private[this] def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String, spliceProperties: scala.collection.immutable.Map[String,String]): Unit = {\n-    val topicName = kafkaTopics.create\n+  private[this] def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String, \n+                           spliceProperties: scala.collection.immutable.Map[String,String]): Long = /*if( ! rdd.isEmpty )*/ {\n+    println(s\"${java.time.Instant.now} SMC.ins get topic name\")\n+    val topicName = kafkaTopics.create()\n //    println( s\"SMC.insert topic $topicName\" )\n \n     // hbase user has read/write permission on the topic\n     try {\n+      insAccum.reset\n+      lastRowsToSend.reset\n+      println(s\"${java.time.Instant.now} SMC.ins sendData\")\n       sendData(topicName, rdd, schema)\n+      sendData(lastRowsToSend.value.asScala, true)\n+\n+      if( ! insAccum.isZero ) {\n+        println(s\"${java.time.Instant.now} SMC.ins prepare sql\")\n+        val colList = columnList(schema) + fmColList\n+        val sProps = spliceProperties.map({ case (k, v) => k + \"=\" + v }).fold(\"--splice-properties useSpark=true\")(_ + \", \" + _)\n+        val sqlText = \"insert into \" + schemaTableName + \" (\" + colList + \") \" + sProps + \"\\nselect \" + colList + \" from \" +\n+          \"new com.splicemachine.derby.vti.KafkaVTI('\" + topicName + \"') \" +\n+          \"as SpliceDatasetVTI (\" + schemaString(schema) + fmSchemaStr + \")\"\n+\n+        println( s\"SMC.insert sql $sqlText\" )\n+        println(s\"${java.time.Instant.now} SMC.ins executeUpdate\")\n+        executeUpdate(sqlText)\n+        println(s\"${java.time.Instant.now} SMC.ins done\")\n+      }\n+      \n+      insAccum.sum\n+    } finally {\n+      kafkaTopics.delete(topicName)\n+    }\n+  }\n+\n+  private[this] val activePartitionAcm =\n+    SparkSession.builder.getOrCreate.sparkContext.collectionAccumulator[String](\"ActivePartitions\")\n \n-      val colList = columnList(schema)\n-      val sProps = spliceProperties.map({ case (k, v) => k + \"=\" + v }).fold(\"--splice-properties useSpark=true\")(_ + \", \" + _)\n-      val sqlText = \"insert into \" + schemaTableName + \" (\" + colList + \") \" + sProps + \"\\nselect \" + colList + \" from \" +\n-        \"new com.splicemachine.derby.vti.KafkaVTI('\" + topicName + \"') \" +\n-        \"as SpliceDatasetVTI (\" + schemaString(schema) + \")\"\n+  def activePartitions(df: DataFrame): Seq[Int] = {\n+    activePartitionAcm.reset\n+    df.rdd.mapPartitionsWithIndex((p, itr) => {\n+      activePartitionAcm.add( s\"$p ${itr.nonEmpty}\" )\n+      Iterator.apply(\"OK\")\n+    }).collect\n+  \n+    activePartitionAcm.value.asScala.filter( _.endsWith(\"true\") ).map( _.split(\" \")(0).toInt )\n+  }\n+\n+  var insertSql: String => String = _\n+  \n+  /* Sets up insertSql to be used by insert_streaming */\n+  def setTable(schemaTableName: String, schema: StructType): Unit = {\n+    val colList = columnList(schema) + fmColList\n+    val schStr = schemaString(schema)\n+    // Line break at the end of the first line and before select is required, other line breaks aren't required\n+    insertSql = (topicName: String) => s\"\"\"insert into $schemaTableName ($colList)\n+                                       select $colList from \n+      new com.splicemachine.derby.vti.KafkaVTI('$topicName') \n+      as SpliceDatasetVTI ($schStr$fmSchemaStr)\"\"\"\n+  }\n+  \n+  private[this] def log(msg: String): Unit = {\n+    Holder.log.info(msg)\n+    println(s\"${java.time.Instant.now} $msg\")\n+  }\n \n-      //println( s\"SMC.insert sql $sqlText\" )\n+  def insert_streaming(topicInfo: String, retries: Int = 0): Unit = {\n+    val topicName = if( topicInfo.contains(\"::\") ) {\n+      topicInfo.split(\"::\")(0)\n+    } else {\n+      topicInfo\n+    }\n+    try {\n+      log(\"SMC.inss prepare sql\")\n+      val sqlText = insertSql(topicInfo)\n+      log(s\"SMC.inss sql $sqlText\")\n+      \n+      //log( s\"SMC.inss topicCount preex ${KafkaUtils.messageCount(kafkaServers, topicName)}\")\n+      \n+      log(\"SMC.inss executeUpdate\")\n       executeUpdate(sqlText)\n+      log(\"SMC.inss done\")\n+\n+      log( s\"SMC.inss topicCount postex ${KafkaUtils.messageCount(kafkaServers, topicName)}\")\n+    } catch {\n+      case e: java.sql.SQLNonTransientConnectionException => \n+        if( retries < 2 ) {\n+          insert_streaming(topicInfo, retries + 1)\n+        }\n     } finally {\n       kafkaTopics.delete(topicName)\n     }\n   }\n \n-  private[this] def sendData(topicName: String, rdd: JavaRDD[Row], schema: StructType): Unit =\n+  def newTopic_streaming(): String = {\n+    log(\"SMC.nit get topic name\")\n+    kafkaTopics.create()\n+  }\n+  \n+  def sendData_streaming(dataFrame: DataFrame, topicName: String): (Seq[RowForKafka], Long) = {\n+    insAccum.reset\n+    lastRowsToSend.reset\n+    println(s\"${java.time.Instant.now} SMC.sds sendData\")\n+    sendData(topicName, dataFrame.rdd, dataFrame.schema)\n+\n+    val rows = lastRowsToSend.value.asScala\n+    //println(s\"${java.time.Instant.now} SMC.sds last rows ${rows.mkString(\"\\n\")}\")\n+\n+    (rows, insAccum.sum)\n+  }\n+  \n+  /** checkRecovery was written to help debug an issue and normally won't need to be called. */\n+  private[this] def checkRecovery(\n+     id: String,\n+     topicName: String, \n+     partition: Int, \n+     itr: Iterator[Row],\n+     schema: StructType\n+   ): Unit = {\n+\n+    val lastVR = KafkaUtils.lastMessageOf(kafkaServers, topicName, partition)\n+      .asInstanceOf[KafkaReadFunction.Message].vr\n+    val cols = if( lastVR.length > 0) { Range(0,lastVR.length-1).toArray } else { Array(0) }\n+    val lastKHash = lastVR.hashCode(cols)\n+\n+    val khashcodes = KafkaUtils.messagesFrom(kafkaServers, topicName, partition)\n+      .map( _.asInstanceOf[KafkaReadFunction.Message].vr.hashCode(cols) )\n+\n+    println(s\"$id SMC.checkRecovery 1st Kafka hashcode ${khashcodes.headOption.getOrElse(-1)}\" )\n+    \n+    var i = 0\n+    var res = Seq.empty[String]\n+    while( itr.hasNext ) {\n+      val hashcode = externalizable(itr.next, schema, partition).hashCode(cols)\n+      res = res :+ s\"$i,${khashcodes.indexOf(hashcode)}\\t${hashcode==lastKHash}\"\n+      i += 1\n+    }\n+    \n+    println(s\"$id SMC.checkRecovery res: Kafka count ${khashcodes.size}\\n${res.mkString(\"\\n\")}\")\n+  }\n+  \n+  private[this] var sendDataTimestamp: Long = _\n+  \n+  private[this] def sendData(topicName: String, rdd: JavaRDD[Row], schema: StructType): Unit = {\n+    sendDataTimestamp = System.currentTimeMillis\n     rdd.rdd.mapPartitionsWithIndex(\n       (partition, itrRow) => {\n-        val taskContext = TaskContext.get\n+        val id = topicName.substring(0,5)+\":\"+partition.toString\n+        //println(s\"$id SMC.sendData p== $partition\")\n \n-        var msgIdx = 0\n-        if (taskContext != null && taskContext.attemptNumber > 0) {\n-          val entriesInKafka = KafkaUtils.messageCount(kafkaServers, topicName, partition)\n-          for(i <- (1: Long) to entriesInKafka) {\n-            itrRow.next\n+        var msgCount = 0\n+        val taskContext = TaskContext.get\n+        val itr = if (taskContext != null && taskContext.attemptNumber > 0) {\n+          // Recover from previous task failure\n+          // Be sure the iterator is advanced past the items previously published to Kafka\n+          \n+          println(s\"$id SMC.sendData Retry $partition ${taskContext.attemptNumber} ${insAccum.sum}\")\n+\n+          //val itr12 = itrRow //.duplicate\n+          //checkRecovery(id, topicName, partition, itr12._1, schema)\n+\n+          val lastMsg = KafkaUtils.lastMessageOf(kafkaServers, topicName, partition)\n+          if( lastMsg.isEmpty ) {\n+            itrRow\n+          } else {\n+            val lastVR = lastMsg.get.asInstanceOf[KafkaReadFunction.Message].vr\n+            val hashCols = if( lastVR.length > 0) { Range(0,lastVR.length-1).toArray } else { Array(0) }\n+            val lastKHash = lastVR.hashCode(hashCols)\n+            def hash: Row => Int = row => externalizable(row, schema, partition).hashCode(hashCols)\n+            \n+            //val itr34 = itr12._2.duplicate\n+            val itr34 = itrRow.duplicate   //itr12.duplicate\n+            \n+            val inKafka_NotInKafka = itr34._1.span( hash(_) != lastKHash )\n+            if( inKafka_NotInKafka._2.hasNext ) {\n+              inKafka_NotInKafka._2.next  // matches the last item in Kafka, get past it\n+              //println(s\"$id SMC.sendData Retry skip ${hash(r)} $lastKHash\")\n+              msgCount = inKafka_NotInKafka._1.size + 1  // this message count was lost during previous task failure\n+              inKafka_NotInKafka._2\n+            } else {  // itrRow starts after the last item added to Kafka\n+              itr34._2\n+            }\n           }\n-          msgIdx = entriesInKafka.asInstanceOf[Int]\n+        } else {\n+          itrRow\n         }\n \n         val props = new Properties\n         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers)\n         props.put(ProducerConfig.CLIENT_ID_CONFIG, \"spark-producer-s2s-smc-\"+java.util.UUID.randomUUID() )\n         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[IntegerSerializer].getName)\n-        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[ExternalizableSerializer].getName)\n-\n-        val producer = new KafkaProducer[Integer, Externalizable](props)\n-\n-        while( itrRow.hasNext ) {\n-          producer.send( new ProducerRecord(topicName, msgIdx, externalizable(itrRow.next, schema)) )\n-          msgIdx += 1\n+        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)\n+//        // Throughput performance?\n+//        println(s\"SMC.sendData batch 1MB linger 750ms\")\n+//        props.put(ProducerConfig.BATCH_SIZE_CONFIG, (1000*1000).toString )\n+//        props.put(ProducerConfig.LINGER_MS_CONFIG, \"500\")\n+\n+        val producer = new KafkaProducer[Integer, Array[Byte]](props)\n+        \n+        val rowK = new RowForKafka(topicName, partition, schema)\n+        rowK.sparkRow = if( itr.hasNext ) {\n+          msgCount += 1\n+          Some(itr.next)\n+        } else None\n+        rowK.msgCount = msgCount\n+        \n+        val kryo = new KryoSerialization()\n+        kryo.init\n+        \n+        while( itr.hasNext ) {\n+          rowK.valueRow = Some(externalizable(rowK.sparkRow.get, schema, partition))\n+          rowK.send(producer, kryo)\n+          msgCount += 1\n+          rowK.sparkRow = Some(itr.next)\n+          rowK.msgCount = msgCount\n         }\n+        lastRowsToSend.add(rowK)\n+        \n+        kryo.close\n \n+        insAccum.add(msgCount)\n+\n+        println(s\"$id SMC.sendData t $topicName p $partition records $msgCount\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 422}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM1NDI5OA==", "bodyText": "Can you explain a bit what's going on here? The naming of variables is a bit confusing.", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r508354298", "createdAt": "2020-10-20T09:35:32Z", "author": {"login": "dgomezferro"}, "path": "splice_spark2/src/main/spark2.2/com/splicemachine/spark2/splicemachine/SplicemachineContext.scala", "diffHunk": "@@ -489,68 +552,269 @@ class SplicemachineContext(options: Map[String, String]) extends Serializable {\n    * @param schema\n    * @param schemaTableName\n    */\n-  def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String): Unit = insert(rdd, schema, schemaTableName, Map[String,String]())\n+  def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String): Long = insert(rdd, schema, schemaTableName, Map[String,String]())\n \n   private[this] def columnList(schema: StructType): String = SpliceJDBCUtil.listColumns(schema.fieldNames)\n   private[this] def schemaString(schema: StructType): String = SpliceJDBCUtil.schemaWithoutNullableString(schema, url).replace(\"\\\"\",\"\")\n \n-  private[this] def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String, spliceProperties: scala.collection.immutable.Map[String,String]): Unit = {\n-    val topicName = kafkaTopics.create\n+  private[this] def insert(rdd: JavaRDD[Row], schema: StructType, schemaTableName: String, \n+                           spliceProperties: scala.collection.immutable.Map[String,String]): Long = /*if( ! rdd.isEmpty )*/ {\n+    println(s\"${java.time.Instant.now} SMC.ins get topic name\")\n+    val topicName = kafkaTopics.create()\n //    println( s\"SMC.insert topic $topicName\" )\n \n     // hbase user has read/write permission on the topic\n     try {\n+      insAccum.reset\n+      lastRowsToSend.reset\n+      println(s\"${java.time.Instant.now} SMC.ins sendData\")\n       sendData(topicName, rdd, schema)\n+      sendData(lastRowsToSend.value.asScala, true)\n+\n+      if( ! insAccum.isZero ) {\n+        println(s\"${java.time.Instant.now} SMC.ins prepare sql\")\n+        val colList = columnList(schema) + fmColList\n+        val sProps = spliceProperties.map({ case (k, v) => k + \"=\" + v }).fold(\"--splice-properties useSpark=true\")(_ + \", \" + _)\n+        val sqlText = \"insert into \" + schemaTableName + \" (\" + colList + \") \" + sProps + \"\\nselect \" + colList + \" from \" +\n+          \"new com.splicemachine.derby.vti.KafkaVTI('\" + topicName + \"') \" +\n+          \"as SpliceDatasetVTI (\" + schemaString(schema) + fmSchemaStr + \")\"\n+\n+        println( s\"SMC.insert sql $sqlText\" )\n+        println(s\"${java.time.Instant.now} SMC.ins executeUpdate\")\n+        executeUpdate(sqlText)\n+        println(s\"${java.time.Instant.now} SMC.ins done\")\n+      }\n+      \n+      insAccum.sum\n+    } finally {\n+      kafkaTopics.delete(topicName)\n+    }\n+  }\n+\n+  private[this] val activePartitionAcm =\n+    SparkSession.builder.getOrCreate.sparkContext.collectionAccumulator[String](\"ActivePartitions\")\n \n-      val colList = columnList(schema)\n-      val sProps = spliceProperties.map({ case (k, v) => k + \"=\" + v }).fold(\"--splice-properties useSpark=true\")(_ + \", \" + _)\n-      val sqlText = \"insert into \" + schemaTableName + \" (\" + colList + \") \" + sProps + \"\\nselect \" + colList + \" from \" +\n-        \"new com.splicemachine.derby.vti.KafkaVTI('\" + topicName + \"') \" +\n-        \"as SpliceDatasetVTI (\" + schemaString(schema) + \")\"\n+  def activePartitions(df: DataFrame): Seq[Int] = {\n+    activePartitionAcm.reset\n+    df.rdd.mapPartitionsWithIndex((p, itr) => {\n+      activePartitionAcm.add( s\"$p ${itr.nonEmpty}\" )\n+      Iterator.apply(\"OK\")\n+    }).collect\n+  \n+    activePartitionAcm.value.asScala.filter( _.endsWith(\"true\") ).map( _.split(\" \")(0).toInt )\n+  }\n+\n+  var insertSql: String => String = _\n+  \n+  /* Sets up insertSql to be used by insert_streaming */\n+  def setTable(schemaTableName: String, schema: StructType): Unit = {\n+    val colList = columnList(schema) + fmColList\n+    val schStr = schemaString(schema)\n+    // Line break at the end of the first line and before select is required, other line breaks aren't required\n+    insertSql = (topicName: String) => s\"\"\"insert into $schemaTableName ($colList)\n+                                       select $colList from \n+      new com.splicemachine.derby.vti.KafkaVTI('$topicName') \n+      as SpliceDatasetVTI ($schStr$fmSchemaStr)\"\"\"\n+  }\n+  \n+  private[this] def log(msg: String): Unit = {\n+    Holder.log.info(msg)\n+    println(s\"${java.time.Instant.now} $msg\")\n+  }\n \n-      //println( s\"SMC.insert sql $sqlText\" )\n+  def insert_streaming(topicInfo: String, retries: Int = 0): Unit = {\n+    val topicName = if( topicInfo.contains(\"::\") ) {\n+      topicInfo.split(\"::\")(0)\n+    } else {\n+      topicInfo\n+    }\n+    try {\n+      log(\"SMC.inss prepare sql\")\n+      val sqlText = insertSql(topicInfo)\n+      log(s\"SMC.inss sql $sqlText\")\n+      \n+      //log( s\"SMC.inss topicCount preex ${KafkaUtils.messageCount(kafkaServers, topicName)}\")\n+      \n+      log(\"SMC.inss executeUpdate\")\n       executeUpdate(sqlText)\n+      log(\"SMC.inss done\")\n+\n+      log( s\"SMC.inss topicCount postex ${KafkaUtils.messageCount(kafkaServers, topicName)}\")\n+    } catch {\n+      case e: java.sql.SQLNonTransientConnectionException => \n+        if( retries < 2 ) {\n+          insert_streaming(topicInfo, retries + 1)\n+        }\n     } finally {\n       kafkaTopics.delete(topicName)\n     }\n   }\n \n-  private[this] def sendData(topicName: String, rdd: JavaRDD[Row], schema: StructType): Unit =\n+  def newTopic_streaming(): String = {\n+    log(\"SMC.nit get topic name\")\n+    kafkaTopics.create()\n+  }\n+  \n+  def sendData_streaming(dataFrame: DataFrame, topicName: String): (Seq[RowForKafka], Long) = {\n+    insAccum.reset\n+    lastRowsToSend.reset\n+    println(s\"${java.time.Instant.now} SMC.sds sendData\")\n+    sendData(topicName, dataFrame.rdd, dataFrame.schema)\n+\n+    val rows = lastRowsToSend.value.asScala\n+    //println(s\"${java.time.Instant.now} SMC.sds last rows ${rows.mkString(\"\\n\")}\")\n+\n+    (rows, insAccum.sum)\n+  }\n+  \n+  /** checkRecovery was written to help debug an issue and normally won't need to be called. */\n+  private[this] def checkRecovery(\n+     id: String,\n+     topicName: String, \n+     partition: Int, \n+     itr: Iterator[Row],\n+     schema: StructType\n+   ): Unit = {\n+\n+    val lastVR = KafkaUtils.lastMessageOf(kafkaServers, topicName, partition)\n+      .asInstanceOf[KafkaReadFunction.Message].vr\n+    val cols = if( lastVR.length > 0) { Range(0,lastVR.length-1).toArray } else { Array(0) }\n+    val lastKHash = lastVR.hashCode(cols)\n+\n+    val khashcodes = KafkaUtils.messagesFrom(kafkaServers, topicName, partition)\n+      .map( _.asInstanceOf[KafkaReadFunction.Message].vr.hashCode(cols) )\n+\n+    println(s\"$id SMC.checkRecovery 1st Kafka hashcode ${khashcodes.headOption.getOrElse(-1)}\" )\n+    \n+    var i = 0\n+    var res = Seq.empty[String]\n+    while( itr.hasNext ) {\n+      val hashcode = externalizable(itr.next, schema, partition).hashCode(cols)\n+      res = res :+ s\"$i,${khashcodes.indexOf(hashcode)}\\t${hashcode==lastKHash}\"\n+      i += 1\n+    }\n+    \n+    println(s\"$id SMC.checkRecovery res: Kafka count ${khashcodes.size}\\n${res.mkString(\"\\n\")}\")\n+  }\n+  \n+  private[this] var sendDataTimestamp: Long = _\n+  \n+  private[this] def sendData(topicName: String, rdd: JavaRDD[Row], schema: StructType): Unit = {\n+    sendDataTimestamp = System.currentTimeMillis\n     rdd.rdd.mapPartitionsWithIndex(\n       (partition, itrRow) => {\n-        val taskContext = TaskContext.get\n+        val id = topicName.substring(0,5)+\":\"+partition.toString\n+        //println(s\"$id SMC.sendData p== $partition\")\n \n-        var msgIdx = 0\n-        if (taskContext != null && taskContext.attemptNumber > 0) {\n-          val entriesInKafka = KafkaUtils.messageCount(kafkaServers, topicName, partition)\n-          for(i <- (1: Long) to entriesInKafka) {\n-            itrRow.next\n+        var msgCount = 0\n+        val taskContext = TaskContext.get\n+        val itr = if (taskContext != null && taskContext.attemptNumber > 0) {\n+          // Recover from previous task failure\n+          // Be sure the iterator is advanced past the items previously published to Kafka\n+          \n+          println(s\"$id SMC.sendData Retry $partition ${taskContext.attemptNumber} ${insAccum.sum}\")\n+\n+          //val itr12 = itrRow //.duplicate\n+          //checkRecovery(id, topicName, partition, itr12._1, schema)\n+\n+          val lastMsg = KafkaUtils.lastMessageOf(kafkaServers, topicName, partition)\n+          if( lastMsg.isEmpty ) {\n+            itrRow\n+          } else {\n+            val lastVR = lastMsg.get.asInstanceOf[KafkaReadFunction.Message].vr\n+            val hashCols = if( lastVR.length > 0) { Range(0,lastVR.length-1).toArray } else { Array(0) }\n+            val lastKHash = lastVR.hashCode(hashCols)\n+            def hash: Row => Int = row => externalizable(row, schema, partition).hashCode(hashCols)\n+            \n+            //val itr34 = itr12._2.duplicate\n+            val itr34 = itrRow.duplicate   //itr12.duplicate\n+            \n+            val inKafka_NotInKafka = itr34._1.span( hash(_) != lastKHash )\n+            if( inKafka_NotInKafka._2.hasNext ) {\n+              inKafka_NotInKafka._2.next  // matches the last item in Kafka, get past it\n+              //println(s\"$id SMC.sendData Retry skip ${hash(r)} $lastKHash\")\n+              msgCount = inKafka_NotInKafka._1.size + 1  // this message count was lost during previous task failure\n+              inKafka_NotInKafka._2\n+            } else {  // itrRow starts after the last item added to Kafka\n+              itr34._2\n+            }\n           }\n-          msgIdx = entriesInKafka.asInstanceOf[Int]\n+        } else {\n+          itrRow", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 377}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf69fd0c65e44b224c6777a872c38cde5c19b3c4", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/bf69fd0c65e44b224c6777a872c38cde5c19b3c4", "committedDate": "2020-10-20T22:19:13Z", "message": "Merge branch 'master' into DB-9924"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94f13b7a9ad85ce06d28fe8e783a87ef3ab9f5a6", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/94f13b7a9ad85ce06d28fe8e783a87ef3ab9f5a6", "committedDate": "2020-10-21T19:13:51Z", "message": "DB-9924 Remove unnecessary comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0263ed86b9c614882b6cde88a47c3caf87ca7027", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/0263ed86b9c614882b6cde88a47c3caf87ca7027", "committedDate": "2020-10-21T19:20:19Z", "message": "DB-9924 Change printlns to logs. Align kafka partition count to that of the input rdd. Limit last row accumulation in sendData to streaming."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4997a486eb3fabc2872718be5cf427bd5af784e3", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/4997a486eb3fabc2872718be5cf427bd5af784e3", "committedDate": "2020-10-21T22:49:13Z", "message": "DB-9924 NSDS v2 Added comments in sendData retry logic."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7885afdc7924c3ef628140113ea0199336f450d1", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/7885afdc7924c3ef628140113ea0199336f450d1", "committedDate": "2020-10-22T04:11:06Z", "message": "DB-9924 Fix Spotbugs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01f1e76fc165e188fafad4fac71d4a128ff8f46b", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/01f1e76fc165e188fafad4fac71d4a128ff8f46b", "committedDate": "2020-10-23T04:16:54Z", "message": "DB-9924 Moved creation of AdminClient."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da8552190acc7bc107ef2b7f9de49c4430c948ad", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/da8552190acc7bc107ef2b7f9de49c4430c948ad", "committedDate": "2020-10-23T04:24:02Z", "message": "DB-9924 NSDS v2 Added logic to handle empty partitions and RDDs with no partitions."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c47077b8db5b743454ad520f9291a57e4688403a", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/c47077b8db5b743454ad520f9291a57e4688403a", "committedDate": "2020-10-28T07:06:23Z", "message": "DB-9924 NSDS v2 Returning partition info from sendData_streaming. Made two utility functions public. Migrated other recent changes from spark2.4 code to the code for other spark versions."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4815d2c9140af470edcea230e8c0cd8bbf5d3a8d", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/4815d2c9140af470edcea230e8c0cd8bbf5d3a8d", "committedDate": "2020-10-28T15:24:09Z", "message": "Merge branch 'master' into DB-9924"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4ODc5MTI2", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-518879126", "createdAt": "2020-10-28T16:50:10Z", "commit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNjo1MDoxMVrOHpz4EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNjo1MDoxMVrOHpz4EA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYwMzYwMA==", "bodyText": "The problem is we are not failing the operation (as far as I can see). So after 10 minutes we complete the write without error. I think we should have a shorter timeout (1 minute?) and raise an exception.", "url": "https://github.com/splicemachine/spliceengine/pull/4303#discussion_r513603600", "createdAt": "2020-10-28T16:50:11Z", "author": {"login": "dgomezferro"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/KafkaReadFunction.java", "diffHunk": "@@ -67,59 +69,99 @@ public KafkaReadFunction(OperationContext context, String topicName, String boot\n         props.put(ConsumerConfig.CLIENT_ID_CONFIG, consumer_id);\n \n         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n-        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ExternalizableDeserializer.class.getName());\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n         props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        \n+        // MAX_POLL_RECORDS_CONFIG helped performance in standalone with lower values (default == 500).\n+        //  With high values, it spent too much time retrieving records from Kafka.\n+        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, \"100\");\n+//        props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, \"10485760\"); // 10% of max == 5242880, default == 1048576\n \n-        KafkaConsumer<Integer, Externalizable> consumer = new KafkaConsumer<Integer, Externalizable>(props);\n+        KafkaConsumer<Integer, byte[]> consumer = new KafkaConsumer<Integer, byte[]>(props);\n         consumer.assign(Arrays.asList(new TopicPartition(topicName, partition)));\n \n+        KryoSerialization kryo = new KryoSerialization();\n+        kryo.init();\n+\n         return new Iterator<ExecRow>() {\n-            Iterator<ConsumerRecord<Integer, Externalizable>> it = null;\n-            \n-            Predicate<ConsumerRecords<Integer, Externalizable>> noRecords = records ->\n+            Iterator<ConsumerRecord<Integer, byte[]>> it = null;\n+            Message prevMessage = new Message();\n+\n+            Predicate<ConsumerRecords<Integer, byte[]>> noRecords = records ->\n                 records == null || records.isEmpty();\n             \n-            private ConsumerRecords<Integer, Externalizable> kafkaRecords(int maxAttempts) throws TaskKilledException {\n+            long totalCount = 0L;\n+            int maxRetries = 10;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODM0MTA0OQ=="}, "originalCommit": {"oid": "08e8c53eea34e7b7116af18293f24fe0f59d75db"}, "originalPosition": 86}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "063e869b22c07e62976c7e10a8b969397010b898", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/063e869b22c07e62976c7e10a8b969397010b898", "committedDate": "2020-10-29T03:40:05Z", "message": "DB-9924 Throwing exception when timing out during record retrieval from Kafka. Decreased long timeout."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5NzkwMzAy", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-519790302", "createdAt": "2020-10-29T15:29:00Z", "commit": {"oid": "063e869b22c07e62976c7e10a8b969397010b898"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "776fe353b07dc2d50d8381ec3e2fde2ff350510a", "author": {"user": {"login": "jpanko1", "name": null}}, "url": "https://github.com/splicemachine/spliceengine/commit/776fe353b07dc2d50d8381ec3e2fde2ff350510a", "committedDate": "2020-10-29T17:06:16Z", "message": "Merge branch 'master' into DB-9924"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwMTk3MDE1", "url": "https://github.com/splicemachine/spliceengine/pull/4303#pullrequestreview-520197015", "createdAt": "2020-10-30T00:15:37Z", "commit": {"oid": "776fe353b07dc2d50d8381ec3e2fde2ff350510a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1106, "cost": 1, "resetAt": "2021-11-02T10:47:05Z"}}}