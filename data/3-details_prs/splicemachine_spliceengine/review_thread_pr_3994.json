{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4ODIyNDA0", "number": 3994, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMzoyNjowN1rOEZC3Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwOTo0MjoxMVrOEZZa4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Njk2NzM1OnYy", "diffSide": "RIGHT", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMzoyNjowN1rOHBoqGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoyOToyOVrOHBzHJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg==", "bodyText": "This might always return false when running in Spark, can you verify that?", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471476762", "createdAt": "2020-08-17T13:26:07Z", "author": {"login": "dgomezferro"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +458,20 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next\n+                                          // <closeCheckInterval>-bytes mark\n+                        if (!store.areWritesEnabled()) { // this call could be expensive.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ4NzMxMw==", "bodyText": "Sure, I am on it.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471487313", "createdAt": "2020-08-17T13:42:54Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +458,20 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next\n+                                          // <closeCheckInterval>-bytes mark\n+                        if (!store.areWritesEnabled()) { // this call could be expensive.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}, "originalCommit": {"oid": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3ODk4MA==", "bodyText": "You're right, when performCompaction is called from Spark executor, the status of regions is always false causing compactions to be cancelled all the time.\nTo solve this, I am adding a isSpark flag that is set when running compactions from Spark, we use this flag to make sure we detect region status only when performCompaction is called from HBase and not Spark.\nThanks for the hint.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471578980", "createdAt": "2020-08-17T15:59:18Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +458,20 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next\n+                                          // <closeCheckInterval>-bytes mark\n+                        if (!store.areWritesEnabled()) { // this call could be expensive.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}, "originalCommit": {"oid": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY0ODAzOA==", "bodyText": "... I added a branch for Spark jobs, if task is interrupted we perform similar cancellation preventing Spark executors from pointlessly running the compaction job.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471648038", "createdAt": "2020-08-17T17:29:29Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +458,20 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next\n+                                          // <closeCheckInterval>-bytes mark\n+                        if (!store.areWritesEnabled()) { // this call could be expensive.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}, "originalCommit": {"oid": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MDYzMzIwOnYy", "diffSide": "RIGHT", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwOTozMzo0OFrOHCLeHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNTozMTozN1rOHCaIQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA0NzEzNA==", "bodyText": "Setting isSpark here is redundant", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472047134", "createdAt": "2020-08-18T09:33:48Z", "author": {"login": "arnaud-splice"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -115,14 +116,16 @@ public SpliceDefaultCompactor(final Configuration conf, final Store store, long\n     @SuppressFBWarnings(value=\"ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD\", justification=\"static attribute hostname is set from here\")\n     public List<Path> compact(CompactionRequestImpl request, ThroughputController throughputController, User user) throws IOException {\n         assert request instanceof SpliceCompactionRequest;\n+        SpliceCompactionRequest spliceRequest = (SpliceCompactionRequest)request;\n         // Used if we cannot compact in Spark\n-        ((SpliceCompactionRequest) request).setPurgeConfig(buildPurgeConfig(request));\n+        spliceRequest.setPurgeConfig(buildPurgeConfig(request));\n \n-        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable())\n+        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable()) {\n+            isSpark = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI4NzI5OQ==", "bodyText": "Right, but I would still leave it there to protect against e.g. accidentally initializing the member variable to true", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472287299", "createdAt": "2020-08-18T15:31:37Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -115,14 +116,16 @@ public SpliceDefaultCompactor(final Configuration conf, final Store store, long\n     @SuppressFBWarnings(value=\"ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD\", justification=\"static attribute hostname is set from here\")\n     public List<Path> compact(CompactionRequestImpl request, ThroughputController throughputController, User user) throws IOException {\n         assert request instanceof SpliceCompactionRequest;\n+        SpliceCompactionRequest spliceRequest = (SpliceCompactionRequest)request;\n         // Used if we cannot compact in Spark\n-        ((SpliceCompactionRequest) request).setPurgeConfig(buildPurgeConfig(request));\n+        spliceRequest.setPurgeConfig(buildPurgeConfig(request));\n \n-        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable())\n+        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable()) {\n+            isSpark = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA0NzEzNA=="}, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MDY1ODYzOnYy", "diffSide": "RIGHT", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwOTo0MDo0OFrOHCLuBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNTozOTowN1rOHCac-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTIwNw==", "bodyText": "Call to toString is redundant, isn't it?", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472051207", "createdAt": "2020-08-18T09:40:48Z", "author": {"login": "arnaud-splice"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +462,19 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next <closeCheckInterval>-bytes mark\n+                        if ((isSpark && TaskContext.get().isInterrupted()) || (!isSpark && !store.areWritesEnabled())) {\n+                            SpliceLogUtils.debug(LOG, \"Compaction cancelled\");\n+                            progress.cancel();\n+                            return false;\n+                        }\n                     }\n                 }\n             }\n-            // Log the progress of long running compactions every minute if\n-            // logging at DEBUG level\n+            // Log the progress of long-running compactions every minute if logging at DEBUG level\n             if (LOG.isDebugEnabled()) {\n                 if ((now - lastMillis) >= 60 * 1000) {\n-                    LOG.debug(\"Compaction progress: \" + progress + String.format(\", rate=%.2f kB/sec\",\n+                    LOG.debug(String.format(\"Compaction progress: %s, rate=%.2f kB/sec\", progress.toString(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI5MjYwMA==", "bodyText": "fixed.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472292600", "createdAt": "2020-08-18T15:39:07Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +462,19 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next <closeCheckInterval>-bytes mark\n+                        if ((isSpark && TaskContext.get().isInterrupted()) || (!isSpark && !store.areWritesEnabled())) {\n+                            SpliceLogUtils.debug(LOG, \"Compaction cancelled\");\n+                            progress.cancel();\n+                            return false;\n+                        }\n                     }\n                 }\n             }\n-            // Log the progress of long running compactions every minute if\n-            // logging at DEBUG level\n+            // Log the progress of long-running compactions every minute if logging at DEBUG level\n             if (LOG.isDebugEnabled()) {\n                 if ((now - lastMillis) >= 60 * 1000) {\n-                    LOG.debug(\"Compaction progress: \" + progress + String.format(\", rate=%.2f kB/sec\",\n+                    LOG.debug(String.format(\"Compaction progress: %s, rate=%.2f kB/sec\", progress.toString(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTIwNw=="}, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MDY2MzM5OnYy", "diffSide": "RIGHT", "path": "hbase_storage/src/main/java/com/splicemachine/si/impl/server/AbstractSICompactionScanner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwOTo0MjoxMVrOHCLxEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjozNTowNlrOHCct8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTk4Ng==", "bodyText": "I suggest renaming size to numberOfScannedBytes or something like this. The size of a scanner is a bit vague.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472051986", "createdAt": "2020-08-18T09:42:11Z", "author": {"login": "arnaud-splice"}, "path": "hbase_storage/src/main/java/com/splicemachine/si/impl/server/AbstractSICompactionScanner.java", "diffHunk": "@@ -107,6 +109,10 @@ public boolean next(List<Cell> list) throws IOException {\n         }\n     }\n \n+    public long getSize() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMyOTcxNQ==", "bodyText": "done.", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472329715", "createdAt": "2020-08-18T16:35:06Z", "author": {"login": "hatyo"}, "path": "hbase_storage/src/main/java/com/splicemachine/si/impl/server/AbstractSICompactionScanner.java", "diffHunk": "@@ -107,6 +109,10 @@ public boolean next(List<Cell> list) throws IOException {\n         }\n     }\n \n+    public long getSize() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTk4Ng=="}, "originalCommit": {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2998, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}