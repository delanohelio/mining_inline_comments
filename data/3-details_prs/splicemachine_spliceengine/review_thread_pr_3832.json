{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5NTgwMTA5", "number": 3832, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODoyNjozNFrOEPcfIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODoyNjozNFrOEPcfIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjMwODE5OnYy", "diffSide": "RIGHT", "path": "hbase_sql/src/main/java/com/splicemachine/stream/accumulator/BadRecordsAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODoyNjozNFrOGzKKSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOToyNzoyNVrOG0vw2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI5NzAzNQ==", "bodyText": "if i understand correctly, you might as well return this here:\nBadRecordsAccumulator only has one internal state, namely the badRecordsRecorder. With this code, every \"copy\" points to the same badRecordsRecorder, so will have a shared state, making copies not really copies. e.g. everything you would add or merge to one BadRecordsAccumulator, you would also see in the copy. Not sure if this is intended.", "url": "https://github.com/splicemachine/spliceengine/pull/3832#discussion_r456297035", "createdAt": "2020-07-17T08:26:34Z", "author": {"login": "martinrupp"}, "path": "hbase_sql/src/main/java/com/splicemachine/stream/accumulator/BadRecordsAccumulator.java", "diffHunk": "@@ -14,34 +14,54 @@\n \n package com.splicemachine.stream.accumulator;\n \n-import org.apache.spark.AccumulableParam;\n import com.splicemachine.derby.stream.control.BadRecordsRecorder;\n+import org.apache.spark.util.AccumulatorV2;\n \n /**\n  *\n  * Accumulator for Bad Records from bulk import.\n  * <p/>\n  * Uses a {@link BadRecordsRecorder} to record each bad record to a temp file. Temp files\n- * will be merged {@link #addInPlace(BadRecordsRecorder, BadRecordsRecorder)}.\n+ * will be merged {@link #merge(AccumulatorV2<String, BadRecordsRecorder>)}.\n  *\n- * @see org.apache.spark.AccumulableParam\n+ * @see org.apache.spark.util.AccumulatorV2;\n  *\n  */\n-public class BadRecordsAccumulator implements AccumulableParam<BadRecordsRecorder, String> {\n+public class BadRecordsAccumulator extends AccumulatorV2<String, BadRecordsRecorder> {\n+\n+    private final BadRecordsRecorder badRecordsRecorder;\n+\n+    public BadRecordsAccumulator(BadRecordsRecorder badRecordsRecorder) {\n+        this.badRecordsRecorder = badRecordsRecorder;\n+    }\n+\n+    @Override\n+    public boolean isZero() {\n+        return badRecordsRecorder.getNumberOfBadRecords() == 0;\n+    }\n+\n+    @Override\n+    public AccumulatorV2<String, BadRecordsRecorder> copy() {\n+        return new BadRecordsAccumulator(badRecordsRecorder);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24a5df8784ab438102b2adb30184c4241a5b7d94"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk2MTY5MQ==", "bodyText": "you are right, thanks. I've improved the copy method, added reset for BadRecordsRecorder as well", "url": "https://github.com/splicemachine/spliceengine/pull/3832#discussion_r457961691", "createdAt": "2020-07-21T09:27:25Z", "author": {"login": "ipraznik-splice"}, "path": "hbase_sql/src/main/java/com/splicemachine/stream/accumulator/BadRecordsAccumulator.java", "diffHunk": "@@ -14,34 +14,54 @@\n \n package com.splicemachine.stream.accumulator;\n \n-import org.apache.spark.AccumulableParam;\n import com.splicemachine.derby.stream.control.BadRecordsRecorder;\n+import org.apache.spark.util.AccumulatorV2;\n \n /**\n  *\n  * Accumulator for Bad Records from bulk import.\n  * <p/>\n  * Uses a {@link BadRecordsRecorder} to record each bad record to a temp file. Temp files\n- * will be merged {@link #addInPlace(BadRecordsRecorder, BadRecordsRecorder)}.\n+ * will be merged {@link #merge(AccumulatorV2<String, BadRecordsRecorder>)}.\n  *\n- * @see org.apache.spark.AccumulableParam\n+ * @see org.apache.spark.util.AccumulatorV2;\n  *\n  */\n-public class BadRecordsAccumulator implements AccumulableParam<BadRecordsRecorder, String> {\n+public class BadRecordsAccumulator extends AccumulatorV2<String, BadRecordsRecorder> {\n+\n+    private final BadRecordsRecorder badRecordsRecorder;\n+\n+    public BadRecordsAccumulator(BadRecordsRecorder badRecordsRecorder) {\n+        this.badRecordsRecorder = badRecordsRecorder;\n+    }\n+\n+    @Override\n+    public boolean isZero() {\n+        return badRecordsRecorder.getNumberOfBadRecords() == 0;\n+    }\n+\n+    @Override\n+    public AccumulatorV2<String, BadRecordsRecorder> copy() {\n+        return new BadRecordsAccumulator(badRecordsRecorder);\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI5NzAzNQ=="}, "originalCommit": {"oid": "24a5df8784ab438102b2adb30184c4241a5b7d94"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3102, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}