{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4Mjc3NDQx", "number": 3814, "title": "DB-9835 reduce time spent in listdirs for isEmptyDirectory", "bodyText": "avoid to check for empty directory if spark does it\ndont use recursive listdir for isEmptyDirectory if FileSystem doesnt implement efficiently", "createdAt": "2020-07-13T14:03:04Z", "url": "https://github.com/splicemachine/spliceengine/pull/3814", "merged": true, "mergeCommit": {"oid": "756365c732a18a616fb95b22c59ee69284ad131d"}, "closed": true, "closedAt": "2020-07-29T21:41:16Z", "author": {"login": "martinrupp"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc0jHiJgBqjM1NDAwNjk3MDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc5OfANAFqTQ1NjI4OTIyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "db6c67d0e30990d7776ed062052229dec1abd9a6", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/db6c67d0e30990d7776ed062052229dec1abd9a6", "committedDate": "2020-07-13T14:01:31Z", "message": "DB-9835 avoid to check for empty directory if spark does it"}, "afterCommit": {"oid": "7853370922dfd405eb68c9cc22361621adb1b05b", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/7853370922dfd405eb68c9cc22361621adb1b05b", "committedDate": "2020-07-13T15:24:33Z", "message": "DB-9835 avoid to check for empty directory if spark does it"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7853370922dfd405eb68c9cc22361621adb1b05b", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/7853370922dfd405eb68c9cc22361621adb1b05b", "committedDate": "2020-07-13T15:24:33Z", "message": "DB-9835 avoid to check for empty directory if spark does it"}, "afterCommit": {"oid": "6a7837e608f6d4085b8a9735fff2bd287bf698f1", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/6a7837e608f6d4085b8a9735fff2bd287bf698f1", "committedDate": "2020-07-16T13:17:49Z", "message": "DB-9835 avoid to check for empty directory if spark does it"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNTEwOTM5", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-450510939", "createdAt": "2020-07-17T09:28:53Z", "commit": {"oid": "6a7837e608f6d4085b8a9735fff2bd287bf698f1"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwOToyODo1NFrOGzMKrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwOToyOTo0OFrOGzMMtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMyOTkwMg==", "bodyText": "So if I understand correctly, you removed the redundant check for directory existence and you move it to exception handling logic during the actual read, right?", "url": "https://github.com/splicemachine/spliceengine/pull/3814#discussion_r456329902", "createdAt": "2020-07-17T09:28:54Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkDataSetProcessor.java", "diffHunk": "@@ -343,23 +343,17 @@ public Partitioner getPartitioner(DataSet<ExecRow> dataSet, ExecRow template, in\n                                           double sampleFraction) throws StandardException {\n         try {\n             Dataset<Row> table = null;\n+            ExternalTableUtils.preSortColumns(tableSchema.fields(), partitionColumnMap);\n \n             try {\n-                DataSet<V> empty_ds = checkExistingOrEmpty( location, context );\n-                if( empty_ds != null ) return empty_ds;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a7837e608f6d4085b8a9735fff2bd287bf698f1"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMzMDQyMw==", "bodyText": "uhm ... do you want to keep this comment? :)", "url": "https://github.com/splicemachine/spliceengine/pull/3814#discussion_r456330423", "createdAt": "2020-07-17T09:29:48Z", "author": {"login": "hatyo"}, "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkDataSetProcessor.java", "diffHunk": "@@ -383,33 +377,34 @@ public Partitioner getPartitioner(DataSet<ExecRow> dataSet, ExecRow template, in\n                                        boolean useSample, double sampleFraction) throws StandardException {\n         try {\n             Dataset<Row> table = null;\n-            try {\n-                DataSet<V> empty_ds = checkExistingOrEmpty( location, context );\n-                if( empty_ds != null ) return empty_ds;\n-\n-                StructType copy = new StructType(Arrays.copyOf(tableSchema.fields(), tableSchema.fields().length));\n+            StructType copy = new StructType(Arrays.copyOf(tableSchema.fields(), tableSchema.fields().length));\n \n-                // Infer schema from external files\\\n-                StructType dataSchema = ExternalTableUtils.getDataSchema(this, tableSchema, partitionColumnMap, location, \"a\");\n+            // Infer schema from external files\n+            // todo: this is slow on bigger directories, as it's calling getExternalFileSchema,\n+            // which will do a spark.read() before doing the spark.read() here ...\n+            StructType dataSchema = ExternalTableUtils.getDataSchema(this, tableSchema, partitionColumnMap, location, \"a\");\n+            if(dataSchema == null)\n+                return getEmpty(RDDName.EMPTY_DATA_SET.displayName(), context);\n \n+            try {\n                 SparkSession spark = SpliceSpark.getSession();\n                 // Creates a DataFrame from a specified file\n                 table = spark.read().schema(dataSchema).format(\"com.databricks.spark.avro\").load(location);\n+            } catch (Exception e) {\n+                return handleExceptionSparkRead(e, location, false);\n+            }\n \n-                int i = 0;\n-                for (StructField sf : copy.fields()) {\n-                    if (sf.dataType().sameType(DataTypes.DateType)) {\n-                        String colName = table.schema().fields()[i].name();\n-                        table = table.withColumn(colName, table.col(colName).cast(DataTypes.DateType));\n-                    }\n-                    i++;\n+            // todo: find out what this is doing and comment it", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a7837e608f6d4085b8a9735fff2bd287bf698f1"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNTEzNjEw", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-450513610", "createdAt": "2020-07-17T09:32:36Z", "commit": {"oid": "6a7837e608f6d4085b8a9735fff2bd287bf698f1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNjU2NjEx", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-450656611", "createdAt": "2020-07-17T13:28:23Z", "commit": {"oid": "05e9d8fafafc5c5629a78b00d3ef98ba72887369"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "05e9d8fafafc5c5629a78b00d3ef98ba72887369", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/05e9d8fafafc5c5629a78b00d3ef98ba72887369", "committedDate": "2020-07-17T11:35:09Z", "message": "DB-9835 address code review"}, "afterCommit": {"oid": "3c92628b17b99780dbc9afd3a53aa8830520f617", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/3c92628b17b99780dbc9afd3a53aa8830520f617", "committedDate": "2020-07-19T18:45:13Z", "message": "DB-9835 address code review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fb5da82fe7f7f640d30193758b2eb2a301ca1b63", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/fb5da82fe7f7f640d30193758b2eb2a301ca1b63", "committedDate": "2020-07-19T19:39:17Z", "message": "DB-9571 adding assertion for external tables running in control"}, "afterCommit": {"oid": "93aa90215de7944604ae5795cda632d14cdd6f97", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/93aa90215de7944604ae5795cda632d14cdd6f97", "committedDate": "2020-07-24T08:40:14Z", "message": "DB-9571 adding assertion for external tables running in control"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0Nzc0NDY0", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-454774464", "createdAt": "2020-07-24T10:11:07Z", "commit": {"oid": "93aa90215de7944604ae5795cda632d14cdd6f97"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxMDoxMTowN1rOG2qIUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxMDoxMTowN1rOG2qIUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2NjU0Nw==", "bodyText": "Is supportAvroDateTypeColumns() function effectively deleted? And, it seems castDateTypeInAvroDataSet() is used only once. Is it expected to be used in other places, too?", "url": "https://github.com/splicemachine/spliceengine/pull/3814#discussion_r459966547", "createdAt": "2020-07-24T10:11:07Z", "author": {"login": "ascend1"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/stream/utils/ExternalTableUtils.java", "diffHunk": "@@ -64,15 +66,18 @@ public static StructType supportAvroDateType(StructType schema, String storedAs)\n         return schema;\n     }\n \n-    public static void supportAvroDateTypeColumns(ExecRow execRow) throws StandardException {\n-        for(int i=0; i < execRow.size(); i++){\n-            if (execRow.getColumn(i + 1).getTypeName().equals(\"DATE\")) {\n-                execRow.setColumn(i + 1, new SQLVarchar());\n+    public static Dataset<Row> castDateTypeInAvroDataSet(Dataset<Row> dataset, StructType tableSchema) {\n+        int i = 0;\n+        for (StructField sf : tableSchema.fields()) {\n+            if (sf.dataType().sameType(DataTypes.DateType)) {\n+                String colName = dataset.schema().fields()[i].name();\n+                dataset = dataset.withColumn(colName, dataset.col(colName).cast(DataTypes.DateType));\n             }\n+            i++;\n         }\n+        return dataset;\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "93aa90215de7944604ae5795cda632d14cdd6f97"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NzgwNDUy", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-454780452", "createdAt": "2020-07-24T10:22:23Z", "commit": {"oid": "93aa90215de7944604ae5795cda632d14cdd6f97"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe55d57bfeafcaabdb731c1a9c93d33db6ff17f8", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/fe55d57bfeafcaabdb731c1a9c93d33db6ff17f8", "committedDate": "2020-07-26T20:52:41Z", "message": "DB-9835 dont use recursive listdir for isEmptyDirectory if FileSystem doesnt implement efficiently\n\nseems like cluster is not using PrestoS3Filesystem, so we rather dont use rec listdir for isEmptyDirectory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f6abf2c86bcc98332c362d68812c53e648d0ab3", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/2f6abf2c86bcc98332c362d68812c53e648d0ab3", "committedDate": "2020-07-26T20:52:41Z", "message": "DB-9835 avoid to check for empty directory if spark does it"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4160bf6d558b9db6a636e7a1306b9f8917037509", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/4160bf6d558b9db6a636e7a1306b9f8917037509", "committedDate": "2020-07-26T20:52:41Z", "message": "DB-9835 address code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9cb98e7862b8b3d887dafff1789e50f39a9a4af", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/a9cb98e7862b8b3d887dafff1789e50f39a9a4af", "committedDate": "2020-07-26T20:52:41Z", "message": "DB-9571 adding assertion for external tables running in control"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "93aa90215de7944604ae5795cda632d14cdd6f97", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/93aa90215de7944604ae5795cda632d14cdd6f97", "committedDate": "2020-07-24T08:40:14Z", "message": "DB-9571 adding assertion for external tables running in control"}, "afterCommit": {"oid": "a9cb98e7862b8b3d887dafff1789e50f39a9a4af", "author": {"user": {"login": "martinrupp", "name": "Martin Rupp"}}, "url": "https://github.com/splicemachine/spliceengine/commit/a9cb98e7862b8b3d887dafff1789e50f39a9a4af", "committedDate": "2020-07-26T20:52:41Z", "message": "DB-9571 adding assertion for external tables running in control"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2Mjg5MjIx", "url": "https://github.com/splicemachine/spliceengine/pull/3814#pullrequestreview-456289221", "createdAt": "2020-07-28T04:12:18Z", "commit": {"oid": "a9cb98e7862b8b3d887dafff1789e50f39a9a4af"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1240, "cost": 1, "resetAt": "2021-11-02T10:47:05Z"}}}