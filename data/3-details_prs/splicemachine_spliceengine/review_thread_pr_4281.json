{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAyNzM4MTY3", "number": 4281, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwNDoyNDozM1rOEtT03w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMTowNjoxN1rOEtbm5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1OTQ2MjA3OnYy", "diffSide": "RIGHT", "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/config/SharedWriteConfiguration.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwNDoyNDozM1rOHhBt0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTo1MDowMVrOHhLKtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDM5MzE2OA==", "bodyText": "What impact will this change have?", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504393168", "createdAt": "2020-10-14T04:24:33Z", "author": {"login": "jyuanca"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/config/SharedWriteConfiguration.java", "diffHunk": "@@ -105,7 +105,7 @@ public WriteResponse partialFailure(BulkWriteResult result, BulkWrite request) t\n                         context.failed(main, mutationResult);\n                     }\n                 }\n-                return WriteResponse.IGNORE;\n+                return WriteResponse.THROW_ERROR;\n             }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU0ODAyMw==", "bodyText": "Changing the WriteResponse to THROW_ERROR will cause the caller is throw an exception, in BuldWriteAction:\nWriteResponse writeResponse=writeConfiguration.partialFailure(bulkWriteResult,currentBulkWrite);\n                        switch(writeResponse){\n                            case THROW_ERROR:\n                                partialThrownErrorRows.add(currentBulkWrite.getSize());\n                                thrown=true;\n                                throw parseIntoException(bulkWriteResult);\n\nThe thrown exception informs the caller of the BulkWriteAction (which in our case, could be yet another WriteHandler) that something went wrong so we also cancel persisting the mutations during the call to flush.\nWithout changing this, I was running into the following problem that is best illustrated with an example; we have three tables parent, child, and grandChild related to each other with FK relationships (notice that child's FK has on delete cascade while grandChild's FK has on delete no action):\ncreate table parent(col1 int, col2 varchar(2), col3 int, col4 int, primary key (col2, col4));\ninsert into parent values (1, 'a', 1, 1);\ninsert into parent values (2, 'b', 2, 2);\ninsert into parent values (3, 'c', 3, 3);\ncreate table child(col1 int primary key, col2 varchar(2), col3 int, col4 timestamp, constraint fkey_1 foreign key(col2, col3) references parent(col2, col4) on delete cascade);\ninsert into child values (1, 'b', 2, '2020-09-09 10:10:10.123456');\ninsert into child values (400, 'a', 1, '2019-09-09 10:10:10.123456');\ninsert into child values (2, 'b', 2, '2018-09-09 10:10:10.123456');\ncreate table grandChild(col1 int references child(col1) on delete no action, col2 varchar(2));\ninsert into grandChild values (1, 'z');\ninsert into grandChild values (1, 'z');\ninsert into grandChild values (1, 'z');\ninsert into grandChild values (400, 'y');\n\nIf we attempt to delete from parent:\ndelete from parent where col1 = 2;\n\nthe deletion will remove the row (2, 'b', 2, 2) from parent and also cause these rows to be deleted from child:\n(1, 'b', 2, '2020-09-09 10:10:10.123456')\n(2, 'b', 2, '2018-09-09 10:10:10.123456')\n\nHowever the deletion of (1, 'b', 2, '2020-09-09 10:10:10.123456') will violate the grandChild's FK since it is referenced by the following rows:\n(1, 'z')\n(1, 'z')\n(1, 'z')\n\nWith WriteResponse.IGNORE;, the failure triggered by the child foreign key interceptor is not send to the parent foreign key interceptor, this means the deletion on the parent works but fails on the child. As a result, we get the following inconsistent results:\nsplice> select * From parent;\nCOL1       |C&|COL3       |COL4\n--------------------------------------\n1          |a |1          |1\n3          |c |3          |3\n2 rows selected\nELAPSED TIME = 29 milliseconds\nsplice> select * from child;\nCOL1       |COL2|COL3       |COL4\n----------------------------------------------------------\n1          |b   |2          |2020-09-09 10:10:10.123456\n2          |b   |2          |2018-09-09 10:10:10.123456\n400        |a   |1          |2019-09-09 10:10:10.123456\n3 rows selected\nELAPSED TIME = 14 milliseconds\nsplice> select * from grandchild;\nCOL1       |COL2\n----------------\n1          |z\n1          |z\n1          |z\n400        |y\n\nWith WriteResponse.THROW_ERROR the exception is propagated and caught by = parent foreign key interceptor so it also cancels the deletion causing the overall operation to rollback and preserving the referential integrity of the database.\nI honestly still do not know the full scope of changing the WriteRespose like that, but it looks to be more correct than the previous behavior (to simply ignore partial failures), I think also @dgomezferro agrees on this. I am hoping we have enough test coverage that can unravel any potential issue introduced with this.", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504548023", "createdAt": "2020-10-14T09:50:01Z", "author": {"login": "hatyo"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/config/SharedWriteConfiguration.java", "diffHunk": "@@ -105,7 +105,7 @@ public WriteResponse partialFailure(BulkWriteResult result, BulkWrite request) t\n                         context.failed(main, mutationResult);\n                     }\n                 }\n-                return WriteResponse.IGNORE;\n+                return WriteResponse.THROW_ERROR;\n             }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDM5MzE2OA=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1OTQ3MDM1OnYy", "diffSide": "RIGHT", "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwNDoyOToyNlrOHhBypw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTo1MjoyOVrOHhLQiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDM5NDQwNw==", "bodyText": "currentRowKey is not used", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504394407", "createdAt": "2020-10-14T04:29:26Z", "author": {"login": "jyuanca"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {\n+        boolean added = false;\n         for (KVPair kvPair : resultsMap.keySet()) {\n             byte[] currentRowKey = kvPair.getRowKey();\n             if (Arrays.equals(currentRowKey, resultRowKey)) {\n                 resultsMap.put(kvPair, result);\n-                return;\n+                added = true;\n+                break;\n+            }\n+        }\n+        if (!added) {\n+            for (KVPair kvPair : resultsMap.keySet()) {\n+                byte[] currentRowKey = kvPair.getRowKey();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU0OTUxNQ==", "bodyText": "Fixed it, thanks!", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504549515", "createdAt": "2020-10-14T09:52:29Z", "author": {"login": "hatyo"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {\n+        boolean added = false;\n         for (KVPair kvPair : resultsMap.keySet()) {\n             byte[] currentRowKey = kvPair.getRowKey();\n             if (Arrays.equals(currentRowKey, resultRowKey)) {\n                 resultsMap.put(kvPair, result);\n-                return;\n+                added = true;\n+                break;\n+            }\n+        }\n+        if (!added) {\n+            for (KVPair kvPair : resultsMap.keySet()) {\n+                byte[] currentRowKey = kvPair.getRowKey();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDM5NDQwNw=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1OTU3MDI3OnYy", "diffSide": "RIGHT", "path": "splice_machine/src/main/java/com/splicemachine/pipeline/foreignkey/actions/OnDeleteAbstractAction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwNToyNjoxMFrOHhCtQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMDoyODoxOFrOHhMhMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQwOTQwOQ==", "bodyText": "Can you comment the magic number 2?", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504409409", "createdAt": "2020-10-14T05:26:10Z", "author": {"login": "jyuanca"}, "path": "splice_machine/src/main/java/com/splicemachine/pipeline/foreignkey/actions/OnDeleteAbstractAction.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright (c) 2012 - 2020 Splice Machine, Inc.\n+ *\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package com.splicemachine.pipeline.foreignkey.actions;\n+\n+import com.carrotsearch.hppc.ObjectObjectHashMap;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.services.io.StoredFormatIds;\n+import com.splicemachine.ddl.DDLMessage;\n+import com.splicemachine.derby.ddl.DDLUtils;\n+import com.splicemachine.derby.utils.marshall.dvd.TypeProvider;\n+import com.splicemachine.derby.utils.marshall.dvd.VersionedSerializers;\n+import com.splicemachine.encoding.Encoding;\n+import com.splicemachine.encoding.MultiFieldDecoder;\n+import com.splicemachine.kvpair.KVPair;\n+import com.splicemachine.pipeline.callbuffer.CallBuffer;\n+import com.splicemachine.pipeline.client.WriteResult;\n+import com.splicemachine.pipeline.context.WriteContext;\n+import com.splicemachine.pipeline.foreignkey.ForeignKeyViolationProcessor;\n+import com.splicemachine.primitives.Bytes;\n+import com.splicemachine.si.api.data.TxnOperationFactory;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.si.impl.SimpleTxnFilter;\n+import com.splicemachine.si.impl.driver.SIDriver;\n+import com.splicemachine.si.impl.readresolve.NoOpReadResolver;\n+import com.splicemachine.si.impl.txn.ActiveWriteTxn;\n+import com.splicemachine.si.impl.txn.WritableTxn;\n+import com.splicemachine.storage.*;\n+import com.splicemachine.utils.Pair;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public abstract class OnDeleteAbstractAction extends Action {\n+\n+    private static final int MAX_BUFFER_SIZE = 1000;\n+\n+    protected final DDLMessage.FKConstraintInfo constraintInfo;\n+    protected final ObjectObjectHashMap<KVPair, KVPair> mutationBuffer;\n+    protected final CallBuffer<KVPair> pipelineBuffer;\n+    Partition indexTable;\n+    private final TxnOperationFactory txnOperationFactory;\n+\n+    private final ForeignKeyViolationProcessor violationProcessor;\n+\n+    public OnDeleteAbstractAction(Long backingIndexConglomId,\n+                                  DDLMessage.FKConstraintInfo constraintInfo,\n+                                  WriteContext writeContext,\n+                                  TxnOperationFactory txnOperationFactory, ForeignKeyViolationProcessor violationProcessor) throws Exception {\n+        super(constraintInfo.getTable().getConglomerate(), backingIndexConglomId);\n+        this.txnOperationFactory = txnOperationFactory;\n+        assert childBaseTableConglomId != null;\n+        assert backingIndexConglomId != null;\n+        assert violationProcessor != null;\n+        this.constraintInfo = constraintInfo;\n+        this.mutationBuffer = new ObjectObjectHashMap<>();\n+        this.pipelineBuffer = writeContext.getSharedWriteBuffer(\n+                DDLUtils.getIndexConglomBytes(childBaseTableConglomId),\n+                this.mutationBuffer,\n+                MAX_BUFFER_SIZE * 2 + 10,\n+                true,\n+                writeContext.getTxn(),\n+                writeContext.getToken());\n+        this.indexTable = null;\n+        this.violationProcessor = violationProcessor;\n+    }\n+\n+    /*\n+     * The way prefix keys work is that longer keys sort after shorter keys. We\n+     * are already starting exactly where we want to be, and we want to end as soon\n+     * as we hit a record which is not this key.\n+     *\n+     * Historically, we did this by using an HBase PrefixFilter. We can do that again,\n+     * but it's a bit of a pain to make that work in an architecture-independent\n+     * way (we would need to implement a version of that for other architectures,\n+     * for example. It's much easier for us to just make use of row key sorting\n+     * to do the job for us.\n+     *\n+     * We start where we want, and we need to end as soon as we run off that. The\n+     * first key which is higher than the start key is the start key as a prefix followed\n+     * by 0x00 (in unsigned sort order). Therefore, we make the end key\n+     * [startKey | 0x00].\n+     */\n+    private static DataScan prepareScan(TxnOperationFactory factory, KVPair needle) {\n+        byte[] startKey = needle.getRowKey();\n+        byte[] stopKey = Bytes.unsignedCopyAndIncrement(startKey); // +1 from startKey.\n+        DataScan scan = factory.newDataScan(null); // Non-Transactional, will resolve on this side\n+        return scan.startKey(startKey).stopKey(stopKey);\n+    }\n+\n+    private static Pair<SimpleTxnFilter, SimpleTxnFilter> prepareScanFilters(TxnView txnView, long indexConglomerateId) throws IOException {\n+        SimpleTxnFilter readUncommittedFilter, readCommittedFilter;\n+        if (txnView instanceof ActiveWriteTxn) {\n+            readCommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((ActiveWriteTxn) txnView).getReadCommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+            readUncommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((ActiveWriteTxn) txnView).getReadUncommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+\n+        } else if (txnView instanceof WritableTxn) {\n+            readCommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((WritableTxn) txnView).getReadCommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+            readUncommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((WritableTxn) txnView).getReadUncommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+        } else {\n+            throw new IOException(\"invalidTxn,\");\n+        }\n+        return Pair.newPair(readCommittedFilter, readUncommittedFilter);\n+    }\n+\n+    private byte[] isVisible(List<DataCell> next, SimpleTxnFilter txnFilter) throws IOException {\n+        int cellCount = next.size();\n+        for(DataCell dc:next){\n+            DataFilter.ReturnCode rC = txnFilter.filterCell(dc);\n+            switch(rC){\n+                case NEXT_ROW:\n+                    return null; //the entire row is filtered\n+                case SKIP:\n+                case NEXT_COL:\n+                case SEEK:\n+                    cellCount--; //the cell is filtered\n+                    break;\n+                case INCLUDE:\n+                case INCLUDE_AND_NEXT_COL: //the cell is included\n+                default:\n+                    break;\n+            }\n+        }\n+        if(cellCount > 0) {\n+            return next.get(0).key();\n+        }\n+        return null;\n+    }\n+\n+    private Partition getTable() throws IOException {\n+        if(indexTable == null) {\n+            indexTable = SIDriver.driver().getTableFactory().getTable(Long.toString((backingIndexConglomId)));\n+        }\n+        return indexTable;\n+    }\n+\n+    protected abstract WriteResult handleExistingRow(byte[] indexRow, byte[] sourceRowKey) throws Exception;\n+\n+    protected static byte[] toChildBaseRowId(byte[] indexRowId, DDLMessage.FKConstraintInfo fkConstraintInfo) throws StandardException {\n+        MultiFieldDecoder multiFieldDecoder = MultiFieldDecoder.create();\n+        TypeProvider typeProvider = VersionedSerializers.typesForVersion(fkConstraintInfo.getParentTableVersion());\n+        int position = 0;\n+        multiFieldDecoder.set(indexRowId);\n+        for (int i = 0; i < fkConstraintInfo.getFormatIdsCount(); i++) {\n+            if (multiFieldDecoder.nextIsNull()) {\n+                throw StandardException.newException(String.format(\"unexpected index rowid format %s\", Bytes.toHex(indexRowId)));\n+            }\n+            if (fkConstraintInfo.getFormatIds(i) == StoredFormatIds.SQL_DOUBLE_ID) {\n+                position += multiFieldDecoder.skipDouble();\n+            } else if (fkConstraintInfo.getFormatIds(i) == StoredFormatIds.SQL_REAL_ID) {\n+                position += multiFieldDecoder.skipFloat();\n+            } else if (typeProvider.isScalar(fkConstraintInfo.getFormatIds(i))) {\n+                position += multiFieldDecoder.skipLong();\n+            } else {\n+                position += multiFieldDecoder.skip();\n+            }\n+        }\n+        int lastKeyIndex = position - 2;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU3MDE2Mg==", "bodyText": "I simplified it a bit and added more documentation.", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504570162", "createdAt": "2020-10-14T10:28:18Z", "author": {"login": "hatyo"}, "path": "splice_machine/src/main/java/com/splicemachine/pipeline/foreignkey/actions/OnDeleteAbstractAction.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright (c) 2012 - 2020 Splice Machine, Inc.\n+ *\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package com.splicemachine.pipeline.foreignkey.actions;\n+\n+import com.carrotsearch.hppc.ObjectObjectHashMap;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.services.io.StoredFormatIds;\n+import com.splicemachine.ddl.DDLMessage;\n+import com.splicemachine.derby.ddl.DDLUtils;\n+import com.splicemachine.derby.utils.marshall.dvd.TypeProvider;\n+import com.splicemachine.derby.utils.marshall.dvd.VersionedSerializers;\n+import com.splicemachine.encoding.Encoding;\n+import com.splicemachine.encoding.MultiFieldDecoder;\n+import com.splicemachine.kvpair.KVPair;\n+import com.splicemachine.pipeline.callbuffer.CallBuffer;\n+import com.splicemachine.pipeline.client.WriteResult;\n+import com.splicemachine.pipeline.context.WriteContext;\n+import com.splicemachine.pipeline.foreignkey.ForeignKeyViolationProcessor;\n+import com.splicemachine.primitives.Bytes;\n+import com.splicemachine.si.api.data.TxnOperationFactory;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.si.impl.SimpleTxnFilter;\n+import com.splicemachine.si.impl.driver.SIDriver;\n+import com.splicemachine.si.impl.readresolve.NoOpReadResolver;\n+import com.splicemachine.si.impl.txn.ActiveWriteTxn;\n+import com.splicemachine.si.impl.txn.WritableTxn;\n+import com.splicemachine.storage.*;\n+import com.splicemachine.utils.Pair;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public abstract class OnDeleteAbstractAction extends Action {\n+\n+    private static final int MAX_BUFFER_SIZE = 1000;\n+\n+    protected final DDLMessage.FKConstraintInfo constraintInfo;\n+    protected final ObjectObjectHashMap<KVPair, KVPair> mutationBuffer;\n+    protected final CallBuffer<KVPair> pipelineBuffer;\n+    Partition indexTable;\n+    private final TxnOperationFactory txnOperationFactory;\n+\n+    private final ForeignKeyViolationProcessor violationProcessor;\n+\n+    public OnDeleteAbstractAction(Long backingIndexConglomId,\n+                                  DDLMessage.FKConstraintInfo constraintInfo,\n+                                  WriteContext writeContext,\n+                                  TxnOperationFactory txnOperationFactory, ForeignKeyViolationProcessor violationProcessor) throws Exception {\n+        super(constraintInfo.getTable().getConglomerate(), backingIndexConglomId);\n+        this.txnOperationFactory = txnOperationFactory;\n+        assert childBaseTableConglomId != null;\n+        assert backingIndexConglomId != null;\n+        assert violationProcessor != null;\n+        this.constraintInfo = constraintInfo;\n+        this.mutationBuffer = new ObjectObjectHashMap<>();\n+        this.pipelineBuffer = writeContext.getSharedWriteBuffer(\n+                DDLUtils.getIndexConglomBytes(childBaseTableConglomId),\n+                this.mutationBuffer,\n+                MAX_BUFFER_SIZE * 2 + 10,\n+                true,\n+                writeContext.getTxn(),\n+                writeContext.getToken());\n+        this.indexTable = null;\n+        this.violationProcessor = violationProcessor;\n+    }\n+\n+    /*\n+     * The way prefix keys work is that longer keys sort after shorter keys. We\n+     * are already starting exactly where we want to be, and we want to end as soon\n+     * as we hit a record which is not this key.\n+     *\n+     * Historically, we did this by using an HBase PrefixFilter. We can do that again,\n+     * but it's a bit of a pain to make that work in an architecture-independent\n+     * way (we would need to implement a version of that for other architectures,\n+     * for example. It's much easier for us to just make use of row key sorting\n+     * to do the job for us.\n+     *\n+     * We start where we want, and we need to end as soon as we run off that. The\n+     * first key which is higher than the start key is the start key as a prefix followed\n+     * by 0x00 (in unsigned sort order). Therefore, we make the end key\n+     * [startKey | 0x00].\n+     */\n+    private static DataScan prepareScan(TxnOperationFactory factory, KVPair needle) {\n+        byte[] startKey = needle.getRowKey();\n+        byte[] stopKey = Bytes.unsignedCopyAndIncrement(startKey); // +1 from startKey.\n+        DataScan scan = factory.newDataScan(null); // Non-Transactional, will resolve on this side\n+        return scan.startKey(startKey).stopKey(stopKey);\n+    }\n+\n+    private static Pair<SimpleTxnFilter, SimpleTxnFilter> prepareScanFilters(TxnView txnView, long indexConglomerateId) throws IOException {\n+        SimpleTxnFilter readUncommittedFilter, readCommittedFilter;\n+        if (txnView instanceof ActiveWriteTxn) {\n+            readCommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((ActiveWriteTxn) txnView).getReadCommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+            readUncommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((ActiveWriteTxn) txnView).getReadUncommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+\n+        } else if (txnView instanceof WritableTxn) {\n+            readCommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((WritableTxn) txnView).getReadCommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+            readUncommittedFilter = new SimpleTxnFilter(Long.toString(indexConglomerateId), ((WritableTxn) txnView).getReadUncommittedActiveTxn(), NoOpReadResolver.INSTANCE, SIDriver.driver().getTxnStore());\n+        } else {\n+            throw new IOException(\"invalidTxn,\");\n+        }\n+        return Pair.newPair(readCommittedFilter, readUncommittedFilter);\n+    }\n+\n+    private byte[] isVisible(List<DataCell> next, SimpleTxnFilter txnFilter) throws IOException {\n+        int cellCount = next.size();\n+        for(DataCell dc:next){\n+            DataFilter.ReturnCode rC = txnFilter.filterCell(dc);\n+            switch(rC){\n+                case NEXT_ROW:\n+                    return null; //the entire row is filtered\n+                case SKIP:\n+                case NEXT_COL:\n+                case SEEK:\n+                    cellCount--; //the cell is filtered\n+                    break;\n+                case INCLUDE:\n+                case INCLUDE_AND_NEXT_COL: //the cell is included\n+                default:\n+                    break;\n+            }\n+        }\n+        if(cellCount > 0) {\n+            return next.get(0).key();\n+        }\n+        return null;\n+    }\n+\n+    private Partition getTable() throws IOException {\n+        if(indexTable == null) {\n+            indexTable = SIDriver.driver().getTableFactory().getTable(Long.toString((backingIndexConglomId)));\n+        }\n+        return indexTable;\n+    }\n+\n+    protected abstract WriteResult handleExistingRow(byte[] indexRow, byte[] sourceRowKey) throws Exception;\n+\n+    protected static byte[] toChildBaseRowId(byte[] indexRowId, DDLMessage.FKConstraintInfo fkConstraintInfo) throws StandardException {\n+        MultiFieldDecoder multiFieldDecoder = MultiFieldDecoder.create();\n+        TypeProvider typeProvider = VersionedSerializers.typesForVersion(fkConstraintInfo.getParentTableVersion());\n+        int position = 0;\n+        multiFieldDecoder.set(indexRowId);\n+        for (int i = 0; i < fkConstraintInfo.getFormatIdsCount(); i++) {\n+            if (multiFieldDecoder.nextIsNull()) {\n+                throw StandardException.newException(String.format(\"unexpected index rowid format %s\", Bytes.toHex(indexRowId)));\n+            }\n+            if (fkConstraintInfo.getFormatIds(i) == StoredFormatIds.SQL_DOUBLE_ID) {\n+                position += multiFieldDecoder.skipDouble();\n+            } else if (fkConstraintInfo.getFormatIds(i) == StoredFormatIds.SQL_REAL_ID) {\n+                position += multiFieldDecoder.skipFloat();\n+            } else if (typeProvider.isScalar(fkConstraintInfo.getFormatIds(i))) {\n+                position += multiFieldDecoder.skipLong();\n+            } else {\n+                position += multiFieldDecoder.skip();\n+            }\n+        }\n+        int lastKeyIndex = position - 2;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQwOTQwOQ=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDczNzAzOnYy", "diffSide": "RIGHT", "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMTowNjoxN1rOHhNxow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwODo1OTo0MFrOHh9grQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5MDc1NQ==", "bodyText": "I don't understand this change, if the rowKey is found it's updated with the result, otherwise all rows are updated with the result? What's the rationale behind it?", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504590755", "createdAt": "2020-10-14T11:06:17Z", "author": {"login": "dgomezferro"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NDk1OA==", "bodyText": "I think previously it wasn't expected to reach this code path with a resultRowKey that is not part of the result.\nNow it is possible when a failure from another inner pipeline is propagated, I thought the best way to handle it is to write the same result (in failing cascade it would be failure) to all rows rolling it back.\nIt kind of makes sense for the particular case of on delete cascade that I demonstrated to Jun in another comment, but I am not this does not break other code paths, therefore I would appreciate more feedback on this if possible.", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r504774958", "createdAt": "2020-10-14T15:32:49Z", "author": {"login": "hatyo"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5MDc1NQ=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTI5MjAzNw==", "bodyText": "I think we need to map the lower level failure to the specific rows that failed at this level, and keep the same code we had here.", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r505292037", "createdAt": "2020-10-15T07:52:41Z", "author": {"login": "dgomezferro"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5MDc1NQ=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM3Mjg0NQ==", "bodyText": "Thanks Daniel, will do.", "url": "https://github.com/splicemachine/spliceengine/pull/4281#discussion_r505372845", "createdAt": "2020-10-15T08:59:40Z", "author": {"login": "hatyo"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/context/PipelineWriteContext.java", "diffHunk": "@@ -124,14 +124,21 @@ public void result(KVPair put, WriteResult result) {\n \n     @Override\n     public void result(byte[] resultRowKey, WriteResult result) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5MDc1NQ=="}, "originalCommit": {"oid": "e80b0bb7b957de7c5eeac040ef3f431c2b66952a"}, "originalPosition": 3}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2871, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}