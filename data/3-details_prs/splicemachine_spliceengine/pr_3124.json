{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwMzM1Mzc2", "number": 3124, "title": "DB-8883 Referencing clause for statement triggers.", "bodyText": "This PR adds support for the REFERENCING clause in statement triggers (DB-8883) and changes read-only row triggers to fire concurrently, for performance (DB-8106).\nREFERENCING clause in statement trigger example:\ncreate table t1 (a int, b int);\ncreate table t2 (a int, b int);\nCREATE TRIGGER mytrig\nAFTER INSERT\nON t1\nREFERENCING NEW_TABLE AS NEW\nFOR EACH STATEMENT\ninsert into t2 select new.a, new.b from new;\nSee DB-8883", "createdAt": "2020-01-08T08:19:54Z", "url": "https://github.com/splicemachine/spliceengine/pull/3124", "merged": true, "mergeCommit": {"oid": "f774c8b8239c9dfaa5de3fd4d709bd26014e6e29"}, "closed": true, "closedAt": "2020-02-03T20:19:32Z", "author": {"login": "msirek"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb4dcwugBqjI5MzMwMTAzNzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_fGgHgH2gAyMzYwMzM1Mzc2OjNiNTA2MzhlZjRjOTEyMDI5ZmM4OTRkMDRkMzlhMDc3NGFhNmRlYWM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7881c3eab5089aa10f292f0d91a5f75f72e272b", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/c7881c3eab5089aa10f292f0d91a5f75f72e272b", "committedDate": "2020-01-08T08:16:16Z", "message": "DB-8883 Referencing clause for statement triggers."}, "afterCommit": {"oid": "06c38571e721c4f637f7c1d6c4775523b1794977", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/06c38571e721c4f637f7c1d6c4775523b1794977", "committedDate": "2020-01-08T22:52:48Z", "message": "DB-8883 Referencing clause for statement triggers."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "06c38571e721c4f637f7c1d6c4775523b1794977", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/06c38571e721c4f637f7c1d6c4775523b1794977", "committedDate": "2020-01-08T22:52:48Z", "message": "DB-8883 Referencing clause for statement triggers."}, "afterCommit": {"oid": "1ec5c205f87e1594cb339e276cdcf8b276623e34", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/1ec5c205f87e1594cb339e276cdcf8b276623e34", "committedDate": "2020-01-08T23:27:13Z", "message": "DB-8883 Referencing clause for statement triggers."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c33c08216e99f17a32b0b8ab4383729409e26fb2", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/c33c08216e99f17a32b0b8ab4383729409e26fb2", "committedDate": "2020-01-13T21:23:26Z", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads."}, "afterCommit": {"oid": "f0a2e536e7f84f591d024d196cba88350b705634", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/f0a2e536e7f84f591d024d196cba88350b705634", "committedDate": "2020-01-16T19:08:49Z", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcd1f23244d112692bcfcf7180bfa69ea5dcaa38", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/fcd1f23244d112692bcfcf7180bfa69ea5dcaa38", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Referencing clause for statement triggers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee100521d3ee0dfc21e6c53b87303b4446a23f88", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/ee100521d3ee0dfc21e6c53b87303b4446a23f88", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "203935dce7626da0f61cb8c02d2f552f31491259", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/203935dce7626da0f61cb8c02d2f552f31491259", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Give nested loop join access to the TriggerExecutionContext."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43ff782ca8baedcfecf11f992c12e79330cfcd86", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/43ff782ca8baedcfecf11f992c12e79330cfcd86", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d41edd6902a097e8dfdee90416864f175912675", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/8d41edd6902a097e8dfdee90416864f175912675", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix ITs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2fe2cff5b99547253a70d64f49054101785fa0a6", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/2fe2cff5b99547253a70d64f49054101785fa0a6", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix trigger bugs involving spawned threads and missing AST visitors."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a5b2a2a40b693fd568fabc56032a7d1578041c5", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/3a5b2a2a40b693fd568fabc56032a7d1578041c5", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix SerDe bugs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da88b934b72d277ea243e39bb82fda4276a33fcb", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/da88b934b72d277ea243e39bb82fda4276a33fcb", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Fix ITs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01f8060e09f9744b04f54cca0f89c8173f61dd71", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/01f8060e09f9744b04f54cca0f89c8173f61dd71", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f0a2e536e7f84f591d024d196cba88350b705634", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/f0a2e536e7f84f591d024d196cba88350b705634", "committedDate": "2020-01-16T19:08:49Z", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads."}, "afterCommit": {"oid": "01f8060e09f9744b04f54cca0f89c8173f61dd71", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/01f8060e09f9744b04f54cca0f89c8173f61dd71", "committedDate": "2020-01-16T22:51:57Z", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2aa80e892d4f0585172e3ce1470b5faf022a2471", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/2aa80e892d4f0585172e3ce1470b5faf022a2471", "committedDate": "2020-01-20T17:07:22Z", "message": "DB-8106 Concurrent read-only row triggers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "835adcf71ec50c2b82e1278fd7dbe81f19bb0bf8", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/835adcf71ec50c2b82e1278fd7dbe81f19bb0bf8", "committedDate": "2020-01-20T17:07:40Z", "message": "DB-8106 Fix statement triggers bug."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7855ea83a3fba64c15490bebcfc31836c4d28074", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/7855ea83a3fba64c15490bebcfc31836c4d28074", "committedDate": "2020-01-21T06:58:26Z", "message": "DB-8106 Fix SET statement and concurrency bugs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "committedDate": "2020-01-22T09:46:38Z", "message": "DB-8883 Fix mem leak and bad username in LCC."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MjY0MTUy", "url": "https://github.com/splicemachine/spliceengine/pull/3124#pullrequestreview-347264152", "createdAt": "2020-01-23T12:37:58Z", "commit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "state": "COMMENTED", "comments": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxMjozNzo1OFrOFg8ssQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNDo0NzoxOVrOFhAyRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5MzIzMw==", "bodyText": "Why?\nIt seems that this cannot happen", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370093233", "createdAt": "2020-01-23T12:37:58Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/DMLStatementNode.java", "diffHunk": "@@ -392,7 +392,7 @@ void generateParameterValueSet(ActivationClassBuilder acb) throws StandardExcept\n         Vector parameterList = getCompilerContext().getParameterList();\n         int numberOfParameters = (parameterList == null) ? 0 : parameterList.size();\n \n-        if (numberOfParameters <= 0)\n+        if (numberOfParameters < 0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NDUzNg==", "bodyText": "Similarly, this would probably always be true.\nEither something is weird here, or we want to remove the if and add an assert numberOfParameters >= 0", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370094536", "createdAt": "2020-01-23T12:41:04Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/ParameterNode.java", "diffHunk": "@@ -426,15 +426,15 @@ static public\tvoid generateParameterValueSet(ExpressionClassBuilder\tacb,\n \t\t\t\t\t\t\t\t   Vector\tparameterList)\n \t\tthrows StandardException\n \t{\n-\t\tif (numberOfParameters > 0)\n+\t\tif (numberOfParameters >= 0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NjA3OA==", "bodyText": "hasReturnParam = numberOfParameters > 0 && ....isReturnOutputParam();", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370096078", "createdAt": "2020-01-23T12:45:00Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/ParameterNode.java", "diffHunk": "@@ -426,15 +426,15 @@ static public\tvoid generateParameterValueSet(ExpressionClassBuilder\tacb,\n \t\t\t\t\t\t\t\t   Vector\tparameterList)\n \t\tthrows StandardException\n \t{\n-\t\tif (numberOfParameters > 0)\n+\t\tif (numberOfParameters >= 0)\n \t\t{\n \t\t\tMethodBuilder\tconstructor = acb.getConstructor();\n \n \t\t\t/*\n \t\t\t** Check the first parameter to see if it is a return\n \t\t\t** parameter.\n \t\t\t*/\n-\t\t\tboolean hasReturnParam = ((ParameterNode)parameterList.get(0)).isReturnOutputParam();\n+\t\t\tboolean hasReturnParam = numberOfParameters > 0 ? ((ParameterNode)parameterList.get(0)).isReturnOutputParam() : false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NzE1Nw==", "bodyText": "Why can triggerStack now be overwritten?", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370097157", "createdAt": "2020-01-23T12:47:34Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/conn/GenericLanguageConnectionContext.java", "diffHunk": "@@ -3636,9 +3636,6 @@ public void enterRestoreMode(){\n \n     @Override\n     public void setTriggerStack(TriggerExecutionStack triggerStack){\n-        if(this.triggerStack!=null){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNTY0MA==", "bodyText": "All those acronyms make the code quite hard to read.\nI think they are fine to use in a small scope such as an inner loop, but should be avoided for class attributes.", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370105640", "createdAt": "2020-01-23T13:07:08Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,69 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext cc;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n     private boolean tecPushed;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNzIwMw==", "bodyText": "Add comments to explain why we have LCC1 and LCC2", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370107203", "createdAt": "2020-01-23T13:10:52Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,69 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext cc;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n     private boolean tecPushed;\n+    private boolean esvPushed;\n+    private LanguageConnectionContext esvLCC1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNTQ3MA==", "bodyText": "Why use a vector here?", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370115470", "createdAt": "2020-01-23T13:28:34Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerExecutionContext.java", "diffHunk": "@@ -83,13 +87,29 @@\n     private int[] changedColIds;\n     private String[] changedColNames;\n     private String statementText;\n+    protected ConnectionContext cc;\n     private UUID targetTableId;\n     private String targetTableName;\n-    private ExecRow triggeringResultSet;\n+    private ExecRow triggeringRow;\n     private TriggerDescriptor triggerd;\n     private ExecRow afterRow;   // used exclusively for InsertResultSets which have autoincrement columns.\n     private TriggerEvent event;\n     private FormatableBitSet heapList;\n+    private ExecRow execRowDefinition;\n+    private String tableVersion;\n+    private long conglomId;\n+\n+    protected CursorResultSet  triggeringResultSet;\n+\n+    /*\n+    ** Used to track all the result sets we have given out to\n+    ** users.  When the trigger context is no longer valid,\n+    ** we close all the result sets that may be in the user\n+    ** space because they can no longer provide meaningful\n+    ** results.\n+    */\n+    @SuppressWarnings(\"UseOfObsoleteCollectionType\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNzM2NA==", "bodyText": "pushContext(lcc)", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370117364", "createdAt": "2020-01-23T13:31:58Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerExecutionContext.java", "diffHunk": "@@ -142,8 +165,126 @@ public TriggerExecutionContext(String statementText,\n             }\n         }\n     }\n+    // Push a LanguageConnectionContext into\n+    // the task's ContextManager, if needed.  Return true if the push was done.\n+    public static boolean\n+    pushLanguageConnectionContextToCM(LanguageConnectionContext newLCC, ContextManager cm)\n+                                                               throws StandardException  {\n+        boolean lccPushed = false;\n+        try {\n+            LanguageConnectionContext currentLCC = ConnectionUtil.getCurrentLCC();\n+            if (newLCC != null) {\n+                if (newLCC != currentLCC) {\n+                    cm.pushContext(newLCC);\n+                    lccPushed = true;\n+                }\n+            }\n+        } catch (SQLException e) {\n+            // If the current LCC is not available in the context,\n+            // push it now.\n+            if (newLCC != null) {\n+                lccPushed = true;\n+                cm.pushContext(newLCC);\n+            }\n+        }\n+        return lccPushed;\n+    }\n+\n+    // Push the LanguageConnectionContext from the Activation into\n+    // the task's ContextManager, if needed.  Return true if the push was done.\n+    public static boolean\n+    pushLanguageConnectionContextFromActivation(Activation activation, ContextManager cm)\n+                                                               throws StandardException  {\n+        boolean lccPushed = false;\n+        try {\n+            LanguageConnectionContext currentLCC = ConnectionUtil.getCurrentLCC();\n+            if (activation != null && activation.getLanguageConnectionContext() != null) {\n+                LanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n+                if (lcc != currentLCC) {\n+                    cm.pushContext(activation.getLanguageConnectionContext());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyNDQzOQ==", "bodyText": "Indent for clarity", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370124439", "createdAt": "2020-01-23T13:45:43Z", "author": {"login": "arnaud-splice"}, "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/callbuffer/PipingCallBuffer.java", "diffHunk": "@@ -295,6 +295,7 @@ public void flushBuffer() throws Exception {\n     @Override\n     public void flushBufferAndWait() throws Exception {\n         flushBuffer();\n+        if (serverNameToRegionServerCBMap != null)\n         for (ServerCallBuffer buffer : serverNameToRegionServerCBMap.values()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMTgxNg==", "bodyText": "Why 1000? Probably add a comment or make it a constant", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370131816", "createdAt": "2020-01-23T13:59:06Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzI1MQ==", "bodyText": "Same, add comment to explain why we use this magic value", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370133251", "createdAt": "2020-01-23T14:01:36Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);\n+                    deSiify(s);\n+\n+                    int numColumns = templateRow.nColumns();\n+                    int[] rowDecodingMap = new int[numColumns];\n+                    for (int i = 0; i < numColumns; i++)\n+                        rowDecodingMap[i] = i;\n+\n+                    DataSet<ExecRow> sourceSet = dsp.<SpliceOperation, ExecRow>newScanSet(op, tableName)\n+                    .activation(activation)\n+                    .transaction(txn)\n+                    .scan(s)\n+                    .template(templateRow)\n+                    .tableVersion(tableVersion)\n+                    .reuseRowLocation(!isSpark)  // Needed for tables with generated columns.\n+                    .ignoreRecentTransactions(false)\n+                    .rowDecodingMap(rowDecodingMap)\n+                    .buildDataSet(op);\n+\n+                    if (cachedRowsSet == null)\n+                        triggerRows = sourceSet;\n+                    else\n+                        triggerRows = sourceSet.union(cachedRowsSet, op.getOperationContext());\n+                }\n+                else\n+                    triggerRows = cachedRowsSet;\n+            }\n+            boolean isOld = (this instanceof TriggerOldTransitionRows);\n+            triggerRows = triggerRows.map(new TriggerRowsMapFunction<>(op.getOperationContext(), isOld));\n+            if (writeOperation != null)\n+                writeOperation.registerCloseable(this);\n+\t    return triggerRows;\n+        }\n+\n+        public OperationContext getOperationContext() {\n+\t    return null;\n+        }\n+\n+        public void finishDeserialization(Activation activation) throws StandardException {\n+\t    if (tec != null) {\n+\t        LanguageConnectionContext lcc = null;\n+\t        try {\n+\t            lcc = activation.getLanguageConnectionContext();\n+\n+\t            if (tec.statementTriggerWithReferencingClause() &&\n+                        !tec.hasTriggeringResultSet() &&\n+                        ConnectionUtil.getCurrentLCC() != lcc &&\n+                        lcc.getTriggerExecutionContext() != null) {\n+\n+\t                TriggerExecutionContext currentTEC =\n+                            ConnectionUtil.getCurrentLCC().getTriggerExecutionContext();\n+                        if (currentTEC != null)\n+                            ConnectionUtil.getCurrentLCC().popTriggerExecutionContext(currentTEC);\n+                        tec = lcc.getTriggerExecutionContext();\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                    }\n+                    if (ConnectionUtil.getCurrentLCC().getTriggerExecutionContext() == null)\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                }\n+\t        catch (SQLException e) {\n+\n+                }\n+                if (rowHolder != null) {\n+\n+                    ConnectionContext cc =\n+                    (ConnectionContext) lcc.getContextManager().\n+                    getContext(ConnectionContext.CONTEXT_ID);\n+                    if (lcc.getTriggerExecutionContext() == null)\n+                        lcc.pushTriggerExecutionContext(tec);\n+\n+                    tec.setConnectionContext(cc);\n+                    rowHolder.setActivation(activation);\n+                    tec.setTriggeringResultSet(rowHolder.getResultSet());\n+                    try {\n+                        if (resultSet != null)\n+                            resultSet.close();\n+                        resultSet = tec.getNewRowSet();\n+                    } catch (SQLException e) {\n+                        throw Exceptions.parseException(e);\n+                    }\n+                }\n+            }\n+        }\n+\n+\tprotected ResultSet initializeResultSet() {\n+\t\ttry {\n+                    if (resultSet != null)\n+                            resultSet.close();\n+\n+                    tec = Factory.getTriggerExecutionContext();\n+                    if (tec != null)\n+                        resultSet = tec.getNewRowSet();\n+                }\n+\t\tcatch (SQLException e) {\n+\t\t    // This may happen on initial deserialization.\n+                    // Don't crash.  We will fill in the tec later\n+                    // in a subsequent deserialization.\n+                }\n+\n+\t\treturn resultSet;\n+\t}\n+    \n+    public ResultSetMetaData getMetaData() throws SQLException\n+    {\n+        if (resultSet != null)\n+            return resultSet.getMetaData();\n+        return null;\n+    }\n+\n+    public void close() throws SQLException {\n+       if (resultSet != null) {\n+           resultSet.close();\n+           resultSet = null;\n+       }\n+       if (sourceSet != null) {\n+           sourceSet.unpersistIt();\n+           sourceSet = null;\n+       }\n+   }\n+\n+    @Override\n+    public double getEstimatedRowCount(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 359}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzMxOA==", "bodyText": "same", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370133318", "createdAt": "2020-01-23T14:01:44Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);\n+                    deSiify(s);\n+\n+                    int numColumns = templateRow.nColumns();\n+                    int[] rowDecodingMap = new int[numColumns];\n+                    for (int i = 0; i < numColumns; i++)\n+                        rowDecodingMap[i] = i;\n+\n+                    DataSet<ExecRow> sourceSet = dsp.<SpliceOperation, ExecRow>newScanSet(op, tableName)\n+                    .activation(activation)\n+                    .transaction(txn)\n+                    .scan(s)\n+                    .template(templateRow)\n+                    .tableVersion(tableVersion)\n+                    .reuseRowLocation(!isSpark)  // Needed for tables with generated columns.\n+                    .ignoreRecentTransactions(false)\n+                    .rowDecodingMap(rowDecodingMap)\n+                    .buildDataSet(op);\n+\n+                    if (cachedRowsSet == null)\n+                        triggerRows = sourceSet;\n+                    else\n+                        triggerRows = sourceSet.union(cachedRowsSet, op.getOperationContext());\n+                }\n+                else\n+                    triggerRows = cachedRowsSet;\n+            }\n+            boolean isOld = (this instanceof TriggerOldTransitionRows);\n+            triggerRows = triggerRows.map(new TriggerRowsMapFunction<>(op.getOperationContext(), isOld));\n+            if (writeOperation != null)\n+                writeOperation.registerCloseable(this);\n+\t    return triggerRows;\n+        }\n+\n+        public OperationContext getOperationContext() {\n+\t    return null;\n+        }\n+\n+        public void finishDeserialization(Activation activation) throws StandardException {\n+\t    if (tec != null) {\n+\t        LanguageConnectionContext lcc = null;\n+\t        try {\n+\t            lcc = activation.getLanguageConnectionContext();\n+\n+\t            if (tec.statementTriggerWithReferencingClause() &&\n+                        !tec.hasTriggeringResultSet() &&\n+                        ConnectionUtil.getCurrentLCC() != lcc &&\n+                        lcc.getTriggerExecutionContext() != null) {\n+\n+\t                TriggerExecutionContext currentTEC =\n+                            ConnectionUtil.getCurrentLCC().getTriggerExecutionContext();\n+                        if (currentTEC != null)\n+                            ConnectionUtil.getCurrentLCC().popTriggerExecutionContext(currentTEC);\n+                        tec = lcc.getTriggerExecutionContext();\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                    }\n+                    if (ConnectionUtil.getCurrentLCC().getTriggerExecutionContext() == null)\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                }\n+\t        catch (SQLException e) {\n+\n+                }\n+                if (rowHolder != null) {\n+\n+                    ConnectionContext cc =\n+                    (ConnectionContext) lcc.getContextManager().\n+                    getContext(ConnectionContext.CONTEXT_ID);\n+                    if (lcc.getTriggerExecutionContext() == null)\n+                        lcc.pushTriggerExecutionContext(tec);\n+\n+                    tec.setConnectionContext(cc);\n+                    rowHolder.setActivation(activation);\n+                    tec.setTriggeringResultSet(rowHolder.getResultSet());\n+                    try {\n+                        if (resultSet != null)\n+                            resultSet.close();\n+                        resultSet = tec.getNewRowSet();\n+                    } catch (SQLException e) {\n+                        throw Exceptions.parseException(e);\n+                    }\n+                }\n+            }\n+        }\n+\n+\tprotected ResultSet initializeResultSet() {\n+\t\ttry {\n+                    if (resultSet != null)\n+                            resultSet.close();\n+\n+                    tec = Factory.getTriggerExecutionContext();\n+                    if (tec != null)\n+                        resultSet = tec.getNewRowSet();\n+                }\n+\t\tcatch (SQLException e) {\n+\t\t    // This may happen on initial deserialization.\n+                    // Don't crash.  We will fill in the tec later\n+                    // in a subsequent deserialization.\n+                }\n+\n+\t\treturn resultSet;\n+\t}\n+    \n+    public ResultSetMetaData getMetaData() throws SQLException\n+    {\n+        if (resultSet != null)\n+            return resultSet.getMetaData();\n+        return null;\n+    }\n+\n+    public void close() throws SQLException {\n+       if (resultSet != null) {\n+           resultSet.close();\n+           resultSet = null;\n+       }\n+       if (sourceSet != null) {\n+           sourceSet.unpersistIt();\n+           sourceSet = null;\n+       }\n+   }\n+\n+    @Override\n+    public double getEstimatedRowCount(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;\n+    }\n+\n+    @Override\n+    public double getEstimatedCostPerInstantiation(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNDg3Mw==", "bodyText": "Why do we cap initialArraySize to 2000?", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370134873", "createdAt": "2020-01-23T14:04:34Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/TriggerRowHolderImpl.java", "diffHunk": "@@ -0,0 +1,517 @@\n+/*\n+ * Copyright (c) 2012 - 2019 Splice Machine, Inc.\n+ *\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package com.splicemachine.derby.impl.sql.execute;\n+\n+\n+import com.splicemachine.access.api.PartitionAdmin;\n+import com.splicemachine.access.api.PartitionFactory;\n+import com.splicemachine.db.iapi.services.sanity.SanityManager;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.sql.conn.ResubmitDistributedException;\n+import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.sql.execute.TemporaryRowHolder;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.ResultDescription;\n+import com.splicemachine.db.iapi.store.access.ConglomerateController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.types.DataValueDescriptor;\n+import com.splicemachine.db.impl.sql.execute.IndexValueRow;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.impl.sql.execute.ValueRow;\n+\n+import java.io.*;\n+import java.util.Iterator;\n+import java.util.Properties;\n+import java.util.concurrent.Callable;\n+\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.TriggerHandler;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.kvpair.KVPair;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.pipeline.PipelineDriver;\n+import com.splicemachine.pipeline.callbuffer.RecordingCallBuffer;\n+import com.splicemachine.pipeline.client.WriteCoordinator;\n+import com.splicemachine.pipeline.config.UnsafeWriteConfiguration;\n+import com.splicemachine.pipeline.config.WriteConfiguration;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.si.impl.driver.SIDriver;\n+import com.splicemachine.storage.Partition;\n+import org.apache.log4j.Logger;\n+\n+import static java.lang.String.format;\n+\n+\n+/**\n+* This is a class that is used to temporarily\n+* (non-persistently) hold rows of the DML result\n+* set for statement triggers.  It will store them in an\n+* array, plus a temporary conglomerate, if there is overflow.\n+* But upon overflow of the array, if running true Splice with HBase, the\n+* statement is aborted and rerouted to run on Spark.\n+* <p>\n+* It is used for deferred DML processing.\n+* This class is a modified version of TemporaryRowHolderImpl.\n+*\n+*/\n+public class TriggerRowHolderImpl implements TemporaryRowHolder, Externalizable\n+{\n+     private static final Logger LOG = Logger.getLogger(TriggerRowHolderImpl.class);\n+\n+    protected static final int STATE_UNINIT = 0;\n+    public static final int STATE_INSERT = 1;\n+    public static final int STATE_DRAIN = 2;\n+\n+\n+    protected ExecRow[]         rowArray;\n+    private int                 numRowsIn = 0;\n+    private int                 lastArraySlot = -1;\n+    public int                  state = STATE_UNINIT;\n+\n+    private long                CID;\n+    private boolean             conglomCreated;\n+    private boolean             pipelineBufferCreated;\n+    private ConglomerateController\tcc;\n+    private Properties\t\t\t\tproperties;\n+\n+    private\tResultDescription\t\tresultDescription;\n+    /** Activation object with local state information. */\n+    public Activation\t\t\t\t\t\tactivation;\n+\n+    int \t\t\toverflowToConglomThreshold;\n+    int \t\t\tswitchToSparkThreshold;\n+    boolean                     isSpark;  // Is the query executing on spark?\n+    private ExecRow execRowDefinition;\n+    private String  tableVersion;\n+\n+    protected WriteCoordinator writeCoordinator;\n+    protected RecordingCallBuffer<KVPair> triggerTempTableWriteBuffer;\n+    protected Callable<Void> triggerTempTableflushCallback;\n+    protected Partition triggerTempPartition;\n+    private TxnView txn;\n+    private byte[] token;\n+    private TriggerExecutionContext tec;\n+\n+    public TriggerRowHolderImpl() {\n+\n+    }\n+\n+    /**\n+     * Create a temporary row holder with the defined overflow to conglom\n+     *\n+     * @param activation the activation\n+     * @param properties the properties of the original table.  Used\n+     *\t\tto help the store use optimal page size, etc.\n+     * @param resultDescription the result description.  Relevant for the getResultDescription\n+     * \t\tcall on the result set returned by getResultSet.  May be null\n+     * @param overflowToConglomThreshold on an attempt to insert\n+     * \t\tthis number of rows, the rows will be put\n+     *\t\tinto a temporary conglomerate.\n+     */\n+    public TriggerRowHolderImpl\n+    (\n+            Activation              activation,\n+            Properties              properties,\n+            ResultDescription       resultDescription,\n+            int                     overflowToConglomThreshold,\n+            int                     switchToSparkThreshold,\n+            ExecRow                 execRowDefinition,\n+            String                  tableVersion,\n+            boolean                 isSpark,\n+            TxnView                 txn,\n+            byte[]                  token,\n+            long                    ConglomID,\n+            TriggerExecutionContext tec\n+    )\n+    {\n+        if (SanityManager.DEBUG)\n+        {\n+                if (overflowToConglomThreshold < 0)\n+                {\n+                        SanityManager.THROWASSERT(\"It is assumed that \"+\n+                                \"the overflow threshold is >= 0.  \"+\n+                                \"If you you need to change this you have to recode some of \"+\n+                                \"this class.\");\n+                }\n+        }\n+\n+        this.activation = activation;\n+        this.properties = properties;\n+        this.resultDescription = resultDescription;\n+        this.txn = txn;\n+        this.token = token;\n+        this.tec = tec;\n+        this.isSpark = isSpark;\n+\n+        int initialArraySize = overflowToConglomThreshold < 1 ? 1 : overflowToConglomThreshold;\n+        if (initialArraySize > 2000)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDI4MA==", "bodyText": "Remove DB-8883 comment", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370144280", "createdAt": "2020-01-23T14:21:04Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/test/java/com/splicemachine/triggers/Trigger_When_Clause_IT.java", "diffHunk": "@@ -547,44 +548,64 @@ public void testDependencies() throws Exception {\n             // table fails, even if the column is not referenced in the WHEN clause\n             // or in the triggered SQL text.\n             // Need DB-8883 for the following commented tests:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0ODQ1Nw==", "bodyText": "this.tableVersion = tableVersion is probably missing", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370148457", "createdAt": "2020-01-23T14:27:55Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/stream/output/direct/DirectPipelineWriter.java", "diffHunk": "@@ -46,10 +46,11 @@\n     private TxnView txn;\n     private final OperationContext opCtx;\n     private final boolean skipIndex;\n+    protected String tableVersion;\n \n     private RecordingCallBuffer<KVPair> writeBuffer;\n \n-    public DirectPipelineWriter(long destConglomerate, TxnView txn, byte[] token, OperationContext opCtx, boolean skipIndex){\n+    public DirectPipelineWriter(long destConglomerate, TxnView txn, byte[] token, OperationContext opCtx, boolean skipIndex, String tableVersion){\n         this.destConglomerate=destConglomerate;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1MjgzNQ==", "bodyText": "Should that 1 million limit also be applied in the other place we use that setting?\nIf so, you can set the limit directly in SQLConfiguration.java\ncf SPARK_COMPACTION_RESOLUTION_SHARE in OlapConfigurations.java for an example", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370152835", "createdAt": "2020-01-23T14:35:18Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -62,36 +75,174 @@\n     private final boolean hasBeforeStatement;\n     private final boolean hasAfterRow;\n     private final boolean hasAfterStatement;\n+    private final boolean hasStatementTriggerWithReferencingClause;\n     private FormatableBitSet heapList;\n+    private ExecRow templateRow;\n+    private String tableVersion;\n+\n+    private DMLWriteInfo writeInfo;\n+    private Activation activation;\n+    private TriggerRowHolderImpl triggerRowHolder;\n+    private boolean isSpark;\n+    private TxnView txn;\n+    private byte[] token;\n+\n+    private Function<Function<LanguageConnectionContext,Void>, Callable> withContext;\n \n     public TriggerHandler(TriggerInfo triggerInfo,\n                           DMLWriteInfo writeInfo,\n                           Activation activation,\n                           TriggerEvent beforeEvent,\n                           TriggerEvent afterEvent,\n-                          FormatableBitSet heapList) throws StandardException {\n+                          FormatableBitSet heapList,\n+                          ExecRow templateRow,\n+                          String tableVersion) throws StandardException {\n         WriteCursorConstantOperation constantAction = (WriteCursorConstantOperation) writeInfo.getConstantAction();\n         initConnectionContext(activation.getLanguageConnectionContext());\n \n         this.beforeEvent = beforeEvent;\n         this.afterEvent = afterEvent;\n+        this.activation = activation;\n         this.resultDescription = activation.getResultDescription();\n         this.pendingAfterRows = Lists.newArrayListWithCapacity(AFTER_ROW_BUFFER_SIZE);\n \n         this.hasBeforeRow = triggerInfo.hasBeforeRowTrigger();\n         this.hasAfterRow = triggerInfo.hasAfterRowTrigger();\n         this.hasBeforeStatement = triggerInfo.hasBeforeStatementTrigger();\n         this.hasAfterStatement = triggerInfo.hasAfterStatementTrigger();\n+        this.hasStatementTriggerWithReferencingClause = triggerInfo.hasStatementTriggerWithReferencingClause();\n         this.heapList = heapList;\n+        this.templateRow = templateRow;\n+        this.tableVersion = tableVersion;\n+        this.activation = activation;\n+        this.writeInfo = writeInfo;\n         initTriggerActivator(activation, constantAction);\n     }\n \n+    public Callable<Void> getTriggerTempTableflushCallback () {\n+        if (triggerRowHolder != null)\n+             return triggerRowHolder.getTriggerTempTableflushCallback();\n+        return null;\n+    }\n+\n+    public void setTxn(TxnView txn) {\n+        this.txn = txn;\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.setTxn(txn);\n+    }\n+\n+    public boolean hasStatementTrigger() {\n+        return hasBeforeStatement || hasAfterStatement;\n+    }\n+\n+    public boolean hasStatementTriggerWithReferencingClause() {\n+        return this.hasStatementTriggerWithReferencingClause;\n+    }\n+\n+    public void addRowToNewTableRowHolder(ExecRow row, KVPair encode) throws StandardException {\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.insert(row, encode);\n+    }\n+\n+    public void setIsSpark(boolean isSpark) {\n+        this.isSpark = isSpark;\n+    }\n+\n+    public boolean isSpark() {\n+        return this.isSpark;\n+    }\n+\n+    public long getTriggerConglomID() {\n+        if (triggerRowHolder != null) {\n+            return triggerRowHolder.getConglomerateId();\n+        }\n+        return 0;\n+    }\n+\n+    public void initTriggerRowHolders(boolean isSpark, TxnView txn, byte[] token, long ConglomID) throws StandardException {\n+        this.isSpark = isSpark;\n+        this.txn = txn;\n+        this.token = token;\n+        Properties properties = new Properties();\n+        if (hasStatementTriggerWithReferencingClause) {\n+            // Use the smaller of ControlExecutionRowLimit or 1000000 to determine when to switch to spark execution.\n+            // Hard cap at 1 million despite the setting of controlExecutionRowLimit since we don't want to exhaust", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NTE2OA==", "bodyText": "withContext = f -> (Callable) () -> { ActivationHolder ah = new ActivationHolder(activation, null); try { ...", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370155168", "createdAt": "2020-01-23T14:39:13Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -62,36 +75,174 @@\n     private final boolean hasBeforeStatement;\n     private final boolean hasAfterRow;\n     private final boolean hasAfterStatement;\n+    private final boolean hasStatementTriggerWithReferencingClause;\n     private FormatableBitSet heapList;\n+    private ExecRow templateRow;\n+    private String tableVersion;\n+\n+    private DMLWriteInfo writeInfo;\n+    private Activation activation;\n+    private TriggerRowHolderImpl triggerRowHolder;\n+    private boolean isSpark;\n+    private TxnView txn;\n+    private byte[] token;\n+\n+    private Function<Function<LanguageConnectionContext,Void>, Callable> withContext;\n \n     public TriggerHandler(TriggerInfo triggerInfo,\n                           DMLWriteInfo writeInfo,\n                           Activation activation,\n                           TriggerEvent beforeEvent,\n                           TriggerEvent afterEvent,\n-                          FormatableBitSet heapList) throws StandardException {\n+                          FormatableBitSet heapList,\n+                          ExecRow templateRow,\n+                          String tableVersion) throws StandardException {\n         WriteCursorConstantOperation constantAction = (WriteCursorConstantOperation) writeInfo.getConstantAction();\n         initConnectionContext(activation.getLanguageConnectionContext());\n \n         this.beforeEvent = beforeEvent;\n         this.afterEvent = afterEvent;\n+        this.activation = activation;\n         this.resultDescription = activation.getResultDescription();\n         this.pendingAfterRows = Lists.newArrayListWithCapacity(AFTER_ROW_BUFFER_SIZE);\n \n         this.hasBeforeRow = triggerInfo.hasBeforeRowTrigger();\n         this.hasAfterRow = triggerInfo.hasAfterRowTrigger();\n         this.hasBeforeStatement = triggerInfo.hasBeforeStatementTrigger();\n         this.hasAfterStatement = triggerInfo.hasAfterStatementTrigger();\n+        this.hasStatementTriggerWithReferencingClause = triggerInfo.hasStatementTriggerWithReferencingClause();\n         this.heapList = heapList;\n+        this.templateRow = templateRow;\n+        this.tableVersion = tableVersion;\n+        this.activation = activation;\n+        this.writeInfo = writeInfo;\n         initTriggerActivator(activation, constantAction);\n     }\n \n+    public Callable<Void> getTriggerTempTableflushCallback () {\n+        if (triggerRowHolder != null)\n+             return triggerRowHolder.getTriggerTempTableflushCallback();\n+        return null;\n+    }\n+\n+    public void setTxn(TxnView txn) {\n+        this.txn = txn;\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.setTxn(txn);\n+    }\n+\n+    public boolean hasStatementTrigger() {\n+        return hasBeforeStatement || hasAfterStatement;\n+    }\n+\n+    public boolean hasStatementTriggerWithReferencingClause() {\n+        return this.hasStatementTriggerWithReferencingClause;\n+    }\n+\n+    public void addRowToNewTableRowHolder(ExecRow row, KVPair encode) throws StandardException {\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.insert(row, encode);\n+    }\n+\n+    public void setIsSpark(boolean isSpark) {\n+        this.isSpark = isSpark;\n+    }\n+\n+    public boolean isSpark() {\n+        return this.isSpark;\n+    }\n+\n+    public long getTriggerConglomID() {\n+        if (triggerRowHolder != null) {\n+            return triggerRowHolder.getConglomerateId();\n+        }\n+        return 0;\n+    }\n+\n+    public void initTriggerRowHolders(boolean isSpark, TxnView txn, byte[] token, long ConglomID) throws StandardException {\n+        this.isSpark = isSpark;\n+        this.txn = txn;\n+        this.token = token;\n+        Properties properties = new Properties();\n+        if (hasStatementTriggerWithReferencingClause) {\n+            // Use the smaller of ControlExecutionRowLimit or 1000000 to determine when to switch to spark execution.\n+            // Hard cap at 1 million despite the setting of controlExecutionRowLimit since we don't want to exhaust\n+            // memory if the sysadmin cranked this setting really high.\n+            int switchToSparkThreshold = EngineDriver.driver().getConfiguration().getControlExecutionRowLimit() <= Integer.MAX_VALUE ?\n+            (int) EngineDriver.driver().getConfiguration().getControlExecutionRowLimit() : Integer.MAX_VALUE;\n+\n+            if (switchToSparkThreshold < 0)\n+                switchToSparkThreshold = 0;\n+            else if (switchToSparkThreshold > 1000000)\n+                switchToSparkThreshold = 1000000;\n+\n+\n+            long doubleDetermineSparkRowThreshold = 2 * getLcc().getOptimizerFactory().getDetermineSparkRowThreshold();\n+            int inMemoryLimit = switchToSparkThreshold;\n+\n+            // Pick the larger of switchToSparkThreshold or 2*determineSparkRowThreshold as the\n+            // threshold for creating a conglomerate.  By design this will cause the trigger rows\n+            // to always be held in memory when executing on control, for performance.\n+            // But the interface also supports values of switchToSparkThreshold which are larger than\n+            // overflowToConglomThreshold, in which case we could create a temporary conglomerate while\n+            // executing in control.\n+            int overflowToConglomThreshold =\n+                 doubleDetermineSparkRowThreshold > inMemoryLimit ? (int)doubleDetermineSparkRowThreshold :\n+                 doubleDetermineSparkRowThreshold < 0 ? 0 :\n+                 inMemoryLimit;\n+\n+            // Spark doesn't support use of an in-memory TriggerRowHolderImpl, so we\n+            // set overflowToConglomThreshold to zero and always use a conglomerate.\n+            if (isSpark) {\n+                switchToSparkThreshold = 0;\n+                overflowToConglomThreshold = 0;\n+            }\n+\n+            triggerRowHolder =\n+                new TriggerRowHolderImpl(activation, properties, writeInfo.getResultDescription(),\n+                                         overflowToConglomThreshold, switchToSparkThreshold,\n+                                         templateRow, tableVersion, isSpark, txn, token, ConglomID,\n+                                          this.getTriggerExecutionContext());\n+        }\n+\n+    }\n+\n+    public TriggerExecutionContext getTriggerExecutionContext() { return this.triggerActivator.getTriggerExecutionContext(); }\n+\n     private void initTriggerActivator(Activation activation, WriteCursorConstantOperation constantAction) throws StandardException {\n         try {\n+            withContext = new Function<Function<LanguageConnectionContext,Void>, Callable>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NzE0Ng==", "bodyText": "Same here, use lambda", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370157146", "createdAt": "2020-01-23T14:42:36Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -147,37 +316,89 @@ public void firePendingAfterTriggers(Callable<Void> flushCallback) throws Except\n          * Which is what we want. Check constraints before firing after triggers. */\n         try {\n             flushCallback.call();\n+            if (getTriggerTempTableflushCallback() != null)\n+                getTriggerTempTableflushCallback().call();\n         } catch (Exception e) {\n             pendingAfterRows.clear();\n             throw e;\n         }\n \n-        for (ExecRow flushedRow : pendingAfterRows) {\n-            fireAfterRowTriggers(flushedRow);\n+        if (!hasAfterRow)\n+            return;\n+\n+        List<Future<Void>> futures = new ArrayList<>();\n+\n+        // The LCC can't be shared amongst threads, so\n+        // only use one level of concurrency for now.\n+        if (true || pendingAfterRows.size() <= 1) {\n+            for (ExecRow flushedRow : pendingAfterRows)\n+                futures.addAll(fireAfterRowConcurrentTriggers(flushedRow));\n+            for (ExecRow flushedRow : pendingAfterRows)\n+                fireAfterRowTriggers(flushedRow);\n+        } else {\n+            Object lock = new Object();\n+            // work concurrently\n+            List<Future<Void>> rowFutures = new ArrayList<>();\n+            for (ExecRow flushedRow : pendingAfterRows) {\n+                rowFutures.add(SIDriver.driver().getExecutorService().submit(withContext.apply(new Function<LanguageConnectionContext,Void>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2MDE5Nw==", "bodyText": "Why are resets still there?", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370160197", "createdAt": "2020-01-23T14:47:19Z", "author": {"login": "arnaud-splice"}, "path": "splice_machine/src/test/java/com/splicemachine/triggers/Trigger_Referencing_Clause_IT.java", "diffHunk": "@@ -0,0 +1,1294 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2019 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.triggers;\n+\n+import com.splicemachine.derby.test.framework.*;\n+import com.splicemachine.test.SerialTest;\n+import org.junit.*;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+import org.spark_project.guava.collect.Lists;\n+\n+import java.sql.*;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static com.splicemachine.db.shared.common.reference.MessageId.SPLICE_GENERIC_EXCEPTION;\n+import static com.splicemachine.db.shared.common.reference.SQLState.LANG_TRIGGER_BAD_REF_MISMATCH;\n+\n+/**\n+ * Test REFERENCING clause in triggers.\n+ */\n+@Category(value = {SerialTest.class})\n+@RunWith(Parameterized.class)\n+public class Trigger_Referencing_Clause_IT extends SpliceUnitTest {\n+\n+\n+    private static final String SCHEMA = Trigger_Referencing_Clause_IT.class.getSimpleName();\n+    public static final String CLASS_NAME = Trigger_Referencing_Clause_IT.class.getSimpleName().toUpperCase();\n+    protected static final String USER1 = \"U1\";\n+    protected static final String PASSWORD1 = \"U1\";\n+    protected static final String USER2 = \"U2\";\n+    protected static final String PASSWORD2 = \"U2\";\n+\n+    @ClassRule\n+    public static SpliceSchemaWatcher spliceSchemaWatcher = new SpliceSchemaWatcher(SCHEMA);\n+\n+    @ClassRule\n+    public static SpliceWatcher classWatcher = new SpliceWatcher(SCHEMA);\n+\n+    @ClassRule\n+    public static SpliceUserWatcher spliceUserWatcher1 = new SpliceUserWatcher(USER1, PASSWORD1);\n+\n+    @ClassRule\n+    public static SpliceUserWatcher spliceUserWatcher2 = new SpliceUserWatcher(USER2, PASSWORD2);\n+\n+    private TestConnection conn;\n+    private TestConnection c1;\n+    private TestConnection c2;\n+\n+    private static final String SYNTAX_ERROR = \"42X01\";\n+    private static final String NON_SCALAR_QUERY = \"21000\";\n+    private static final String TRIGGER_RECURSION = \"54038\";\n+\n+\n+    @Parameterized.Parameters\n+    public static Collection<Object[]> data() {\n+        Collection<Object[]> params = Lists.newArrayListWithCapacity(2);\n+        params.add(new Object[]{\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin\"});\n+        params.add(new Object[]{\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin;useSpark=true\"});\n+        return params;\n+    }\n+\n+    private String connectionString;\n+\n+    public Trigger_Referencing_Clause_IT(String connectionString ) {\n+        this.connectionString = connectionString;\n+    }\n+\n+    protected void createInt_Proc() throws Exception {\n+        Connection c = conn;\n+        try(Statement s = c.createStatement()) {\n+            s.execute(\"create function f(x varchar(50)) returns boolean \"\n+            + \"language java parameter style java external name \"\n+            + \"'org.splicetest.sqlj.SqlJTestProcs.tableIsEmpty' reads sql data\");\n+\n+            s.executeUpdate(\"create procedure int_proc(i int) language java \"\n+            + \"parameter style java external name \"\n+            + \"'org.splicetest.sqlj.SqlJTestProcs.intProcedure' reads sql data\");\n+            // If running tests in IntelliJ, use one of the commented-out versions of STORED_PROCS_JAR_FILE.\n+            String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/target/sql-it/sql-it.jar\";\n+            //String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/../platform_it/target/sql-it/sql-it.jar\";\n+            //String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/../mem_sql/target/sql-it/sql-it.jar\";\n+            String JAR_FILE_SQL_NAME = CLASS_NAME + \".\" + \"SQLJ_IT_PROCS_JAR\";\n+            s.execute(String.format(\"CALL SQLJ.INSTALL_JAR('%s', '%s', 0)\", STORED_PROCS_JAR_FILE, JAR_FILE_SQL_NAME));\n+            s.execute(String.format(\"CALL SYSCS_UTIL.SYSCS_SET_GLOBAL_DATABASE_PROPERTY('derby.database.classpath', '%s')\", JAR_FILE_SQL_NAME));\n+            c.commit();\n+        }\n+    }\n+\n+    /* Each test starts with same table state */\n+    @Before\n+    public void initTable() throws Exception {\n+        spliceSchemaWatcher.cleanSchemaObjects();\n+        conn = new TestConnection(DriverManager.getConnection(connectionString, new Properties()));\n+        // grant schema privileges\n+        conn.execute(format(\"grant ALL PRIVILEGES on schema %s to %s\", SCHEMA, USER1));\n+        conn.execute(format(\"grant access on schema %s to %s\", SCHEMA, USER2));\n+\n+        // grant execution privileges\n+        conn.execute(format(\"grant execute on procedure syscs_util.syscs_get_schema_info to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure syscs_util.syscs_get_schema_info to %s\", USER2));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_GLOBAL_DICTIONARY_CACHE to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_GLOBAL_DICTIONARY_CACHE to %s\", USER2));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_DICTIONARY_CACHE to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_DICTIONARY_CACHE to %s\", USER2));\n+\n+        conn.setAutoCommit(false);\n+        conn.setSchema(SCHEMA.toUpperCase());\n+\n+        c1 = classWatcher.createConnection(\"U1\", \"U1\");\n+        c2 = classWatcher.createConnection(\"U2\", \"U2\");\n+        c1.setAutoCommit(false);\n+        c1.setSchema(SCHEMA.toUpperCase());\n+        c2.setAutoCommit(false);\n+        c2.setSchema(SCHEMA.toUpperCase());\n+    }\n+\n+    @After\n+    public void rollback() throws Exception{\n+        conn.rollback();\n+        //conn.reset();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 153}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ca022525e200e504d68b9d377a85e15bbfc8189", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/3ca022525e200e504d68b9d377a85e15bbfc8189", "committedDate": "2020-01-27T06:52:00Z", "message": "DB-8883 Address review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/492bcc740ab765f2eccdabd08314221183af4ed8", "committedDate": "2020-01-27T16:18:50Z", "message": "DB-8106 Fix synchronization issue."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ4ODQ1NTkx", "url": "https://github.com/splicemachine/spliceengine/pull/3124#pullrequestreview-348845591", "createdAt": "2020-01-27T17:33:15Z", "commit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzozMzoxNVrOFiLRig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzozNjo1M1rOFiLYfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4MDYxOA==", "bodyText": "the way numberOfParameters is calculated, it seems that we will never enter the if indeed, so let's remove it.", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371380618", "createdAt": "2020-01-27T17:33:15Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/DMLStatementNode.java", "diffHunk": "@@ -392,7 +392,7 @@ void generateParameterValueSet(ActivationClassBuilder acb) throws StandardExcept\n         Vector parameterList = getCompilerContext().getParameterList();\n         int numberOfParameters = (parameterList == null) ? 0 : parameterList.size();\n \n-        if (numberOfParameters <= 0)\n+        if (numberOfParameters < 0)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5MzIzMw=="}, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4MjM5OQ==", "bodyText": "Vector seems to be obsolete, but I don't know much about it. I'd say we leave it like this for now.", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371382399", "createdAt": "2020-01-27T17:36:53Z", "author": {"login": "arnaud-splice"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerExecutionContext.java", "diffHunk": "@@ -83,13 +87,29 @@\n     private int[] changedColIds;\n     private String[] changedColNames;\n     private String statementText;\n+    protected ConnectionContext cc;\n     private UUID targetTableId;\n     private String targetTableName;\n-    private ExecRow triggeringResultSet;\n+    private ExecRow triggeringRow;\n     private TriggerDescriptor triggerd;\n     private ExecRow afterRow;   // used exclusively for InsertResultSets which have autoincrement columns.\n     private TriggerEvent event;\n     private FormatableBitSet heapList;\n+    private ExecRow execRowDefinition;\n+    private String tableVersion;\n+    private long conglomId;\n+\n+    protected CursorResultSet  triggeringResultSet;\n+\n+    /*\n+    ** Used to track all the result sets we have given out to\n+    ** users.  When the trigger context is no longer valid,\n+    ** we close all the result sets that may be in the user\n+    ** space because they can no longer provide meaningful\n+    ** results.\n+    */\n+    @SuppressWarnings(\"UseOfObsoleteCollectionType\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNTQ3MA=="}, "originalCommit": {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwOTgyMjM4", "url": "https://github.com/splicemachine/spliceengine/pull/3124#pullrequestreview-350982238", "createdAt": "2020-01-30T16:54:02Z", "commit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwNzg5MzI3", "url": "https://github.com/splicemachine/spliceengine/pull/3124#pullrequestreview-350789327", "createdAt": "2020-01-30T12:34:56Z", "commit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxMjozNDo1NlrOFjpaIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNjoyNzoxMFrOFjxZkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkyMjkxNA==", "bodyText": "What's this for?", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r372922914", "createdAt": "2020-01-30T12:34:56Z", "author": {"login": "dgomezferro"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/catalog/DataDictionaryImpl.java", "diffHunk": "@@ -4013,11 +4017,20 @@ public String getTriggerActionString(\n             // Add the replacement code that accesses a value in the\n             // transition variable.\n             final int replacementOffset = newText.length();\n+            boolean isSetTarget = false;\n+            if (actionStmt instanceof SetNode) {\n+                String regex    =   \"(^set[\\\\s]+$)|([\\\\s]+set[\\\\s]+$)|(,[\\\\s]*$)\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAzMzU0OQ==", "bodyText": "Having all these LCCs around doesn't seem like a good thing. Does trigger execution require both for some specific reason or is it that it just didn't work without both? Context handling is very messy in general and I feel we are making it even worse, but I don't have specific advice on how to make it better. We'd need someone to spend a significant amount of time going through it and trying to come up with a simpler design.", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373033549", "createdAt": "2020-01-30T15:54:14Z", "author": {"login": "dgomezferro"}, "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,78 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext connectionContext;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n-    private boolean tecPushed;\n+    private boolean triggerExecutionContextPushed;\n+    private boolean executionStmtValidatorPushed;\n+\n+    // getLcc() may return a different LanguageConnectionContext at the time\n+    // we pop the triggerExecutionContext and executionStmtValidator, versus\n+    // at the time they were pushed.  Saving the original \"LCC\" at the time of\n+    // the push ensures that we pop from the correct LCC.  We sometimes need to\n+    // save two versions LCCs because we may push to the LCC in the activation,\n+    // and also to the LCC stored in the current ContextManager, if they happen\n+    // to be different.  Trigger execution requires that both the activation and\n+    // the current ContextManager both have a triggerExecutionContext.\n+    private LanguageConnectionContext esvLCC1;\n+    private LanguageConnectionContext esvLCC2;\n+    private LanguageConnectionContext tecLCC1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1Mzg0Mw==", "bodyText": "This branch is always going to be picked", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373053843", "createdAt": "2020-01-30T16:27:10Z", "author": {"login": "dgomezferro"}, "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -147,37 +316,89 @@ public void firePendingAfterTriggers(Callable<Void> flushCallback) throws Except\n          * Which is what we want. Check constraints before firing after triggers. */\n         try {\n             flushCallback.call();\n+            if (getTriggerTempTableflushCallback() != null)\n+                getTriggerTempTableflushCallback().call();\n         } catch (Exception e) {\n             pendingAfterRows.clear();\n             throw e;\n         }\n \n-        for (ExecRow flushedRow : pendingAfterRows) {\n-            fireAfterRowTriggers(flushedRow);\n+        if (!hasAfterRow)\n+            return;\n+\n+        List<Future<Void>> futures = new ArrayList<>();\n+\n+        // The LCC can't be shared amongst threads, so\n+        // only use one level of concurrency for now.\n+        if (true || pendingAfterRows.size() <= 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8"}, "originalPosition": 280}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b50638ef4c912029fc894d04d39a0774aa6deac", "author": {"user": {"login": "msirek", "name": "Mark Sirek"}}, "url": "https://github.com/splicemachine/spliceengine/commit/3b50638ef4c912029fc894d04d39a0774aa6deac", "committedDate": "2020-01-30T18:46:19Z", "message": "Merge branch 'master' into DB-8883_final"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 980, "cost": 1, "resetAt": "2021-11-02T10:47:05Z"}}}