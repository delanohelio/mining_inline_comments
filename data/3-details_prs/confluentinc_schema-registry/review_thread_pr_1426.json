{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4ODA2MDY2", "number": 1426, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjozMzo0NVrOD27XAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjo1NDo1NlrOD27vkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4OTIyMjQwOnYy", "diffSide": "RIGHT", "path": "core/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjozMzo0NVrOGM6hyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMzowNDozNFrOGM7U8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5NTAxNw==", "bodyText": "Nit: '//'.", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416195017", "createdAt": "2020-04-27T22:33:45Z", "author": {"login": "dragosvictor"}, "path": "core/pom.xml", "diffHunk": "@@ -256,7 +256,28 @@\n                     <mainClass>io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain</mainClass>\n                 </configuration>\n             </plugin>\n-\n+            <plugin>\n+                <groupId>org.apache.avro</groupId>\n+                <artifactId>avro-maven-plugin</artifactId>\n+                <executions>\n+                    <execution>\n+                        <phase>generate-sources</phase>\n+                        <goals>\n+                            <goal>schema</goal>\n+                        </goals>\n+                        <configuration>\n+                            <testSourceDirectory>${project.basedir}/src/test/avro</testSourceDirectory>\n+                            <imports>\n+                                <import>${project.basedir}/src/test//avro/subrecord.avsc</import>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwODExMw==", "bodyText": "Ack", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416208113", "createdAt": "2020-04-27T23:04:34Z", "author": {"login": "rayokota"}, "path": "core/pom.xml", "diffHunk": "@@ -256,7 +256,28 @@\n                     <mainClass>io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain</mainClass>\n                 </configuration>\n             </plugin>\n-\n+            <plugin>\n+                <groupId>org.apache.avro</groupId>\n+                <artifactId>avro-maven-plugin</artifactId>\n+                <executions>\n+                    <execution>\n+                        <phase>generate-sources</phase>\n+                        <goals>\n+                            <goal>schema</goal>\n+                        </goals>\n+                        <configuration>\n+                            <testSourceDirectory>${project.basedir}/src/test/avro</testSourceDirectory>\n+                            <imports>\n+                                <import>${project.basedir}/src/test//avro/subrecord.avsc</import>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5NTAxNw=="}, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4OTI0MjY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjo0MDoyOVrOGM6tBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMzowNDo0NlrOGM7VTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5Nzg5Mg==", "bodyText": "Is this optimization still happening ? As it is, we are parsing the previous schemas.", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416197892", "createdAt": "2020-04-27T22:40:29Z", "author": {"login": "dragosvictor"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -1182,23 +1207,27 @@ public boolean isCompatible(String subject,\n       throw new InvalidSchemaException(\"Previous schema not provided\");\n     }\n \n-    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n-    if (compatibility == CompatibilityLevel.NONE) {\n-      // optimization to avoid parsing schemas\n-      return true;\n-    }\n-\n     List<ParsedSchema> prevParsedSchemas = new ArrayList<>(previousSchemas.size());\n     for (Schema previousSchema : previousSchemas) {\n       ParsedSchema prevParsedSchema = parseSchema(previousSchema);\n       prevParsedSchemas.add(prevParsedSchema);\n     }\n \n-    ParsedSchema parsedSchema = parseSchema(newSchema);\n-    boolean isCompatible = parsedSchema.isCompatible(compatibility, prevParsedSchemas);\n-    // Allow schema providers to modify the schema during compatibility checks\n-    newSchema.setSchema(parsedSchema.canonicalString());\n-    return isCompatible;\n+    return isCompatibleWithPrevious(subject, parseSchema(newSchema), prevParsedSchemas);\n+  }\n+\n+  private boolean isCompatibleWithPrevious(String subject,\n+                                           ParsedSchema parsedSchema,\n+                                           List<ParsedSchema> previousSchemas)\n+      throws SchemaRegistryException {\n+\n+    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n+    if (compatibility == CompatibilityLevel.NONE) {\n+      // optimization to avoid parsing schemas\n+      return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwNzU0OQ==", "bodyText": "Yes, this optimization is moved to another method.", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416207549", "createdAt": "2020-04-27T23:03:05Z", "author": {"login": "rayokota"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -1182,23 +1207,27 @@ public boolean isCompatible(String subject,\n       throw new InvalidSchemaException(\"Previous schema not provided\");\n     }\n \n-    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n-    if (compatibility == CompatibilityLevel.NONE) {\n-      // optimization to avoid parsing schemas\n-      return true;\n-    }\n-\n     List<ParsedSchema> prevParsedSchemas = new ArrayList<>(previousSchemas.size());\n     for (Schema previousSchema : previousSchemas) {\n       ParsedSchema prevParsedSchema = parseSchema(previousSchema);\n       prevParsedSchemas.add(prevParsedSchema);\n     }\n \n-    ParsedSchema parsedSchema = parseSchema(newSchema);\n-    boolean isCompatible = parsedSchema.isCompatible(compatibility, prevParsedSchemas);\n-    // Allow schema providers to modify the schema during compatibility checks\n-    newSchema.setSchema(parsedSchema.canonicalString());\n-    return isCompatible;\n+    return isCompatibleWithPrevious(subject, parseSchema(newSchema), prevParsedSchemas);\n+  }\n+\n+  private boolean isCompatibleWithPrevious(String subject,\n+                                           ParsedSchema parsedSchema,\n+                                           List<ParsedSchema> previousSchemas)\n+      throws SchemaRegistryException {\n+\n+    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n+    if (compatibility == CompatibilityLevel.NONE) {\n+      // optimization to avoid parsing schemas\n+      return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5Nzg5Mg=="}, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwNzg4OA==", "bodyText": "Ok, I see what you mean.  Yes, it is no longer happening.  I'll remove.", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416207888", "createdAt": "2020-04-27T23:04:01Z", "author": {"login": "rayokota"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -1182,23 +1207,27 @@ public boolean isCompatible(String subject,\n       throw new InvalidSchemaException(\"Previous schema not provided\");\n     }\n \n-    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n-    if (compatibility == CompatibilityLevel.NONE) {\n-      // optimization to avoid parsing schemas\n-      return true;\n-    }\n-\n     List<ParsedSchema> prevParsedSchemas = new ArrayList<>(previousSchemas.size());\n     for (Schema previousSchema : previousSchemas) {\n       ParsedSchema prevParsedSchema = parseSchema(previousSchema);\n       prevParsedSchemas.add(prevParsedSchema);\n     }\n \n-    ParsedSchema parsedSchema = parseSchema(newSchema);\n-    boolean isCompatible = parsedSchema.isCompatible(compatibility, prevParsedSchemas);\n-    // Allow schema providers to modify the schema during compatibility checks\n-    newSchema.setSchema(parsedSchema.canonicalString());\n-    return isCompatible;\n+    return isCompatibleWithPrevious(subject, parseSchema(newSchema), prevParsedSchemas);\n+  }\n+\n+  private boolean isCompatibleWithPrevious(String subject,\n+                                           ParsedSchema parsedSchema,\n+                                           List<ParsedSchema> previousSchemas)\n+      throws SchemaRegistryException {\n+\n+    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n+    if (compatibility == CompatibilityLevel.NONE) {\n+      // optimization to avoid parsing schemas\n+      return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5Nzg5Mg=="}, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwODIwNQ==", "bodyText": "Good catch :)", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416208205", "createdAt": "2020-04-27T23:04:46Z", "author": {"login": "rayokota"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -1182,23 +1207,27 @@ public boolean isCompatible(String subject,\n       throw new InvalidSchemaException(\"Previous schema not provided\");\n     }\n \n-    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n-    if (compatibility == CompatibilityLevel.NONE) {\n-      // optimization to avoid parsing schemas\n-      return true;\n-    }\n-\n     List<ParsedSchema> prevParsedSchemas = new ArrayList<>(previousSchemas.size());\n     for (Schema previousSchema : previousSchemas) {\n       ParsedSchema prevParsedSchema = parseSchema(previousSchema);\n       prevParsedSchemas.add(prevParsedSchema);\n     }\n \n-    ParsedSchema parsedSchema = parseSchema(newSchema);\n-    boolean isCompatible = parsedSchema.isCompatible(compatibility, prevParsedSchemas);\n-    // Allow schema providers to modify the schema during compatibility checks\n-    newSchema.setSchema(parsedSchema.canonicalString());\n-    return isCompatible;\n+    return isCompatibleWithPrevious(subject, parseSchema(newSchema), prevParsedSchemas);\n+  }\n+\n+  private boolean isCompatibleWithPrevious(String subject,\n+                                           ParsedSchema parsedSchema,\n+                                           List<ParsedSchema> previousSchemas)\n+      throws SchemaRegistryException {\n+\n+    CompatibilityLevel compatibility = getCompatibilityLevelInScope(subject);\n+    if (compatibility == CompatibilityLevel.NONE) {\n+      // optimization to avoid parsing schemas\n+      return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5Nzg5Mg=="}, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4OTI4NTI5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjo1NDo1NlrOGM7E-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMzowMjo1MVrOGM7SYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwNDAyNA==", "bodyText": "Do we need to collect this ?", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416204024", "createdAt": "2020-04-27T22:54:56Z", "author": {"login": "dragosvictor"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -432,26 +434,35 @@ public int register(String subject,\n \n       // determine the latest version of the schema in the subject\n       List<SchemaValue> allVersions = getAllSchemaValues(subject);\n+      Collections.reverse(allVersions);\n \n       List<SchemaValue> deletedVersions = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwNzQ1Ng==", "bodyText": "Yes, we delete them later.", "url": "https://github.com/confluentinc/schema-registry/pull/1426#discussion_r416207456", "createdAt": "2020-04-27T23:02:51Z", "author": {"login": "rayokota"}, "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -432,26 +434,35 @@ public int register(String subject,\n \n       // determine the latest version of the schema in the subject\n       List<SchemaValue> allVersions = getAllSchemaValues(subject);\n+      Collections.reverse(allVersions);\n \n       List<SchemaValue> deletedVersions = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjIwNDAyNA=="}, "originalCommit": {"oid": "a792bff3cb0380ca95446b88b9dfa07f53d5fbb8"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1861, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}