{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNTA2ODMx", "number": 8466, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyNjo0NFrOE_CR0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMzo1MlrOE_CsSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTMzMDc1OnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/org/apache/ignite/examples/ml/preprocessing/encoding/TargetEncoderExample.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyNjo0NFrOH8guZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODozNjo1MVrOH-rbkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxMjc3Mw==", "bodyText": "Sorry, but I didn't understand this pipeline? Why those 3 encoders are combined here? Could they work only in this combination?\nIn my opinion, user have a choice what to do with Strings, but he should choose one method (not the chain of methods).\nPlease share your vision here", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533212773", "createdAt": "2020-12-01T09:26:44Z", "author": {"login": "zaleslaw"}, "path": "examples/src/main/java/org/apache/ignite/examples/ml/preprocessing/encoding/TargetEncoderExample.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.examples.ml.preprocessing.encoding;\n+\n+import java.io.FileNotFoundException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.ignite.Ignite;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.Ignition;\n+import org.apache.ignite.examples.ml.util.MLSandboxDatasets;\n+import org.apache.ignite.examples.ml.util.SandboxMLCache;\n+import org.apache.ignite.ml.composition.ModelsComposition;\n+import org.apache.ignite.ml.composition.boosting.GDBTrainer;\n+import org.apache.ignite.ml.composition.boosting.convergence.median.MedianOfMedianConvergenceCheckerFactory;\n+import org.apache.ignite.ml.dataset.feature.extractor.Vectorizer;\n+import org.apache.ignite.ml.dataset.feature.extractor.impl.ObjectArrayVectorizer;\n+import org.apache.ignite.ml.preprocessing.Preprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderTrainer;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderType;\n+import org.apache.ignite.ml.selection.scoring.evaluator.Evaluator;\n+import org.apache.ignite.ml.selection.scoring.metric.classification.Accuracy;\n+import org.apache.ignite.ml.tree.boosting.GDBBinaryClassifierOnTreesTrainer;\n+\n+/**\n+ * Example that shows how to use Target Encoder preprocessor to encode labels presented as a mean target value.\n+ * <p>\n+ * Code in this example launches Ignite grid and fills the cache with test data (based on mushrooms dataset).</p>\n+ * <p>\n+ * After that it defines preprocessors that extract features from an upstream data and encode category with avarage\n+ * target value (categories). </p>\n+ * <p>\n+ * Then, it trains the model based on the processed data using gradient boosing decision tree classification.</p>\n+ * <p>\n+ * Finally, this example uses {@link Evaluator} functionality to compute metrics from predictions.</p>\n+ *\n+ * <p>Daniele Miccii-Barreca (2001). A Preprocessing Scheme for High-Cardinality Categorical\n+ * Attributes in Classification and Prediction Problems. SIGKDD Explor. Newsl. 3, 1.\n+ * From http://dx.doi.org/10.1145/507533.507538</p>\n+ */\n+public class TargetEncoderExample {\n+    /**\n+     * Run example.\n+     */\n+    public static void main(String[] args) {\n+        System.out.println();\n+        System.out.println(\">>> Train Gradient Boosing Decision Tree model on amazon-employee-access-challenge_train.csv dataset.\");\n+\n+        try (Ignite ignite = Ignition.start(\"examples/config/example-ignite.xml\")) {\n+            try {\n+                IgniteCache<Integer, Object[]> dataCache = new SandboxMLCache(ignite)\n+                    .fillObjectCacheWithCategoricalData(MLSandboxDatasets.AMAZON_EMPLOYEE_ACCESS);\n+\n+                Set<Integer> featuresIndexies = new HashSet<>(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9));\n+                Set<Integer> targetEncodedfeaturesIndexies = new HashSet<>(Arrays.asList(1, 5, 6));\n+                Integer targetIndex = 0;\n+\n+                final Vectorizer<Integer, Object[], Integer, Object> vectorizer = new ObjectArrayVectorizer<Integer>(featuresIndexies.toArray(new Integer[0]))\n+                    .labeled(targetIndex);\n+\n+                Preprocessor<Integer, Object[]> strEncoderPreprocessor = new EncoderTrainer<Integer, Object[]>()\n+                    .withEncoderType(EncoderType.STRING_ENCODER)\n+                    .withEncodedFeature(0)\n+                    .withEncodedFeatures(featuresIndexies)\n+                    .fit(ignite,\n+                        dataCache,\n+                        vectorizer\n+                    );\n+\n+                Preprocessor<Integer, Object[]> targetEncoderProcessor = new EncoderTrainer<Integer, Object[]>()\n+                    .withEncoderType(EncoderType.TARGET_ENCODER)\n+                    .labeled(0)\n+                    .withEncodedFeatures(targetEncodedfeaturesIndexies)\n+                    .minSamplesLeaf(1)\n+                    .minCategorySize(1L)\n+                    .smoothing(1d)\n+                    .fit(ignite,\n+                        dataCache,\n+                        strEncoderPreprocessor\n+                    );\n+\n+                Preprocessor<Integer, Object[]> lbEncoderPreprocessor = new EncoderTrainer<Integer, Object[]>()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ4NTMzMA==", "bodyText": "I think that we want use EncoderType.TARGET_ENCODER only for a few columns (may be only one). In this example I use EncoderType.STRING_ENCODER as general propose encoder and EncoderType.TARGET_ENCODER for special one.", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535485330", "createdAt": "2020-12-03T18:36:51Z", "author": {"login": "mrk-andreev"}, "path": "examples/src/main/java/org/apache/ignite/examples/ml/preprocessing/encoding/TargetEncoderExample.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.examples.ml.preprocessing.encoding;\n+\n+import java.io.FileNotFoundException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.ignite.Ignite;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.Ignition;\n+import org.apache.ignite.examples.ml.util.MLSandboxDatasets;\n+import org.apache.ignite.examples.ml.util.SandboxMLCache;\n+import org.apache.ignite.ml.composition.ModelsComposition;\n+import org.apache.ignite.ml.composition.boosting.GDBTrainer;\n+import org.apache.ignite.ml.composition.boosting.convergence.median.MedianOfMedianConvergenceCheckerFactory;\n+import org.apache.ignite.ml.dataset.feature.extractor.Vectorizer;\n+import org.apache.ignite.ml.dataset.feature.extractor.impl.ObjectArrayVectorizer;\n+import org.apache.ignite.ml.preprocessing.Preprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderTrainer;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderType;\n+import org.apache.ignite.ml.selection.scoring.evaluator.Evaluator;\n+import org.apache.ignite.ml.selection.scoring.metric.classification.Accuracy;\n+import org.apache.ignite.ml.tree.boosting.GDBBinaryClassifierOnTreesTrainer;\n+\n+/**\n+ * Example that shows how to use Target Encoder preprocessor to encode labels presented as a mean target value.\n+ * <p>\n+ * Code in this example launches Ignite grid and fills the cache with test data (based on mushrooms dataset).</p>\n+ * <p>\n+ * After that it defines preprocessors that extract features from an upstream data and encode category with avarage\n+ * target value (categories). </p>\n+ * <p>\n+ * Then, it trains the model based on the processed data using gradient boosing decision tree classification.</p>\n+ * <p>\n+ * Finally, this example uses {@link Evaluator} functionality to compute metrics from predictions.</p>\n+ *\n+ * <p>Daniele Miccii-Barreca (2001). A Preprocessing Scheme for High-Cardinality Categorical\n+ * Attributes in Classification and Prediction Problems. SIGKDD Explor. Newsl. 3, 1.\n+ * From http://dx.doi.org/10.1145/507533.507538</p>\n+ */\n+public class TargetEncoderExample {\n+    /**\n+     * Run example.\n+     */\n+    public static void main(String[] args) {\n+        System.out.println();\n+        System.out.println(\">>> Train Gradient Boosing Decision Tree model on amazon-employee-access-challenge_train.csv dataset.\");\n+\n+        try (Ignite ignite = Ignition.start(\"examples/config/example-ignite.xml\")) {\n+            try {\n+                IgniteCache<Integer, Object[]> dataCache = new SandboxMLCache(ignite)\n+                    .fillObjectCacheWithCategoricalData(MLSandboxDatasets.AMAZON_EMPLOYEE_ACCESS);\n+\n+                Set<Integer> featuresIndexies = new HashSet<>(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9));\n+                Set<Integer> targetEncodedfeaturesIndexies = new HashSet<>(Arrays.asList(1, 5, 6));\n+                Integer targetIndex = 0;\n+\n+                final Vectorizer<Integer, Object[], Integer, Object> vectorizer = new ObjectArrayVectorizer<Integer>(featuresIndexies.toArray(new Integer[0]))\n+                    .labeled(targetIndex);\n+\n+                Preprocessor<Integer, Object[]> strEncoderPreprocessor = new EncoderTrainer<Integer, Object[]>()\n+                    .withEncoderType(EncoderType.STRING_ENCODER)\n+                    .withEncodedFeature(0)\n+                    .withEncodedFeatures(featuresIndexies)\n+                    .fit(ignite,\n+                        dataCache,\n+                        vectorizer\n+                    );\n+\n+                Preprocessor<Integer, Object[]> targetEncoderProcessor = new EncoderTrainer<Integer, Object[]>()\n+                    .withEncoderType(EncoderType.TARGET_ENCODER)\n+                    .labeled(0)\n+                    .withEncodedFeatures(targetEncodedfeaturesIndexies)\n+                    .minSamplesLeaf(1)\n+                    .minCategorySize(1L)\n+                    .smoothing(1d)\n+                    .fit(ignite,\n+                        dataCache,\n+                        strEncoderPreprocessor\n+                    );\n+\n+                Preprocessor<Integer, Object[]> lbEncoderPreprocessor = new EncoderTrainer<Integer, Object[]>()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxMjc3Mw=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM1MDYxOnYy", "diffSide": "RIGHT", "path": "modules/ml/src/test/java/org/apache/ignite/ml/preprocessing/encoding/TargetEncoderPreprocessorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyODo1M1rOH8g8ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODoyMTo1MVrOH_FvhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxNjM2Mg==", "bodyText": "Could you explain please numbers in the last columns: why are they 1.0 and 2.0? not 0.33 and 0.66", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533216362", "createdAt": "2020-12-01T09:28:53Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/test/java/org/apache/ignite/ml/preprocessing/encoding/TargetEncoderPreprocessorTest.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.ml.preprocessing.encoding;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import org.apache.ignite.ml.dataset.feature.extractor.Vectorizer;\n+import org.apache.ignite.ml.dataset.feature.extractor.impl.DummyVectorizer;\n+import org.apache.ignite.ml.math.primitives.vector.Vector;\n+import org.apache.ignite.ml.math.primitives.vector.impl.DenseVector;\n+import org.apache.ignite.ml.preprocessing.encoding.target.TargetEncoderPreprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.target.TargetEncodingMeta;\n+import org.junit.Test;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * Tests for {@link TargetEncoderPreprocessor}.\n+ */\n+public class TargetEncoderPreprocessorTest {\n+    /** Tests {@code apply()} method. */\n+    @Test\n+    public void testApply() {\n+        Vector[] data = new Vector[] {\n+            new DenseVector(new Serializable[] {\"1\", \"Moscow\", \"A\"}),\n+            new DenseVector(new Serializable[] {\"2\", \"Moscow\", \"B\"}),\n+            new DenseVector(new Serializable[] {\"3\", \"Moscow\", \"B\"}),\n+        };\n+\n+        Vectorizer<Integer, Vector, Integer, Double> vectorizer = new DummyVectorizer<>(0, 1, 2);\n+\n+        TargetEncoderPreprocessor<Integer, Vector> preprocessor = new TargetEncoderPreprocessor<Integer, Vector>(\n+            new TargetEncodingMeta[]{\n+                new TargetEncodingMeta(\n+                    0.5,\n+                    new HashMap() {\n+                        {\n+                            put(\"1\", 1.0);\n+                            put(\"2\", 0.0);\n+                        }\n+                    }\n+                ),\n+                new TargetEncodingMeta(\n+                    0.1,\n+                    new HashMap() {}\n+                ),\n+                new TargetEncodingMeta(\n+                    0.1,\n+                    new HashMap() {\n+                        {\n+                            put(\"A\", 1.0);\n+                            put(\"B\", 2.0);\n+                        }\n+                    }\n+                ),\n+            },\n+            vectorizer,\n+            new HashSet() {\n+                {\n+                    add(0);\n+                    add(1);\n+                    add(2);\n+                }\n+            });\n+\n+        double[][] postProcessedData = new double[][] {\n+            {1.0, 0.1, 1.0},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkxNjQyMA==", "bodyText": "Described each case", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535916420", "createdAt": "2020-12-04T08:21:51Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/test/java/org/apache/ignite/ml/preprocessing/encoding/TargetEncoderPreprocessorTest.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.ml.preprocessing.encoding;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import org.apache.ignite.ml.dataset.feature.extractor.Vectorizer;\n+import org.apache.ignite.ml.dataset.feature.extractor.impl.DummyVectorizer;\n+import org.apache.ignite.ml.math.primitives.vector.Vector;\n+import org.apache.ignite.ml.math.primitives.vector.impl.DenseVector;\n+import org.apache.ignite.ml.preprocessing.encoding.target.TargetEncoderPreprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.target.TargetEncodingMeta;\n+import org.junit.Test;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * Tests for {@link TargetEncoderPreprocessor}.\n+ */\n+public class TargetEncoderPreprocessorTest {\n+    /** Tests {@code apply()} method. */\n+    @Test\n+    public void testApply() {\n+        Vector[] data = new Vector[] {\n+            new DenseVector(new Serializable[] {\"1\", \"Moscow\", \"A\"}),\n+            new DenseVector(new Serializable[] {\"2\", \"Moscow\", \"B\"}),\n+            new DenseVector(new Serializable[] {\"3\", \"Moscow\", \"B\"}),\n+        };\n+\n+        Vectorizer<Integer, Vector, Integer, Double> vectorizer = new DummyVectorizer<>(0, 1, 2);\n+\n+        TargetEncoderPreprocessor<Integer, Vector> preprocessor = new TargetEncoderPreprocessor<Integer, Vector>(\n+            new TargetEncodingMeta[]{\n+                new TargetEncodingMeta(\n+                    0.5,\n+                    new HashMap() {\n+                        {\n+                            put(\"1\", 1.0);\n+                            put(\"2\", 0.0);\n+                        }\n+                    }\n+                ),\n+                new TargetEncodingMeta(\n+                    0.1,\n+                    new HashMap() {}\n+                ),\n+                new TargetEncodingMeta(\n+                    0.1,\n+                    new HashMap() {\n+                        {\n+                            put(\"A\", 1.0);\n+                            put(\"B\", 2.0);\n+                        }\n+                    }\n+                ),\n+            },\n+            vectorizer,\n+            new HashSet() {\n+                {\n+                    add(0);\n+                    add(1);\n+                    add(2);\n+                }\n+            });\n+\n+        double[][] postProcessedData = new double[][] {\n+            {1.0, 0.1, 1.0},", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxNjM2Mg=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM2MTExOnYy", "diffSide": "RIGHT", "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/target/TargetEncoderPreprocessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMDowMVrOH8hDzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODozODozNVrOH-rflA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxODI1Mw==", "bodyText": "looks like min_samples_leaf is not used in this class", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533218253", "createdAt": "2020-12-01T09:30:01Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/target/TargetEncoderPreprocessor.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.ml.preprocessing.encoding.target;\n+\n+import java.util.Set;\n+import org.apache.ignite.ml.math.primitives.vector.VectorUtils;\n+import org.apache.ignite.ml.preprocessing.Preprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderPreprocessor;\n+import org.apache.ignite.ml.structures.LabeledVector;\n+\n+/**\n+ * Preprocessing function that makes Target encoding.\n+ *\n+ * The Target Encoder Preprocessor encodes string values (categories) to double values\n+ * in range [0.0, 1], where the value will be presented as a regularized mean target value of\n+ * a category.\n+ *\n+ * alpha = 1 / (1 + exp(-(categorySize - min_samples_leaf) / beta))\n+ * encodedValue = globalTargetMean * (1 - alpha) + categoryTargetMean * alpha\n+ * if categorySize == 1 then use globalTargetMean\n+ *\n+ * min_samples_leaf - minimum samples to take category average into account.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ4NjM1Ng==", "bodyText": "Yes, but it is used for evaluate TargetEncodingMeta, so I wanted to mention this in encoder class.", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535486356", "createdAt": "2020-12-03T18:38:35Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/target/TargetEncoderPreprocessor.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.ml.preprocessing.encoding.target;\n+\n+import java.util.Set;\n+import org.apache.ignite.ml.math.primitives.vector.VectorUtils;\n+import org.apache.ignite.ml.preprocessing.Preprocessor;\n+import org.apache.ignite.ml.preprocessing.encoding.EncoderPreprocessor;\n+import org.apache.ignite.ml.structures.LabeledVector;\n+\n+/**\n+ * Preprocessing function that makes Target encoding.\n+ *\n+ * The Target Encoder Preprocessor encodes string values (categories) to double values\n+ * in range [0.0, 1], where the value will be presented as a regularized mean target value of\n+ * a category.\n+ *\n+ * alpha = 1 / (1 + exp(-(categorySize - min_samples_leaf) / beta))\n+ * encodedValue = globalTargetMean * (1 - alpha) + categoryTargetMean * alpha\n+ * if categorySize == 1 then use globalTargetMean\n+ *\n+ * min_samples_leaf - minimum samples to take category average into account.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIxODI1Mw=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM4MTYwOnYy", "diffSide": "RIGHT", "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMjowNlrOH8hRqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODoyMjoxNFrOH_FwhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMTgwMg==", "bodyText": "I suggest to refactor constructor parameters to separate variables for readability purposes", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533221802", "createdAt": "2020-12-01T09:32:06Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkxNjY3Ng==", "bodyText": "Extracted to new method", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535916676", "createdAt": "2020-12-04T08:22:14Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMTgwMg=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM4NTcyOnYy", "diffSide": "RIGHT", "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMjozM1rOH8hUaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODoyMjozN1rOH_FxPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMjUwNA==", "bodyText": "Also this lambda should be encapsulated and commented separately", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533222504", "createdAt": "2020-12-01T09:32:33Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),\n+                    targetCounters[i].getCategoryTargetSum().entrySet().stream()\n+                        .collect(Collectors.toMap(\n+                            Map.Entry::getKey,\n+                            value -> {\n+                                double prior = targetCounters[finalI].getTargetSum() /", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkxNjg2MQ==", "bodyText": "prior evaluation extracted but lambda still exists.", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535916861", "createdAt": "2020-12-04T08:22:37Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),\n+                    targetCounters[i].getCategoryTargetSum().entrySet().stream()\n+                        .collect(Collectors.toMap(\n+                            Map.Entry::getKey,\n+                            value -> {\n+                                double prior = targetCounters[finalI].getTargetSum() /", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMjUwNA=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM4ODE3OnYy", "diffSide": "RIGHT", "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMjo0NlrOH8hV_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODoyMjo0M1rOH_FxaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMjkwOA==", "bodyText": "remove the blank line", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533222908", "createdAt": "2020-12-01T09:32:46Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),\n+                    targetCounters[i].getCategoryTargetSum().entrySet().stream()\n+                        .collect(Collectors.toMap(\n+                            Map.Entry::getKey,\n+                            value -> {\n+                                double prior = targetCounters[finalI].getTargetSum() /\n+                                    targetCounters[finalI].getTargetCount();\n+                                double targetSum = targetCounters[finalI].getCategoryTargetSum()\n+                                    .get(value.getKey());\n+                                long categorySize = targetCounters[finalI].getCategoryCounts()\n+                                    .get(value.getKey());\n+\n+                                if (categorySize < minCategorySize) {\n+                                    return prior;\n+                                } else {\n+                                    double categoryMean = targetSum / categorySize;\n+\n+                                    double smoove = 1 / (1 +\n+                                        Math.exp(-(categorySize - minSamplesLeaf) / smoothing));\n+                                    return prior * (1 - smoove) + categoryMean * smoove;\n+                                }\n+                            }\n+                        ))\n+                );\n+            }\n+        }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkxNjkwNQ==", "bodyText": "Done", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535916905", "createdAt": "2020-12-04T08:22:43Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -116,6 +143,77 @@\n         }\n     }\n \n+    /**\n+     * Calculates encoding frequencies as frequency divided on amount of rows in dataset.\n+     *\n+     * NOTE: The amount of rows is calculated as sum of absolute frequencies.\n+     *\n+     * @param dataset Dataset.\n+     * @return Encoding frequency for each feature.\n+     */\n+    private TargetEncodingMeta[] calculateTargetEncodingFrequencies(Dataset<EmptyContext, EncoderPartitionData> dataset) {\n+        TargetCounter[] targetCounters = dataset.compute(\n+            EncoderPartitionData::targetCounters,\n+            (a, b) -> {\n+                if (a == null)\n+                    return b;\n+\n+                if (b == null)\n+                    return a;\n+\n+                assert a.length == b.length;\n+\n+                for (int i = 0; i < a.length; i++) {\n+                    if (handledIndices.contains(i)) {\n+                        int finalI = i;\n+                        b[i].setTargetSum(a[i].getTargetSum() + b[i].getTargetSum());\n+                        b[i].setTargetCount(a[i].getTargetCount() + b[i].getTargetCount());\n+                        a[i].getCategoryCounts()\n+                            .forEach((k, v) -> b[finalI].getCategoryCounts().merge(k, v, Long::sum));\n+                        a[i].getCategoryTargetSum()\n+                            .forEach((k, v) -> b[finalI].getCategoryTargetSum().merge(k, v, Double::sum));\n+                    }\n+                }\n+                return b;\n+            }\n+        );\n+\n+        TargetEncodingMeta[] targetEncodingMetas = new TargetEncodingMeta[targetCounters.length];\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                int finalI = i;\n+\n+                targetEncodingMetas[i] = new TargetEncodingMeta(\n+                    targetCounters[i].getTargetSum() / targetCounters[i].getTargetCount(),\n+                    targetCounters[i].getCategoryTargetSum().entrySet().stream()\n+                        .collect(Collectors.toMap(\n+                            Map.Entry::getKey,\n+                            value -> {\n+                                double prior = targetCounters[finalI].getTargetSum() /\n+                                    targetCounters[finalI].getTargetCount();\n+                                double targetSum = targetCounters[finalI].getCategoryTargetSum()\n+                                    .get(value.getKey());\n+                                long categorySize = targetCounters[finalI].getCategoryCounts()\n+                                    .get(value.getKey());\n+\n+                                if (categorySize < minCategorySize) {\n+                                    return prior;\n+                                } else {\n+                                    double categoryMean = targetSum / categorySize;\n+\n+                                    double smoove = 1 / (1 +\n+                                        Math.exp(-(categorySize - minSamplesLeaf) / smoothing));\n+                                    return prior * (1 - smoove) + categoryMean * smoove;\n+                                }\n+                            }\n+                        ))\n+                );\n+            }\n+        }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyMjkwOA=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTM5ODUxOnYy", "diffSide": "RIGHT", "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTozMzo1MlrOH8hdMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODoyMzoxMVrOH_FyWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyNDc1NA==", "bodyText": "Maybe add type conversion to Doulbe from another Number types (and boolean)", "url": "https://github.com/apache/ignite/pull/8466#discussion_r533224754", "createdAt": "2020-12-01T09:33:52Z", "author": {"login": "zaleslaw"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -343,6 +441,81 @@ else if (lbVal instanceof Double)\n         return categoryFrequencies;\n     }\n \n+    /**\n+     * Updates frequencies by values and features.\n+     *\n+     * @param row Feature vector.\n+     * @param targetCounters Holds the frequencies of categories by values and features.\n+     * @return target counter.\n+     */\n+    private TargetCounter[] updateTargetCountersForNextRow(LabeledVector row,\n+                                                           TargetCounter[] targetCounters) {\n+        if (targetCounters == null)\n+            targetCounters = initializeTargetCounters(row);\n+        else\n+            assert targetCounters.length == row.size() : \"Base preprocessor must return exactly \"\n+                + targetCounters.length + \" features\";\n+\n+        double targetValue = row.features().get(targetLabelIndex);\n+\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                String strVal;\n+                Object featureVal = row.features().getRaw(i);\n+\n+                if (featureVal.equals(Double.NaN)) {\n+                    strVal = EncoderPreprocessor.KEY_FOR_NULL_VALUES;\n+                    row.features().setRaw(i, strVal);\n+                }\n+                else if (featureVal instanceof String)\n+                    strVal = (String)featureVal;\n+                else if (featureVal instanceof Double)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkxNzE0Nw==", "bodyText": "Add Number & Boolean", "url": "https://github.com/apache/ignite/pull/8466#discussion_r535917147", "createdAt": "2020-12-04T08:23:11Z", "author": {"login": "mrk-andreev"}, "path": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/encoding/EncoderTrainer.java", "diffHunk": "@@ -343,6 +441,81 @@ else if (lbVal instanceof Double)\n         return categoryFrequencies;\n     }\n \n+    /**\n+     * Updates frequencies by values and features.\n+     *\n+     * @param row Feature vector.\n+     * @param targetCounters Holds the frequencies of categories by values and features.\n+     * @return target counter.\n+     */\n+    private TargetCounter[] updateTargetCountersForNextRow(LabeledVector row,\n+                                                           TargetCounter[] targetCounters) {\n+        if (targetCounters == null)\n+            targetCounters = initializeTargetCounters(row);\n+        else\n+            assert targetCounters.length == row.size() : \"Base preprocessor must return exactly \"\n+                + targetCounters.length + \" features\";\n+\n+        double targetValue = row.features().get(targetLabelIndex);\n+\n+        for (int i = 0; i < targetCounters.length; i++) {\n+            if (handledIndices.contains(i)) {\n+                String strVal;\n+                Object featureVal = row.features().getRaw(i);\n+\n+                if (featureVal.equals(Double.NaN)) {\n+                    strVal = EncoderPreprocessor.KEY_FOR_NULL_VALUES;\n+                    row.features().setRaw(i, strVal);\n+                }\n+                else if (featureVal instanceof String)\n+                    strVal = (String)featureVal;\n+                else if (featureVal instanceof Double)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIyNDc1NA=="}, "originalCommit": {"oid": "97b633fae1c50284deb23085601e38d7fd074f5c"}, "originalPosition": 167}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2613, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}