{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc4MDcwMDEw", "number": 8211, "reviewThreads": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoxMzoxOVrOEp1F6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMzowNDozMVrOEufgSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjk2OTM4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoxMzoxOVrOHbvP1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1ODo0NFrOHcAfyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0NzcwMg==", "bodyText": "please use super().teardown()", "url": "https://github.com/apache/ignite/pull/8211#discussion_r498847702", "createdAt": "2020-10-02T14:13:19Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"\n+\n     def __init__(self, test_context):\n         super().__init__(test_context=test_context)\n \n+    def teardown(self):\n+        for node in self.test_context.cluster.nodes:\n+            node.account.ssh_client.exec_command(\"rm -drf \" + self.TEMP_PATH_ROOT)\n+\n+        Test.teardown(self)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDMxNQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130315", "createdAt": "2020-10-03T08:58:44Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"\n+\n     def __init__(self, test_context):\n         super().__init__(test_context=test_context)\n \n+    def teardown(self):\n+        for node in self.test_context.cluster.nodes:\n+            node.account.ssh_client.exec_command(\"rm -drf \" + self.TEMP_PATH_ROOT)\n+\n+        Test.teardown(self)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0NzcwMg=="}, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjk3MDM1OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoxMzozNlrOHbvQeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1ODozOVrOHcAfyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0Nzg2NQ==", "bodyText": "please, use super().teardown()", "url": "https://github.com/apache/ignite/pull/8211#discussion_r498847865", "createdAt": "2020-10-02T14:13:36Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +173,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        IgniteTest.setup(self)\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            path_to_store = self.NETFILTER_SAVED_SETTINGS\n+\n+            node.account.ssh_client.exec_command(f\"rm -drf {path_to_store} && mkdir -p $(dirname {path_to_store})\")\n+\n+            cmd = \"sudo iptables-save | tee \" + self.NETFILTER_SAVED_SETTINGS\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.NETFILTER_SAVED_SETTINGS\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.NETFILTER_SAVED_SETTINGS\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        IgniteTest.teardown(self)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDMxNA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130314", "createdAt": "2020-10-03T08:58:39Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +173,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        IgniteTest.setup(self)\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            path_to_store = self.NETFILTER_SAVED_SETTINGS\n+\n+            node.account.ssh_client.exec_command(f\"rm -drf {path_to_store} && mkdir -p $(dirname {path_to_store})\")\n+\n+            cmd = \"sudo iptables-save | tee \" + self.NETFILTER_SAVED_SETTINGS\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.NETFILTER_SAVED_SETTINGS\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.NETFILTER_SAVED_SETTINGS\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        IgniteTest.teardown(self)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0Nzg2NQ=="}, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 260}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjk3MTE1OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoxMzo0N1rOHbvQ7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1ODozNFrOHcAfxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0Nzk4Mw==", "bodyText": "please, use super().setup()", "url": "https://github.com/apache/ignite/pull/8211#discussion_r498847983", "createdAt": "2020-10-02T14:13:47Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +173,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        IgniteTest.setup(self)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDMwOA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130308", "createdAt": "2020-10-03T08:58:34Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +173,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        IgniteTest.setup(self)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0Nzk4Mw=="}, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 220}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjk4Njc0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/services/zk/zookeeper.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoxODowMVrOHbvasg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1ODoyOVrOHcAfvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg1MDQ4Mg==", "bodyText": "I suppose that it's better leave tick time and add assertion that min_session_timeout is at least twice as tick_time.\nIt's ok to pass tickTime as 1000 ms, and set minSessionTimeout as 3000 ms\nBy default, let them be 1000 and 2000", "url": "https://github.com/apache/ignite/pull/8211#discussion_r498850482", "createdAt": "2020-10-02T14:18:01Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/services/zk/zookeeper.py", "diffHunk": "@@ -27,8 +27,9 @@ class ZookeeperSettings:\n     \"\"\"\n     Settings for zookeeper quorum nodes.\n     \"\"\"\n-    def __init__(self, tick_time=1000, init_limit=10, sync_limit=5, client_port=2181):\n-        self.tick_time = tick_time\n+    def __init__(self, min_session_timeout=2000, init_limit=10, sync_limit=5, client_port=2181):\n+        self.tick_time = min_session_timeout // 2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDMwMg==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130302", "createdAt": "2020-10-03T08:58:29Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/services/zk/zookeeper.py", "diffHunk": "@@ -27,8 +27,9 @@ class ZookeeperSettings:\n     \"\"\"\n     Settings for zookeeper quorum nodes.\n     \"\"\"\n-    def __init__(self, tick_time=1000, init_limit=10, sync_limit=5, client_port=2181):\n-        self.tick_time = tick_time\n+    def __init__(self, min_session_timeout=2000, init_limit=10, sync_limit=5, client_port=2181):\n+        self.tick_time = min_session_timeout // 2", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg1MDQ4Mg=="}, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjk5NDQxOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDoyMDowMlrOHbvfVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1ODoxOFrOHcAfsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg1MTY2OQ==", "bodyText": "If linter allowed longer method name, may be call it not_sequential_zk?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r498851669", "createdAt": "2020-10-02T14:20:02Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,63 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT = 1000\n \n     DATA_AMOUNT = 5_000_000\n \n     WARMUP_DATA_AMOUNT = 10_000\n \n+    NETFILTER_SAVED_SETTINGS = os.path.join(IgniteTest.TEMP_PATH_ROOT, \"discovery_test\", \"netfilter.bak\")\n+\n     @cluster(num_nodes=NUM_NODES)\n     @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n-    @matrix(kill_coordinator=[False, True],\n-            nodes_to_kill=[1, 2],\n+    @matrix(nodes_to_kill=[1, 2],\n             load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n-    def test_node_fail_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, load_type):\n+    def test_nodes_fail_notseq_tcp(self, ignite_version, nodes_to_kill, load_type):\n         \"\"\"\n-        Test nodes failure scenario with TcpDiscoverySpi.\n-        :param load_type: How to load cluster during the test: 0 - no loading; 1 - do some loading; 2 - transactional.\n+        Test nodes failure scenario with TcpDiscoverySpi not allowing nodes to fail in a row.\n         \"\"\"\n-        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), kill_coordinator=kill_coordinator,\n-                                          nodes_to_kill=nodes_to_kill, load_type=load_type, with_zk=False)\n+        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), nodes_to_kill=nodes_to_kill,\n+                                          load_type=load_type, sequential_failure=False)\n+\n+        return self._perform_node_fail_scenario(test_config)\n+\n+    @cluster(num_nodes=NUM_NODES)\n+    @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n+    @matrix(load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n+    def test_2_nodes_fail_seq_tcp(self, ignite_version, load_type):\n+        \"\"\"\n+        Test 2 nodes sequential failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), nodes_to_kill=2, load_type=load_type,\n+                                          sequential_failure=True)\n \n         return self._perform_node_fail_scenario(test_config)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n     @version_if(lambda version: version != V_2_8_0)  # ignite-zookeeper package is broken in 2.8.0\n     @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n-    @matrix(kill_coordinator=[False, True],\n-            nodes_to_kill=[1, 2],\n+    @matrix(nodes_to_kill=[1, 2],\n             load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n-    def test_node_fail_zk(self, ignite_version, kill_coordinator, nodes_to_kill, load_type):\n+    def test_nodes_fail_notseq_zk(self, ignite_version, nodes_to_kill, load_type):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDI5MA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130290", "createdAt": "2020-10-03T08:58:18Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,63 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT = 1000\n \n     DATA_AMOUNT = 5_000_000\n \n     WARMUP_DATA_AMOUNT = 10_000\n \n+    NETFILTER_SAVED_SETTINGS = os.path.join(IgniteTest.TEMP_PATH_ROOT, \"discovery_test\", \"netfilter.bak\")\n+\n     @cluster(num_nodes=NUM_NODES)\n     @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n-    @matrix(kill_coordinator=[False, True],\n-            nodes_to_kill=[1, 2],\n+    @matrix(nodes_to_kill=[1, 2],\n             load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n-    def test_node_fail_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, load_type):\n+    def test_nodes_fail_notseq_tcp(self, ignite_version, nodes_to_kill, load_type):\n         \"\"\"\n-        Test nodes failure scenario with TcpDiscoverySpi.\n-        :param load_type: How to load cluster during the test: 0 - no loading; 1 - do some loading; 2 - transactional.\n+        Test nodes failure scenario with TcpDiscoverySpi not allowing nodes to fail in a row.\n         \"\"\"\n-        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), kill_coordinator=kill_coordinator,\n-                                          nodes_to_kill=nodes_to_kill, load_type=load_type, with_zk=False)\n+        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), nodes_to_kill=nodes_to_kill,\n+                                          load_type=load_type, sequential_failure=False)\n+\n+        return self._perform_node_fail_scenario(test_config)\n+\n+    @cluster(num_nodes=NUM_NODES)\n+    @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n+    @matrix(load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n+    def test_2_nodes_fail_seq_tcp(self, ignite_version, load_type):\n+        \"\"\"\n+        Test 2 nodes sequential failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        test_config = DiscoveryTestConfig(version=IgniteVersion(ignite_version), nodes_to_kill=2, load_type=load_type,\n+                                          sequential_failure=True)\n \n         return self._perform_node_fail_scenario(test_config)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n     @version_if(lambda version: version != V_2_8_0)  # ignite-zookeeper package is broken in 2.8.0\n     @ignite_versions(str(DEV_BRANCH), str(LATEST_2_8))\n-    @matrix(kill_coordinator=[False, True],\n-            nodes_to_kill=[1, 2],\n+    @matrix(nodes_to_kill=[1, 2],\n             load_type=[ClusterLoad.NONE, ClusterLoad.ATOMIC, ClusterLoad.TRANSACTIONAL])\n-    def test_node_fail_zk(self, ignite_version, kill_coordinator, nodes_to_kill, load_type):\n+    def test_nodes_fail_notseq_zk(self, ignite_version, nodes_to_kill, load_type):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg1MTY2OQ=="}, "originalCommit": {"oid": "091f1279e38aa08fa0dd667f32ffa94011d7a168"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDc4NzgwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/pme_free_switch_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwODo1MDowNFrOHcAdvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QwOTowMDoxNlrOHcAgQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEyOTc4OA==", "bodyText": "This will not work, should be IgniteVersion(ignite_version) < V_2_8_0.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499129788", "createdAt": "2020-10-03T08:50:04Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/pme_free_switch_test.py", "diffHunk": "@@ -81,7 +81,8 @@ def test(self, ignite_version):\n \n         ignites.stop_node(ignites.nodes[self.NUM_NODES - 1])\n \n-        long_tx_streamer.await_event(\"Node left topology\", 60, from_the_beginning=True)\n+        long_tx_streamer.await_event(\"Node left topology\", 120 if ignite_version < V_2_8_0 else 60,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b33ecfcc46ba2b2cba5beddd69bec7e97b69470"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEzMDQzMg==", "bodyText": "Yep. Missed this in hurry. Fixed.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499130432", "createdAt": "2020-10-03T09:00:16Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/pme_free_switch_test.py", "diffHunk": "@@ -81,7 +81,8 @@ def test(self, ignite_version):\n \n         ignites.stop_node(ignites.nodes[self.NUM_NODES - 1])\n \n-        long_tx_streamer.await_event(\"Node left topology\", 60, from_the_beginning=True)\n+        long_tx_streamer.await_event(\"Node left topology\", 120 if ignite_version < V_2_8_0 else 60,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEyOTc4OA=="}, "originalCommit": {"oid": "5b33ecfcc46ba2b2cba5beddd69bec7e97b69470"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjc5ODU3OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzo0MTozNlrOHcQ2Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDozMTozM1rOHcXCgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM5ODE1OQ==", "bodyText": "Python has tools to create temporary folders. You don't need this.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499398159", "createdAt": "2020-10-05T07:41:36Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQwMjE0OQ==", "bodyText": "Used in DiscoveryTest:     NETFILTER_SAVED_SETTINGS = os.path.join(IgniteTest.TEMP_PATH_ROOT, \"discovery_test\", \"netfilter.bak\")", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499402149", "createdAt": "2020-10-05T07:49:01Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM5ODE1OQ=="}, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxNjA2MA==", "bodyText": "This is wrong usage, please, use appropriate tools. And revert this change to IgniteTest.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499416060", "createdAt": "2020-10-05T08:09:55Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM5ODE1OQ=="}, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQ5OTY1MA==", "bodyText": "Removed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499499650", "createdAt": "2020-10-05T10:31:33Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/utils/ignite_test.py", "diffHunk": "@@ -26,9 +26,17 @@ class IgniteTest(Test):\n     \"\"\"\n     Basic ignite test.\n     \"\"\"\n+    TEMP_PATH_ROOT = \"/mnt/ducktests\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM5ODE1OQ=="}, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjkwODE4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwODowNzo1NlrOHcR31A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDozMToyNFrOHcXCLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxNDk5Ng==", "bodyText": "This will not work in parallel execution (class variable), use tempfile module and instance variable", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499414996", "createdAt": "2020-10-05T08:07:56Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,65 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT_TCP = 1000\n+\n+    FAILURE_DETECTION_TIMEOUT_ZK = 3000\n \n     DATA_AMOUNT = 5_000_000\n \n     WARMUP_DATA_AMOUNT = 10_000\n \n+    NETFILTER_SAVED_SETTINGS = os.path.join(IgniteTest.TEMP_PATH_ROOT, \"discovery_test\", \"netfilter.bak\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQ5OTU2NQ==", "bodyText": "Removed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499499565", "createdAt": "2020-10-05T10:31:24Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,65 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT_TCP = 1000\n+\n+    FAILURE_DETECTION_TIMEOUT_ZK = 3000\n \n     DATA_AMOUNT = 5_000_000\n \n     WARMUP_DATA_AMOUNT = 10_000\n \n+    NETFILTER_SAVED_SETTINGS = os.path.join(IgniteTest.TEMP_PATH_ROOT, \"discovery_test\", \"netfilter.bak\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxNDk5Ng=="}, "originalCommit": {"oid": "a2ac83d1e3572aeea4aa76108c03351469161587"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzYwODkxOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMToxNzo0OFrOHcYdwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo0NzoyMFrOHcba6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUyMzAxMA==", "bodyText": "This will not work -- you created directory", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499523010", "createdAt": "2020-10-05T11:17:48Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +177,136 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_saved_settings = tempfile.mkdtemp()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "488dc3def1b0b210bab7f759f3a13ab322fbe600"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3MTQzNQ==", "bodyText": "Reverted, re-implemented.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499571435", "createdAt": "2020-10-05T12:47:20Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +177,136 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_saved_settings = tempfile.mkdtemp()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUyMzAxMA=="}, "originalCommit": {"oid": "488dc3def1b0b210bab7f759f3a13ab322fbe600"}, "originalPosition": 235}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODUzODEyOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNTowNTo1NlrOHchX6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNToxMzozMlrOHchtew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY2ODk2OQ==", "bodyText": "It seems, that FAILURE_DETECTION_TIMEOUT_TCP not used", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499668969", "createdAt": "2020-10-05T15:05:56Z", "author": {"login": "ivandasch"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,68 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT_TCP = 1000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ed67a57f41b2c8752044285debce5d6f4265556"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3NDQ5MQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r499674491", "createdAt": "2020-10-05T15:13:32Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -71,40 +72,68 @@ class DiscoveryTest(IgniteTest):\n     \"\"\"\n     NUM_NODES = 7\n \n-    FAILURE_DETECTION_TIMEOUT = 2000\n+    FAILURE_DETECTION_TIMEOUT_TCP = 1000", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY2ODk2OQ=="}, "originalCommit": {"oid": "2ed67a57f41b2c8752044285debce5d6f4265556"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MDk5MjI0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQwOTo1ODoxOFrOHiyp5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQxMzoxMDoyNlrOHkNhhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw==", "bodyText": "any reason to not to encapsulate node_fail_task (to call it outside the method) when we have only one usage of _simulate_nodes_failure?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506243557", "createdAt": "2020-10-16T09:58:18Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYwNzUxNw==", "bodyText": "Node stopping relies on parallel and simulatous execution of configurable task. The parameters are outside of this execution\u2019s API and are not it\u2019s responsibilities. But task relies on the configuration. It\u2019s much more simpler to form the task somewhere by a method and return lambda. Also helps to keep admissible function parameters.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507607517", "createdAt": "2020-10-19T09:35:34Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYwODM5OA==", "bodyText": "Also shortens makes more reeadable, simplifies _simulate_nodes_failure.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507608398", "createdAt": "2020-10-19T09:36:52Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcwOTIwNA==", "bodyText": "Not sure I got an answer.\nnode_fail_task content (or call) can be (should?) inlined to _simulate_nodes_failure instead of being its param since it can be used only inside this method.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507709204", "createdAt": "2020-10-19T12:34:14Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyMDc1Nw==", "bodyText": "_simulate_nodes_failure will look like def _simulate_nodes_failure(self, servers, failed_nodes, survived_node, test_config, ignite_config): \"\"\" Perform node failure scenario \"\"\" kill_node_task = node_fail_task(ignite_config, test_config)\nAnd pylint will say Too many arguments (6/5) (too-many-arguments) and Too many local variables (17/15) (too-many-locals)", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507720757", "createdAt": "2020-10-19T12:52:15Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyMTMyMw==", "bodyText": "_simulate_nodes_failure should not be overloaded any more with any locals and parameters.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507721323", "createdAt": "2020-10-19T12:53:08Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzczMjM1OA==", "bodyText": "got it", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507732358", "createdAt": "2020-10-19T13:10:26Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0MzU1Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTAyMDQ0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDowMjoyOVrOHiy9Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQwOTo0MTo1MVrOHkGJaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0ODQ4Nw==", "bodyText": "why not inlined to node_fail_task?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506248487", "createdAt": "2020-10-16T10:02:29Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYxMTQ5Ng==", "bodyText": "Lambda is quite simple and has no log. Also we need this logging only after execution of all tasks which can have gap in time. Simplifies to read and search the log. All the records are in the row.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507611496", "createdAt": "2020-10-19T09:41:51Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI0ODQ4Nw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTA5NzY0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDoxOTo0NFrOHizu-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQxMzo0Njo0NlrOHkPLLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2MTI0MQ==", "bodyText": "should we check all alive nodes for detection duration?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506261241", "createdAt": "2020-10-16T10:19:44Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYxMzM4Mw==", "bodyText": "We can't until we stabilize number of IP addresses and merge IGNITE-13465. Additionally, we cannot check it without 'magic numbers' like \"+100ms for GC\". We've already rejected checking this timings in IGNITE-13134 and IGNITE-13012. Only benchmarks are attached in the tickets. We decided to write benchmarks/integration tests. So, here we are. The integration test without measuring timings. Only comparison with previous versions.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507613383", "createdAt": "2020-10-19T09:44:41Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2MTI0MQ=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyMzI5OQ==", "bodyText": "The goal is to see timings and seeing them find ways to improve.\nIf we have bad timings now on other nodes let's see this.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507723299", "createdAt": "2020-10-19T12:56:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2MTI0MQ=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyNjI2Mg==", "bodyText": "My goal for this ticket was to see timings in the logs and have ability to compare with another ignite versions. Timings appear strange. But test works as it can with current bug in discovery and the disadvantages with multiple IP addresses. Test show timings but was not supposed to do assertions. Is it another ticket?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507726262", "createdAt": "2020-10-19T13:00:42Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2MTI0MQ=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzc1OTQwNQ==", "bodyText": "Another ticket, not a problem. Just mentioned that we need to have more info.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507759405", "createdAt": "2020-10-19T13:46:46Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2MTI0MQ=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTEzMjU3OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDoyNjoyMFrOHi0FnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQxMjozMDoxNlrOHkL9mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2NzAzNw==", "bodyText": "self.NUM_NODES - 1 (6 nodes) seems to be too small cluster", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506267037", "createdAt": "2020-10-16T10:26:20Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -131,14 +161,14 @@ def _perform_node_fail_scenario(self, test_config):\n \n         servers, start_servers_sec = start_servers(self.test_context, self.NUM_NODES - 1, ignite_config, modules)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYxODAzOQ==", "bodyText": "1 node is required for the loader. I keep always same number of server nodes by your advice. Previous version chooced self.NUM_NODES or self.NUM_NODES-1 depending on with_load or without_load.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507618039", "createdAt": "2020-10-19T09:52:05Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -131,14 +161,14 @@ def _perform_node_fail_scenario(self, test_config):\n \n         servers, start_servers_sec = start_servers(self.test_context, self.NUM_NODES - 1, ignite_config, modules)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2NzAzNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY5OTA4Ng==", "bodyText": "We have 12 nodes in total. Can we start 9 nodes cluster?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507699086", "createdAt": "2020-10-19T12:17:55Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -131,14 +161,14 @@ def _perform_node_fail_scenario(self, test_config):\n \n         servers, start_servers_sec = start_servers(self.test_context, self.NUM_NODES - 1, ignite_config, modules)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2NzAzNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcwNjc3Ng==", "bodyText": "Fixed.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507706776", "createdAt": "2020-10-19T12:30:16Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -131,14 +161,14 @@ def _perform_node_fail_scenario(self, test_config):\n \n         servers, start_servers_sec = start_servers(self.test_context, self.NUM_NODES - 1, ignite_config, modules)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2NzAzNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTEzODg5OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDoyNzoyOFrOHi0KBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQwOTo1NTozNlrOHkGrqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2ODE2NA==", "bodyText": "why not a part of _simulate_nodes_failure or node_fail_task?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506268164", "createdAt": "2020-10-16T10:27:28Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYyMDI2Nw==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507620267", "createdAt": "2020-10-19T09:55:36Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2ODE2NA=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTE0Mzg5OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDoyODozNFrOHi0Nsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQwNzozMzoyN1rOHkufdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw==", "bodyText": "should be close to start_servers_sec set?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506269107", "createdAt": "2020-10-16T10:28:34Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYyMDcyMQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507620721", "createdAt": "2020-10-19T09:56:15Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyNTQwNw==", "bodyText": "I meant that \"data['blabla']=val\" should be next line to the \"val = xxx\".\nyou may just write\ndata = []\nand then append results to it, not defining\ndata = self._simulate_nodes_failure...\ndata['Ignite cluster start time (s)'] = ...\nat the method end.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507725407", "createdAt": "2020-10-19T12:59:25Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzgyNTk2OQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507825969", "createdAt": "2020-10-19T15:02:30Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODI2OTA4MQ==", "bodyText": "idea was to have the following\ndata = {}\n\nfailed_nodes, survived_node = choose_node_to_kill(servers, test_config.nodes_to_kill,\n                                                          test_config.sequential_failure)\n\ndata['Ignite cluster start time (s)'] = start_servers_sec\n\n...\ndata.update(self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n                                                 survived_node))\nreturn data\n\nto make code more refactoring friendly.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508269081", "createdAt": "2020-10-20T07:27:47Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODI3MjUwMw==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508272503", "createdAt": "2020-10-20T07:33:27Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI2OTEwNw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTE4MzgzOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDozNjoyM1rOHi0n-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxMToxOTowM1rOHk3XaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw==", "bodyText": "should this be an IgniteApplication feature?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506275833", "createdAt": "2020-10-16T10:36:23Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYyNDY3NA==", "bodyText": "I don't think so. This test kills nodes and awaits for node failure. We IgniteApplication should knowe something about logic of certain test? Also, we monitor nodes not on client, not on IgniteApplication", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507624674", "createdAt": "2020-10-19T10:02:41Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzcyODk0Mg==", "bodyText": "This should be the part of the framework, since the format may change.\nFor example https://github.com/apache/ignite/pull/8294/files#diff-0d466e0ce9a05556fdc0b52bd392bf09945e2ebc21eccf1fe4a69e11e1e3aad6R245", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507728942", "createdAt": "2020-10-19T13:05:04Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzgyNTkwNg==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507825906", "createdAt": "2020-10-19T15:02:24Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODI3MDk5Mg==", "bodyText": "Idea was to have a universal method which able to extract any event time.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508270992", "createdAt": "2020-10-20T07:30:53Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMyNTQzNw==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508325437", "createdAt": "2020-10-20T08:53:32Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQwMzkzNA==", "bodyText": "lets rename to get_event_time and node_failed_event_pattern", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508403934", "createdAt": "2020-10-20T10:54:46Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQwOTkwMw==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508409903", "createdAt": "2020-10-20T11:05:05Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQxMzgyMA==", "bodyText": "still see pattern_time method, push missed?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508413820", "createdAt": "2020-10-20T11:11:52Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQxNzg5Nw==", "bodyText": "Check again", "url": "https://github.com/apache/ignite/pull/8211#discussion_r508417897", "createdAt": "2020-10-20T11:19:03Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI3NTgzMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 192}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTIzMTkzOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMDo0Njo1OVrOHi1IiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQxMDoxMzowNVrOHkHUHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI4NDE2OQ==", "bodyText": "lets split to failed amount check and ?segmentation? check", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506284169", "createdAt": "2020-10-16T10:46:59Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYzMDYyMg==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507630622", "createdAt": "2020-10-19T10:13:05Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjI4NDE2OQ=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 207}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3MTg2MTIyOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxMzowNDozMVrOHi7qUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQxMzo0NzoxMVrOHkPMew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM5MTEyMw==", "bodyText": "should this be at some test_superclass?", "url": "https://github.com/apache/ignite/pull/8211#discussion_r506391123", "createdAt": "2020-10-16T13:04:31Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_store_path = os.path.join(self.tmp_path_root, \"iptables.bak\")\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            cmd = \"sudo iptables-save | tee \" + self.netfilter_store_path\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.netfilter_store_path\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.netfilter_store_path\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        super().teardown()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYzNDE5Mw==", "bodyText": "We have no such superclass for network issues. For now, there are no responsibilities for other test/class to care for netfilter restoring. Also, the test environment clears iptables.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507634193", "createdAt": "2020-10-19T10:19:14Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_store_path = os.path.join(self.tmp_path_root, \"iptables.bak\")\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            cmd = \"sudo iptables-save | tee \" + self.netfilter_store_path\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.netfilter_store_path\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.netfilter_store_path\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        super().teardown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM5MTEyMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzczMDI3NQ==", "bodyText": "AFAIU, @ivandasch need this feature (or it's part) at another test?\nIf so, let's define the base class.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507730275", "createdAt": "2020-10-19T13:07:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_store_path = os.path.join(self.tmp_path_root, \"iptables.bak\")\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            cmd = \"sudo iptables-save | tee \" + self.netfilter_store_path\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.netfilter_store_path\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.netfilter_store_path\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        super().teardown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM5MTEyMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzczMzkwMQ==", "bodyText": "I suggest to split the tickets. Let's made refactoring ticket separate.", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507733901", "createdAt": "2020-10-19T13:12:52Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_store_path = os.path.join(self.tmp_path_root, \"iptables.bak\")\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            cmd = \"sudo iptables-save | tee \" + self.netfilter_store_path\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.netfilter_store_path\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.netfilter_store_path\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        super().teardown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM5MTEyMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzc1OTczOQ==", "bodyText": "Ok", "url": "https://github.com/apache/ignite/pull/8211#discussion_r507759739", "createdAt": "2020-10-19T13:47:11Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -149,18 +179,134 @@ def _perform_node_fail_scenario(self, test_config):\n \n             start_load_app(self.test_context, ignite_config=load_config, params=params, modules=modules)\n \n-        data = simulate_nodes_failure(servers, failed_nodes, survived_node)\n+        for node in failed_nodes:\n+            self.logger.info(\n+                \"Simulating failure of node '%s' (order %d) on '%s'\" % (node_id(node), order(node), node.name))\n+\n+        data = self._simulate_nodes_failure(servers, node_fail_task(ignite_config, test_config), failed_nodes,\n+                                            survived_node)\n \n         data['Ignite cluster start time (s)'] = start_servers_sec\n \n         return data\n \n+    def _simulate_nodes_failure(self, servers, kill_node_task, failed_nodes, survived_node):\n+        \"\"\"\n+        Perform node failure scenario\n+        \"\"\"\n+        ids_to_wait = [node_id(n) for n in failed_nodes]\n+\n+        _, first_terminated = servers.exec_on_nodes_async(failed_nodes, kill_node_task)\n+\n+        for node in failed_nodes:\n+            self.logger.debug(\n+                \"Netfilter activated on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        # Keeps dates of logged node failures.\n+        logged_timestamps = []\n+        data = {}\n+\n+        for failed_id in ids_to_wait:\n+            servers.await_event_on_node(failed_pattern(failed_id), survived_node, 15, from_the_beginning=True,\n+                                        backoff_sec=0.3)\n+\n+            _, stdout, _ = survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(failed_id), IgniteAwareService.STDOUT_STDERR_CAPTURE))\n+\n+            logged_timestamps.append(\n+                datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                                  \"[%Y-%m-%d %H:%M:%S,%f]\"))\n+\n+        self._check_results(failed_nodes, survived_node)\n+\n+        logged_timestamps.sort(reverse=True)\n+\n+        first_kill_time = epoch_mills(first_terminated)\n+        detection_delay = epoch_mills(logged_timestamps[0]) - first_kill_time\n+\n+        data['Detection of node(s) failure (ms)'] = detection_delay\n+        data['All detection delays (ms):'] = str([epoch_mills(ts) - first_kill_time for ts in logged_timestamps])\n+        data['Nodes failed'] = len(failed_nodes)\n+\n+        return data\n+\n+    def _check_results(self, failed_nodes, survived_node):\n+        \"\"\"Ensures test finishes correctly.\"\"\"\n+        cmd = \"grep '%s' %s | wc -l\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+        failed_cnt = int(str(survived_node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding()))\n+\n+        if failed_cnt != len(failed_nodes):\n+            failed = str(survived_node.account.ssh_client.exec_command(\n+                \"grep '%s' %s\" % (failed_pattern(), IgniteAwareService.STDOUT_STDERR_CAPTURE))[1].read(),\n+                         sys.getdefaultencoding())\n+\n+            self.logger.warn(\"Node '%s' (%s) has detected the following failures:%s%s\" % (\n+                survived_node.name, node_id(survived_node), os.linesep, failed))\n+\n+            raise AssertionError(\n+                \"Wrong number of failed nodes: %d. Expected: %d. Check the logs.\" % (failed_cnt, len(failed_nodes)))\n+\n+        for service in [srv for srv in self.test_context.services if isinstance(srv, IgniteAwareService)]:\n+            for node in [srv_node for srv_node in service.nodes if srv_node not in failed_nodes]:\n+                cmd = \"grep -i '%s' %s | wc -l\" % (\"local no1de segmented\", IgniteAwareService.STDOUT_STDERR_CAPTURE)\n+\n+                failed = str(node.account.ssh_client.exec_command(cmd)[1].read(), sys.getdefaultencoding())\n+\n+                if int(failed) > 0:\n+                    raise AssertionError(\n+                        \"Wrong node failed (segmented) on '%s'. Check the logs.\" % node.name)\n+\n+    def setup(self):\n+        super().setup()\n+\n+        self.netfilter_store_path = os.path.join(self.tmp_path_root, \"iptables.bak\")\n+\n+        # Store current network filter settings.\n+        for node in self.test_context.cluster.nodes:\n+            cmd = \"sudo iptables-save | tee \" + self.netfilter_store_path\n+\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if \"Warning: iptables-legacy tables present\" in exec_error:\n+                cmd = \"sudo iptables-legacy-save | tee \" + self.netfilter_store_path\n+\n+                exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            assert len(exec_error) == 0, \"Failed to store iptables rules on '%s': %s\" % (node.name, exec_error)\n+\n+            self.logger.debug(\"Netfilter before launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+    def teardown(self):\n+        # Restore previous network filter settings.\n+        cmd = \"sudo iptables-restore < \" + self.netfilter_store_path\n+\n+        errors = []\n+\n+        for node in self.test_context.cluster.nodes:\n+            exec_error = str(node.account.ssh_client.exec_command(cmd)[2].read(), sys.getdefaultencoding())\n+\n+            if len(exec_error) > 0:\n+                errors.append(\"Failed to restore iptables rules on '%s': %s\" % (node.name, exec_error))\n+            else:\n+                self.logger.debug(\"Netfilter after launch on '%s': %s\" % (node.name, dump_netfilter_settings(node)))\n+\n+        if len(errors) > 0:\n+            self.logger.error(\"Failed restoring actions:\" + os.linesep + os.linesep.join(errors))\n+\n+            raise RuntimeError(\"Unable to restore node states. See the log above.\")\n+\n+        super().teardown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM5MTEyMw=="}, "originalCommit": {"oid": "42bcdb32b471ba21a5e5d1034192b8c148270e54"}, "originalPosition": 273}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2756, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}