{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4ODI0MDA5", "number": 8159, "reviewThreads": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODowNjowMFrOEZ3GCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTo1NDozMFrOEbfmLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTUyNTIxOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODowNjowMFrOHC7q2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowMzo1MFrOHEqk5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw==", "bodyText": "according to the documentation, \"Data streamer will perform better if this flag is disabled.\"", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472836827", "createdAt": "2020-08-19T08:06:00Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4OTg3OQ==", "bodyText": "Yes, but we don't need this performance for loading. Instead, we need to re-write data sometimes to keep loading.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472889879", "createdAt": "2020-08-19T09:23:58Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NjkyMg==", "bodyText": "For the most of the tests, we need to load asap.\nYou may make this an option.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472896922", "createdAt": "2020-08-19T09:34:48Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NTY2NQ==", "bodyText": "For the most of the tests, we need to load asap.\nYou may make this an option.\n\n'Optimized' was involved only for one goal: to work with hard failure of node/data_streamer on kill-signal. An error araises, not exception. It hinders to graceful shutdown, to finish instead of get broken. Current soulution is without 'optimized' option: kust a wrap on the error.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473775665", "createdAt": "2020-08-20T08:46:30Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMTM1Mw==", "bodyText": "If you need to continue streaming on topology change, just restart it.\nI don't like the idea of changing the semantic on the fly.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474601353", "createdAt": "2020-08-21T10:02:01Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDcwNg==", "bodyText": "I think we don't need streaming at all. The idia is to put some load on cluster. There is no idea how exactly at now. Certain load type might be considered on next step as an option. I think cache.put() wold be enough. I just support the code which was before. We don't need restart streaming here. We need to begin and to spot it. That's all.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474604706", "createdAt": "2020-08-21T10:09:28Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNTYwMA==", "bodyText": "The idia is to put some load on cluster.\n\nThat's not true. The name is %Generation% and see the usage at AddNodeRebalanceTest (used to generate data, not to stream).\nMaybe you need to add new DataStreamingApplication instead?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474615600", "createdAt": "2020-08-21T10:32:12Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMjUzMA==", "bodyText": "In AddNodeRebalanceTest it works as earlier: sequentially and with the datastreamer. This wasn't changed. AddNodeRebalanceTest uses streaming too.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474622530", "createdAt": "2020-08-21T10:49:11Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1MzkyNg==", "bodyText": "Simplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474653926", "createdAt": "2020-08-21T12:03:50Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTUzMzMwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODowNzozM1rOHC7wOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0Njo0NlrOHD0_SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg==", "bodyText": "any reason to have constant with single usage?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472838202", "createdAt": "2020-08-19T08:07:33Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5MDQ3NQ==", "bodyText": "The reason is we watch this message in the log. This is a marker. I think it should not be hardcoded.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472890475", "createdAt": "2020-08-19T09:24:53Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NzQzMg==", "bodyText": "See my comments below, not sure we need this.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472897432", "createdAt": "2020-08-19T09:35:37Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NTk0NA==", "bodyText": "The constants got removed.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473775944", "createdAt": "2020-08-20T08:46:46Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTU0MzUzOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODowOTozN1rOHC73PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0NzoyMlrOHD1BSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw==", "bodyText": "use asBoolean(dflt) instead", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472839997", "createdAt": "2020-08-19T08:09:37Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5Mjc0Mg==", "bodyText": "It crashes with NPE if memory serves. It doesn't expect null. Only tries to convert not-null to boolean.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472892742", "createdAt": "2020-08-19T09:28:12Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5ODI0OA==", "bodyText": "Sound strange. What's the reason to have asBoolean with default in that case?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472898248", "createdAt": "2020-08-19T09:37:01Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMzA2Ng==", "bodyText": "It tries to convert not-null-value to a boolean.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472903066", "createdAt": "2020-08-19T09:45:33Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwNzU3Nw==", "bodyText": "according to documentation\n* If representation cannot be converted to a boolean value (including structured types\n* like Objects and Arrays),\n* specified defaultValue will be returned; no exceptions are thrown.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472907577", "createdAt": "2020-08-19T09:53:47Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzAzMDE4Ng==", "bodyText": "yes, but NPE happends before: jsonNode.get(\"infinite\") gives null.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473030186", "createdAt": "2020-08-19T13:30:12Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA1MTU2Mw==", "bodyText": "That's why I cant understand the reason to have API with default boolean :)", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473051563", "createdAt": "2020-08-19T13:59:48Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjQ1OQ==", "bodyText": "Did as earlier: with checking for null-json-node but without default values.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776459", "createdAt": "2020-08-20T08:47:22Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTU4ODY5OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODoxNzo1MVrOHC8VMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNDoyNVrOHEql3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw==", "bodyText": "you may extend run method with \"throws InterruptedException\" instead", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472847667", "createdAt": "2020-08-19T08:17:51Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjczNg==", "bodyText": "No need now: not separated thread runs.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776736", "createdAt": "2020-08-20T08:47:43Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNjU1OQ==", "bodyText": "The idea is just to allow framework to handle Exceptions. No need to overcomplicate your application", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474616559", "createdAt": "2020-08-21T10:34:37Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDE3NQ==", "bodyText": "No extra catch or throw now.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654175", "createdAt": "2020-08-21T12:04:25Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTYwNTg5OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODoyMTowMlrOHC8gwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0Nzo1NFrOHD1DFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ==", "bodyText": "what's the reason to have separated thread here with sync wait at another?\ncan we enlarge possible threads count?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472850625", "createdAt": "2020-08-19T08:21:02Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NDk3NQ==", "bodyText": "The reason is the application catches exit-signal right after exiting and stops the node.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472894975", "createdAt": "2020-08-19T09:31:39Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NTg0Mw==", "bodyText": "We can enlarge possible thread count if we need. But I think it is better to enlarge number of loading clients. Not part of this PR.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472895843", "createdAt": "2020-08-19T09:33:02Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMDAxMQ==", "bodyText": "For now, you need no additional threads since you have ... sync wait for a single thread case which equals to executing code at the main thread.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472900011", "createdAt": "2020-08-19T09:40:07Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMjMyOQ==", "bodyText": "I need this thread to keep loading while nodes failes. Not before. The main test do not wait to exit main(), it waits for \"mark initialized\"", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472902329", "createdAt": "2020-08-19T09:44:17Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMzYwOA==", "bodyText": "just relocate loop to main thread and markInitialized to finish waiting for service start.\nsee SingleKeyTxStreamerApplication for example", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472903608", "createdAt": "2020-08-19T09:46:34Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjkxNw==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776917", "createdAt": "2020-08-20T08:47:54Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTcxMTk2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODo0ODowM1rOHC9hgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0ODowMVrOHD1DXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg2NzIwMA==", "bodyText": "why __ needed?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472867200", "createdAt": "2020-08-19T08:48:03Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -45,6 +47,8 @@ class DiscoveryTest(IgniteTest):\n \n     FAILURE_DETECTION_TIMEOUT = 2000\n \n+    __DATA_AMOUNT = 100000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3Njk5MQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776991", "createdAt": "2020-08-20T08:48:01Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -45,6 +47,8 @@ class DiscoveryTest(IgniteTest):\n \n     FAILURE_DETECTION_TIMEOUT = 2000\n \n+    __DATA_AMOUNT = 100000", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg2NzIwMA=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTczNTY2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODo1MzozOFrOHC9vwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0ODoxOVrOHD1ESA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3MDg0OA==", "bodyText": "seems you relocated method description to wrong place", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472870848", "createdAt": "2020-08-19T08:53:38Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzIyNA==", "bodyText": "Did some reallocations. Looks well to me.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777224", "createdAt": "2020-08-20T08:48:19Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3MDg0OA=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTc3NjE1OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwOTowMzoyNFrOHC-Iaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0ODoyNVrOHD1EmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3NzE2Mw==", "bodyText": "this will produce incomparable results.\nlet's have the same clusters.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472877163", "createdAt": "2020-08-19T09:03:24Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"\n         :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n         nodes of given number.\n         \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1 if with_load else self.NUM_NODES,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzMwNA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777304", "createdAt": "2020-08-20T08:48:25Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"\n         :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n         nodes of given number.\n         \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1 if with_load else self.NUM_NODES,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3NzE2Mw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTc5ODg4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwOTowOTo0NFrOHC-W1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0ODozMlrOHD1FBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MDg1NA==", "bodyText": ".start() already waits for markInitialized() use this HB instead.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472880854", "createdAt": "2020-08-19T09:09:44Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzQxNQ==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777415", "createdAt": "2020-08-20T08:48:32Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MDg1NA=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NTgwMjE4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwOToxMDozNlrOHC-YzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwODo0ODozOVrOHD1FdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw==", "bodyText": "this should be covered by application as well", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472881357", "createdAt": "2020-08-19T09:10:36Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMTEzNQ==", "bodyText": "Didn't catch you", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472901135", "createdAt": "2020-08-19T09:42:07Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwNjcwMQ==", "bodyText": "it related to the previous comment.\nyou should incapsulate this to app.\nmark app initialized when it did preparations, and finished when it finished.\n.start() will wait for initialisation but .run() will wait for finish", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472906701", "createdAt": "2020-08-19T09:52:06Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwODkzNg==", "bodyText": "The application is initialized when it is just started, got a cache. The idea is to wait while it fills some amount of data.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472908936", "createdAt": "2020-08-19T09:56:22Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkxOTg2Ng==", "bodyText": "just initialize when you have some amount of data filled", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472919866", "createdAt": "2020-08-19T10:16:18Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzUyNA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777524", "createdAt": "2020-08-20T08:48:39Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjM1OTQzOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTozMjoxNlrOHEl75w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNDo1NlrOHEqmoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU3Nzg5NQ==", "bodyText": "AFAIK, single line javadocs allowed only for fields", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474577895", "createdAt": "2020-08-21T09:32:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -102,24 +107,28 @@ protected void markInitialized() {\n         inited = true;\n     }\n \n-    /**\n-     *\n-     */\n-    protected void markFinished() {\n+    /** */\n+    protected void markFinished(boolean removeShutdownHook) {\n         assert !finished;\n         assert !broken;\n \n         log.info(APP_FINISHED);\n \n-        removeShutdownHook();\n+        if (removeShutdownHook)\n+            removeShutdownHook();\n \n         finished = true;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDM2OA==", "bodyText": "Someone insist on inlining such comments :) Reverted.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654368", "createdAt": "2020-08-21T12:04:56Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -102,24 +107,28 @@ protected void markInitialized() {\n         inited = true;\n     }\n \n-    /**\n-     *\n-     */\n-    protected void markFinished() {\n+    /** */\n+    protected void markFinished(boolean removeShutdownHook) {\n         assert !finished;\n         assert !broken;\n \n         log.info(APP_FINISHED);\n \n-        removeShutdownHook();\n+        if (removeShutdownHook)\n+            removeShutdownHook();\n \n         finished = true;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU3Nzg5NQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjM3NjAwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTozNToxN1rOHEmGlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNTowNVrOHEqm7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ==", "bodyText": "Some architectural leak here.\nThe application should not be aware of shutdown hook.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474580631", "createdAt": "2020-08-21T09:35:17Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMzEwNQ==", "bodyText": "Yes. I think markBroken, markTerminated, markFinished is overcomplicated and should be reconsidered. But not in this ticket. Is it ok?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474623105", "createdAt": "2020-08-21T10:50:21Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDQ0NA==", "bodyText": "Simplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654444", "createdAt": "2020-08-21T12:05:05Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjM4MzI4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTozNjozMVrOHEmLHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNToxMVrOHEqnKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MTc5MQ==", "bodyText": "newline required here because of different variable purpose", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474581791", "createdAt": "2020-08-21T09:36:31Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDUwNA==", "bodyText": "Fixed.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654504", "createdAt": "2020-08-21T12:05:11Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MTc5MQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjM5MjAwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTozODoxNlrOHEmQvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNToyM1rOHEqnhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MzIyOQ==", "bodyText": "seems to be overcomplicated", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474583229", "createdAt": "2020-08-21T09:38:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDU5Ng==", "bodyText": "Smplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654596", "createdAt": "2020-08-21T12:05:23Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MzIyOQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjQ2MjIwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTo1MDo1NlrOHEm9rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNTozMlrOHEqn0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ==", "bodyText": "just do not catch such exceptions. App moll be marked as broken at IgniteAwareApplication#start", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474594735", "createdAt": "2020-08-21T09:50:56Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNTAyNQ==", "bodyText": "That has reasons. Some time was spent to make this code choise. Catching no exception causes app marked broken what is not actually broken. The datastreamer seems to have no way to stop correctly on node stoppage. I tried to cancel it on node stop event, on shutdown-hook. Another exception arises. Such behaviour is interesting but I decided not to research it within trivial and raw loading test.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474615025", "createdAt": "2020-08-21T10:30:47Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDY3Mw==", "bodyText": "Simplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654673", "createdAt": "2020-08-21T12:05:32Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjQ2Njg4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTo1MTo0MFrOHEnAng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNTo0MFrOHEqoBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NTQ4Ng==", "bodyText": "newline required here because of different variable purpose", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474595486", "createdAt": "2020-08-21T09:51:40Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDcyNw==", "bodyText": "Fixed.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654727", "createdAt": "2020-08-21T12:05:40Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NTQ4Ng=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjQ3NDE1OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTo1MzoyMlrOHEnFPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNTo1NFrOHEqoaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NjY2OQ==", "bodyText": "any reason to spend time on transforming the value?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474596669", "createdAt": "2020-08-21T09:53:22Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDgyNQ==", "bodyText": "Simplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654825", "createdAt": "2020-08-21T12:05:54Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NjY2OQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjQ4NTg2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTo1NjoxNlrOHEnMcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNjowMVrOHEqopQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg==", "bodyText": "Not sure I got how notification related to the initialization.\nHow about to relocate init to the loop(generate)?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474598512", "createdAt": "2020-08-21T09:56:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));\n+\n+                if (notifyTime + DATAGEN_NOTIFY_INTERVAL_NANO < System.nanoTime() ||\n+                    i - streamed >= DATAGEN_NOTIFY_INTERVAL_AMOUNT) {\n+                    notifyTime = System.nanoTime();\n+\n+                    if (markInited && !inited())\n+                        markInitialized();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNjYyMA==", "bodyText": "As you advised the delayed initialization was put into the app code. It begins putting data, loads some anount ant realeses the test to crash nodes after. I think if we wont reallocate it secod time, we forgot what we wanted to do.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474616620", "createdAt": "2020-08-21T10:34:45Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));\n+\n+                if (notifyTime + DATAGEN_NOTIFY_INTERVAL_NANO < System.nanoTime() ||\n+                    i - streamed >= DATAGEN_NOTIFY_INTERVAL_AMOUNT) {\n+                    notifyTime = System.nanoTime();\n+\n+                    if (markInited && !inited())\n+                        markInitialized();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDg4NQ==", "bodyText": "Simplified.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654885", "createdAt": "2020-08-21T12:06:01Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));\n+\n+                if (notifyTime + DATAGEN_NOTIFY_INTERVAL_NANO < System.nanoTime() ||\n+                    i - streamed >= DATAGEN_NOTIFY_INTERVAL_AMOUNT) {\n+                    notifyTime = System.nanoTime();\n+\n+                    if (markInited && !inited())\n+                        markInitialized();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjQ5MTQ0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTo1ODoxMFrOHEnP_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMzozMDoxOVrOHEtQew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg==", "bodyText": "do we really need this additional logging?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474599422", "createdAt": "2020-08-21T09:58:10Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -76,8 +76,11 @@ protected IgniteAwareApplication() {\n             else\n                 log.info(\"Application already done [finished=\" + finished + \", broken=\" + broken + \"]\");\n \n+            log.info(\"Waiting for graceful termination...\");\n+\n             while (!finished && !broken) {\n-                log.info(\"Waiting for graceful termnation.\");\n+                if (log.isTraceEnabled())\n+                    log.trace(\"Waiting for graceful termination cycle...\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNzc4OQ==", "bodyText": "To me helps a lot to see what is going on when the app catches the stop signal. Ok, lets remove it.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474617789", "createdAt": "2020-08-21T10:37:30Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -76,8 +76,11 @@ protected IgniteAwareApplication() {\n             else\n                 log.info(\"Application already done [finished=\" + finished + \", broken=\" + broken + \"]\");\n \n+            log.info(\"Waiting for graceful termination...\");\n+\n             while (!finished && !broken) {\n-                log.info(\"Waiting for graceful termnation.\");\n+                if (log.isTraceEnabled())\n+                    log.trace(\"Waiting for graceful termination cycle...\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY5Nzg1MQ==", "bodyText": "oki-doki. lets keep", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474697851", "createdAt": "2020-08-21T13:30:19Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -76,8 +76,11 @@ protected IgniteAwareApplication() {\n             else\n                 log.info(\"Application already done [finished=\" + finished + \", broken=\" + broken + \"]\");\n \n+            log.info(\"Waiting for graceful termination...\");\n+\n             while (!finished && !broken) {\n-                log.info(\"Waiting for graceful termnation.\");\n+                if (log.isTraceEnabled())\n+                    log.trace(\"Waiting for graceful termination cycle...\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjUxNDE5OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDowNTozNVrOHEnd2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMzo1NjowOVrOHEuPdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ==", "bodyText": "Kill 0 means kill_crd. Any reason to have special param?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474602971", "createdAt": "2020-08-21T10:05:35Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxODA5NA==", "bodyText": "Yes. It kils 0 nodes, but kills the coordinator and kills coordinator with load.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474618094", "createdAt": "2020-08-21T10:38:18Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyNjY5OA==", "bodyText": "\"Kill 0 means kill_crd. \" Was. In presious commit. Now it go as externalized, configurable params and there is no such hidden meanings. Now eacp param works according to its name.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474626698", "createdAt": "2020-08-21T10:58:43Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDcxMDkxOQ==", "bodyText": "Seems overcomplicated", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474710919", "createdAt": "2020-08-21T13:50:52Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDcxMzk3NQ==", "bodyText": "What exactly? Trivial to me. No idea how to change.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474713975", "createdAt": "2020-08-21T13:56:09Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjUyNDA4OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDowODo1NlrOHEnjrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMjowNjo1NVrOHEqqMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDQ2MA==", "bodyText": "overcomplicated", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474604460", "createdAt": "2020-08-21T10:08:56Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -175,16 +138,19 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n+        if config.nodes_to_kill + (1 if config.kill_coordinator else 0) > self.servers.num_nodes - 1:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NTI4Mw==", "bodyText": "Removed.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474655283", "createdAt": "2020-08-21T12:06:55Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -175,16 +138,19 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n+        if config.nodes_to_kill + (1 if config.kill_coordinator else 0) > self.servers.num_nodes - 1:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDQ2MA=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NjUzMzAyOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDoxMTo0OVrOHEnpKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDo0NjozNVrOHEol_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNTg2NA==", "bodyText": "should not be the diff between what node to kill.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474605864", "createdAt": "2020-08-21T10:11:49Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +177,78 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n-\n-        assert by_log > 0, \"Negative node failure detection delay: \" + by_log + \". Probably it is a timezone issue.\"\n-        assert by_log <= time_holder, \"Value of node failure detection delay taken from by the node log (\" + \\\n-                                      str(by_log) + \"ms) must be lesser than measured value (\" + str(time_holder) + \\\n-                                      \"ms) because watching this event consumes extra time.\"\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))\n \n-        data['Detection of node(s) failure, measured (ms)'] = time_holder\n-        data['Detection of node(s) failure, by the log (ms)'] = by_log\n         data['Nodes failed'] = len(failed_nodes)\n \n         return data\n \n+    @staticmethod\n+    def __check_and_store_results(data, measured, delay_by_log):\n+        assert delay_by_log > 0, \\\n+            \"Negative failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms). It is \\\n+            probably an issue of the timezone or system clock settings.\"\n+        assert delay_by_log <= measured, \\\n+            \"Failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms) must be lesser than  \\\n+            measured value (\" + str(measured) + \"ms) because watching this event consumes extra time. It is  \\\n+            probably an issue of the timezone or system clock settings.\"\n+\n+        data['Detection of node(s) failure, measured (ms)'] = measured\n+        data['Detection of node(s) failure, by the log (ms)'] = delay_by_log\n+\n     @staticmethod\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMTQzNg==", "bodyText": "We decided to separete coordinator failure. It should fail too, but we wanted to see the differeace with an ordinary node. Didn't we? There are set op parametrized tests for it: kill only coordinator, kill coordinator + 1 node, kill coordinator + 2 nodes. All ander load and without. Also: kill 1 node without coordinator, kill 2 nodes without coordinator. Did we change our mind and don't check exactly coordinator failure?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474621436", "createdAt": "2020-08-21T10:46:35Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +177,78 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n-\n-        assert by_log > 0, \"Negative node failure detection delay: \" + by_log + \". Probably it is a timezone issue.\"\n-        assert by_log <= time_holder, \"Value of node failure detection delay taken from by the node log (\" + \\\n-                                      str(by_log) + \"ms) must be lesser than measured value (\" + str(time_holder) + \\\n-                                      \"ms) because watching this event consumes extra time.\"\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))\n \n-        data['Detection of node(s) failure, measured (ms)'] = time_holder\n-        data['Detection of node(s) failure, by the log (ms)'] = by_log\n         data['Nodes failed'] = len(failed_nodes)\n \n         return data\n \n+    @staticmethod\n+    def __check_and_store_results(data, measured, delay_by_log):\n+        assert delay_by_log > 0, \\\n+            \"Negative failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms). It is \\\n+            probably an issue of the timezone or system clock settings.\"\n+        assert delay_by_log <= measured, \\\n+            \"Failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms) must be lesser than  \\\n+            measured value (\" + str(measured) + \"ms) because watching this event consumes extra time. It is  \\\n+            probably an issue of the timezone or system clock settings.\"\n+\n+        data['Detection of node(s) failure, measured (ms)'] = measured\n+        data['Detection of node(s) failure, by the log (ms)'] = delay_by_log\n+\n     @staticmethod\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNTg2NA=="}, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 275}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjE2NzQ0OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwNzo1NTo0M1rOHFYlng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxMToyMzoxN1rOHFgGmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwNzc3NA==", "bodyText": "let it be a \"warmup\" option", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475407774", "createdAt": "2020-08-24T07:55:43Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzMDkwNA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475530904", "createdAt": "2020-08-24T11:23:17Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwNzc3NA=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjE3ODA2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwNzo1ODoxOVrOHFYrqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo1MDo0M1rOHFtyew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw==", "bodyText": "This makes behavior counter-intuitive.\nThe small range should not force warmup finish.\nRange 10 (keys 0-9) and warmup 10M is a possible case for small memory consumption checks.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475409323", "createdAt": "2020-08-24T07:58:19Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwMTUwMQ==", "bodyText": "How do we make the app started witout markInitialized()? The test will fail witout the app initialization.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475501501", "createdAt": "2020-08-24T10:27:11Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU0OTc0Nw==", "bodyText": "we should markInitialized only when warmup is done.\nDoes not matter that is bigger (warmup or range)", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475549747", "createdAt": "2020-08-24T12:02:27Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NTEzMQ==", "bodyText": "Used a % as an warming up amount.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475755131", "createdAt": "2020-08-24T16:50:43Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjE4OTk1OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwODowMTo0N1rOHFYytg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo1MTozMVrOHFt0XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg==", "bodyText": "no reason to create datastreamer if (when) cache.put is used", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475411126", "createdAt": "2020-08-24T08:01:47Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ5NDgxNQ==", "bodyText": "The reason is simplier code. If/ try-catch witch finally-close. Why not?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475494815", "createdAt": "2020-08-24T10:17:21Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MDkzMg==", "bodyText": "This technique makes reading harder.\nYou see that DS created but put is used. This can scare you %)", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475550932", "createdAt": "2020-08-24T12:04:59Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NTYxMw==", "bodyText": "no optimized option makes this inactual.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475755613", "createdAt": "2020-08-24T16:51:31Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjE5OTY2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwODowNDo1M1rOHFY4zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxMToyMzowOVrOHFgGWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMjY4NA==", "bodyText": "one-line javadocs are not allowed for methods", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475412684", "createdAt": "2020-08-24T08:04:53Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -165,6 +173,16 @@ protected boolean terminated() {\n         return terminated;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzMDg0MA==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475530840", "createdAt": "2020-08-24T11:23:09Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -165,6 +173,16 @@ protected boolean terminated() {\n         return terminated;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMjY4NA=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjM5MjM2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwODo1Nzo1MVrOHFarDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo0NDowMlrOHFtjDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg==", "bodyText": "does it really make sense to have backoff_sec=0.01?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475441932", "createdAt": "2020-08-24T08:57:51Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwMzM3NQ==", "bodyText": "Why not? We have slow test and we'll get more test and more. The faster the are, the better. Let's detect target values, indicators asap. Make sense?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475503375", "createdAt": "2020-08-24T10:29:13Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MTY4OA==", "bodyText": "We should not use this approach.\nwe already have explicit time at logs.\nand we'll make sure time is sync across the cluster at other tests.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475551688", "createdAt": "2020-08-24T12:06:32Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1MTE4Mw==", "bodyText": "Only the logged time left.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475751183", "createdAt": "2020-08-24T16:44:02Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjU1MzczOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTozMjo0MVrOHFcQAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo0MzozNVrOHFtiKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ==", "bodyText": "how about \"batched\" or something like that?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475467779", "createdAt": "2020-08-24T09:32:41Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwOTkxNg==", "bodyText": "Why expose internal inplementation? It's not only buffered. It also choises nodes to load data by keys. It's an optimized load. What's the reason to name by one optimization step?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475509916", "createdAt": "2020-08-24T10:38:10Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MjQ3OA==", "bodyText": "the better case is to create 2 classes (DSDataGenerator and PutDG, or something like this) to make this simple.\nJust overwrite method from abstract DGApplication class)", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475552478", "createdAt": "2020-08-24T12:08:17Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1MDk1Mg==", "bodyText": "'optimized' got removed. It was involved to wrap node-stop-issue of the data streamer. The code got changed, I kept it as simple option which looks useful. Thi look to me trivilab, but if rised discussion, we don't need it in this ticket. For now, we need only contiguous loading. The streamer was introdused before. It is ok.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475750952", "createdAt": "2020-08-24T16:43:35Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjYzODcwOnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTo1MjoyOVrOHFdFFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo0MDo1MFrOHFtb3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ==", "bodyText": "how about to rename to last_blabla (as opposed to first_terminated)?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475481365", "createdAt": "2020-08-24T09:52:29Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUxMzY2OA==", "bodyText": "This returns time of first kill command. Why last?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475513668", "createdAt": "2020-08-24T10:46:27Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MzAxMA==", "bodyText": "since you have a loop, it will record last turn time.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475553010", "createdAt": "2020-08-24T12:09:28Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc0OTM0Mg==", "bodyText": "first_terminated is out the loop, it's before it. There is an atomic inside. It holds time of the first kill command.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475749342", "createdAt": "2020-08-24T16:40:50Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MjY0Njg2OnYy", "diffSide": "RIGHT", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTo1NDozMFrOHFdJug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxMTozMzozMFrOHFgbIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MjU1NA==", "bodyText": "how about also provide raw list here? duration1 and duration2.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475482554", "createdAt": "2020-08-24T09:54:30Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +165,75 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzNjE2Mg==", "bodyText": "Fixed", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475536162", "createdAt": "2020-08-24T11:33:30Z", "author": {"login": "Vladsz83"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +165,75 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MjU1NA=="}, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 235}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2721, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}