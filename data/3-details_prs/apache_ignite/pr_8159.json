{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4ODI0MDA5", "number": 8159, "title": "Loading in discovery tests.", "bodyText": "Loading in discovery tests.", "createdAt": "2020-08-17T13:13:33Z", "url": "https://github.com/apache/ignite/pull/8159", "merged": true, "mergeCommit": {"oid": "c6f55041ad4033d94cda759995c4245192d8bad4"}, "closed": true, "closedAt": "2020-08-26T09:36:58Z", "author": {"login": "Vladsz83"}, "timelineItems": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-j91MAH2gAyNDY4ODI0MDA5OjI3YWExNDQ3ZTE3ODEyOTA3MDQzMGEwOTc0M2ZlODVhNzQwOGM5YmY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdCY8lngH2gAyNDY4ODI0MDA5Ojk1MWNlMDNkNWUxNGNiM2MwNDQwNGQ1Y2Y4ZjQwNTZhOTViMzk5MjM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "27aa1447e178129070430a09743fe85a7408c9bf", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/27aa1447e178129070430a09743fe85a7408c9bf", "committedDate": "2020-08-13T18:03:36Z", "message": "amend"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0803983cf489782092a2038e953863c44ed74586", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/0803983cf489782092a2038e953863c44ed74586", "committedDate": "2020-08-14T16:18:08Z", "message": "looks good"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95260bceb7df3a5b05df8472a92c610ff02b5720", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/95260bceb7df3a5b05df8472a92c610ff02b5720", "committedDate": "2020-08-14T17:22:37Z", "message": "amendme. in progress. fixing zk client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13dd5764add5fc5dc3a8d8a56d910615633c29f6", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/13dd5764add5fc5dc3a8d8a56d910615633c29f6", "committedDate": "2020-08-17T12:56:22Z", "message": "Parametrization."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "399be251eff8908e70adb9db583e7341d1b8a043", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/399be251eff8908e70adb9db583e7341d1b8a043", "committedDate": "2020-08-17T12:56:40Z", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load\n\n# Conflicts:\n#\tmodules/ducktests/tests/ignitetest/tests/discovery_test.py"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "403642c413a9e5caccfc683f97fcae01d9fe4704", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/403642c413a9e5caccfc683f97fcae01d9fe4704", "committedDate": "2020-08-17T13:12:11Z", "message": "Minorities."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c64c5d8f4c362e415d7497cdc50c8ecc7a7ab8b8", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/c64c5d8f4c362e415d7497cdc50c8ecc7a7ab8b8", "committedDate": "2020-08-17T17:25:04Z", "message": "fix stage log. Better awaiting timeout"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25483bfa9cf1921b6bbc1171d19f3425f024e399", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/25483bfa9cf1921b6bbc1171d19f3425f024e399", "committedDate": "2020-08-17T21:37:33Z", "message": "fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f838188945890deb019c1ea7577201cd69adf65b", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/f838188945890deb019c1ea7577201cd69adf65b", "committedDate": "2020-08-18T09:12:45Z", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load\n\n# Conflicts:\n#\tmodules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java\n#\tmodules/ducktests/tests/ignitetest/services/utils/ignite_aware_app.py\n#\tmodules/ducktests/tests/ignitetest/tests/discovery_test.py"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/ec679f631ebd611807b3ef02d31fc254ac323400", "committedDate": "2020-08-18T10:48:36Z", "message": "merged ignite-ducktape"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwMjE5NDE1", "url": "https://github.com/apache/ignite/pull/8159#pullrequestreview-470219415", "createdAt": "2020-08-19T08:05:59Z", "commit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwODowNjowMFrOHC7q2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwOToxMDozNlrOHC-YzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw==", "bodyText": "according to the documentation, \"Data streamer will perform better if this flag is disabled.\"", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472836827", "createdAt": "2020-08-19T08:06:00Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg==", "bodyText": "any reason to have constant with single usage?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472838202", "createdAt": "2020-08-19T08:07:33Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw==", "bodyText": "use asBoolean(dflt) instead", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472839997", "createdAt": "2020-08-19T08:09:37Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw==", "bodyText": "you may extend run method with \"throws InterruptedException\" instead", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472847667", "createdAt": "2020-08-19T08:17:51Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ==", "bodyText": "what's the reason to have separated thread here with sync wait at another?\ncan we enlarge possible threads count?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472850625", "createdAt": "2020-08-19T08:21:02Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg2NzIwMA==", "bodyText": "why __ needed?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472867200", "createdAt": "2020-08-19T08:48:03Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -45,6 +47,8 @@ class DiscoveryTest(IgniteTest):\n \n     FAILURE_DETECTION_TIMEOUT = 2000\n \n+    __DATA_AMOUNT = 100000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3MDg0OA==", "bodyText": "seems you relocated method description to wrong place", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472870848", "createdAt": "2020-08-19T08:53:38Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3NzE2Mw==", "bodyText": "this will produce incomparable results.\nlet's have the same clusters.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472877163", "createdAt": "2020-08-19T09:03:24Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"\n         :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n         nodes of given number.\n         \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1 if with_load else self.NUM_NODES,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MDg1NA==", "bodyText": ".start() already waits for markInitialized() use this HB instead.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472880854", "createdAt": "2020-08-19T09:09:44Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw==", "bodyText": "this should be covered by application as well", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472881357", "createdAt": "2020-08-19T09:10:36Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 250}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbedf807aa273cf361b5bdf350f63ca8874a4a9e", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/fbedf807aa273cf361b5bdf350f63ca8874a4a9e", "committedDate": "2020-08-19T10:33:21Z", "message": "fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d834baa0a61f2a950f977c3867d82f42ff27b30", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/4d834baa0a61f2a950f977c3867d82f42ff27b30", "committedDate": "2020-08-19T10:33:48Z", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f5245867e2f6a3a55cdecf6bbabed7f8319331a", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/5f5245867e2f6a3a55cdecf6bbabed7f8319331a", "committedDate": "2020-08-19T10:50:48Z", "message": "fixes2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c2a77af659afcd6899729dd1fd98ba8d53f75ce", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/3c2a77af659afcd6899729dd1fd98ba8d53f75ce", "committedDate": "2020-08-19T19:28:56Z", "message": "fixes2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80e4718d6a39f6cd5b6be95cf55f60c91da31602", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/80e4718d6a39f6cd5b6be95cf55f60c91da31602", "committedDate": "2020-08-19T19:29:38Z", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b4a9ea7692f1761c8fd0d0e08df76665db89ea1", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/4b4a9ea7692f1761c8fd0d0e08df76665db89ea1", "committedDate": "2020-08-19T19:52:43Z", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac7005138446847346cf0dfe123eb4281b9a9f0c", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/ac7005138446847346cf0dfe123eb4281b9a9f0c", "committedDate": "2020-08-20T06:32:27Z", "message": "import order fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/405298b6389d26a2558d8811f97e4feaab5d0770", "committedDate": "2020-08-21T07:49:28Z", "message": "+overwrite"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyMzQ1NTY1", "url": "https://github.com/apache/ignite/pull/8159#pullrequestreview-472345565", "createdAt": "2020-08-21T09:32:16Z", "commit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOTozMjoxNlrOHEl75w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDowMjowMVrOHEnXiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU3Nzg5NQ==", "bodyText": "AFAIK, single line javadocs allowed only for fields", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474577895", "createdAt": "2020-08-21T09:32:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -102,24 +107,28 @@ protected void markInitialized() {\n         inited = true;\n     }\n \n-    /**\n-     *\n-     */\n-    protected void markFinished() {\n+    /** */\n+    protected void markFinished(boolean removeShutdownHook) {\n         assert !finished;\n         assert !broken;\n \n         log.info(APP_FINISHED);\n \n-        removeShutdownHook();\n+        if (removeShutdownHook)\n+            removeShutdownHook();\n \n         finished = true;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ==", "bodyText": "Some architectural leak here.\nThe application should not be aware of shutdown hook.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474580631", "createdAt": "2020-08-21T09:35:17Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MTc5MQ==", "bodyText": "newline required here because of different variable purpose", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474581791", "createdAt": "2020-08-21T09:36:31Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MzIyOQ==", "bodyText": "seems to be overcomplicated", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474583229", "createdAt": "2020-08-21T09:38:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ==", "bodyText": "just do not catch such exceptions. App moll be marked as broken at IgniteAwareApplication#start", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474594735", "createdAt": "2020-08-21T09:50:56Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NTQ4Ng==", "bodyText": "newline required here because of different variable purpose", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474595486", "createdAt": "2020-08-21T09:51:40Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NjY2OQ==", "bodyText": "any reason to spend time on transforming the value?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474596669", "createdAt": "2020-08-21T09:53:22Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg==", "bodyText": "Not sure I got how notification related to the initialization.\nHow about to relocate init to the loop(generate)?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474598512", "createdAt": "2020-08-21T09:56:16Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));\n+\n+                if (notifyTime + DATAGEN_NOTIFY_INTERVAL_NANO < System.nanoTime() ||\n+                    i - streamed >= DATAGEN_NOTIFY_INTERVAL_AMOUNT) {\n+                    notifyTime = System.nanoTime();\n+\n+                    if (markInited && !inited())\n+                        markInitialized();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg==", "bodyText": "do we really need this additional logging?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474599422", "createdAt": "2020-08-21T09:58:10Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -76,8 +76,11 @@ protected IgniteAwareApplication() {\n             else\n                 log.info(\"Application already done [finished=\" + finished + \", broken=\" + broken + \"]\");\n \n+            log.info(\"Waiting for graceful termination...\");\n+\n             while (!finished && !broken) {\n-                log.info(\"Waiting for graceful termnation.\");\n+                if (log.isTraceEnabled())\n+                    log.trace(\"Waiting for graceful termination cycle...\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMTM1Mw==", "bodyText": "If you need to continue streaming on topology change, just restart it.\nI don't like the idea of changing the semantic on the fly.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474601353", "createdAt": "2020-08-21T10:02:01Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, "originalCommit": {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400"}, "originalPosition": 124}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyMzY3NDcz", "url": "https://github.com/apache/ignite/pull/8159#pullrequestreview-472367473", "createdAt": "2020-08-21T10:05:34Z", "commit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDowNTozNVrOHEnd2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMDoxMTo0OVrOHEnpKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ==", "bodyText": "Kill 0 means kill_crd. Any reason to have special param?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474602971", "createdAt": "2020-08-21T10:05:35Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDQ2MA==", "bodyText": "overcomplicated", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474604460", "createdAt": "2020-08-21T10:08:56Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -175,16 +138,19 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n+        if config.nodes_to_kill + (1 if config.kill_coordinator else 0) > self.servers.num_nodes - 1:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNTg2NA==", "bodyText": "should not be the diff between what node to kill.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474605864", "createdAt": "2020-08-21T10:11:49Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +177,78 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n-\n-        assert by_log > 0, \"Negative node failure detection delay: \" + by_log + \". Probably it is a timezone issue.\"\n-        assert by_log <= time_holder, \"Value of node failure detection delay taken from by the node log (\" + \\\n-                                      str(by_log) + \"ms) must be lesser than measured value (\" + str(time_holder) + \\\n-                                      \"ms) because watching this event consumes extra time.\"\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))\n \n-        data['Detection of node(s) failure, measured (ms)'] = time_holder\n-        data['Detection of node(s) failure, by the log (ms)'] = by_log\n         data['Nodes failed'] = len(failed_nodes)\n \n         return data\n \n+    @staticmethod\n+    def __check_and_store_results(data, measured, delay_by_log):\n+        assert delay_by_log > 0, \\\n+            \"Negative failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms). It is \\\n+            probably an issue of the timezone or system clock settings.\"\n+        assert delay_by_log <= measured, \\\n+            \"Failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms) must be lesser than  \\\n+            measured value (\" + str(measured) + \"ms) because watching this event consumes extra time. It is  \\\n+            probably an issue of the timezone or system clock settings.\"\n+\n+        data['Detection of node(s) failure, measured (ms)'] = measured\n+        data['Detection of node(s) failure, by the log (ms)'] = delay_by_log\n+\n     @staticmethod\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770"}, "originalPosition": 275}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2bbeaca014d0580b4e82e1eb55e0cc1d194d44a3", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/2bbeaca014d0580b4e82e1eb55e0cc1d194d44a3", "committedDate": "2020-08-21T12:02:44Z", "message": "Fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "committedDate": "2020-08-21T13:58:08Z", "message": "Separated warmup."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a205e2670a6d36498ff39038023a34284aebec6d", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/a205e2670a6d36498ff39038023a34284aebec6d", "committedDate": "2020-08-24T09:22:38Z", "message": "Fixed nodes num and coordinator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea9e184f519f9769409f8f7b87d38d5684af01e5", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/ea9e184f519f9769409f8f7b87d38d5684af01e5", "committedDate": "2020-08-24T09:23:15Z", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/53d082db24f889bec993ab282289fe5cd8556239", "committedDate": "2020-08-24T09:24:07Z", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczMTk5NTA5", "url": "https://github.com/apache/ignite/pull/8159#pullrequestreview-473199509", "createdAt": "2020-08-24T07:55:42Z", "commit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwNzo1NTo0M1rOHFYlng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTo1NDozMFrOHFdJug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwNzc3NA==", "bodyText": "let it be a \"warmup\" option", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475407774", "createdAt": "2020-08-24T07:55:43Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw==", "bodyText": "This makes behavior counter-intuitive.\nThe small range should not force warmup finish.\nRange 10 (keys 0-9) and warmup 10M is a possible case for small memory consumption checks.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475409323", "createdAt": "2020-08-24T07:58:19Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg==", "bodyText": "no reason to create datastreamer if (when) cache.put is used", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475411126", "createdAt": "2020-08-24T08:01:47Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMjY4NA==", "bodyText": "one-line javadocs are not allowed for methods", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475412684", "createdAt": "2020-08-24T08:04:53Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -165,6 +173,16 @@ protected boolean terminated() {\n         return terminated;\n     }\n \n+    /** */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg==", "bodyText": "does it really make sense to have backoff_sec=0.01?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475441932", "createdAt": "2020-08-24T08:57:51Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ==", "bodyText": "how about \"batched\" or something like that?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475467779", "createdAt": "2020-08-24T09:32:41Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ==", "bodyText": "how about to rename to last_blabla (as opposed to first_terminated)?", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475481365", "createdAt": "2020-08-24T09:52:29Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MjU1NA==", "bodyText": "how about also provide raw list here? duration1 and duration2.", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475482554", "createdAt": "2020-08-24T09:54:30Z", "author": {"login": "anton-vinogradov"}, "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +165,75 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53d082db24f889bec993ab282289fe5cd8556239"}, "originalPosition": 235}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7950c928424f31d00160e30521a38bbea707dda7", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/7950c928424f31d00160e30521a38bbea707dda7", "committedDate": "2020-08-24T11:22:59Z", "message": "Fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ef9e977a62085fa1d95565b33f6cd9e79e9fa7f", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/5ef9e977a62085fa1d95565b33f6cd9e79e9fa7f", "committedDate": "2020-08-24T11:34:00Z", "message": "Fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ad215619742db560ed0f28e608d366082f682e3", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/2ad215619742db560ed0f28e608d366082f682e3", "committedDate": "2020-08-24T11:51:05Z", "message": "removed results check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b167ab98b46053604014c6904d83b70aba499ea7", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/b167ab98b46053604014c6904d83b70aba499ea7", "committedDate": "2020-08-25T07:54:41Z", "message": "Fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee5dbf4a5ce6a99fbf2c88b29d577ca07d186a86", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/ee5dbf4a5ce6a99fbf2c88b29d577ca07d186a86", "committedDate": "2020-08-25T08:41:43Z", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ee5b244cb3241b66e9ce9a71063d81512bdd37e", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/7ee5b244cb3241b66e9ce9a71063d81512bdd37e", "committedDate": "2020-08-25T15:02:49Z", "message": "Separated data loading."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79fc150ac5fb9e030031130ec367142f48d95836", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/79fc150ac5fb9e030031130ec367142f48d95836", "committedDate": "2020-08-25T15:16:41Z", "message": "spelling fix."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "951ce03d5e14cb3c04404d5cf8f4056a95b39923", "author": {"user": {"login": "Vladsz83", "name": "Vladimir Steshin"}}, "url": "https://github.com/apache/ignite/commit/951ce03d5e14cb3c04404d5cf8f4056a95b39923", "committedDate": "2020-08-25T15:28:59Z", "message": "+info"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3242, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}