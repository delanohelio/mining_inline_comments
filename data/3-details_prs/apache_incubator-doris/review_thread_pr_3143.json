{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkwNzgzMjU4", "number": 3143, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMTo1MDo0NlrODpuwPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTo0NTowOFrOD3sCmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MDg0MjIxOnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMTo1MDo0NlrOF5Fwqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMTo1MDo0NlrOF5Fwqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwNzUzMA==", "bodyText": "Better to add some comments to explain how the work is done, which will make others understand this code easily.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395407530", "createdAt": "2020-03-20T01:50:46Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -95,72 +193,79 @@ class NodeChannel {\n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    std::atomic<bool> _rpc_error{false};\n+    std::atomic<bool> _is_cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};\n+\n+    bool _eos_is_produced{false}; // only for restricting producer behaviors\n+\n+    std::unique_ptr<RowDescriptor> _row_desc;\n+    int _batch_size = 0;\n+    std::unique_ptr<RowBatch> _cur_batch;\n+    PTabletWriterAddBatchRequest _cur_add_batch_request;\n+\n+    std::mutex _pending_batches_lock;\n+    using AddBatchReq = std::pair<std::unique_ptr<RowBatch>, PTabletWriterAddBatchRequest>;\n+    std::queue<AddBatchReq> _pending_batches;\n+    std::atomic<int> _pending_batches_num{0};\n+\n     palo::PInternalService_Stub* _stub = nullptr;\n     RefCountClosure<PTabletWriterOpenResult>* _open_closure = nullptr;\n-    RefCountClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n+    ReusableClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n \n     std::vector<TTabletWithPartition> _all_tablets;\n-    PTabletWriterAddBatchRequest _add_batch_request;\n+    std::vector<TTabletCommitInfo> _tablet_commit_infos;\n+\n+    AddBatchCounter _add_batch_counter;\n+    int64_t _queue_push_lock_ns = 0;\n+    int64_t _serialize_batch_ns = 0;\n+    int64_t _actual_consume_ns = 0;\n };\n \n class IndexChannel {\n public:\n     IndexChannel(OlapTableSink* parent, int64_t index_id, int32_t schema_hash)\n-            : _parent(parent), _index_id(index_id),\n-            _schema_hash(schema_hash) {\n-    }\n+            : _parent(parent), _index_id(index_id), _schema_hash(schema_hash) {}\n     ~IndexChannel();\n \n-    Status init(RuntimeState* state,\n-                const std::vector<TTabletWithPartition>& tablets);\n-    Status open();\n-    Status add_row(Tuple* tuple, int64_t tablet_id);\n+    Status init(RuntimeState* state, const std::vector<TTabletWithPartition>& tablets);\n \n-    Status close(RuntimeState* state);\n+    Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    void cancel();\n+    void for_each_node_channel(std::function<void(NodeChannel*)> func) {\n+        for (auto& it : _node_channels) {\n+            func(it.second);\n+        }\n+    }\n \n-private:\n-    // return true if this load can't success.\n-    bool _handle_failed_node(NodeChannel* channel);\n+    void mark_as_failed(NodeChannel* ch) { _failed_channels.insert(ch->node_id()); }\n+    bool has_intolerable_failure();\n \n private:\n     OlapTableSink* _parent;\n     int64_t _index_id;\n     int32_t _schema_hash;\n-    int _num_failed_channels = 0;\n \n     // BeId -> channel\n     std::unordered_map<int64_t, NodeChannel*> _node_channels;\n     // from tablet_id to backend channel\n     std::unordered_map<int64_t, std::vector<NodeChannel*>> _channels_by_tablet;\n-};\n-\n-// The counter of add_batch rpc of a single node\n-struct AddBatchCounter {\n-    // total execution time of a add_batch rpc\n-    int64_t add_batch_execution_time_ns = 0;\n-    // lock waiting time in a add_batch rpc\n-    int64_t add_batch_wait_lock_time_ns = 0;\n-    // number of add_batch call\n-    int64_t add_batch_num = 0;\n+    // BeId\n+    std::set<int64_t> _failed_channels;\n };\n \n // write data to Olap Table.\n // this class distributed data according to\n class OlapTableSink : public DataSink {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 281}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MDg2MTQ2OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjowNTo0NFrOF5F7sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDoyODoyMFrOF5OY-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDM1NQ==", "bodyText": "I think should add ref count for this closure. Because this closure is created by channel, and the RPC call has this pointer. However it is not sure when the RPC will call this->Run(). If this channel is destructed before the RPC's callback, it will make invalid memory access. Otherwise it should wait until the RPC finish, which is unnecessary.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395410355", "createdAt": "2020-03-20T02:05:44Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -47,18 +48,101 @@ class ExprContext;\n class TExpr;\n \n namespace stream_load {\n- \n+\n class OlapTableSink;\n \n+// The counter of add_batch rpc of a single node\n+struct AddBatchCounter {\n+    // total execution time of a add_batch rpc\n+    int64_t add_batch_execution_time_us = 0;\n+    // lock waiting time in a add_batch rpc\n+    int64_t add_batch_wait_lock_time_us = 0;\n+    // number of add_batch call\n+    int64_t add_batch_num = 0;\n+    AddBatchCounter& operator+=(const AddBatchCounter& rhs) {\n+        add_batch_execution_time_us += rhs.add_batch_execution_time_us;\n+        add_batch_wait_lock_time_us += rhs.add_batch_wait_lock_time_us;\n+        add_batch_num += rhs.add_batch_num;\n+        return *this;\n+    }\n+    friend AddBatchCounter operator+(const AddBatchCounter& lhs, const AddBatchCounter& rhs) {\n+        AddBatchCounter sum = lhs;\n+        sum += rhs;\n+        return sum;\n+    }\n+};\n+\n+template <typename T>\n+class ReusableClosure : public google::protobuf::Closure {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ5MjAwNw==", "bodyText": "Actually, I want the NodeChannel to be the owner of add_batch_closure.\nhttps://github.com/apache/incubator-doris/pull/3143/files#diff-4007834d7219c2282c8ae5c454f01dbaR47-R51\nIn NodeChannel's dtor _add_batch_closure->release();, release() will do brpc::Join(). So RPC won't call Run() after channel is destructed.\nIf OlapTableSink is closed normally, _add_batch_closure->release(); has no effect.\nBut as you mentioned about unnecessary waiting RPC finished , if OlapTableSink is closed with error, _add_batch_closure->release(); in NodeChannel dtor may take some time to wait add_batch repsonse, although the add_batch response is useless under the circumstance that we cancelled the whole sink.\nI've considered about brpc::StartCancel(call_id), but I'm not good enough at understanding brpc, so I wrote a comment here. And just let the channel wait for the useless RPC response.\nMaybe we should do brpc::StartCancel(call_id)?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395492007", "createdAt": "2020-03-20T08:27:39Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -47,18 +48,101 @@ class ExprContext;\n class TExpr;\n \n namespace stream_load {\n- \n+\n class OlapTableSink;\n \n+// The counter of add_batch rpc of a single node\n+struct AddBatchCounter {\n+    // total execution time of a add_batch rpc\n+    int64_t add_batch_execution_time_us = 0;\n+    // lock waiting time in a add_batch rpc\n+    int64_t add_batch_wait_lock_time_us = 0;\n+    // number of add_batch call\n+    int64_t add_batch_num = 0;\n+    AddBatchCounter& operator+=(const AddBatchCounter& rhs) {\n+        add_batch_execution_time_us += rhs.add_batch_execution_time_us;\n+        add_batch_wait_lock_time_us += rhs.add_batch_wait_lock_time_us;\n+        add_batch_num += rhs.add_batch_num;\n+        return *this;\n+    }\n+    friend AddBatchCounter operator+(const AddBatchCounter& lhs, const AddBatchCounter& rhs) {\n+        AddBatchCounter sum = lhs;\n+        sum += rhs;\n+        return sum;\n+    }\n+};\n+\n+template <typename T>\n+class ReusableClosure : public google::protobuf::Closure {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDM1NQ=="}, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTUyNDAwNw==", "bodyText": "Yes, you are right.\nIt is OK to call release before delete it. But it should be commented carefully.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395524007", "createdAt": "2020-03-20T09:36:59Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -47,18 +48,101 @@ class ExprContext;\n class TExpr;\n \n namespace stream_load {\n- \n+\n class OlapTableSink;\n \n+// The counter of add_batch rpc of a single node\n+struct AddBatchCounter {\n+    // total execution time of a add_batch rpc\n+    int64_t add_batch_execution_time_us = 0;\n+    // lock waiting time in a add_batch rpc\n+    int64_t add_batch_wait_lock_time_us = 0;\n+    // number of add_batch call\n+    int64_t add_batch_num = 0;\n+    AddBatchCounter& operator+=(const AddBatchCounter& rhs) {\n+        add_batch_execution_time_us += rhs.add_batch_execution_time_us;\n+        add_batch_wait_lock_time_us += rhs.add_batch_wait_lock_time_us;\n+        add_batch_num += rhs.add_batch_num;\n+        return *this;\n+    }\n+    friend AddBatchCounter operator+(const AddBatchCounter& lhs, const AddBatchCounter& rhs) {\n+        AddBatchCounter sum = lhs;\n+        sum += rhs;\n+        return sum;\n+    }\n+};\n+\n+template <typename T>\n+class ReusableClosure : public google::protobuf::Closure {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDM1NQ=="}, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0ODkyMA==", "bodyText": "I think the func name release() is a little hard to understand, let me think about it, and I'll add more comments on the usage of ReusableClosure.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395548920", "createdAt": "2020-03-20T10:28:20Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -47,18 +48,101 @@ class ExprContext;\n class TExpr;\n \n namespace stream_load {\n- \n+\n class OlapTableSink;\n \n+// The counter of add_batch rpc of a single node\n+struct AddBatchCounter {\n+    // total execution time of a add_batch rpc\n+    int64_t add_batch_execution_time_us = 0;\n+    // lock waiting time in a add_batch rpc\n+    int64_t add_batch_wait_lock_time_us = 0;\n+    // number of add_batch call\n+    int64_t add_batch_num = 0;\n+    AddBatchCounter& operator+=(const AddBatchCounter& rhs) {\n+        add_batch_execution_time_us += rhs.add_batch_execution_time_us;\n+        add_batch_wait_lock_time_us += rhs.add_batch_wait_lock_time_us;\n+        add_batch_num += rhs.add_batch_num;\n+        return *this;\n+    }\n+    friend AddBatchCounter operator+(const AddBatchCounter& lhs, const AddBatchCounter& rhs) {\n+        AddBatchCounter sum = lhs;\n+        sum += rhs;\n+        return sum;\n+    }\n+};\n+\n+template <typename T>\n+class ReusableClosure : public google::protobuf::Closure {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDM1NQ=="}, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MDg3MjE1OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjoxNTozM1rOF5GCIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwNzowNTozNlrOF5JOzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMjAwMQ==", "bodyText": "I think it is better to declare all your capture other than a &. And what's more, referencing a local variable will lead to invalid memory access, because when the lambda is called, the reference is not valid.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395412001", "createdAt": "2020-03-20T02:15:33Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +127,127 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([&]() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ1NjE5OA==", "bodyText": "The two handlers both need to capture _rpc_error(the member variable), I'm afraid I can only change [&] to [this].\nThere's an alternate way to explicit capture, although I don't like this style. How about this?\nauto& rpc_error_ref=_rpc_error;\n_add_batch_closure->addFailedHandler([&rpc_error_ref](){})", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395456198", "createdAt": "2020-03-20T06:30:30Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +127,127 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([&]() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMjAwMQ=="}, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2NDM5Ng==", "bodyText": "I think [this] is OK", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395464396", "createdAt": "2020-03-20T07:05:36Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +127,127 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([&]() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMjAwMQ=="}, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MDg4MTMxOnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjoyMzoyOFrOF5GHjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjoyMzoyOFrOF5GHjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMzM5MQ==", "bodyText": "I think most of the scenarios are still normal. better to construct strings when it is abnormal", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395413391", "createdAt": "2020-03-20T02:23:28Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +257,89 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {\n+    auto st = none_of({_rpc_error, _is_cancelled, _send_finished});\n+    if (!st.ok()) {\n+        return 0;\n     }\n \n-    SCOPED_RAW_TIMER(_parent->mutable_wait_in_flight_packet_ns());\n-    _add_batch_closure->join();\n-    _has_in_flight_packet = false;\n-    if (_add_batch_closure->cntl.Failed()) {\n-        LOG(WARNING) << \"failed to send batch, error=\"\n-            << berror(_add_batch_closure->cntl.ErrorCode())\n-            << \", error_text=\" << _add_batch_closure->cntl.ErrorText();\n-        return Status::InternalError(\"failed to send batch\");\n-    }\n+    if (!_add_batch_closure->is_packet_in_flight() && _pending_batches_num > 0) {\n+        SCOPED_RAW_TIMER(&_actual_consume_ns);\n+        AddBatchReq send_batch;\n+        {\n+            std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+            DCHECK(!_pending_batches.empty());\n+            send_batch = std::move(_pending_batches.front());\n+            _pending_batches.pop();\n+            _pending_batches_num--;\n+        }\n \n-    if (_add_batch_closure->result.has_execution_time_us()) {\n-        _parent->update_node_add_batch_counter(_node_id,\n-                _add_batch_closure->result.execution_time_us(),\n-                _add_batch_closure->result.wait_lock_time_us());\n-    }\n-    return {_add_batch_closure->result.status()};\n-}\n+        auto row_batch = std::move(send_batch.first);\n+        auto request = std::move(send_batch.second); // doesn't need to be saved in heap\n \n-Status NodeChannel::_send_cur_batch(bool eos) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n+        // tablet_ids has already set when add row\n+        request.set_packet_seq(_next_packet_seq);\n+        if (row_batch->num_rows() > 0) {\n+            SCOPED_RAW_TIMER(&_serialize_batch_ns);\n+            row_batch->serialize(request.mutable_row_batch());\n+        }\n \n-    // tablet_ids has already set when add row\n-    _add_batch_request.set_eos(eos);\n-    _add_batch_request.set_packet_seq(_next_packet_seq);\n-    if (_batch->num_rows() > 0) {\n-        SCOPED_RAW_TIMER(_parent->mutable_serialize_batch_ns());\n-        _batch->serialize(_add_batch_request.mutable_row_batch());\n-    }\n+        _add_batch_closure->reset();\n+        _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n \n-    _add_batch_closure->ref();\n-    _add_batch_closure->cntl.Reset();\n-    _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n+        if (request.eos()) {\n+            for (auto pid : _parent->_partition_ids) {\n+                request.add_partition_ids(pid);\n+            }\n \n-    if (eos) {\n-        for (auto pid : _parent->_partition_ids) {\n-            _add_batch_request.add_partition_ids(pid);\n+            // eos request must be the last request\n+            _add_batch_closure->end_mark();\n+            _send_finished = true;\n+            DCHECK(_pending_batches_num == 0);\n+            LOG(INFO) << name() << \" send finished, should wait the last repsonse\";\n         }\n-    }\n \n-    _stub->tablet_writer_add_batch(&_add_batch_closure->cntl,\n-                                   &_add_batch_request,\n-                                   &_add_batch_closure->result,\n-                                   _add_batch_closure);\n-    _add_batch_request.clear_tablet_ids();\n-    _add_batch_request.clear_row_batch();\n-    _add_batch_request.clear_partition_ids();\n+        _add_batch_closure->set_in_flight();\n+        _stub->tablet_writer_add_batch(&_add_batch_closure->cntl, &request,\n+                                       &_add_batch_closure->result, _add_batch_closure);\n \n-    _has_in_flight_packet = true;\n-    _next_packet_seq++;\n+        _next_packet_seq++;\n+    }\n \n-    _batch->reset();\n-    return Status::OK();\n+    return _send_finished ? 0 : 1;\n }\n \n-IndexChannel::~IndexChannel() {\n+Status NodeChannel::none_of(std::initializer_list<bool> vars) {\n+    bool none = true;\n+    std::string vars_str;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 378}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1NDIxOTE3OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjowNTo0MlrOF5m86w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjowNTo0MlrOF5m86w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTMzOQ==", "bodyText": "Is this log needed?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395951339", "createdAt": "2020-03-21T02:05:42Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1NDIyMjU2OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjoxMjowMlrOF5m-vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwODoxNDozM1rOGDORgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTgwNg==", "bodyText": "If there is no other workload, will this cause a busy-loop?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395951806", "createdAt": "2020-03-21T02:12:02Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -877,5 +920,24 @@ int OlapTableSink::_validate_data(RuntimeState* state, RowBatch* batch, Bitmap*\n     return filtered_rows;\n }\n \n+void OlapTableSink::_send_batch_process() {\n+    SCOPED_RAW_TIMER(&_non_blocking_send_ns);\n+    while (true) {\n+        int running_channels_num = 0;\n+        for (auto index_channel : _channels) {\n+            index_channel->for_each_node_channel([&](NodeChannel* ch) {\n+                running_channels_num += ch->try_send_and_fetch_status();\n+            });\n+        }\n+\n+        if (running_channels_num == 0) {\n+            LOG(INFO) << \"all node channels are stopped(maybe finished/offending/cancelled), \"\n+                         \"consumer thread exit.\";\n+            return;\n+        }\n+        std::this_thread::yield();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 806}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1OTU2NQ==", "bodyText": "Yes, it's the easiest to implement, but not good enough. I've consider about writing an algorithm that can choose the property sleep interval, e.g. if every channel is empty, we can sleep for a while. bla bla bla\nBut taking the trouble to do this may lead to small gains.\nOr we should just sleep_for? Long sleep interval saves CPU, but waste time.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395959565", "createdAt": "2020-03-21T04:13:14Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -877,5 +920,24 @@ int OlapTableSink::_validate_data(RuntimeState* state, RowBatch* batch, Bitmap*\n     return filtered_rows;\n }\n \n+void OlapTableSink::_send_batch_process() {\n+    SCOPED_RAW_TIMER(&_non_blocking_send_ns);\n+    while (true) {\n+        int running_channels_num = 0;\n+        for (auto index_channel : _channels) {\n+            index_channel->for_each_node_channel([&](NodeChannel* ch) {\n+                running_channels_num += ch->try_send_and_fetch_status();\n+            });\n+        }\n+\n+        if (running_channels_num == 0) {\n+            LOG(INFO) << \"all node channels are stopped(maybe finished/offending/cancelled), \"\n+                         \"consumer thread exit.\";\n+            return;\n+        }\n+        std::this_thread::yield();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTgwNg=="}, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 806}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAzMjc3MQ==", "bodyText": "change it to sleep(interval_time)", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r406032771", "createdAt": "2020-04-09T08:14:33Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -877,5 +920,24 @@ int OlapTableSink::_validate_data(RuntimeState* state, RowBatch* batch, Bitmap*\n     return filtered_rows;\n }\n \n+void OlapTableSink::_send_batch_process() {\n+    SCOPED_RAW_TIMER(&_non_blocking_send_ns);\n+    while (true) {\n+        int running_channels_num = 0;\n+        for (auto index_channel : _channels) {\n+            index_channel->for_each_node_channel([&](NodeChannel* ch) {\n+                running_channels_num += ch->try_send_and_fetch_status();\n+            });\n+        }\n+\n+        if (running_channels_num == 0) {\n+            LOG(INFO) << \"all node channels are stopped(maybe finished/offending/cancelled), \"\n+                         \"consumer thread exit.\";\n+            return;\n+        }\n+        std::this_thread::yield();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTgwNg=="}, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 806}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1NDIzMzM2OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjozMTo1NFrOF5nEeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjozMTo1NFrOF5nEeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MzI3Mg==", "bodyText": "should remove this trace log", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395953272", "createdAt": "2020-03-21T02:31:54Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +260,90 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {\n+    auto st = none_of({_rpc_error, _is_cancelled, _send_finished});\n+    if (!st.ok()) {\n+        return 0;\n     }\n \n-    SCOPED_RAW_TIMER(_parent->mutable_wait_in_flight_packet_ns());\n-    _add_batch_closure->join();\n-    _has_in_flight_packet = false;\n-    if (_add_batch_closure->cntl.Failed()) {\n-        LOG(WARNING) << \"failed to send batch, error=\"\n-            << berror(_add_batch_closure->cntl.ErrorCode())\n-            << \", error_text=\" << _add_batch_closure->cntl.ErrorText();\n-        return Status::InternalError(\"failed to send batch\");\n-    }\n+    if (!_add_batch_closure->is_packet_in_flight() && _pending_batches_num > 0) {\n+        SCOPED_RAW_TIMER(&_actual_consume_ns);\n+        AddBatchReq send_batch;\n+        {\n+            std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+            DCHECK(!_pending_batches.empty());\n+            send_batch = std::move(_pending_batches.front());\n+            _pending_batches.pop();\n+            _pending_batches_num--;\n+        }\n \n-    if (_add_batch_closure->result.has_execution_time_us()) {\n-        _parent->update_node_add_batch_counter(_node_id,\n-                _add_batch_closure->result.execution_time_us(),\n-                _add_batch_closure->result.wait_lock_time_us());\n-    }\n-    return {_add_batch_closure->result.status()};\n-}\n+        auto row_batch = std::move(send_batch.first);\n+        auto request = std::move(send_batch.second); // doesn't need to be saved in heap\n \n-Status NodeChannel::_send_cur_batch(bool eos) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n+        // tablet_ids has already set when add row\n+        request.set_packet_seq(_next_packet_seq);\n+        if (row_batch->num_rows() > 0) {\n+            SCOPED_RAW_TIMER(&_serialize_batch_ns);\n+            row_batch->serialize(request.mutable_row_batch());\n+        }\n \n-    // tablet_ids has already set when add row\n-    _add_batch_request.set_eos(eos);\n-    _add_batch_request.set_packet_seq(_next_packet_seq);\n-    if (_batch->num_rows() > 0) {\n-        SCOPED_RAW_TIMER(_parent->mutable_serialize_batch_ns());\n-        _batch->serialize(_add_batch_request.mutable_row_batch());\n-    }\n+        _add_batch_closure->reset();\n+        _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n \n-    _add_batch_closure->ref();\n-    _add_batch_closure->cntl.Reset();\n-    _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n+        if (request.eos()) {\n+            for (auto pid : _parent->_partition_ids) {\n+                request.add_partition_ids(pid);\n+            }\n \n-    if (eos) {\n-        for (auto pid : _parent->_partition_ids) {\n-            _add_batch_request.add_partition_ids(pid);\n+            // eos request must be the last request\n+            _add_batch_closure->end_mark();\n+            _send_finished = true;\n+            DCHECK(_pending_batches_num == 0);\n+            LOG(INFO) << name() << \" send finished, should wait the last repsonse\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 353}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1NDIzNzE2OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjozNzo1OFrOF5nGVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjozNzo1OFrOF5nGVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1Mzc1MQ==", "bodyText": "change  to explicit capture", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395953751", "createdAt": "2020-03-21T02:37:58Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -611,57 +633,79 @@ Status OlapTableSink::close(RuntimeState* state, Status close_status) {\n         // only if status is ok can we call this _profile->total_time_counter().\n         // if status is not ok, this sink may not be prepared, so that _profile is null\n         SCOPED_TIMER(_profile->total_time_counter());\n+        int64_t serialize_batch_ns = 0, queue_push_lock_ns = 0, actual_consume_ns = 0;\n         {\n             SCOPED_TIMER(_close_timer);\n-            for (auto channel : _channels) {\n-                status = channel->close(state);\n-                if (!status.ok()) {\n-                    LOG(WARNING) << \"close channel failed, load_id=\" << print_id(_load_id)\n-                        << \", txn_id=\" << _txn_id;\n-                }\n+            for (auto index_channel : _channels) {\n+                index_channel->for_each_node_channel(\n+                        [&](NodeChannel* ch) { WARN_IF_ERROR(ch->mark_close(), \"\"); });\n+            }\n+\n+            for (auto index_channel : _channels) {\n+                index_channel->for_each_node_channel([&](NodeChannel* ch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 638}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1NDI0MDc0OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjo0NToyOVrOF5nIPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwNTozNDo0MFrOF5nuPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NDIzOQ==", "bodyText": "we should limit the length of pending_batches.\nWhen sender is blocked, this queue will consume memory without limit", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395954239", "createdAt": "2020-03-21T02:45:29Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";\n+                    }\n+                } else {\n+                    _rpc_error = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status not ok, load_id=\"\n+                                 << _parent->_load_id << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_rpc_error, _is_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. rpc_error/cancelled/eos: \");\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NjMyMQ==", "bodyText": "As I commented here https://github.com/apache/incubator-doris/pull/3143/files#diff-4007834d7219c2282c8ae5c454f01dbaR67 , the scan node can do the memory limit. I should add more comments.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395956321", "createdAt": "2020-03-21T03:17:49Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";\n+                    }\n+                } else {\n+                    _rpc_error = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status not ok, load_id=\"\n+                                 << _parent->_load_id << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_rpc_error, _is_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. rpc_error/cancelled/eos: \");\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NDIzOQ=="}, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2Mzk2NQ==", "bodyText": "_plan node in PlanFragmentExec may not limit the mem, so I add mem limit check in NodeChannel::add_row, it'll block the main thread if mem limit exceeded.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395963965", "createdAt": "2020-03-21T05:34:40Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";\n+                    }\n+                } else {\n+                    _rpc_error = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status not ok, load_id=\"\n+                                 << _parent->_load_id << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_rpc_error, _is_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. rpc_error/cancelled/eos: \");\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NDIzOQ=="}, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3MTE3Mjg2OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDoyNDowOFrOF8JY0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwNTowMzowOFrOF8jS7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYxMjY5MQ==", "bodyText": "Why not using bool as return value?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r398612691", "createdAt": "2020-03-26T14:24:08Z", "author": {"login": "morningman"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +267,89 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f076de20a808a3899a10601dea8d7ea87c3160"}, "originalPosition": 292}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAzNzE2NA==", "bodyText": "I want the consumer to have global observation,  sum() is the simplest way to do it.\nAnd maybe we can add more status(>0) to let consumer know more infos about channels.\nBut I think the preliminary design should be simple.\nSo current design of status value is \"0-channel stopped; 1-still working\".", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r399037164", "createdAt": "2020-03-27T05:03:08Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +267,89 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYxMjY5MQ=="}, "originalCommit": {"oid": "37f076de20a808a3899a10601dea8d7ea87c3160"}, "originalPosition": 292}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MTgwMjI1OnYy", "diffSide": "RIGHT", "path": "be/src/common/config.h", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjozNzozOFrOGNR3yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjozNzozOFrOGNR3yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjU3NzQ4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                CONF_Int32(olap_table_sink_send_interval_ms, \"10\");\n          \n          \n            \n                CONF_mInt32(olap_table_sink_send_interval_ms, \"10\");", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r416577481", "createdAt": "2020-04-28T12:37:38Z", "author": {"login": "imay"}, "path": "be/src/common/config.h", "diffHunk": "@@ -296,6 +296,8 @@ namespace config {\n     // you may need to increase this timeout if using larger 'streaming_load_max_mb',\n     // or encounter 'tablet writer write failed' error when loading.\n     // CONF_Int32(tablet_writer_rpc_timeout_sec, \"600\");\n+    // OlapTableSink sender's send interval, should be less than the real response time of a tablet writer rpc.\n+    CONF_Int32(olap_table_sink_send_interval_ms, \"10\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30288c47f8fbb2418b34daf92fa8264640912a45"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MTg1NzUwOnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjo1MDo1N1rOGNSZFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjo1MDo1N1rOGNSZFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjU4NjAwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void for_each_node_channel(std::function<void(NodeChannel*)> func) {\n          \n          \n            \n                void for_each_node_channel(const std::function<void(NodeChannel*)>& func) {", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r416586004", "createdAt": "2020-04-28T12:50:57Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";\n+    }\n \n-private:\n-    Status _send_cur_batch(bool eos = false);\n-    // wait inflight packet finish, return error if inflight packet return failed\n-    Status _wait_in_flight_packet();\n-\n-    Status _close(RuntimeState* state);\n+    Status none_of(std::initializer_list<bool> vars);\n \n private:\n     OlapTableSink* _parent = nullptr;\n     int64_t _index_id = -1;\n     int64_t _node_id = -1;\n     int32_t _schema_hash = 0;\n+    std::string _load_info;\n \n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    // user cancel or get some errors\n+    std::atomic<bool> _cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};\n+\n+    bool _eos_is_produced{false}; // only for restricting producer behaviors\n+\n+    std::unique_ptr<RowDescriptor> _row_desc;\n+    int _batch_size = 0;\n+    std::unique_ptr<RowBatch> _cur_batch;\n+    PTabletWriterAddBatchRequest _cur_add_batch_request;\n+\n+    std::mutex _pending_batches_lock;\n+    using AddBatchReq = std::pair<std::unique_ptr<RowBatch>, PTabletWriterAddBatchRequest>;\n+    std::queue<AddBatchReq> _pending_batches;\n+    std::atomic<int> _pending_batches_num{0};\n+\n     palo::PInternalService_Stub* _stub = nullptr;\n     RefCountClosure<PTabletWriterOpenResult>* _open_closure = nullptr;\n-    RefCountClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n+    ReusableClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n \n     std::vector<TTabletWithPartition> _all_tablets;\n-    PTabletWriterAddBatchRequest _add_batch_request;\n+    std::vector<TTabletCommitInfo> _tablet_commit_infos;\n+\n+    AddBatchCounter _add_batch_counter;\n+    int64_t _serialize_batch_ns = 0;\n+\n+    int64_t _mem_exceeded_block_ns = 0;\n+    int64_t _queue_push_lock_ns = 0;\n+    int64_t _actual_consume_ns = 0;\n };\n \n class IndexChannel {\n public:\n     IndexChannel(OlapTableSink* parent, int64_t index_id, int32_t schema_hash)\n-            : _parent(parent), _index_id(index_id),\n-            _schema_hash(schema_hash) {\n-    }\n+            : _parent(parent), _index_id(index_id), _schema_hash(schema_hash) {}\n     ~IndexChannel();\n \n-    Status init(RuntimeState* state,\n-                const std::vector<TTabletWithPartition>& tablets);\n-    Status open();\n-    Status add_row(Tuple* tuple, int64_t tablet_id);\n+    Status init(RuntimeState* state, const std::vector<TTabletWithPartition>& tablets);\n \n-    Status close(RuntimeState* state);\n+    Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    void cancel();\n+    void for_each_node_channel(std::function<void(NodeChannel*)> func) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30288c47f8fbb2418b34daf92fa8264640912a45"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NzAwMjE1OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTowMjoxMFrOGODPlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTowMjoxMFrOGODPlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM4NjM4OA==", "bodyText": "If param will be modified, prefer pointer rather than reference.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417386388", "createdAt": "2020-04-29T15:02:10Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NzAwODc5OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTowMzo0N1rOGODT6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNDoyNTowN1rOGOZK_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM4NzQ5OQ==", "bodyText": "Prefer strings::Substitute in gutils/strings/Substitute.h.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417387499", "createdAt": "2020-04-29T15:03:47Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() const { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc0NTY2MA==", "bodyText": "including gutils/strings/Substitute.h will occur redefinition error\nIn file included from /root/incubator-doris/be/src/gutil/strings/stringpiece.h:128:0,\n                 from /root/incubator-doris/be/src/gutil/strings/substitute.h:9,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.cpp:28:\n/root/incubator-doris/be/src/gutil/hash/hash.h:251:26: error: redefinition of 'struct __gnu_cxx::hash<Type*>'\n template<class T> struct hash<T*> {\n                          ^~~~~~~~\nIn file included from /root/incubator-doris/thirdparty/installed/include/butil/containers/flat_map.h:101:0,\n                 from /root/incubator-doris/be/src/service/brpc.h:48,\n                 from /root/incubator-doris/be/src/util/ref_count_closure.h:24,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.h:36,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.cpp:18:\n/root/incubator-doris/thirdparty/installed/include/butil/containers/hash_tables.h:262:8: note: previous definition of 'struct __gnu_cxx::hash<Type*>'\n struct hash<Type*> {\n        ^~~~~~~~~~~\nIn file included from /root/incubator-doris/be/src/gutil/strings/stringpiece.h:128:0,\n                 from /root/incubator-doris/be/src/gutil/strings/substitute.h:9,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.cpp:28:\n/root/incubator-doris/be/src/gutil/hash/hash.h:309:8: error: redefinition of 'struct __gnu_cxx::hash<std::pair<_T1, _T2> >'\n struct hash<pair<First, Second> > {\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~\nIn file included from /root/incubator-doris/thirdparty/installed/include/butil/containers/flat_map.h:101:0,\n                 from /root/incubator-doris/be/src/service/brpc.h:48,\n                 from /root/incubator-doris/be/src/util/ref_count_closure.h:24,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.h:36,\n                 from /root/incubator-doris/be/src/exec/tablet_sink.cpp:18:\n/root/incubator-doris/thirdparty/installed/include/butil/containers/hash_tables.h:256:8: note: previous definition of 'struct __gnu_cxx::hash<std::pair<_T1, _T2> >'\n struct hash<std::pair<Type1, Type2> > {\n\nI will initialize the name_string in init(), to avoid string building in name()", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417745660", "createdAt": "2020-04-30T04:25:07Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() const { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM4NzQ5OQ=="}, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NzA4MjE4OnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.cpp", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNToxOTozOFrOGOECFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNTozNjoyN1rOGOaRQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM5OTMxNw==", "bodyText": "Do we need these log?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417399317", "createdAt": "2020-04-29T15:19:38Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,54 +131,136 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _cancelled = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, \" << print_load_info()\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                    }\n+                } else {\n+                    _cancelled = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status isn't ok, \"\n+                                 << print_load_info() << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. cancelled/eos: \");\n+    }\n+\n+    // We use OlapTableSink mem_tracker which has the same ancestor of _plan node,\n+    // so in the ideal case, mem limit is a matter for _plan node.\n+    // But there is still some unfinished things, we do mem limit here temporarily.\n+    while (_parent->_mem_tracker->any_limit_exceeded()) {\n+        SCOPED_RAW_TIMER(&_mem_exceeded_block_ns);\n+        SleepFor(MonoDelta::FromMilliseconds(10));\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+            _pending_batches_num++;\n+        }\n+\n+        _cur_batch.reset(new RowBatch(*_row_desc, _batch_size, _parent->_mem_tracker));\n+        _cur_add_batch_request.clear_tablet_ids();\n+\n+        row_no = _cur_batch->add_row();\n     }\n     DCHECK_NE(row_no, RowBatch::INVALID_ROW_INDEX);\n-    auto tuple = input_tuple->deep_copy(*_tuple_desc, _batch->tuple_data_pool());\n-    _batch->get_row(row_no)->set_tuple(0, tuple);\n-    _batch->commit_last_row();\n-    _add_batch_request.add_tablet_ids(tablet_id);\n+    auto tuple = input_tuple->deep_copy(*_tuple_desc, _cur_batch->tuple_data_pool());\n+    _cur_batch->get_row(row_no)->set_tuple(0, tuple);\n+    _cur_batch->commit_last_row();\n+    _cur_add_batch_request.add_tablet_ids(tablet_id);\n     return Status::OK();\n }\n \n-Status NodeChannel::close(RuntimeState* state) {\n-    auto st = _close(state);\n-    _batch.reset();\n-    return st;\n-}\n+Status NodeChannel::mark_close() {\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't mark as closed. cancelled/eos: \");\n+    }\n \n-Status NodeChannel::_close(RuntimeState* state) {\n-    return _send_cur_batch(true);\n+    _cur_add_batch_request.set_eos(true);\n+    {\n+        std::lock_guard<std::mutex> l(_pending_batches_lock);\n+        _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+        _pending_batches_num++;\n+        DCHECK(_pending_batches.back().second.eos());\n+    }\n+\n+    _eos_is_produced = true;\n+\n+    _cur_batch.reset();\n+    return Status::OK();\n }\n \n Status NodeChannel::close_wait(RuntimeState* state) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n-    Status status(_add_batch_closure->result.status());\n-    if (status.ok()) {\n-        for (auto& tablet : _add_batch_closure->result.tablet_vec()) {\n-            TTabletCommitInfo commit_info;\n-            commit_info.tabletId = tablet.tablet_id();\n-            commit_info.backendId = _node_id;\n-            state->tablet_commit_infos().emplace_back(std::move(commit_info));\n-        }\n+    auto st = none_of({_cancelled, !_eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, skip waiting for close. cancelled/!eos: \");\n     }\n-    // clear batch after sendt\n-    _batch.reset();\n-    return status;\n+\n+    // waiting for finished, it may take a long time, so we could't set a timeout\n+    // use log to make it easier\n+    LOG(INFO) << name() << \"start close_wait\";\n+    while (!_add_batches_finished && !_cancelled) {\n+        SleepFor(MonoDelta::FromMilliseconds(1));\n+    }\n+    LOG(INFO) << name() << \"close_wait done\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcyODkzNg==", "bodyText": "We just count the total time of channel's close(). There may be some slow BE hide inside. I think this logs are good for analyzing the state at that time. It's convenient for developers.\nHow about set it to vlog?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417728936", "createdAt": "2020-04-30T03:08:50Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,54 +131,136 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _cancelled = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, \" << print_load_info()\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                    }\n+                } else {\n+                    _cancelled = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status isn't ok, \"\n+                                 << print_load_info() << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. cancelled/eos: \");\n+    }\n+\n+    // We use OlapTableSink mem_tracker which has the same ancestor of _plan node,\n+    // so in the ideal case, mem limit is a matter for _plan node.\n+    // But there is still some unfinished things, we do mem limit here temporarily.\n+    while (_parent->_mem_tracker->any_limit_exceeded()) {\n+        SCOPED_RAW_TIMER(&_mem_exceeded_block_ns);\n+        SleepFor(MonoDelta::FromMilliseconds(10));\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+            _pending_batches_num++;\n+        }\n+\n+        _cur_batch.reset(new RowBatch(*_row_desc, _batch_size, _parent->_mem_tracker));\n+        _cur_add_batch_request.clear_tablet_ids();\n+\n+        row_no = _cur_batch->add_row();\n     }\n     DCHECK_NE(row_no, RowBatch::INVALID_ROW_INDEX);\n-    auto tuple = input_tuple->deep_copy(*_tuple_desc, _batch->tuple_data_pool());\n-    _batch->get_row(row_no)->set_tuple(0, tuple);\n-    _batch->commit_last_row();\n-    _add_batch_request.add_tablet_ids(tablet_id);\n+    auto tuple = input_tuple->deep_copy(*_tuple_desc, _cur_batch->tuple_data_pool());\n+    _cur_batch->get_row(row_no)->set_tuple(0, tuple);\n+    _cur_batch->commit_last_row();\n+    _cur_add_batch_request.add_tablet_ids(tablet_id);\n     return Status::OK();\n }\n \n-Status NodeChannel::close(RuntimeState* state) {\n-    auto st = _close(state);\n-    _batch.reset();\n-    return st;\n-}\n+Status NodeChannel::mark_close() {\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't mark as closed. cancelled/eos: \");\n+    }\n \n-Status NodeChannel::_close(RuntimeState* state) {\n-    return _send_cur_batch(true);\n+    _cur_add_batch_request.set_eos(true);\n+    {\n+        std::lock_guard<std::mutex> l(_pending_batches_lock);\n+        _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+        _pending_batches_num++;\n+        DCHECK(_pending_batches.back().second.eos());\n+    }\n+\n+    _eos_is_produced = true;\n+\n+    _cur_batch.reset();\n+    return Status::OK();\n }\n \n Status NodeChannel::close_wait(RuntimeState* state) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n-    Status status(_add_batch_closure->result.status());\n-    if (status.ok()) {\n-        for (auto& tablet : _add_batch_closure->result.tablet_vec()) {\n-            TTabletCommitInfo commit_info;\n-            commit_info.tabletId = tablet.tablet_id();\n-            commit_info.backendId = _node_id;\n-            state->tablet_commit_infos().emplace_back(std::move(commit_info));\n-        }\n+    auto st = none_of({_cancelled, !_eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, skip waiting for close. cancelled/!eos: \");\n     }\n-    // clear batch after sendt\n-    _batch.reset();\n-    return status;\n+\n+    // waiting for finished, it may take a long time, so we could't set a timeout\n+    // use log to make it easier\n+    LOG(INFO) << name() << \"start close_wait\";\n+    while (!_add_batches_finished && !_cancelled) {\n+        SleepFor(MonoDelta::FromMilliseconds(1));\n+    }\n+    LOG(INFO) << name() << \"close_wait done\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM5OTMxNw=="}, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc0NDcwMA==", "bodyText": "If You want to, you can count the time with StopWatch and log the time in one log.\nI suggest to use vlog.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417744700", "createdAt": "2020-04-30T04:20:49Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,54 +131,136 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _cancelled = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, \" << print_load_info()\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                    }\n+                } else {\n+                    _cancelled = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status isn't ok, \"\n+                                 << print_load_info() << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. cancelled/eos: \");\n+    }\n+\n+    // We use OlapTableSink mem_tracker which has the same ancestor of _plan node,\n+    // so in the ideal case, mem limit is a matter for _plan node.\n+    // But there is still some unfinished things, we do mem limit here temporarily.\n+    while (_parent->_mem_tracker->any_limit_exceeded()) {\n+        SCOPED_RAW_TIMER(&_mem_exceeded_block_ns);\n+        SleepFor(MonoDelta::FromMilliseconds(10));\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+            _pending_batches_num++;\n+        }\n+\n+        _cur_batch.reset(new RowBatch(*_row_desc, _batch_size, _parent->_mem_tracker));\n+        _cur_add_batch_request.clear_tablet_ids();\n+\n+        row_no = _cur_batch->add_row();\n     }\n     DCHECK_NE(row_no, RowBatch::INVALID_ROW_INDEX);\n-    auto tuple = input_tuple->deep_copy(*_tuple_desc, _batch->tuple_data_pool());\n-    _batch->get_row(row_no)->set_tuple(0, tuple);\n-    _batch->commit_last_row();\n-    _add_batch_request.add_tablet_ids(tablet_id);\n+    auto tuple = input_tuple->deep_copy(*_tuple_desc, _cur_batch->tuple_data_pool());\n+    _cur_batch->get_row(row_no)->set_tuple(0, tuple);\n+    _cur_batch->commit_last_row();\n+    _cur_add_batch_request.add_tablet_ids(tablet_id);\n     return Status::OK();\n }\n \n-Status NodeChannel::close(RuntimeState* state) {\n-    auto st = _close(state);\n-    _batch.reset();\n-    return st;\n-}\n+Status NodeChannel::mark_close() {\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't mark as closed. cancelled/eos: \");\n+    }\n \n-Status NodeChannel::_close(RuntimeState* state) {\n-    return _send_cur_batch(true);\n+    _cur_add_batch_request.set_eos(true);\n+    {\n+        std::lock_guard<std::mutex> l(_pending_batches_lock);\n+        _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+        _pending_batches_num++;\n+        DCHECK(_pending_batches.back().second.eos());\n+    }\n+\n+    _eos_is_produced = true;\n+\n+    _cur_batch.reset();\n+    return Status::OK();\n }\n \n Status NodeChannel::close_wait(RuntimeState* state) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n-    Status status(_add_batch_closure->result.status());\n-    if (status.ok()) {\n-        for (auto& tablet : _add_batch_closure->result.tablet_vec()) {\n-            TTabletCommitInfo commit_info;\n-            commit_info.tabletId = tablet.tablet_id();\n-            commit_info.backendId = _node_id;\n-            state->tablet_commit_infos().emplace_back(std::move(commit_info));\n-        }\n+    auto st = none_of({_cancelled, !_eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, skip waiting for close. cancelled/!eos: \");\n     }\n-    // clear batch after sendt\n-    _batch.reset();\n-    return status;\n+\n+    // waiting for finished, it may take a long time, so we could't set a timeout\n+    // use log to make it easier\n+    LOG(INFO) << name() << \"start close_wait\";\n+    while (!_add_batches_finished && !_cancelled) {\n+        SleepFor(MonoDelta::FromMilliseconds(1));\n+    }\n+    LOG(INFO) << name() << \"close_wait done\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM5OTMxNw=="}, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc2MzY1MQ==", "bodyText": "Good advice, I'll fix it.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417763651", "createdAt": "2020-04-30T05:36:27Z", "author": {"login": "vagetablechicken"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,54 +131,136 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _cancelled = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, \" << print_load_info()\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                    }\n+                } else {\n+                    _cancelled = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status isn't ok, \"\n+                                 << print_load_info() << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. cancelled/eos: \");\n+    }\n+\n+    // We use OlapTableSink mem_tracker which has the same ancestor of _plan node,\n+    // so in the ideal case, mem limit is a matter for _plan node.\n+    // But there is still some unfinished things, we do mem limit here temporarily.\n+    while (_parent->_mem_tracker->any_limit_exceeded()) {\n+        SCOPED_RAW_TIMER(&_mem_exceeded_block_ns);\n+        SleepFor(MonoDelta::FromMilliseconds(10));\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+            _pending_batches_num++;\n+        }\n+\n+        _cur_batch.reset(new RowBatch(*_row_desc, _batch_size, _parent->_mem_tracker));\n+        _cur_add_batch_request.clear_tablet_ids();\n+\n+        row_no = _cur_batch->add_row();\n     }\n     DCHECK_NE(row_no, RowBatch::INVALID_ROW_INDEX);\n-    auto tuple = input_tuple->deep_copy(*_tuple_desc, _batch->tuple_data_pool());\n-    _batch->get_row(row_no)->set_tuple(0, tuple);\n-    _batch->commit_last_row();\n-    _add_batch_request.add_tablet_ids(tablet_id);\n+    auto tuple = input_tuple->deep_copy(*_tuple_desc, _cur_batch->tuple_data_pool());\n+    _cur_batch->get_row(row_no)->set_tuple(0, tuple);\n+    _cur_batch->commit_last_row();\n+    _cur_add_batch_request.add_tablet_ids(tablet_id);\n     return Status::OK();\n }\n \n-Status NodeChannel::close(RuntimeState* state) {\n-    auto st = _close(state);\n-    _batch.reset();\n-    return st;\n-}\n+Status NodeChannel::mark_close() {\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't mark as closed. cancelled/eos: \");\n+    }\n \n-Status NodeChannel::_close(RuntimeState* state) {\n-    return _send_cur_batch(true);\n+    _cur_add_batch_request.set_eos(true);\n+    {\n+        std::lock_guard<std::mutex> l(_pending_batches_lock);\n+        _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+        _pending_batches_num++;\n+        DCHECK(_pending_batches.back().second.eos());\n+    }\n+\n+    _eos_is_produced = true;\n+\n+    _cur_batch.reset();\n+    return Status::OK();\n }\n \n Status NodeChannel::close_wait(RuntimeState* state) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n-    Status status(_add_batch_closure->result.status());\n-    if (status.ok()) {\n-        for (auto& tablet : _add_batch_closure->result.tablet_vec()) {\n-            TTabletCommitInfo commit_info;\n-            commit_info.tabletId = tablet.tablet_id();\n-            commit_info.backendId = _node_id;\n-            state->tablet_commit_infos().emplace_back(std::move(commit_info));\n-        }\n+    auto st = none_of({_cancelled, !_eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, skip waiting for close. cancelled/!eos: \");\n     }\n-    // clear batch after sendt\n-    _batch.reset();\n-    return status;\n+\n+    // waiting for finished, it may take a long time, so we could't set a timeout\n+    // use log to make it easier\n+    LOG(INFO) << name() << \"start close_wait\";\n+    while (!_add_batches_finished && !_cancelled) {\n+        SleepFor(MonoDelta::FromMilliseconds(1));\n+    }\n+    LOG(INFO) << name() << \"close_wait done\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM5OTMxNw=="}, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 241}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NzE5ODMyOnYy", "diffSide": "RIGHT", "path": "be/src/exec/tablet_sink.h", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTo0NTowOVrOGOFNgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTo0NTowOVrOGOFNgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQxODYyNw==", "bodyText": "what's the difference between these two flags?\nShould comment to let us know", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417418627", "createdAt": "2020-04-29T15:45:09Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() const { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";\n+    }\n \n-private:\n-    Status _send_cur_batch(bool eos = false);\n-    // wait inflight packet finish, return error if inflight packet return failed\n-    Status _wait_in_flight_packet();\n-\n-    Status _close(RuntimeState* state);\n+    Status none_of(std::initializer_list<bool> vars);\n \n private:\n     OlapTableSink* _parent = nullptr;\n     int64_t _index_id = -1;\n     int64_t _node_id = -1;\n     int32_t _schema_hash = 0;\n+    std::string _load_info;\n \n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    // user cancel or get some errors\n+    std::atomic<bool> _cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 202}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1972, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}