{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3Mzc2MDA0", "number": 3584, "title": "[OUTFILE] Support `INTO OUTFILE` to export query result", "bodyText": "The proposal can be found here: #3549\nThis CL mainly changes:\n\nSupport SELECT INTO OUTFILE command.\nSupport export query result to a file via Broker.\nSupport CSV export format with specified column separator and line delimiter.\n\nThe following feature will be implemented in next PR:\n\nSupport Parquet export file.\n\nFor easy review, please first see the proposal #3549.\nThan see the user doc in administrator-guide/outfile.md", "createdAt": "2020-05-13T13:50:10Z", "url": "https://github.com/apache/incubator-doris/pull/3584", "merged": true, "mergeCommit": {"oid": "3ffc447b38e054ed1827d2ed9e451c87e6a3a4dd"}, "closed": true, "closedAt": "2020-05-25T13:24:56Z", "author": {"login": "morningman"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABciXa6PgFqTQxMzIzNzYzOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABckuLUSgFqTQxNzY0MDc4OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzMjM3NjM5", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-413237639", "createdAt": "2020-05-18T02:28:47Z", "commit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMjoyODo0N1rOGWl0hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzozMTowOFrOGWmg2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTUwOQ==", "bodyText": "why not ARROW_RETURN_NOT_OK(st)", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426341509", "createdAt": "2020-05-18T02:28:47Z", "author": {"login": "yangzhg"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTg3Nw==", "bodyText": "why not ARROW_RETURN_NOT_OK(st)", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426341877", "createdAt": "2020-05-18T02:30:39Z", "author": {"login": "yangzhg"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {\n+        return arrow::Status::IOError(st.get_error_msg());\n+    }\n+    _cur_pos += written_len;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Tell(int64_t* position) const {\n+    *position = _cur_pos;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Close() {\n+    Status st = _file_writer->close();\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0Nzk4MQ==", "bodyText": "_file_writer seems owned by  ParquetWriterWrapper  by not realeased in ParquetOutputStream or ParquetWriterWrapper how about create and own it in ParquetWriterWrapper, and use use unique_prt to handle  _file_writer, _parquet_writer in this class", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426347981", "createdAt": "2020-05-18T03:03:21Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0ODcyOQ==", "bodyText": "why not nullptr", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426348729", "createdAt": "2020-05-18T03:08:01Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0OTU5MA==", "bodyText": "????", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426349590", "createdAt": "2020-05-18T03:12:48Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {\n+        return Status::OK();\n+    }\n+\n+    SCOPED_TIMER(_append_row_batch_timer);\n+    if (_parquet_writer != nullptr) {\n+        RETURN_IF_ERROR(_parquet_writer->write(*batch));\n+    } else {\n+        RETURN_IF_ERROR(_write_csv_file(*batch));\n+    }\n+\n+    _written_rows += batch->num_rows();\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_write_csv_file(const RowBatch& batch) {\n+    int num_rows = batch.num_rows();\n+    for (int i = 0; i < num_rows; ++i) {\n+        TupleRow* row = batch.get_row(i);\n+        RETURN_IF_ERROR(_write_one_row_as_csv(row));\n+    }\n+    _flush_plain_text_outstream(true);\n+    return Status::OK();\n+}\n+\n+// actually, this logic is same as `ExportSink::gen_row_buffer`\n+// TODO(cmy): find a way to unify them.\n+Status FileResultWriter::_write_one_row_as_csv(TupleRow* row) {\n+    {\n+        SCOPED_TIMER(_convert_tuple_timer);\n+        int num_columns = _output_expr_ctxs.size();\n+        for (int i = 0; i < num_columns; ++i) {\n+            void* item = _output_expr_ctxs[i]->get_value(row);\n+\n+            if (item == nullptr) {\n+                _plain_text_outstream << NULL_IN_CSV;\n+                continue;\n+            }\n+\n+            switch (_output_expr_ctxs[i]->root()->type().type) {\n+                case TYPE_BOOLEAN:\n+                case TYPE_TINYINT:\n+                    _plain_text_outstream << (int)*static_cast<int8_t*>(item);\n+                    break;\n+                case TYPE_SMALLINT:\n+                    _plain_text_outstream << *static_cast<int16_t*>(item);\n+                    break;\n+                case TYPE_INT:\n+                    _plain_text_outstream << *static_cast<int32_t*>(item);\n+                    break;\n+                case TYPE_BIGINT:\n+                    _plain_text_outstream << *static_cast<int64_t*>(item);\n+                    break;\n+                case TYPE_LARGEINT:\n+                    _plain_text_outstream << reinterpret_cast<PackedInt128*>(item)->value;\n+                    break;\n+                case TYPE_FLOAT: {\n+                    char buffer[MAX_FLOAT_STR_LENGTH + 2];\n+                    float float_value = *static_cast<float*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = FloatToBuffer(float_value, MAX_FLOAT_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt float failed, float value=\" << float_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DOUBLE: {\n+                    // To prevent loss of precision on float and double types,\n+                    // they are converted to strings before output.\n+                    // For example: For a double value 27361919854.929001,\n+                    // the direct output of using std::stringstream is 2.73619e+10,\n+                    // and after conversion to a string, it outputs 27361919854.929001\n+                    char buffer[MAX_DOUBLE_STR_LENGTH + 2];\n+                    double double_value = *static_cast<double*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = DoubleToBuffer(double_value, MAX_DOUBLE_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt double failed, double value=\" << double_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DATE:\n+                case TYPE_DATETIME: {\n+                    char buf[64];\n+                    const DateTimeValue* time_val = (const DateTimeValue*)(item);\n+                    time_val->to_string(buf);\n+                    _plain_text_outstream << buf;\n+                    break;\n+                }\n+                case TYPE_VARCHAR:\n+                case TYPE_CHAR: {\n+                    const StringValue* string_val = (const StringValue*)(item);\n+                    if (string_val->ptr == NULL) {\n+                        if (string_val->len != 0) {\n+                            _plain_text_outstream << NULL_IN_CSV;\n+                        }\n+                    } else {\n+                        _plain_text_outstream << std::string(string_val->ptr, string_val->len);\n+                    }\n+                    break;\n+                }\n+                case TYPE_DECIMAL: {\n+                    const DecimalValue* decimal_val = reinterpret_cast<const DecimalValue*>(item);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val->to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val->to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                case TYPE_DECIMALV2: {\n+                    const DecimalV2Value decimal_val(reinterpret_cast<const PackedInt128*>(item)->value);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val.to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val.to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                default: {\n+                    // not supported type, like BITMAP, HLL, just export null\n+                    _plain_text_outstream << NULL_IN_CSV;\n+                }\n+            }\n+            if (i < num_columns - 1) {\n+                _plain_text_outstream << _file_opts->column_separator;\n+            }\n+        } // end for columns\n+        _plain_text_outstream << _file_opts->line_delimiter;\n+    }\n+\n+    // write one line to file\n+    return _flush_plain_text_outstream(false);\n+}\n+\n+Status FileResultWriter::_flush_plain_text_outstream(bool eos) {\n+    SCOPED_TIMER(_file_write_timer);\n+    size_t pos = _plain_text_outstream.tellp();\n+    if (pos == 0 || (pos < OUTSTREAM_BUFFER_SIZE_BYTES && !eos)) {\n+        return Status::OK();\n+    }\n+    \n+    const std::string& buf = _plain_text_outstream.str();\n+    size_t written_len = 0;\n+    RETURN_IF_ERROR(_file_writer->write(reinterpret_cast<const uint8_t*>(buf.c_str()),\n+            buf.size(), &written_len));\n+    COUNTER_UPDATE(_written_data_bytes, written_len);\n+    _current_written_bytes += written_len;\n+\n+    // clear the stream\n+    _plain_text_outstream.str(\"\");\n+    _plain_text_outstream.clear();\n+\n+    // split file if exceed limit\n+    RETURN_IF_ERROR(_create_new_file_if_exceed_size());\n+\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_create_new_file_if_exceed_size() {\n+    if (_current_written_bytes < _file_opts->max_file_size_bytes) {\n+        return Status::OK();\n+    }\n+    // current file size exceed the max file size. close this file\n+    // and create new one\n+    RETURN_IF_ERROR(_close_file_writer(false));\n+    _current_written_bytes = 0;\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_close_file_writer(bool done) {\n+    SCOPED_TIMER(_writer_close_timer);\n+    if (_parquet_writer != nullptr) {\n+        _parquet_writer->close();\n+        delete _parquet_writer;\n+        _parquet_writer = nullptr;\n+        if (!done) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDM4Ng==", "bodyText": "why two private, and add_one_row not start with _", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426350386", "createdAt": "2020-05-18T03:17:28Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDYyNw==", "bodyText": "why not use unique_ptr", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426350627", "createdAt": "2020-05-18T03:18:59Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);\n+\n+    // The expressions that are run to create tuples to be written to hbase.\n+    BufferControlBlock* _sinker;\n+    const std::vector<ExprContext*>& _output_expr_ctxs;\n+    MysqlRowBuffer* _row_buffer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MTQzNA==", "bodyText": "|| sink.type == TResultSinkType::MYSQL_PROTOCAL is unnecessary", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426351434", "createdAt": "2020-05-18T03:23:35Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/result_sink.cpp", "diffHunk": "@@ -35,6 +36,17 @@ ResultSink::ResultSink(const RowDescriptor& row_desc, const std::vector<TExpr>&\n     : _row_desc(row_desc),\n       _t_output_expr(t_output_expr),\n       _buf_size(buffer_size) {\n+\n+    if (!sink.__isset.type || sink.type == TResultSinkType::MYSQL_PROTOCAL) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MjUwMA==", "bodyText": "forget to removed ?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426352500", "createdAt": "2020-05-18T03:29:26Z", "author": {"login": "yangzhg"}, "path": "build.sh", "diffHunk": "@@ -42,6 +42,7 @@ if [[ ! -f ${DORIS_THIRDPARTY}/installed/lib/libs2.a ]]; then\n fi\n \n PARALLEL=$[$(nproc)/4+1]\n+PARALLEL=12", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1Mjg1Nw==", "bodyText": "\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6 \u66f4\u597d\u4e00\u70b9", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426352857", "createdAt": "2020-05-18T03:31:08Z", "author": {"login": "yangzhg"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u67e5\u8be2\u7ed3\u679c\u96c6\u5bfc\u51fa\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 3}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MTQ1MTgw", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-414145180", "createdAt": "2020-05-19T06:46:05Z", "commit": {"oid": "43ad42a03b8322017499ea1fa3cb23ca6b8b9dcb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjowNVrOGXSClw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjowNVrOGXSClw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA2NjAwNw==", "bodyText": "OUTFILE?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427066007", "createdAt": "2020-05-19T06:46:05Z", "author": {"login": "zhangy5"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUFILE \"file_path\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ad42a03b8322017499ea1fa3cb23ca6b8b9dcb"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE1NDkxNTg5", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-415491589", "createdAt": "2020-05-20T16:06:13Z", "commit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjowNjoxM1rOGYTHYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoyMDoxMFrOGYTrtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzMjE5Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n          \n          \n            \n            \u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428132193", "createdAt": "2020-05-20T16:06:13Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDY0Mw==", "bodyText": "\u662f\u5426\u4ea7\u751f\u7a7a\u6587\u4ef6\u5e94\u8be5\u662f\u53ef\u914d\u7f6e\u7684\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428134643", "createdAt": "2020-05-20T16:09:56Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u4e0d\u4f1a\u68c0\u67e5\u6587\u4ef6\u53ca\u6587\u4ef6\u8def\u5f84\u662f\u5426\u5b58\u5728\u3002\u662f\u5426\u4f1a\u81ea\u52a8\u521b\u5efa\u8def\u5f84\u3001\u6216\u662f\u5426\u4f1a\u8986\u76d6\u5df2\u5b58\u5728\u6587\u4ef6\uff0c\u5b8c\u5168\u7531\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u7684\u8bed\u4e49\u51b3\u5b9a\u3002\n+* \u5982\u679c\u5728\u5bfc\u51fa\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef\uff0c\u53ef\u80fd\u4f1a\u6709\u5bfc\u51fa\u6587\u4ef6\u6b8b\u7559\u5728\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e0a\u3002Doris \u4e0d\u4f1a\u6e05\u7406\u8fd9\u4e9b\u6587\u4ef6\u3002\u9700\u8981\u7528\u6237\u624b\u52a8\u6e05\u7406\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u7684\u8d85\u65f6\u65f6\u95f4\u540c\u67e5\u8be2\u7684\u8d85\u65f6\u65f6\u95f4\u3002\u53ef\u4ee5\u901a\u8fc7 `SET query_timeout=xxx` \u8fdb\u884c\u8bbe\u7f6e\u3002\n+* \u5bf9\u4e8e\u7ed3\u679c\u96c6\u4e3a\u7a7a\u7684\u67e5\u8be2\uff0c\u4f9d\u7136\u540e\u4ea7\u751f\u4e00\u4e2a\u5927\u5c0f\u4e3a0\u7684\u6587\u4ef6\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDk2MQ==", "bodyText": "\u4e4b\u540e\u4f1a\u652f\u6301\u591a\u7ebf\u7a0b\u5417\uff1f", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428134961", "createdAt": "2020-05-20T16:10:21Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNzc2MA==", "bodyText": "Hbase?  Remove it.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428137760", "createdAt": "2020-05-20T16:14:38Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+    // convert one tuple row\n+    Status _add_one_row(TupleRow* row);\n+\n+private:\n+    // The expressions that are run to create tuples to be written to hbase.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzODI1OA==", "bodyText": "Should mark final.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428138258", "createdAt": "2020-05-20T16:15:21Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTAwMw==", "bodyText": "unordered_map?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428141003", "createdAt": "2020-05-20T16:19:31Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTQ5Mg==", "bodyText": "Should mark final.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428141492", "createdAt": "2020-05-20T16:20:10Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;\n+\n+    ResultFileOptions(const TResultFileSinkOptions& t_opt) {\n+        file_path = t_opt.file_path;\n+        file_format = t_opt.file_format;\n+        column_separator = t_opt.__isset.column_separator ? t_opt.column_separator : \"\\t\";\n+        line_delimiter = t_opt.__isset.line_delimiter ? t_opt.line_delimiter : \"\\n\";\n+        max_file_size_bytes = t_opt.__isset.max_file_size_bytes ?\n+                t_opt.max_file_size_bytes : max_file_size_bytes;\n+\n+        is_local_file = true;\n+        if (t_opt.__isset.broker_addresses) {\n+            broker_addresses = t_opt.broker_addresses;\n+            is_local_file = false;\n+        }\n+        if (t_opt.__isset.broker_properties) {\n+            broker_properties = t_opt.broker_properties;\n+        }\n+    }\n+};\n+\n+// write result to file\n+class FileResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2NjE2MjQ2", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-416616246", "createdAt": "2020-05-22T02:52:09Z", "commit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2NjE0NjAy", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-416614602", "createdAt": "2020-05-22T02:46:07Z", "commit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjo0NjowN1rOGZJAhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjo1NDo1NFrOGZJIKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTE3Mw==", "bodyText": "max_file_size\u66f4\u597d\u4e00\u4e9b\uff0c\u56e0\u4e3a\u540e\u9762\u53ef\u4ee5\u6307\u5b9a\u5355\u4f4d\u4e86", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429015173", "createdAt": "2020-05-22T02:46:07Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTQyNA==", "bodyText": "\u6211\u89c9\u5f97\u53ef\u4ee5\u662fmy_file0.csv\u5427\uff0c\u7528\u6237\u5982\u679c\u60f3\u5bfc\u5165my_file_0.csv\uff0c\u90a3\u4e48\u8f93\u5165\u7684\u53c2\u6570\u662f\u201chdfs://path/to/my_file_\u201d\u5c31\u53ef\u4ee5\u8fbe\u5230\u4e86", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429015424", "createdAt": "2020-05-22T02:47:17Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNzEyOA==", "bodyText": "\u6211\u89c9\u5f97broker\u672a\u6765\u53ef\u80fd\u5e76\u4e0d\u662f\u4e00\u4e2a\u5fc5\u5907\u9009\u9879\u3002\u6240\u4ee5\u4e0d\u5efa\u8bae\u628awith broker\u663e\u793a\u7684\u5199\u5728\u8bed\u6cd5\u4e2d\u3002\n\u662f\u4e0d\u662f\u53ef\u4ee5\u628abroker\u4fe1\u606f\u90fd\u653e\u5230property\u91cc\u9762\u5462\uff1f\u589e\u52a0\u4e0b\u9762\u7c7b\u4f3c\u7684\u914d\u7f6e\uff1f\n\"broker\" = \"\"\n\"broker.username\" = \"\n\"broker.password\" = \"\"", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429017128", "createdAt": "2020-05-22T02:54:54Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 39}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9a94170ceae3e689fb5e67908bd18bfd1f545906", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/9a94170ceae3e689fb5e67908bd18bfd1f545906", "committedDate": "2020-05-22T16:39:02Z", "message": "fix bug"}, "afterCommit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/4a6a21cdb0252bef71dd7526650b816f53134530", "committedDate": "2020-05-23T03:53:33Z", "message": "fix bug"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MzU3NzIy", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-417357722", "createdAt": "2020-05-24T13:14:47Z", "commit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxMzoxNDo0N1rOGZu3pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxMzoxNDo0N1rOGZu3pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTYzNTQ5NA==", "bodyText": "better to give a default value.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429635494", "createdAt": "2020-05-24T13:14:47Z", "author": {"login": "imay"}, "path": "be/src/runtime/query_statistics.h", "diffHunk": "@@ -71,6 +77,9 @@ class QueryStatistics {\n \n     int64_t scan_rows;\n     int64_t scan_bytes;\n+    // number rows returned by query.\n+    // only set once by result sink when closing.\n+    int64_t returned_rows;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "babec813a53add812795be1df9dc28359668d42d", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/babec813a53add812795be1df9dc28359668d42d", "committedDate": "2020-05-25T07:56:23Z", "message": "first"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b92794a06cc9a3001114d2bfc91553c65367a1e2", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/b92794a06cc9a3001114d2bfc91553c65367a1e2", "committedDate": "2020-05-25T07:56:24Z", "message": "fe"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ac8693eac6aedc71c5311aecbd47034958a38f7", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/6ac8693eac6aedc71c5311aecbd47034958a38f7", "committedDate": "2020-05-25T07:56:24Z", "message": "fix bug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c69bea3115362b41eef4efdf0b6eb0681909ef32", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/c69bea3115362b41eef4efdf0b6eb0681909ef32", "committedDate": "2020-05-25T07:56:24Z", "message": "fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f96a928ea1feffd6f12e845446203120b090d874", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/f96a928ea1feffd6f12e845446203120b090d874", "committedDate": "2020-05-25T07:56:24Z", "message": "fix bug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f3b8fd478018c63d008c633041e6c44ee98ad0c", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/8f3b8fd478018c63d008c633041e6c44ee98ad0c", "committedDate": "2020-05-25T07:56:24Z", "message": "add doc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f886ce9160eaba7e5a62f6dfb46e496845e1f55", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/5f886ce9160eaba7e5a62f6dfb46e496845e1f55", "committedDate": "2020-05-25T07:56:24Z", "message": "add en doc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71d43c2b44c6ab712e12dc6818afb2b6f9b1d068", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/71d43c2b44c6ab712e12dc6818afb2b6f9b1d068", "committedDate": "2020-05-25T07:56:24Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "155a3ca939897a32a603556e34f4c72073fbe6d8", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/155a3ca939897a32a603556e34f4c72073fbe6d8", "committedDate": "2020-05-25T07:56:25Z", "message": "add max file size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7e115025fb065a66558bca3af59cbb9fadf7005", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/b7e115025fb065a66558bca3af59cbb9fadf7005", "committedDate": "2020-05-25T07:56:25Z", "message": "add split file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "af61e173d78cbd24629acef8b4fd80d2baddfa83", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/af61e173d78cbd24629acef8b4fd80d2baddfa83", "committedDate": "2020-05-25T07:56:25Z", "message": "fix by review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46df705ba3d0876ecf3c1abf7f22c7173ad7ae5d", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/46df705ba3d0876ecf3c1abf7f22c7173ad7ae5d", "committedDate": "2020-05-25T07:56:25Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dc92c8c1ff1cc4492d75705de034671f8d57555", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/6dc92c8c1ff1cc4492d75705de034671f8d57555", "committedDate": "2020-05-25T07:56:25Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9334a4bfa38ed2f4a62b8c6dae1a57f8c6d2986c", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/9334a4bfa38ed2f4a62b8c6dae1a57f8c6d2986c", "committedDate": "2020-05-25T07:56:25Z", "message": "fix by review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f8514939492ff62c19b1e88da51d10a6150240f", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/9f8514939492ff62c19b1e88da51d10a6150240f", "committedDate": "2020-05-25T07:56:25Z", "message": "modify syntax"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbd908509b053bea3cb5fd9dc92f25cbf6307efe", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/fbd908509b053bea3cb5fd9dc92f25cbf6307efe", "committedDate": "2020-05-25T07:56:25Z", "message": "fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88b18d768bd3ef44d5848c4cc8e1199c1af9e365", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/88b18d768bd3ef44d5848c4cc8e1199c1af9e365", "committedDate": "2020-05-25T07:56:25Z", "message": "fix bug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfea2c3ed436148d716765a8bd6f93fb086eb3bd", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/cfea2c3ed436148d716765a8bd6f93fb086eb3bd", "committedDate": "2020-05-25T07:57:44Z", "message": "init returned_rows"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530", "author": {"user": {"login": "morningman-cmy", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/4a6a21cdb0252bef71dd7526650b816f53134530", "committedDate": "2020-05-23T03:53:33Z", "message": "fix bug"}, "afterCommit": {"oid": "cfea2c3ed436148d716765a8bd6f93fb086eb3bd", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/cfea2c3ed436148d716765a8bd6f93fb086eb3bd", "committedDate": "2020-05-25T07:57:44Z", "message": "init returned_rows"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3NjQwNzg5", "url": "https://github.com/apache/incubator-doris/pull/3584#pullrequestreview-417640789", "createdAt": "2020-05-25T11:15:21Z", "commit": {"oid": "cfea2c3ed436148d716765a8bd6f93fb086eb3bd"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2644, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}