{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMzQxNDg1", "number": 2858, "title": "fix core when using grouping sets in large data", "bodyText": "fix a core when using grouping sets in large data #2859", "createdAt": "2020-02-07T10:30:44Z", "url": "https://github.com/apache/incubator-doris/pull/2858", "merged": true, "mergeCommit": {"oid": "502fa2eb50d69e16f9b3343c86ce0950cdd529d5"}, "closed": true, "closedAt": "2020-02-07T13:40:29Z", "author": {"login": "yangzhg"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcB9fNJAH2gAyMzcyMzQxNDg1OmVhYTA0OGJhN2JmNWM2ODgwZmQ2OWY4NDcwZTU4YjY5MDUxYTE3NTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcB_gNAAFqTM1NTE2MDM1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "eaa048ba7bf5c6880fd69f8470e58b69051a1754", "author": {"user": {"login": "yangzhg", "name": "Zhengguo Yang"}}, "url": "https://github.com/apache/incubator-doris/commit/eaa048ba7bf5c6880fd69f8470e58b69051a1754", "committedDate": "2020-02-07T11:18:18Z", "message": "fix core when using grouping sets in large data"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9dc131206d56458f573cac9bce2e3927aa579c45", "author": {"user": {"login": "yangzhg", "name": "Zhengguo Yang"}}, "url": "https://github.com/apache/incubator-doris/commit/9dc131206d56458f573cac9bce2e3927aa579c45", "committedDate": "2020-02-07T10:29:52Z", "message": "fix core when using grouping sets in large data"}, "afterCommit": {"oid": "eaa048ba7bf5c6880fd69f8470e58b69051a1754", "author": {"user": {"login": "yangzhg", "name": "Zhengguo Yang"}}, "url": "https://github.com/apache/incubator-doris/commit/eaa048ba7bf5c6880fd69f8470e58b69051a1754", "committedDate": "2020-02-07T11:18:18Z", "message": "fix core when using grouping sets in large data"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1MTEzOTQ1", "url": "https://github.com/apache/incubator-doris/pull/2858#pullrequestreview-355113945", "createdAt": "2020-02-07T12:08:02Z", "commit": {"oid": "eaa048ba7bf5c6880fd69f8470e58b69051a1754"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjowODowM1rOFm7GqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjowODowM1rOFm7GqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM1ODU2OQ==", "bodyText": "is it a typo? should we use row_batch's capacity to calculate one tuple's memory size?", "url": "https://github.com/apache/incubator-doris/pull/2858#discussion_r376358569", "createdAt": "2020-02-07T12:08:03Z", "author": {"login": "lingbin"}, "path": "be/src/exec/repeat_node.cpp", "diffHunk": "@@ -100,10 +93,18 @@ Status RepeatNode::get_repeated_batch(\n                 continue;\n             }\n \n-            char* new_tuple = reinterpret_cast<char*>(dst_tuples[j]);\n-            new_tuple += (*dst_it)->byte_size();\n-            dst_tuples[j] = reinterpret_cast<Tuple*>(new_tuple);\n-\n+            if (dst_tuples[j] == nullptr) {\n+                int size = row_batch->capacity() * (*dst_it)->byte_size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaa048ba7bf5c6880fd69f8470e58b69051a1754"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1MTYwMzUy", "url": "https://github.com/apache/incubator-doris/pull/2858#pullrequestreview-355160352", "createdAt": "2020-02-07T13:39:12Z", "commit": {"oid": "eaa048ba7bf5c6880fd69f8470e58b69051a1754"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3719, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}