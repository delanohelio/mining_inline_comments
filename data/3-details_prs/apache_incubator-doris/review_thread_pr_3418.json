{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEwMjYzOTQ3", "number": 3418, "reviewThreads": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzo1NzowM1rOD37waA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwOTo0MTo0N1rOD-5DVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTc3MzIwOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzo1NzowM1rOGOeAeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzo1NzowM1rOGOeAeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgyNDg4OQ==", "bodyText": "Is \"Spark Load\" a good name? Maybe we will support Hadoop or Hive later, however they will share the same load framework.\nSo we should give this feature a common name, and spark is only one of all methods.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417824889", "createdAt": "2020-04-30T07:57:03Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgwNDA0OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNjozMVrOGOeUqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNjozMVrOGOeUqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMDA1Ng==", "bodyText": "Prefer spark.args spark.configs", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417830056", "createdAt": "2020-04-30T08:06:31Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",\n+\"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+\"broker\" = \"broker0\",\n+\"yarn_configs\" = \"yarn.resourcemanager.address=1.1.1.1:800;fs.defaultFS=hdfs://1.1.1.1:801\",\n+\"spark_args\" = \"--files=/file1,/file2;--jars=/a.jar,/b.jar\",\n+\"spark_configs\" = \"spark.driver.memory=1g;spark.executor.memory=1g\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgwNTE0OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNjo0OVrOGOeVXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNjo0OVrOGOeVXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMDIzNw==", "bodyText": "\"yarn.configs\"", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417830237", "createdAt": "2020-04-30T08:06:49Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",\n+\"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+\"broker\" = \"broker0\",\n+\"yarn_configs\" = \"yarn.resourcemanager.address=1.1.1.1:800;fs.defaultFS=hdfs://1.1.1.1:801\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgwNjQzOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNzoxN1rOGOeWLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowNzoxN1rOGOeWLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMDQ0Ng==", "bodyText": "what is the master mean? It is not very clear.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417830446", "createdAt": "2020-04-30T08:07:17Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgxMjExOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowOTowMlrOGOeZyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODowOTowMlrOGOeZyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMTM2OA==", "bodyText": "Better to explain for what this path is used. And should remove hdfs_ prefix, because the file may locate in S3 or other external path.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417831368", "createdAt": "2020-04-30T08:09:02Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgxNjE2OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoxMDoxN1rOGOecQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoxMDoxN1rOGOecQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMjAwMw==", "bodyText": "Whose deploy_mode? If it is spark's deploy_mode, better to call it \"spark.deploy_mode\"", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417832003", "createdAt": "2020-04-30T08:10:17Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgxOTQwOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoxMToxOFrOGOeeTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoxMToxOFrOGOeeTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzMjUyNw==", "bodyText": "Should explain this option more clearly. And I don't know what this master stands for.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417832527", "createdAt": "2020-04-30T08:11:18Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 131}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTgzNjcxOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoxNjoyNFrOGOepVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0Njo0OVrOGXkGBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzNTM0OQ==", "bodyText": "Is this broker is necessary to define a cluster? I think user can specify it in Load stmt. Keep consistent with current syntax \"with broker\"", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417835349", "createdAt": "2020-04-30T08:16:24Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",\n+\"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+\"broker\" = \"broker0\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM2MTc5OA==", "bodyText": "the broker is used to read the ETL intermediate results in the working_dir, not user source data.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427361798", "createdAt": "2020-05-19T14:46:49Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",\n+\"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+\"broker\" = \"broker0\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzNTM0OQ=="}, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTg0OTgwOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoyMDowOFrOGOex2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoyMDowOFrOGOex2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzgzNzUyOA==", "bodyText": "spark.configs", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417837528", "createdAt": "2020-04-30T08:20:08Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name\n+PROPERTIES(\"key1\" = \"value1\", ...)\n+\n+-- \u5220\u9664 ETL \u96c6\u7fa4\n+ALTER SYSTEM DROP LOAD CLUSTER cluster_name\n+\n+-- \u67e5\u770b ETL \u96c6\u7fa4\n+SHOW LOAD CLUSTERS\n+SHOW PROC \"/load_etl_clusters\"\n+```\n+\n+`cluster_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u96c6\u7fa4\u7684\u540d\u5b57\u3002\n+\n+PROPERTIES \u662f ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u96c6\u7fa4\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark ETL \u96c6\u7fa4\u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `master`\uff1a\u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `deploy_mode`\uff1a \u53ef\u9009\uff0c\u9ed8\u8ba4\u4e3a cluster\u3002\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `hdfs_etl_path`\uff1aETL \u4f7f\u7528\u7684 HDFS \u76ee\u5f55\u3002\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+  - `broker`\uff1abroker \u540d\u5b57\u3002\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `yarn_configs`\uff1a HDFS YARN \u53c2\u6570\uff0cmaster \u4e3a yarn \u65f6\u5fc5\u586b\u3002\u9700\u8981\u6307\u5b9a yarn.resourcemanager.address \u548c fs.defaultFS\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+  - `spark_args`\uff1a Spark \u4efb\u52a1\u63d0\u4ea4\u65f6\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53ef\u53c2\u8003 spark-submit \u547d\u4ee4\uff0c\u6bcf\u4e2a arg  \u5fc5\u987b\u4ee5`--`\u5f00\u5934\uff0c\u4e0d\u540c args \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\u4f8b\u5982--files=/file1,/file2;--jars=/a.jar,/b.jar\u3002\n+  - `spark_configs`\uff1a Spark \u53c2\u6570\uff0c\u53ef\u9009\u3002\u5177\u4f53\u53c2\u6570\u53ef\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\u4e0d\u540c configs \u4e4b\u95f4\u4f7f\u7528`;`\u62fc\u63a5\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster0\"\n+PROPERTIES\n+(\n+\"type\" = \"spark\", \n+\"master\" = \"yarn\",\n+\"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+\"broker\" = \"broker0\",\n+\"yarn_configs\" = \"yarn.resourcemanager.address=1.1.1.1:800;fs.defaultFS=hdfs://1.1.1.1:801\",\n+\"spark_args\" = \"--files=/file1,/file2;--jars=/a.jar,/b.jar\",\n+\"spark_configs\" = \"spark.driver.memory=1g;spark.executor.memory=1g\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+ALTER SYSTEM ADD LOAD CLUSTER \"cluster1\"\n+PROPERTIES\n+(\n+ \"type\" = \"spark\", \n+ \"master\" = \"spark://1.1.1.1:802\",\n+ \"deploy_mode\" = \"client\",\n+ \"hdfs_etl_path\" = \"hdfs://1.1.1.1:801/tmp/doris\",\n+ \"broker\" = \"broker1\"\n+);\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH CLUSTER cluster_name cluster_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* cluster_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH CLUSTER 'cluster0'\n+(\n+    \"broker.username\"=\"user\",\n+    \"broker.password\"=\"pass\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Cluster \u53c2\u6570\n+\n+ETL cluster\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+\u53e6\u5916\u5982\u679c\u9700\u8981\u6307\u5b9a\u989d\u5916\u7684 Broker \u53c2\u6570\uff0c\u5219\u9700\u8981\u6307\u5b9a\"broker.key\" = \"value\"\u3002\u5177\u4f53\u53c2\u6570\u8bf7\u53c2\u9605 [Broker\u6587\u6863](../broker.md)\u3002\u4f8b\u5982\u9700\u8981\u6307\u5b9a\u7528\u6237\u540d\u5bc6\u7801\uff0c\u5982\u4e0b\uff1a\n+\n+```sql\n+WITH CLUSTER 'cluster0'\n+(\n+    \"spark_configs\" = \"spark.driver.memory=1g;spark.executor.memory=1g\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTg3Mjg1OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoyNjoxMlrOGOfANg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwODoyNjoxMlrOGOfANg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzg0MTIwNg==", "bodyText": "Is cluster is a good name?\nI think Doris will support multi cluster in the future. And some cluster will be used as load cluster. Then it will be a conflict between two clusters.\nSo we better to choose another name.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r417841206", "createdAt": "2020-04-30T08:26:12Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,351 @@\n+---                                                                                 \n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- \u6dfb\u52a0 ETL \u96c6\u7fa4\n+ALTER SYSTEM ADD LOAD CLUSTER cluster_name", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c47224b56d5e17b2ec99a24d2ed7ba234b5b799"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM2MTk3OnYy", "diffSide": "RIGHT", "path": "fe/src/main/cup/sql_parser.cup", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjoyMDowOFrOGWej4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjoyMDowOFrOGWej4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMjU2MQ==", "bodyText": "Should update documents for all changed SQL reference.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426222561", "createdAt": "2020-05-17T06:20:08Z", "author": {"login": "imay"}, "path": "fe/src/main/cup/sql_parser.cup", "diffHunk": "@@ -1083,6 +1084,11 @@ create_stmt ::=\n     {:\n         RESULT = new AlterTableStmt(tableName, Lists.newArrayList(new CreateIndexClause(tableName, new IndexDef(indexName, cols, indexType, comment), false)));\n     :}\n+    /* resource */\n+    | KW_CREATE opt_external:isExternal KW_RESOURCE ident_or_text:resourceName opt_properties:properties\n+    {:\n+        RESULT = new CreateResourceStmt(isExternal, resourceName, properties);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM2NDA2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/analysis/CreateResourceStmt.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjoyNDowNVrOGWek7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MjoyOVrOGXj4eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMjgzMQ==", "bodyText": "If there are properties which are not valid, better to throw exception to let users know", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426222831", "createdAt": "2020-05-17T06:24:05Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/analysis/CreateResourceStmt.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.catalog.Catalog;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.ErrorCode;\n+import org.apache.doris.common.ErrorReport;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.PrintableMap;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import java.util.Map;\n+\n+// CREATE [EXTERNAL] RESOURCE resource_name\n+// PROPERTIES (key1 = value1, ...)\n+public class CreateResourceStmt extends DdlStmt {\n+    private static final String TYPE = \"type\";\n+\n+    private final boolean isExternal;\n+    private final String resourceName;\n+    private final Map<String, String> properties;\n+\n+    public CreateResourceStmt(boolean isExternal, String resourceName, Map<String, String> properties) {\n+        this.isExternal = isExternal;\n+        this.resourceName = resourceName;\n+        this.properties = properties;\n+    }\n+\n+    public String getResourceName() {\n+        return resourceName;\n+    }\n+\n+    public Map<String, String> getProperties() {\n+        return properties;\n+    }\n+\n+    public ResourceType getResourceType() {\n+        return ResourceType.fromString(properties.get(TYPE));\n+    }\n+\n+    @Override\n+    public void analyze(Analyzer analyzer) throws UserException {\n+        super.analyze(analyzer);\n+\n+        // check auth\n+        if (!Catalog.getCurrentCatalog().getAuth().checkGlobalPriv(ConnectContext.get(), PrivPredicate.ADMIN)) {\n+            ErrorReport.reportAnalysisException(ErrorCode.ERR_SPECIFIC_ACCESS_DENIED_ERROR, \"ADMIN\");\n+        }\n+\n+        // check name\n+        FeNameFormat.checkResourceName(resourceName);\n+\n+        // check type in properties\n+        if (properties == null || properties.isEmpty()) {\n+            throw new AnalysisException(\"Resource properties can't be null\");\n+        }\n+        String type = properties.get(TYPE);\n+        if (type == null) {\n+            throw new AnalysisException(\"Resource type can't be null\");\n+        }\n+        ResourceType resourceType = ResourceType.fromString(type);\n+        if (resourceType == null) {\n+            throw new AnalysisException(\"Unsupported resource type: \" + type);\n+        }\n+        if (resourceType == ResourceType.SPARK && !isExternal) {\n+            throw new AnalysisException(\"Spark is external resource\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1ODMzMA==", "bodyText": "already check in SparkResource", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427358330", "createdAt": "2020-05-19T14:42:29Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/analysis/CreateResourceStmt.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.catalog.Catalog;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.ErrorCode;\n+import org.apache.doris.common.ErrorReport;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.PrintableMap;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import java.util.Map;\n+\n+// CREATE [EXTERNAL] RESOURCE resource_name\n+// PROPERTIES (key1 = value1, ...)\n+public class CreateResourceStmt extends DdlStmt {\n+    private static final String TYPE = \"type\";\n+\n+    private final boolean isExternal;\n+    private final String resourceName;\n+    private final Map<String, String> properties;\n+\n+    public CreateResourceStmt(boolean isExternal, String resourceName, Map<String, String> properties) {\n+        this.isExternal = isExternal;\n+        this.resourceName = resourceName;\n+        this.properties = properties;\n+    }\n+\n+    public String getResourceName() {\n+        return resourceName;\n+    }\n+\n+    public Map<String, String> getProperties() {\n+        return properties;\n+    }\n+\n+    public ResourceType getResourceType() {\n+        return ResourceType.fromString(properties.get(TYPE));\n+    }\n+\n+    @Override\n+    public void analyze(Analyzer analyzer) throws UserException {\n+        super.analyze(analyzer);\n+\n+        // check auth\n+        if (!Catalog.getCurrentCatalog().getAuth().checkGlobalPriv(ConnectContext.get(), PrivPredicate.ADMIN)) {\n+            ErrorReport.reportAnalysisException(ErrorCode.ERR_SPECIFIC_ACCESS_DENIED_ERROR, \"ADMIN\");\n+        }\n+\n+        // check name\n+        FeNameFormat.checkResourceName(resourceName);\n+\n+        // check type in properties\n+        if (properties == null || properties.isEmpty()) {\n+            throw new AnalysisException(\"Resource properties can't be null\");\n+        }\n+        String type = properties.get(TYPE);\n+        if (type == null) {\n+            throw new AnalysisException(\"Resource type can't be null\");\n+        }\n+        ResourceType resourceType = ResourceType.fromString(type);\n+        if (resourceType == null) {\n+            throw new AnalysisException(\"Unsupported resource type: \" + type);\n+        }\n+        if (resourceType == ResourceType.SPARK && !isExternal) {\n+            throw new AnalysisException(\"Spark is external resource\");\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMjgzMQ=="}, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM2NDc5OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/analysis/CreateResourceStmt.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjoyNTowMFrOGWelRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjoyNTowMFrOGWelRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMjkxOA==", "bodyText": "If the resource type has been resolved, better to save it as a class member.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426222918", "createdAt": "2020-05-17T06:25:00Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/analysis/CreateResourceStmt.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.catalog.Catalog;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.ErrorCode;\n+import org.apache.doris.common.ErrorReport;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.PrintableMap;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import java.util.Map;\n+\n+// CREATE [EXTERNAL] RESOURCE resource_name\n+// PROPERTIES (key1 = value1, ...)\n+public class CreateResourceStmt extends DdlStmt {\n+    private static final String TYPE = \"type\";\n+\n+    private final boolean isExternal;\n+    private final String resourceName;\n+    private final Map<String, String> properties;\n+\n+    public CreateResourceStmt(boolean isExternal, String resourceName, Map<String, String> properties) {\n+        this.isExternal = isExternal;\n+        this.resourceName = resourceName;\n+        this.properties = properties;\n+    }\n+\n+    public String getResourceName() {\n+        return resourceName;\n+    }\n+\n+    public Map<String, String> getProperties() {\n+        return properties;\n+    }\n+\n+    public ResourceType getResourceType() {\n+        return ResourceType.fromString(properties.get(TYPE));\n+    }\n+\n+    @Override\n+    public void analyze(Analyzer analyzer) throws UserException {\n+        super.analyze(analyzer);\n+\n+        // check auth\n+        if (!Catalog.getCurrentCatalog().getAuth().checkGlobalPriv(ConnectContext.get(), PrivPredicate.ADMIN)) {\n+            ErrorReport.reportAnalysisException(ErrorCode.ERR_SPECIFIC_ACCESS_DENIED_ERROR, \"ADMIN\");\n+        }\n+\n+        // check name\n+        FeNameFormat.checkResourceName(resourceName);\n+\n+        // check type in properties\n+        if (properties == null || properties.isEmpty()) {\n+            throw new AnalysisException(\"Resource properties can't be null\");\n+        }\n+        String type = properties.get(TYPE);\n+        if (type == null) {\n+            throw new AnalysisException(\"Resource type can't be null\");\n+        }\n+        ResourceType resourceType = ResourceType.fromString(type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3MDI4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzoyOVrOGWen8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzoyOVrOGWen8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzYwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    SPARK;\n          \n          \n            \n                    UNKNOWN,\n          \n          \n            \n                    SPARK;", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426223603", "createdAt": "2020-05-17T06:33:29Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public abstract class Resource implements Writable {\n+    public enum ResourceType {\n+        SPARK;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3MDQyOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzo1OVrOGWeoBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzo1OVrOGWeoBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzYyMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return null;\n          \n          \n            \n                        return UNKNOWN;", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426223623", "createdAt": "2020-05-17T06:33:59Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public abstract class Resource implements Writable {\n+    public enum ResourceType {\n+        SPARK;\n+\n+        public static ResourceType fromString(String resourceType) {\n+            for (ResourceType type : ResourceType.values()) {\n+                if (type.name().equalsIgnoreCase(resourceType)) {\n+                    return type;\n+                }\n+            }\n+            return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3NTkxOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo0MjozNlrOGWeqwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo0MjozNlrOGWeqwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDMyMQ==", "bodyText": "should give comments for these functions to help others know how to implement them", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r426224321", "createdAt": "2020-05-17T06:42:36Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "diffHunk": "@@ -0,0 +1,100 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public abstract class Resource implements Writable {\n+    public enum ResourceType {\n+        SPARK;\n+\n+        public static ResourceType fromString(String resourceType) {\n+            for (ResourceType type : ResourceType.values()) {\n+                if (type.name().equalsIgnoreCase(resourceType)) {\n+                    return type;\n+                }\n+            }\n+            return null;\n+        }\n+    }\n+\n+    @SerializedName(value = \"name\")\n+    protected String name;\n+    @SerializedName(value = \"type\")\n+    protected ResourceType type;\n+\n+    public Resource(String name, ResourceType type) {\n+        this.name = name;\n+        this.type = type;\n+    }\n+\n+    public static Resource fromStmt(CreateResourceStmt stmt) throws DdlException {\n+        Resource resource = null;\n+        ResourceType type = stmt.getResourceType();\n+        switch (type) {\n+            case SPARK:\n+                resource = new SparkResource(stmt.getResourceName());\n+                break;\n+            default:\n+                throw new DdlException(\"Only support Spark resource.\");\n+        }\n+\n+        resource.setProperties(stmt.getProperties());\n+        return resource;\n+    }\n+\n+    public String getName() {\n+        return name;\n+    }\n+\n+    public ResourceType getType() {\n+        return type;\n+    }\n+\n+    protected abstract void setProperties(Map<String, String> properties) throws DdlException;\n+    protected abstract void getProcNodeData(BaseProcResult result);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26facbf1f12221b2603ace89c8bba8cf824fba78"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTU1NDA0OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozMDo0N1rOGXjS7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozMDo0N1rOGXjS7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM0ODcxOQ==", "bodyText": "resource management \u5e94\u8be5\u5355\u72ec\u5199\u4e00\u4e2a\u6587\u6863", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427348719", "createdAt": "2020-05-19T14:30:47Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTU2MDIyOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozMjowOFrOGXjXDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTozNToyOFrOGY3vrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM0OTc3Mg==", "bodyText": "How about \"spark.working_dir\"?", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427349772", "createdAt": "2020-05-19T14:32:08Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczMjMzNQ==", "bodyText": "spark.xxx is the standard format of spark configuration\uff0cso i think it is better to use working_dir to distinguish", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r428732335", "createdAt": "2020-05-21T15:35:28Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM0OTc3Mg=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTU5MDIyOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozODowNlrOGXjpyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwOToyMzoyOVrOGZQmHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NDU2OQ==", "bodyText": "Can this be updated in realtime?", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427354569", "createdAt": "2020-05-19T14:38:06Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+- `broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker0\",\n+  \"broker.username\" = \"user0\",\n+  \"broker.password\" = \"password0\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+CREATE EXTERNAL RESOURCE \"spark1\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\", \n+  \"spark.master\" = \"spark://127.0.0.1:7777\",\n+  \"spark.submit.deployMode\" = \"client\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker1\"\n+);\n+```\n+\n+#### \u67e5\u770b\u8d44\u6e90\n+\n+\u666e\u901a\u8d26\u6237\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u6709USAGE_PRIV\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\n+\n+root\u548cadmin\u8d26\u6237\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u8d44\u6e90\u3002\n+\n+#### \u8d44\u6e90\u6743\u9650\n+\n+\u8d44\u6e90\u6743\u9650\u901a\u8fc7GRANT REVOKE\u6765\u7ba1\u7406\uff0c\u76ee\u524d\u4ec5\u652f\u6301USAGE_PRIV\u4f7f\u7528\u6743\u9650\u3002\n+\n+\u53ef\u4ee5\u5c06USAGE_PRIV\u6743\u9650\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u6216\u8005\u67d0\u4e2a\u89d2\u8272\uff0c\u89d2\u8272\u7684\u4f7f\u7528\u4e0e\u4e4b\u524d\u4e00\u81f4\u3002\n+```sql\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO \"user0\"@\"%\";\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO ROLE \"role0\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE * TO \"user0\"@\"%\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE * TO ROLE \"role0\";\n+-- \u64a4\u9500\u7528\u6237user0\u7684spark0\u8d44\u6e90\u4f7f\u7528\u6743\u9650\n+REVOKE USAGE_PRIV ON RESOURCE \"spark0\" FROM \"user0\"@\"%\";\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH RESOURCE resource_name resource_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* resource_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH RESOURCE 'spark0'\n+(\n+    \"spark.executor.memory\" = \"2g\",\n+    \"spark.shuffle.compress\" = \"true\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Spark\u8d44\u6e90\u53c2\u6570\n+\n+Spark\u8d44\u6e90\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u5e76\u4e14\u8d4b\u4e88\u7528\u6237USAGE_PRIV\u6743\u9650\u540e\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+```sql\n+WITH RESOURCE 'spark0'\n+(\n+  \"spark.driver.memory\" = \"1g\",\n+  \"spark.executor.memory\" = \"3g\"\n+)\n+```\n+\n+\n+\n+### \u67e5\u770b\u5bfc\u5165\n+\n+Spark load \u5bfc\u5165\u65b9\u5f0f\u540c Broker load \u4e00\u6837\u90fd\u662f\u5f02\u6b65\u7684\uff0c\u6240\u4ee5\u7528\u6237\u5fc5\u987b\u5c06\u521b\u5efa\u5bfc\u5165\u7684 Label \u8bb0\u5f55\uff0c\u5e76\u4e14\u5728**\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u4e2d\u4f7f\u7528 Label \u6765\u67e5\u770b\u5bfc\u5165\u7ed3\u679c**\u3002\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u5728\u6240\u6709\u5bfc\u5165\u65b9\u5f0f\u4e2d\u662f\u901a\u7528\u7684\uff0c\u5177\u4f53\u8bed\u6cd5\u53ef\u6267\u884c ```HELP SHOW LOAD``` \u67e5\u770b\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```\n+mysql> show load order by createtime desc limit 1\\G\n+*************************** 1. row ***************************\n+         JobId: 76391\n+         Label: label1\n+         State: FINISHED\n+      Progress: ETL:100%; LOAD:100%\n+          Type: SPARK\n+       EtlInfo: unselected.rows=4; dpp.abnorm.ALL=15; dpp.norm.ALL=28133376\n+      TaskInfo: cluster:cluster0; timeout(s):10800; max_filter_ratio:5.0E-5\n+      ErrorMsg: N/A\n+    CreateTime: 2019-07-27 11:46:42\n+  EtlStartTime: 2019-07-27 11:46:44\n+ EtlFinishTime: 2019-07-27 11:49:44\n+ LoadStartTime: 2019-07-27 11:49:44\n+LoadFinishTime: 2019-07-27 11:50:16\n+           URL: http://1.1.1.1:8089/proxy/application_1586619723848_0035/\n+    JobDetails: {\"ScannedRows\":28133395,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":200000}\n+```\n+\n+\u8fd4\u56de\u7ed3\u679c\u96c6\u4e2d\u53c2\u6570\u610f\u4e49\u53ef\u4ee5\u53c2\u8003 Broker load\u3002\u4e0d\u540c\u70b9\u5982\u4e0b\uff1a\n+\n++ State\n+\n+    \u5bfc\u5165\u4efb\u52a1\u5f53\u524d\u6240\u5904\u7684\u9636\u6bb5\u3002\u4efb\u52a1\u63d0\u4ea4\u4e4b\u540e\u72b6\u6001\u4e3a PENDING\uff0c\u63d0\u4ea4 Spark ETL \u4e4b\u540e\u72b6\u6001\u53d8\u4e3a ETL\uff0cETL \u5b8c\u6210\u4e4b\u540e FE \u8c03\u5ea6 BE \u6267\u884c push \u64cd\u4f5c\u72b6\u6001\u53d8\u4e3a LOADING\uff0cpush \u5b8c\u6210\u5e76\u4e14\u7248\u672c\u751f\u6548\u540e\u72b6\u6001\u53d8\u4e3a FINISHED\u3002\n+    \n+    \u5bfc\u5165\u4efb\u52a1\u7684\u6700\u7ec8\u9636\u6bb5\u6709\u4e24\u4e2a\uff1aCANCELLED \u548c FINISHED\uff0c\u5f53 Load job \u5904\u4e8e\u8fd9\u4e24\u4e2a\u9636\u6bb5\u65f6\u5bfc\u5165\u5b8c\u6210\u3002\u5176\u4e2d CANCELLED \u4e3a\u5bfc\u5165\u5931\u8d25\uff0cFINISHED \u4e3a\u5bfc\u5165\u6210\u529f\u3002\n+    \n++ Progress\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u8fdb\u5ea6\u63cf\u8ff0\u3002\u5206\u4e3a\u4e24\u79cd\u8fdb\u5ea6\uff1aETL \u548c LOAD\uff0c\u5bf9\u5e94\u4e86\u5bfc\u5165\u6d41\u7a0b\u7684\u4e24\u4e2a\u9636\u6bb5 ETL \u548c LOADING\u3002\n+    \n+    LOAD \u7684\u8fdb\u5ea6\u8303\u56f4\u4e3a\uff1a0~100%\u3002\n+    \n+    ```LOAD \u8fdb\u5ea6 = \u5f53\u524d\u5df2\u5b8c\u6210\u6240\u6709replica\u5bfc\u5165\u7684tablet\u4e2a\u6570 / \u672c\u6b21\u5bfc\u5165\u4efb\u52a1\u7684\u603btablet\u4e2a\u6570 * 100%``` \n+    \n+    **\u5982\u679c\u6240\u6709\u5bfc\u5165\u8868\u5747\u5b8c\u6210\u5bfc\u5165\uff0c\u6b64\u65f6 LOAD \u7684\u8fdb\u5ea6\u4e3a 99%** \u5bfc\u5165\u8fdb\u5165\u5230\u6700\u540e\u751f\u6548\u9636\u6bb5\uff0c\u6574\u4e2a\u5bfc\u5165\u5b8c\u6210\u540e\uff0cLOAD \u7684\u8fdb\u5ea6\u624d\u4f1a\u6539\u4e3a 100%\u3002\n+    \n+    \u5bfc\u5165\u8fdb\u5ea6\u5e76\u4e0d\u662f\u7ebf\u6027\u7684\u3002\u6240\u4ee5\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u5185\u8fdb\u5ea6\u6ca1\u6709\u53d8\u5316\uff0c\u5e76\u4e0d\u4ee3\u8868\u5bfc\u5165\u6ca1\u6709\u5728\u6267\u884c\u3002\n+    \n++ Type\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u7c7b\u578b\u3002Spark load \u4e3a SPARK\u3002    \n+\n++ CreateTime/EtlStartTime/EtlFinishTime/LoadStartTime/LoadFinishTime\n+\n+    \u8fd9\u51e0\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u5bfc\u5165\u521b\u5efa\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5b8c\u6210\u7684\u65f6\u95f4\uff0cLOADING \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\u548c\u6574\u4e2a\u5bfc\u5165\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u3002\n+\n++ JobDetails\n+\n+    \u663e\u793a\u4e00\u4e9b\u4f5c\u4e1a\u7684\u8be6\u7ec6\u8fd0\u884c\u72b6\u6001\uff0cETL \u7ed3\u675f\u7684\u65f6\u5019\u66f4\u65b0\u3002\u5305\u62ec\u5bfc\u5165\u6587\u4ef6\u7684\u4e2a\u6570\u3001\u603b\u5927\u5c0f\uff08\u5b57\u8282\uff09\u3001\u5b50\u4efb\u52a1\u4e2a\u6570\u3001\u5df2\u5904\u7406\u7684\u539f\u59cb\u884c\u6570\u7b49\u3002\n+\n+    ```{\"ScannedRows\":139264,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":940754064}```", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczNDczOA==", "bodyText": "No, FE gets the statis when etl job is finished", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r428734738", "createdAt": "2020-05-21T15:39:33Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+- `broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker0\",\n+  \"broker.username\" = \"user0\",\n+  \"broker.password\" = \"password0\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+CREATE EXTERNAL RESOURCE \"spark1\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\", \n+  \"spark.master\" = \"spark://127.0.0.1:7777\",\n+  \"spark.submit.deployMode\" = \"client\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker1\"\n+);\n+```\n+\n+#### \u67e5\u770b\u8d44\u6e90\n+\n+\u666e\u901a\u8d26\u6237\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u6709USAGE_PRIV\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\n+\n+root\u548cadmin\u8d26\u6237\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u8d44\u6e90\u3002\n+\n+#### \u8d44\u6e90\u6743\u9650\n+\n+\u8d44\u6e90\u6743\u9650\u901a\u8fc7GRANT REVOKE\u6765\u7ba1\u7406\uff0c\u76ee\u524d\u4ec5\u652f\u6301USAGE_PRIV\u4f7f\u7528\u6743\u9650\u3002\n+\n+\u53ef\u4ee5\u5c06USAGE_PRIV\u6743\u9650\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u6216\u8005\u67d0\u4e2a\u89d2\u8272\uff0c\u89d2\u8272\u7684\u4f7f\u7528\u4e0e\u4e4b\u524d\u4e00\u81f4\u3002\n+```sql\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO \"user0\"@\"%\";\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO ROLE \"role0\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE * TO \"user0\"@\"%\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE * TO ROLE \"role0\";\n+-- \u64a4\u9500\u7528\u6237user0\u7684spark0\u8d44\u6e90\u4f7f\u7528\u6743\u9650\n+REVOKE USAGE_PRIV ON RESOURCE \"spark0\" FROM \"user0\"@\"%\";\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH RESOURCE resource_name resource_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* resource_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH RESOURCE 'spark0'\n+(\n+    \"spark.executor.memory\" = \"2g\",\n+    \"spark.shuffle.compress\" = \"true\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Spark\u8d44\u6e90\u53c2\u6570\n+\n+Spark\u8d44\u6e90\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u5e76\u4e14\u8d4b\u4e88\u7528\u6237USAGE_PRIV\u6743\u9650\u540e\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+```sql\n+WITH RESOURCE 'spark0'\n+(\n+  \"spark.driver.memory\" = \"1g\",\n+  \"spark.executor.memory\" = \"3g\"\n+)\n+```\n+\n+\n+\n+### \u67e5\u770b\u5bfc\u5165\n+\n+Spark load \u5bfc\u5165\u65b9\u5f0f\u540c Broker load \u4e00\u6837\u90fd\u662f\u5f02\u6b65\u7684\uff0c\u6240\u4ee5\u7528\u6237\u5fc5\u987b\u5c06\u521b\u5efa\u5bfc\u5165\u7684 Label \u8bb0\u5f55\uff0c\u5e76\u4e14\u5728**\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u4e2d\u4f7f\u7528 Label \u6765\u67e5\u770b\u5bfc\u5165\u7ed3\u679c**\u3002\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u5728\u6240\u6709\u5bfc\u5165\u65b9\u5f0f\u4e2d\u662f\u901a\u7528\u7684\uff0c\u5177\u4f53\u8bed\u6cd5\u53ef\u6267\u884c ```HELP SHOW LOAD``` \u67e5\u770b\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```\n+mysql> show load order by createtime desc limit 1\\G\n+*************************** 1. row ***************************\n+         JobId: 76391\n+         Label: label1\n+         State: FINISHED\n+      Progress: ETL:100%; LOAD:100%\n+          Type: SPARK\n+       EtlInfo: unselected.rows=4; dpp.abnorm.ALL=15; dpp.norm.ALL=28133376\n+      TaskInfo: cluster:cluster0; timeout(s):10800; max_filter_ratio:5.0E-5\n+      ErrorMsg: N/A\n+    CreateTime: 2019-07-27 11:46:42\n+  EtlStartTime: 2019-07-27 11:46:44\n+ EtlFinishTime: 2019-07-27 11:49:44\n+ LoadStartTime: 2019-07-27 11:49:44\n+LoadFinishTime: 2019-07-27 11:50:16\n+           URL: http://1.1.1.1:8089/proxy/application_1586619723848_0035/\n+    JobDetails: {\"ScannedRows\":28133395,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":200000}\n+```\n+\n+\u8fd4\u56de\u7ed3\u679c\u96c6\u4e2d\u53c2\u6570\u610f\u4e49\u53ef\u4ee5\u53c2\u8003 Broker load\u3002\u4e0d\u540c\u70b9\u5982\u4e0b\uff1a\n+\n++ State\n+\n+    \u5bfc\u5165\u4efb\u52a1\u5f53\u524d\u6240\u5904\u7684\u9636\u6bb5\u3002\u4efb\u52a1\u63d0\u4ea4\u4e4b\u540e\u72b6\u6001\u4e3a PENDING\uff0c\u63d0\u4ea4 Spark ETL \u4e4b\u540e\u72b6\u6001\u53d8\u4e3a ETL\uff0cETL \u5b8c\u6210\u4e4b\u540e FE \u8c03\u5ea6 BE \u6267\u884c push \u64cd\u4f5c\u72b6\u6001\u53d8\u4e3a LOADING\uff0cpush \u5b8c\u6210\u5e76\u4e14\u7248\u672c\u751f\u6548\u540e\u72b6\u6001\u53d8\u4e3a FINISHED\u3002\n+    \n+    \u5bfc\u5165\u4efb\u52a1\u7684\u6700\u7ec8\u9636\u6bb5\u6709\u4e24\u4e2a\uff1aCANCELLED \u548c FINISHED\uff0c\u5f53 Load job \u5904\u4e8e\u8fd9\u4e24\u4e2a\u9636\u6bb5\u65f6\u5bfc\u5165\u5b8c\u6210\u3002\u5176\u4e2d CANCELLED \u4e3a\u5bfc\u5165\u5931\u8d25\uff0cFINISHED \u4e3a\u5bfc\u5165\u6210\u529f\u3002\n+    \n++ Progress\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u8fdb\u5ea6\u63cf\u8ff0\u3002\u5206\u4e3a\u4e24\u79cd\u8fdb\u5ea6\uff1aETL \u548c LOAD\uff0c\u5bf9\u5e94\u4e86\u5bfc\u5165\u6d41\u7a0b\u7684\u4e24\u4e2a\u9636\u6bb5 ETL \u548c LOADING\u3002\n+    \n+    LOAD \u7684\u8fdb\u5ea6\u8303\u56f4\u4e3a\uff1a0~100%\u3002\n+    \n+    ```LOAD \u8fdb\u5ea6 = \u5f53\u524d\u5df2\u5b8c\u6210\u6240\u6709replica\u5bfc\u5165\u7684tablet\u4e2a\u6570 / \u672c\u6b21\u5bfc\u5165\u4efb\u52a1\u7684\u603btablet\u4e2a\u6570 * 100%``` \n+    \n+    **\u5982\u679c\u6240\u6709\u5bfc\u5165\u8868\u5747\u5b8c\u6210\u5bfc\u5165\uff0c\u6b64\u65f6 LOAD \u7684\u8fdb\u5ea6\u4e3a 99%** \u5bfc\u5165\u8fdb\u5165\u5230\u6700\u540e\u751f\u6548\u9636\u6bb5\uff0c\u6574\u4e2a\u5bfc\u5165\u5b8c\u6210\u540e\uff0cLOAD \u7684\u8fdb\u5ea6\u624d\u4f1a\u6539\u4e3a 100%\u3002\n+    \n+    \u5bfc\u5165\u8fdb\u5ea6\u5e76\u4e0d\u662f\u7ebf\u6027\u7684\u3002\u6240\u4ee5\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u5185\u8fdb\u5ea6\u6ca1\u6709\u53d8\u5316\uff0c\u5e76\u4e0d\u4ee3\u8868\u5bfc\u5165\u6ca1\u6709\u5728\u6267\u884c\u3002\n+    \n++ Type\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u7c7b\u578b\u3002Spark load \u4e3a SPARK\u3002    \n+\n++ CreateTime/EtlStartTime/EtlFinishTime/LoadStartTime/LoadFinishTime\n+\n+    \u8fd9\u51e0\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u5bfc\u5165\u521b\u5efa\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5b8c\u6210\u7684\u65f6\u95f4\uff0cLOADING \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\u548c\u6574\u4e2a\u5bfc\u5165\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u3002\n+\n++ JobDetails\n+\n+    \u663e\u793a\u4e00\u4e9b\u4f5c\u4e1a\u7684\u8be6\u7ec6\u8fd0\u884c\u72b6\u6001\uff0cETL \u7ed3\u675f\u7684\u65f6\u5019\u66f4\u65b0\u3002\u5305\u62ec\u5bfc\u5165\u6587\u4ef6\u7684\u4e2a\u6570\u3001\u603b\u5927\u5c0f\uff08\u5b57\u8282\uff09\u3001\u5b50\u4efb\u52a1\u4e2a\u6570\u3001\u5df2\u5904\u7406\u7684\u539f\u59cb\u884c\u6570\u7b49\u3002\n+\n+    ```{\"ScannedRows\":139264,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":940754064}```", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NDU2OQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjE5NQ==", "bodyText": "Maybe we can add a rpc client in our DPP application, so that we can send some info back to the FE periodically.\nThis is just an optimization, can be done later.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429082195", "createdAt": "2020-05-22T07:17:14Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+- `broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker0\",\n+  \"broker.username\" = \"user0\",\n+  \"broker.password\" = \"password0\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+CREATE EXTERNAL RESOURCE \"spark1\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\", \n+  \"spark.master\" = \"spark://127.0.0.1:7777\",\n+  \"spark.submit.deployMode\" = \"client\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker1\"\n+);\n+```\n+\n+#### \u67e5\u770b\u8d44\u6e90\n+\n+\u666e\u901a\u8d26\u6237\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u6709USAGE_PRIV\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\n+\n+root\u548cadmin\u8d26\u6237\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u8d44\u6e90\u3002\n+\n+#### \u8d44\u6e90\u6743\u9650\n+\n+\u8d44\u6e90\u6743\u9650\u901a\u8fc7GRANT REVOKE\u6765\u7ba1\u7406\uff0c\u76ee\u524d\u4ec5\u652f\u6301USAGE_PRIV\u4f7f\u7528\u6743\u9650\u3002\n+\n+\u53ef\u4ee5\u5c06USAGE_PRIV\u6743\u9650\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u6216\u8005\u67d0\u4e2a\u89d2\u8272\uff0c\u89d2\u8272\u7684\u4f7f\u7528\u4e0e\u4e4b\u524d\u4e00\u81f4\u3002\n+```sql\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO \"user0\"@\"%\";\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO ROLE \"role0\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE * TO \"user0\"@\"%\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE * TO ROLE \"role0\";\n+-- \u64a4\u9500\u7528\u6237user0\u7684spark0\u8d44\u6e90\u4f7f\u7528\u6743\u9650\n+REVOKE USAGE_PRIV ON RESOURCE \"spark0\" FROM \"user0\"@\"%\";\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH RESOURCE resource_name resource_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* resource_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH RESOURCE 'spark0'\n+(\n+    \"spark.executor.memory\" = \"2g\",\n+    \"spark.shuffle.compress\" = \"true\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Spark\u8d44\u6e90\u53c2\u6570\n+\n+Spark\u8d44\u6e90\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u5e76\u4e14\u8d4b\u4e88\u7528\u6237USAGE_PRIV\u6743\u9650\u540e\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+```sql\n+WITH RESOURCE 'spark0'\n+(\n+  \"spark.driver.memory\" = \"1g\",\n+  \"spark.executor.memory\" = \"3g\"\n+)\n+```\n+\n+\n+\n+### \u67e5\u770b\u5bfc\u5165\n+\n+Spark load \u5bfc\u5165\u65b9\u5f0f\u540c Broker load \u4e00\u6837\u90fd\u662f\u5f02\u6b65\u7684\uff0c\u6240\u4ee5\u7528\u6237\u5fc5\u987b\u5c06\u521b\u5efa\u5bfc\u5165\u7684 Label \u8bb0\u5f55\uff0c\u5e76\u4e14\u5728**\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u4e2d\u4f7f\u7528 Label \u6765\u67e5\u770b\u5bfc\u5165\u7ed3\u679c**\u3002\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u5728\u6240\u6709\u5bfc\u5165\u65b9\u5f0f\u4e2d\u662f\u901a\u7528\u7684\uff0c\u5177\u4f53\u8bed\u6cd5\u53ef\u6267\u884c ```HELP SHOW LOAD``` \u67e5\u770b\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```\n+mysql> show load order by createtime desc limit 1\\G\n+*************************** 1. row ***************************\n+         JobId: 76391\n+         Label: label1\n+         State: FINISHED\n+      Progress: ETL:100%; LOAD:100%\n+          Type: SPARK\n+       EtlInfo: unselected.rows=4; dpp.abnorm.ALL=15; dpp.norm.ALL=28133376\n+      TaskInfo: cluster:cluster0; timeout(s):10800; max_filter_ratio:5.0E-5\n+      ErrorMsg: N/A\n+    CreateTime: 2019-07-27 11:46:42\n+  EtlStartTime: 2019-07-27 11:46:44\n+ EtlFinishTime: 2019-07-27 11:49:44\n+ LoadStartTime: 2019-07-27 11:49:44\n+LoadFinishTime: 2019-07-27 11:50:16\n+           URL: http://1.1.1.1:8089/proxy/application_1586619723848_0035/\n+    JobDetails: {\"ScannedRows\":28133395,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":200000}\n+```\n+\n+\u8fd4\u56de\u7ed3\u679c\u96c6\u4e2d\u53c2\u6570\u610f\u4e49\u53ef\u4ee5\u53c2\u8003 Broker load\u3002\u4e0d\u540c\u70b9\u5982\u4e0b\uff1a\n+\n++ State\n+\n+    \u5bfc\u5165\u4efb\u52a1\u5f53\u524d\u6240\u5904\u7684\u9636\u6bb5\u3002\u4efb\u52a1\u63d0\u4ea4\u4e4b\u540e\u72b6\u6001\u4e3a PENDING\uff0c\u63d0\u4ea4 Spark ETL \u4e4b\u540e\u72b6\u6001\u53d8\u4e3a ETL\uff0cETL \u5b8c\u6210\u4e4b\u540e FE \u8c03\u5ea6 BE \u6267\u884c push \u64cd\u4f5c\u72b6\u6001\u53d8\u4e3a LOADING\uff0cpush \u5b8c\u6210\u5e76\u4e14\u7248\u672c\u751f\u6548\u540e\u72b6\u6001\u53d8\u4e3a FINISHED\u3002\n+    \n+    \u5bfc\u5165\u4efb\u52a1\u7684\u6700\u7ec8\u9636\u6bb5\u6709\u4e24\u4e2a\uff1aCANCELLED \u548c FINISHED\uff0c\u5f53 Load job \u5904\u4e8e\u8fd9\u4e24\u4e2a\u9636\u6bb5\u65f6\u5bfc\u5165\u5b8c\u6210\u3002\u5176\u4e2d CANCELLED \u4e3a\u5bfc\u5165\u5931\u8d25\uff0cFINISHED \u4e3a\u5bfc\u5165\u6210\u529f\u3002\n+    \n++ Progress\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u8fdb\u5ea6\u63cf\u8ff0\u3002\u5206\u4e3a\u4e24\u79cd\u8fdb\u5ea6\uff1aETL \u548c LOAD\uff0c\u5bf9\u5e94\u4e86\u5bfc\u5165\u6d41\u7a0b\u7684\u4e24\u4e2a\u9636\u6bb5 ETL \u548c LOADING\u3002\n+    \n+    LOAD \u7684\u8fdb\u5ea6\u8303\u56f4\u4e3a\uff1a0~100%\u3002\n+    \n+    ```LOAD \u8fdb\u5ea6 = \u5f53\u524d\u5df2\u5b8c\u6210\u6240\u6709replica\u5bfc\u5165\u7684tablet\u4e2a\u6570 / \u672c\u6b21\u5bfc\u5165\u4efb\u52a1\u7684\u603btablet\u4e2a\u6570 * 100%``` \n+    \n+    **\u5982\u679c\u6240\u6709\u5bfc\u5165\u8868\u5747\u5b8c\u6210\u5bfc\u5165\uff0c\u6b64\u65f6 LOAD \u7684\u8fdb\u5ea6\u4e3a 99%** \u5bfc\u5165\u8fdb\u5165\u5230\u6700\u540e\u751f\u6548\u9636\u6bb5\uff0c\u6574\u4e2a\u5bfc\u5165\u5b8c\u6210\u540e\uff0cLOAD \u7684\u8fdb\u5ea6\u624d\u4f1a\u6539\u4e3a 100%\u3002\n+    \n+    \u5bfc\u5165\u8fdb\u5ea6\u5e76\u4e0d\u662f\u7ebf\u6027\u7684\u3002\u6240\u4ee5\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u5185\u8fdb\u5ea6\u6ca1\u6709\u53d8\u5316\uff0c\u5e76\u4e0d\u4ee3\u8868\u5bfc\u5165\u6ca1\u6709\u5728\u6267\u884c\u3002\n+    \n++ Type\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u7c7b\u578b\u3002Spark load \u4e3a SPARK\u3002    \n+\n++ CreateTime/EtlStartTime/EtlFinishTime/LoadStartTime/LoadFinishTime\n+\n+    \u8fd9\u51e0\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u5bfc\u5165\u521b\u5efa\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5b8c\u6210\u7684\u65f6\u95f4\uff0cLOADING \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\u548c\u6574\u4e2a\u5bfc\u5165\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u3002\n+\n++ JobDetails\n+\n+    \u663e\u793a\u4e00\u4e9b\u4f5c\u4e1a\u7684\u8be6\u7ec6\u8fd0\u884c\u72b6\u6001\uff0cETL \u7ed3\u675f\u7684\u65f6\u5019\u66f4\u65b0\u3002\u5305\u62ec\u5bfc\u5165\u6587\u4ef6\u7684\u4e2a\u6570\u3001\u603b\u5927\u5c0f\uff08\u5b57\u8282\uff09\u3001\u5b50\u4efb\u52a1\u4e2a\u6570\u3001\u5df2\u5904\u7406\u7684\u539f\u59cb\u884c\u6570\u7b49\u3002\n+\n+    ```{\"ScannedRows\":139264,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":940754064}```", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NDU2OQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTEzOTQ4NQ==", "bodyText": "ok", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429139485", "createdAt": "2020-05-22T09:23:29Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+- `broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker0\",\n+  \"broker.username\" = \"user0\",\n+  \"broker.password\" = \"password0\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+CREATE EXTERNAL RESOURCE \"spark1\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\", \n+  \"spark.master\" = \"spark://127.0.0.1:7777\",\n+  \"spark.submit.deployMode\" = \"client\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker1\"\n+);\n+```\n+\n+#### \u67e5\u770b\u8d44\u6e90\n+\n+\u666e\u901a\u8d26\u6237\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u6709USAGE_PRIV\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\n+\n+root\u548cadmin\u8d26\u6237\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u8d44\u6e90\u3002\n+\n+#### \u8d44\u6e90\u6743\u9650\n+\n+\u8d44\u6e90\u6743\u9650\u901a\u8fc7GRANT REVOKE\u6765\u7ba1\u7406\uff0c\u76ee\u524d\u4ec5\u652f\u6301USAGE_PRIV\u4f7f\u7528\u6743\u9650\u3002\n+\n+\u53ef\u4ee5\u5c06USAGE_PRIV\u6743\u9650\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u6216\u8005\u67d0\u4e2a\u89d2\u8272\uff0c\u89d2\u8272\u7684\u4f7f\u7528\u4e0e\u4e4b\u524d\u4e00\u81f4\u3002\n+```sql\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO \"user0\"@\"%\";\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO ROLE \"role0\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE * TO \"user0\"@\"%\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE * TO ROLE \"role0\";\n+-- \u64a4\u9500\u7528\u6237user0\u7684spark0\u8d44\u6e90\u4f7f\u7528\u6743\u9650\n+REVOKE USAGE_PRIV ON RESOURCE \"spark0\" FROM \"user0\"@\"%\";\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH RESOURCE resource_name resource_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* resource_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH RESOURCE 'spark0'\n+(\n+    \"spark.executor.memory\" = \"2g\",\n+    \"spark.shuffle.compress\" = \"true\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Spark\u8d44\u6e90\u53c2\u6570\n+\n+Spark\u8d44\u6e90\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u5e76\u4e14\u8d4b\u4e88\u7528\u6237USAGE_PRIV\u6743\u9650\u540e\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+```sql\n+WITH RESOURCE 'spark0'\n+(\n+  \"spark.driver.memory\" = \"1g\",\n+  \"spark.executor.memory\" = \"3g\"\n+)\n+```\n+\n+\n+\n+### \u67e5\u770b\u5bfc\u5165\n+\n+Spark load \u5bfc\u5165\u65b9\u5f0f\u540c Broker load \u4e00\u6837\u90fd\u662f\u5f02\u6b65\u7684\uff0c\u6240\u4ee5\u7528\u6237\u5fc5\u987b\u5c06\u521b\u5efa\u5bfc\u5165\u7684 Label \u8bb0\u5f55\uff0c\u5e76\u4e14\u5728**\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u4e2d\u4f7f\u7528 Label \u6765\u67e5\u770b\u5bfc\u5165\u7ed3\u679c**\u3002\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u5728\u6240\u6709\u5bfc\u5165\u65b9\u5f0f\u4e2d\u662f\u901a\u7528\u7684\uff0c\u5177\u4f53\u8bed\u6cd5\u53ef\u6267\u884c ```HELP SHOW LOAD``` \u67e5\u770b\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```\n+mysql> show load order by createtime desc limit 1\\G\n+*************************** 1. row ***************************\n+         JobId: 76391\n+         Label: label1\n+         State: FINISHED\n+      Progress: ETL:100%; LOAD:100%\n+          Type: SPARK\n+       EtlInfo: unselected.rows=4; dpp.abnorm.ALL=15; dpp.norm.ALL=28133376\n+      TaskInfo: cluster:cluster0; timeout(s):10800; max_filter_ratio:5.0E-5\n+      ErrorMsg: N/A\n+    CreateTime: 2019-07-27 11:46:42\n+  EtlStartTime: 2019-07-27 11:46:44\n+ EtlFinishTime: 2019-07-27 11:49:44\n+ LoadStartTime: 2019-07-27 11:49:44\n+LoadFinishTime: 2019-07-27 11:50:16\n+           URL: http://1.1.1.1:8089/proxy/application_1586619723848_0035/\n+    JobDetails: {\"ScannedRows\":28133395,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":200000}\n+```\n+\n+\u8fd4\u56de\u7ed3\u679c\u96c6\u4e2d\u53c2\u6570\u610f\u4e49\u53ef\u4ee5\u53c2\u8003 Broker load\u3002\u4e0d\u540c\u70b9\u5982\u4e0b\uff1a\n+\n++ State\n+\n+    \u5bfc\u5165\u4efb\u52a1\u5f53\u524d\u6240\u5904\u7684\u9636\u6bb5\u3002\u4efb\u52a1\u63d0\u4ea4\u4e4b\u540e\u72b6\u6001\u4e3a PENDING\uff0c\u63d0\u4ea4 Spark ETL \u4e4b\u540e\u72b6\u6001\u53d8\u4e3a ETL\uff0cETL \u5b8c\u6210\u4e4b\u540e FE \u8c03\u5ea6 BE \u6267\u884c push \u64cd\u4f5c\u72b6\u6001\u53d8\u4e3a LOADING\uff0cpush \u5b8c\u6210\u5e76\u4e14\u7248\u672c\u751f\u6548\u540e\u72b6\u6001\u53d8\u4e3a FINISHED\u3002\n+    \n+    \u5bfc\u5165\u4efb\u52a1\u7684\u6700\u7ec8\u9636\u6bb5\u6709\u4e24\u4e2a\uff1aCANCELLED \u548c FINISHED\uff0c\u5f53 Load job \u5904\u4e8e\u8fd9\u4e24\u4e2a\u9636\u6bb5\u65f6\u5bfc\u5165\u5b8c\u6210\u3002\u5176\u4e2d CANCELLED \u4e3a\u5bfc\u5165\u5931\u8d25\uff0cFINISHED \u4e3a\u5bfc\u5165\u6210\u529f\u3002\n+    \n++ Progress\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u8fdb\u5ea6\u63cf\u8ff0\u3002\u5206\u4e3a\u4e24\u79cd\u8fdb\u5ea6\uff1aETL \u548c LOAD\uff0c\u5bf9\u5e94\u4e86\u5bfc\u5165\u6d41\u7a0b\u7684\u4e24\u4e2a\u9636\u6bb5 ETL \u548c LOADING\u3002\n+    \n+    LOAD \u7684\u8fdb\u5ea6\u8303\u56f4\u4e3a\uff1a0~100%\u3002\n+    \n+    ```LOAD \u8fdb\u5ea6 = \u5f53\u524d\u5df2\u5b8c\u6210\u6240\u6709replica\u5bfc\u5165\u7684tablet\u4e2a\u6570 / \u672c\u6b21\u5bfc\u5165\u4efb\u52a1\u7684\u603btablet\u4e2a\u6570 * 100%``` \n+    \n+    **\u5982\u679c\u6240\u6709\u5bfc\u5165\u8868\u5747\u5b8c\u6210\u5bfc\u5165\uff0c\u6b64\u65f6 LOAD \u7684\u8fdb\u5ea6\u4e3a 99%** \u5bfc\u5165\u8fdb\u5165\u5230\u6700\u540e\u751f\u6548\u9636\u6bb5\uff0c\u6574\u4e2a\u5bfc\u5165\u5b8c\u6210\u540e\uff0cLOAD \u7684\u8fdb\u5ea6\u624d\u4f1a\u6539\u4e3a 100%\u3002\n+    \n+    \u5bfc\u5165\u8fdb\u5ea6\u5e76\u4e0d\u662f\u7ebf\u6027\u7684\u3002\u6240\u4ee5\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u5185\u8fdb\u5ea6\u6ca1\u6709\u53d8\u5316\uff0c\u5e76\u4e0d\u4ee3\u8868\u5bfc\u5165\u6ca1\u6709\u5728\u6267\u884c\u3002\n+    \n++ Type\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u7c7b\u578b\u3002Spark load \u4e3a SPARK\u3002    \n+\n++ CreateTime/EtlStartTime/EtlFinishTime/LoadStartTime/LoadFinishTime\n+\n+    \u8fd9\u51e0\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u5bfc\u5165\u521b\u5efa\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5b8c\u6210\u7684\u65f6\u95f4\uff0cLOADING \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\u548c\u6574\u4e2a\u5bfc\u5165\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u3002\n+\n++ JobDetails\n+\n+    \u663e\u793a\u4e00\u4e9b\u4f5c\u4e1a\u7684\u8be6\u7ec6\u8fd0\u884c\u72b6\u6001\uff0cETL \u7ed3\u675f\u7684\u65f6\u5019\u66f4\u65b0\u3002\u5305\u62ec\u5bfc\u5165\u6587\u4ef6\u7684\u4e2a\u6570\u3001\u603b\u5927\u5c0f\uff08\u5b57\u8282\uff09\u3001\u5b50\u4efb\u52a1\u4e2a\u6570\u3001\u5df2\u5904\u7406\u7684\u539f\u59cb\u884c\u6570\u7b49\u3002\n+\n+    ```{\"ScannedRows\":139264,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":940754064}```", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NDU2OQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 364}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTU5NTU3OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozOTowOVrOGXjtSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozOTowOVrOGXjtSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NTQ2Ng==", "bodyText": "\u8fd9\u4e2a\u6700\u597d\u6709\u5177\u4f53\u8bf4\u660e", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427355466", "createdAt": "2020-05-19T14:39:09Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/load-data/spark-load-manual.md", "diffHunk": "@@ -0,0 +1,397 @@\n+---\n+{\n+    \"title\": \"Spark Load\",\n+    \"language\": \"zh-CN\"\n+}\n+---  \n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Spark Load\n+\n+Spark load \u901a\u8fc7 Spark \u5b9e\u73b0\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\uff0c\u63d0\u9ad8 Doris \u5927\u6570\u636e\u91cf\u7684\u5bfc\u5165\u6027\u80fd\u5e76\u4e14\u8282\u7701 Doris \u96c6\u7fa4\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u4e3b\u8981\u7528\u4e8e\u521d\u6b21\u8fc1\u79fb\uff0c\u5927\u6570\u636e\u91cf\u5bfc\u5165 Doris \u7684\u573a\u666f\u3002\n+\n+Spark load \u662f\u4e00\u79cd\u5f02\u6b65\u5bfc\u5165\u65b9\u5f0f\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 MySQL \u534f\u8bae\u521b\u5efa Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7 `SHOW LOAD` \u67e5\u770b\u5bfc\u5165\u7ed3\u679c\u3002\n+\n+\n+\n+## \u9002\u7528\u573a\u666f\n+\n+* \u6e90\u6570\u636e\u5728 Spark \u53ef\u4ee5\u8bbf\u95ee\u7684\u5b58\u50a8\u7cfb\u7edf\u4e2d\uff0c\u5982 HDFS\u3002\n+* \u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\n+\n+\n+\n+## \u540d\u8bcd\u89e3\u91ca\n+\n+1. Frontend\uff08FE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u5143\u6570\u636e\u548c\u8c03\u5ea6\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u5bfc\u5165\u4efb\u52a1\u7684\u8c03\u5ea6\u5de5\u4f5c\u3002\n+2. Backend\uff08BE\uff09\uff1aDoris \u7cfb\u7edf\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u8282\u70b9\u3002\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5199\u5165\u53ca\u5b58\u50a8\u3002\n+3. Spark ETL\uff1a\u5728\u5bfc\u5165\u6d41\u7a0b\u4e2d\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u7684 ETL \u5de5\u4f5c\uff0c\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+4. Broker\uff1aBroker \u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u65e0\u72b6\u6001\u8fdb\u7a0b\u3002\u5c01\u88c5\u4e86\u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3\uff0c\u63d0\u4f9b Doris \u8bfb\u53d6\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6587\u4ef6\u7684\u80fd\u529b\u3002\n+\n+\n+## \u57fa\u672c\u539f\u7406\n+\n+### \u57fa\u672c\u6d41\u7a0b\n+\n+\u7528\u6237\u901a\u8fc7 MySQL \u5ba2\u6237\u7aef\u63d0\u4ea4 Spark \u7c7b\u578b\u5bfc\u5165\u4efb\u52a1\uff0cFE\u8bb0\u5f55\u5143\u6570\u636e\u5e76\u8fd4\u56de\u7528\u6237\u63d0\u4ea4\u6210\u529f\u3002\n+\n+Spark load \u4efb\u52a1\u7684\u6267\u884c\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b5\u4e2a\u9636\u6bb5\u3002\n+\n+1. FE \u8c03\u5ea6\u63d0\u4ea4 ETL \u4efb\u52a1\u5230 Spark \u96c6\u7fa4\u6267\u884c\u3002\n+2. Spark \u96c6\u7fa4\u6267\u884c ETL \u5b8c\u6210\u5bf9\u5bfc\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u3002\u5305\u62ec\u5168\u5c40\u5b57\u5178\u6784\u5efa\uff08BITMAP\u7c7b\u578b\uff09\u3001\u5206\u533a\u3001\u6392\u5e8f\u3001\u805a\u5408\u7b49\u3002\n+3. ETL \u4efb\u52a1\u5b8c\u6210\u540e\uff0cFE \u83b7\u53d6\u9884\u5904\u7406\u8fc7\u7684\u6bcf\u4e2a\u5206\u7247\u7684\u6570\u636e\u8def\u5f84\uff0c\u5e76\u8c03\u5ea6\u76f8\u5173\u7684 BE \u6267\u884c Push \u4efb\u52a1\u3002\n+4. BE \u901a\u8fc7 Broker \u8bfb\u53d6\u6570\u636e\uff0c\u8f6c\u5316\u4e3a Doris \u5e95\u5c42\u5b58\u50a8\u683c\u5f0f\u3002\n+5. FE \u8c03\u5ea6\u751f\u6548\u7248\u672c\uff0c\u5b8c\u6210\u5bfc\u5165\u4efb\u52a1\u3002\n+\n+```\n+                 +\n+                 | 0. User create spark load job\n+            +----v----+\n+            |   FE    |---------------------------------+\n+            +----+----+                                 |\n+                 | 3. FE send push tasks                |\n+                 | 5. FE publish version                |\n+    +------------+------------+                         |\n+    |            |            |                         |\n++---v---+    +---v---+    +---v---+                     |\n+|  BE   |    |  BE   |    |  BE   |                     |1. FE submit Spark ETL job\n++---^---+    +---^---+    +---^---+                     |\n+    |4. BE push with broker   |                         |\n++---+---+    +---+---+    +---+---+                     |\n+|Broker |    |Broker |    |Broker |                     |\n++---^---+    +---^---+    +---^---+                     |\n+    |            |            |                         |\n++---+------------+------------+---+ 2.ETL +-------------v---------------+\n+|               HDFS              +------->       Spark cluster         |\n+|                                 <-------+                             |\n++---------------------------------+       +-----------------------------+\n+\n+```\n+\n+\n+\n+### \u5168\u5c40\u5b57\u5178\n+\n+\u5f85\u8865\n+\n+\n+\n+### \u6570\u636e\u9884\u5904\u7406\uff08DPP\uff09\n+\n+\u5f85\u8865\n+\n+\n+\n+## \u57fa\u672c\u64cd\u4f5c\n+\n+### \u914d\u7f6e ETL \u96c6\u7fa4\n+\n+Spark\u4f5c\u4e3a\u4e00\u79cd\u5916\u90e8\u8ba1\u7b97\u8d44\u6e90\u5728Doris\u4e2d\u7528\u6765\u5b8c\u6210ETL\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u80fd\u8fd8\u6709\u5176\u4ed6\u7684\u5916\u90e8\u8d44\u6e90\u4f1a\u52a0\u5165\u5230Doris\u4e2d\u4f7f\u7528\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cMapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165resource management\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\u63d0\u4ea4 Spark \u5bfc\u5165\u4efb\u52a1\u4e4b\u524d\uff0c\u9700\u8981\u914d\u7f6e\u6267\u884c ETL \u4efb\u52a1\u7684 Spark \u96c6\u7fa4\u3002\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+-- create spark resource\n+CREATE EXTERNAL RESOURCE resource_name\n+PROPERTIES \n+(                 \n+  type = spark,\n+  spark_conf_key = spark_conf_value,\n+  working_dir = path,\n+  broker = broker_name,\n+  broker.property_key = property_value\n+)\n+\n+-- drop spark resource\n+DROP RESOURCE resource_name\n+\n+-- show resources\n+SHOW RESOURCES\n+SHOW PROC \"/resources\"\n+\n+-- privileges\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO user_identity\n+GRANT USAGE_PRIV ON RESOURCE resource_name TO ROLE role_name\n+\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM user_identity\n+REVOKE USAGE_PRIV ON RESOURCE resource_name FROM ROLE role_name\n+```\n+\n+#### \u521b\u5efa\u8d44\u6e90\n+\n+`resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684 Spark \u8d44\u6e90\u7684\u540d\u5b57\u3002\n+\n+`PROPERTIES` \u662f Spark \u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+\n+- `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+\n+- Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+  - `spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+  - `spark.submit.deployMode`:  Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+  - `spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - `spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+  - \u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html \n+- `working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+- `broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002\n+  - `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+-- yarn cluster \u6a21\u5f0f \n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker0\",\n+  \"broker.username\" = \"user0\",\n+  \"broker.password\" = \"password0\"\n+);\n+\n+-- spark standalone client \u6a21\u5f0f\n+CREATE EXTERNAL RESOURCE \"spark1\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\", \n+  \"spark.master\" = \"spark://127.0.0.1:7777\",\n+  \"spark.submit.deployMode\" = \"client\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",\n+  \"broker\" = \"broker1\"\n+);\n+```\n+\n+#### \u67e5\u770b\u8d44\u6e90\n+\n+\u666e\u901a\u8d26\u6237\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u6709USAGE_PRIV\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\n+\n+root\u548cadmin\u8d26\u6237\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u8d44\u6e90\u3002\n+\n+#### \u8d44\u6e90\u6743\u9650\n+\n+\u8d44\u6e90\u6743\u9650\u901a\u8fc7GRANT REVOKE\u6765\u7ba1\u7406\uff0c\u76ee\u524d\u4ec5\u652f\u6301USAGE_PRIV\u4f7f\u7528\u6743\u9650\u3002\n+\n+\u53ef\u4ee5\u5c06USAGE_PRIV\u6743\u9650\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u6216\u8005\u67d0\u4e2a\u89d2\u8272\uff0c\u89d2\u8272\u7684\u4f7f\u7528\u4e0e\u4e4b\u524d\u4e00\u81f4\u3002\n+```sql\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO \"user0\"@\"%\";\n+-- \u6388\u4e88spark0\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE \"spark0\" TO ROLE \"role0\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237user0\n+GRANT USAGE_PRIV ON RESOURCE * TO \"user0\"@\"%\";\n+-- \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272role0\n+GRANT USAGE_PRIV ON RESOURCE * TO ROLE \"role0\";\n+-- \u64a4\u9500\u7528\u6237user0\u7684spark0\u8d44\u6e90\u4f7f\u7528\u6743\u9650\n+REVOKE USAGE_PRIV ON RESOURCE \"spark0\" FROM \"user0\"@\"%\";\n+```\n+\n+\n+\n+### \u521b\u5efa\u5bfc\u5165\n+\n+\u8bed\u6cd5\uff1a\n+\n+```sql\n+LOAD LABEL load_label \n+    (data_desc, ...)\n+    WITH RESOURCE resource_name resource_properties\n+    [PROPERTIES (key1=value1, ... )]\n+\n+* load_label:\n+\tdb_name.label_name\n+\n+* data_desc:\n+    DATA INFILE ('file_path', ...)\n+    [NEGATIVE]\n+    INTO TABLE tbl_name\n+    [PARTITION (p1, p2)]\n+    [COLUMNS TERMINATED BY separator ]\n+    [(col1, ...)]\n+    [SET (k1=f1(xx), k2=f2(xx))]\n+    [WHERE predicate]\n+\n+* resource_properties: \n+    (key2=value2, ...)\n+```\n+\u793a\u4f8b\uff1a\n+\n+```sql\n+LOAD LABEL db1.label1\n+(\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file1\")\n+    INTO TABLE tbl1\n+    COLUMNS TERMINATED BY \",\"\n+    (tmp_c1,tmp_c2)\n+    SET\n+    (\n+        id=tmp_c2,\n+        name=tmp_c1\n+    ),\n+    DATA INFILE(\"hdfs://abc.com:8888/user/palo/test/ml/file2\")\n+    INTO TABLE tbl2\n+    COLUMNS TERMINATED BY \",\"\n+    (col1, col2)\n+    where col1 > 1\n+)\n+WITH RESOURCE 'spark0'\n+(\n+    \"spark.executor.memory\" = \"2g\",\n+    \"spark.shuffle.compress\" = \"true\"\n+)\n+PROPERTIES\n+(\n+    \"timeout\" = \"3600\"\n+);\n+\n+```\n+\n+\u521b\u5efa\u5bfc\u5165\u7684\u8be6\u7ec6\u8bed\u6cd5\u6267\u884c ```HELP SPARK LOAD``` \u67e5\u770b\u8bed\u6cd5\u5e2e\u52a9\u3002\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd Spark load \u7684\u521b\u5efa\u5bfc\u5165\u8bed\u6cd5\u4e2d\u53c2\u6570\u610f\u4e49\u548c\u6ce8\u610f\u4e8b\u9879\u3002\n+\n+#### Label\n+\n+\u5bfc\u5165\u4efb\u52a1\u7684\u6807\u8bc6\u3002\u6bcf\u4e2a\u5bfc\u5165\u4efb\u52a1\uff0c\u90fd\u6709\u4e00\u4e2a\u5728\u5355 database \u5185\u90e8\u552f\u4e00\u7684 Label\u3002\u5177\u4f53\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u6570\u636e\u63cf\u8ff0\u7c7b\u53c2\u6570\n+\n+\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u6e90\u6709CSV\u548chive table\u3002\u5176\u4ed6\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### \u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\n+\n+\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u4e3b\u8981\u6307\u7684\u662f Spark load \u521b\u5efa\u5bfc\u5165\u8bed\u53e5\u4e2d\u7684\u5c5e\u4e8e ```opt_properties```\u90e8\u5206\u7684\u53c2\u6570\u3002\u5bfc\u5165\u4f5c\u4e1a\u53c2\u6570\u662f\u4f5c\u7528\u4e8e\u6574\u4e2a\u5bfc\u5165\u4f5c\u4e1a\u7684\u3002\u89c4\u5219\u4e0e `Broker Load` \u4e00\u81f4\u3002\n+\n+#### Spark\u8d44\u6e90\u53c2\u6570\n+\n+Spark\u8d44\u6e90\u9700\u8981\u63d0\u524d\u914d\u7f6e\u5230 Doris\u7cfb\u7edf\u4e2d\u5e76\u4e14\u8d4b\u4e88\u7528\u6237USAGE_PRIV\u6743\u9650\u540e\u624d\u80fd\u4f7f\u7528 Spark load\u3002\n+\n+\u5f53\u7528\u6237\u6709\u4e34\u65f6\u6027\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u589e\u52a0\u4efb\u52a1\u4f7f\u7528\u7684\u8d44\u6e90\u800c\u4fee\u6539 Spark configs\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6e\uff0c\u8bbe\u7f6e\u4ec5\u5bf9\u672c\u6b21\u4efb\u52a1\u751f\u6548\uff0c\u5e76\u4e0d\u5f71\u54cd Doris \u96c6\u7fa4\u4e2d\u5df2\u6709\u7684\u914d\u7f6e\u3002\n+\n+```sql\n+WITH RESOURCE 'spark0'\n+(\n+  \"spark.driver.memory\" = \"1g\",\n+  \"spark.executor.memory\" = \"3g\"\n+)\n+```\n+\n+\n+\n+### \u67e5\u770b\u5bfc\u5165\n+\n+Spark load \u5bfc\u5165\u65b9\u5f0f\u540c Broker load \u4e00\u6837\u90fd\u662f\u5f02\u6b65\u7684\uff0c\u6240\u4ee5\u7528\u6237\u5fc5\u987b\u5c06\u521b\u5efa\u5bfc\u5165\u7684 Label \u8bb0\u5f55\uff0c\u5e76\u4e14\u5728**\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u4e2d\u4f7f\u7528 Label \u6765\u67e5\u770b\u5bfc\u5165\u7ed3\u679c**\u3002\u67e5\u770b\u5bfc\u5165\u547d\u4ee4\u5728\u6240\u6709\u5bfc\u5165\u65b9\u5f0f\u4e2d\u662f\u901a\u7528\u7684\uff0c\u5177\u4f53\u8bed\u6cd5\u53ef\u6267\u884c ```HELP SHOW LOAD``` \u67e5\u770b\u3002\n+\n+\u793a\u4f8b\uff1a\n+\n+```\n+mysql> show load order by createtime desc limit 1\\G\n+*************************** 1. row ***************************\n+         JobId: 76391\n+         Label: label1\n+         State: FINISHED\n+      Progress: ETL:100%; LOAD:100%\n+          Type: SPARK\n+       EtlInfo: unselected.rows=4; dpp.abnorm.ALL=15; dpp.norm.ALL=28133376\n+      TaskInfo: cluster:cluster0; timeout(s):10800; max_filter_ratio:5.0E-5\n+      ErrorMsg: N/A\n+    CreateTime: 2019-07-27 11:46:42\n+  EtlStartTime: 2019-07-27 11:46:44\n+ EtlFinishTime: 2019-07-27 11:49:44\n+ LoadStartTime: 2019-07-27 11:49:44\n+LoadFinishTime: 2019-07-27 11:50:16\n+           URL: http://1.1.1.1:8089/proxy/application_1586619723848_0035/\n+    JobDetails: {\"ScannedRows\":28133395,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":200000}\n+```\n+\n+\u8fd4\u56de\u7ed3\u679c\u96c6\u4e2d\u53c2\u6570\u610f\u4e49\u53ef\u4ee5\u53c2\u8003 Broker load\u3002\u4e0d\u540c\u70b9\u5982\u4e0b\uff1a\n+\n++ State\n+\n+    \u5bfc\u5165\u4efb\u52a1\u5f53\u524d\u6240\u5904\u7684\u9636\u6bb5\u3002\u4efb\u52a1\u63d0\u4ea4\u4e4b\u540e\u72b6\u6001\u4e3a PENDING\uff0c\u63d0\u4ea4 Spark ETL \u4e4b\u540e\u72b6\u6001\u53d8\u4e3a ETL\uff0cETL \u5b8c\u6210\u4e4b\u540e FE \u8c03\u5ea6 BE \u6267\u884c push \u64cd\u4f5c\u72b6\u6001\u53d8\u4e3a LOADING\uff0cpush \u5b8c\u6210\u5e76\u4e14\u7248\u672c\u751f\u6548\u540e\u72b6\u6001\u53d8\u4e3a FINISHED\u3002\n+    \n+    \u5bfc\u5165\u4efb\u52a1\u7684\u6700\u7ec8\u9636\u6bb5\u6709\u4e24\u4e2a\uff1aCANCELLED \u548c FINISHED\uff0c\u5f53 Load job \u5904\u4e8e\u8fd9\u4e24\u4e2a\u9636\u6bb5\u65f6\u5bfc\u5165\u5b8c\u6210\u3002\u5176\u4e2d CANCELLED \u4e3a\u5bfc\u5165\u5931\u8d25\uff0cFINISHED \u4e3a\u5bfc\u5165\u6210\u529f\u3002\n+    \n++ Progress\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u8fdb\u5ea6\u63cf\u8ff0\u3002\u5206\u4e3a\u4e24\u79cd\u8fdb\u5ea6\uff1aETL \u548c LOAD\uff0c\u5bf9\u5e94\u4e86\u5bfc\u5165\u6d41\u7a0b\u7684\u4e24\u4e2a\u9636\u6bb5 ETL \u548c LOADING\u3002\n+    \n+    LOAD \u7684\u8fdb\u5ea6\u8303\u56f4\u4e3a\uff1a0~100%\u3002\n+    \n+    ```LOAD \u8fdb\u5ea6 = \u5f53\u524d\u5df2\u5b8c\u6210\u6240\u6709replica\u5bfc\u5165\u7684tablet\u4e2a\u6570 / \u672c\u6b21\u5bfc\u5165\u4efb\u52a1\u7684\u603btablet\u4e2a\u6570 * 100%``` \n+    \n+    **\u5982\u679c\u6240\u6709\u5bfc\u5165\u8868\u5747\u5b8c\u6210\u5bfc\u5165\uff0c\u6b64\u65f6 LOAD \u7684\u8fdb\u5ea6\u4e3a 99%** \u5bfc\u5165\u8fdb\u5165\u5230\u6700\u540e\u751f\u6548\u9636\u6bb5\uff0c\u6574\u4e2a\u5bfc\u5165\u5b8c\u6210\u540e\uff0cLOAD \u7684\u8fdb\u5ea6\u624d\u4f1a\u6539\u4e3a 100%\u3002\n+    \n+    \u5bfc\u5165\u8fdb\u5ea6\u5e76\u4e0d\u662f\u7ebf\u6027\u7684\u3002\u6240\u4ee5\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u5185\u8fdb\u5ea6\u6ca1\u6709\u53d8\u5316\uff0c\u5e76\u4e0d\u4ee3\u8868\u5bfc\u5165\u6ca1\u6709\u5728\u6267\u884c\u3002\n+    \n++ Type\n+\n+    \u5bfc\u5165\u4efb\u52a1\u7684\u7c7b\u578b\u3002Spark load \u4e3a SPARK\u3002    \n+\n++ CreateTime/EtlStartTime/EtlFinishTime/LoadStartTime/LoadFinishTime\n+\n+    \u8fd9\u51e0\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u5bfc\u5165\u521b\u5efa\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\uff0cETL \u9636\u6bb5\u5b8c\u6210\u7684\u65f6\u95f4\uff0cLOADING \u9636\u6bb5\u5f00\u59cb\u7684\u65f6\u95f4\u548c\u6574\u4e2a\u5bfc\u5165\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u3002\n+\n++ JobDetails\n+\n+    \u663e\u793a\u4e00\u4e9b\u4f5c\u4e1a\u7684\u8be6\u7ec6\u8fd0\u884c\u72b6\u6001\uff0cETL \u7ed3\u675f\u7684\u65f6\u5019\u66f4\u65b0\u3002\u5305\u62ec\u5bfc\u5165\u6587\u4ef6\u7684\u4e2a\u6570\u3001\u603b\u5927\u5c0f\uff08\u5b57\u8282\uff09\u3001\u5b50\u4efb\u52a1\u4e2a\u6570\u3001\u5df2\u5904\u7406\u7684\u539f\u59cb\u884c\u6570\u7b49\u3002\n+\n+    ```{\"ScannedRows\":139264,\"TaskNumber\":1,\"FileNumber\":1,\"FileSize\":940754064}```\n+\n+### \u53d6\u6d88\u5bfc\u5165\n+\n+\u5f53 Spark load \u4f5c\u4e1a\u72b6\u6001\u4e0d\u4e3a CANCELLED \u6216 FINISHED \u65f6\uff0c\u53ef\u4ee5\u88ab\u7528\u6237\u624b\u52a8\u53d6\u6d88\u3002\u53d6\u6d88\u65f6\u9700\u8981\u6307\u5b9a\u5f85\u53d6\u6d88\u5bfc\u5165\u4efb\u52a1\u7684 Label \u3002\u53d6\u6d88\u5bfc\u5165\u547d\u4ee4\u8bed\u6cd5\u53ef\u6267\u884c ```HELP CANCEL LOAD```\u67e5\u770b\u3002\n+\n+\n+\n+## \u76f8\u5173\u7cfb\u7edf\u914d\u7f6e\n+\n+### FE \u914d\u7f6e\n+\n+\u4e0b\u9762\u914d\u7f6e\u5c5e\u4e8e Spark load \u7684\u7cfb\u7edf\u7ea7\u522b\u914d\u7f6e\uff0c\u4e5f\u5c31\u662f\u4f5c\u7528\u4e8e\u6240\u6709 Spark load \u5bfc\u5165\u4efb\u52a1\u7684\u914d\u7f6e\u3002\u4e3b\u8981\u901a\u8fc7\u4fee\u6539 ``` fe.conf```\u6765\u8c03\u6574\u914d\u7f6e\u503c\u3002\n+\n++ spark_load_default_timeout_second\n+  \n+    \u4efb\u52a1\u9ed8\u8ba4\u8d85\u65f6\u65f6\u95f4\u4e3a259200\u79d2\uff083\u5929\uff09\u3002\n+    \n+    \n+\n+## \u6700\u4f73\u5b9e\u8df5\n+\n+### \u5e94\u7528\u573a\u666f\n+\n+\u4f7f\u7528 Spark load \u6700\u9002\u5408\u7684\u573a\u666f\u5c31\u662f\u539f\u59cb\u6570\u636e\u5728\u6587\u4ef6\u7cfb\u7edf\uff08HDFS\uff09\u4e2d\uff0c\u6570\u636e\u91cf\u5728 \u51e0\u5341 GB \u5230 TB \u7ea7\u522b\u3002\u5c0f\u6570\u636e\u91cf\u8fd8\u662f\u5efa\u8bae\u4f7f\u7528 Stream load \u6216\u8005 Broker load\u3002\n+\n+\n+\n+## \u5e38\u89c1\u95ee\u9898\n+\n+* \u4f7f\u7528Spark load\u65f6\u9700\u8981\u5728FE\u673a\u5668\u8bbe\u7f6eSPARK_HOME\u53caHADOOP_CONF_DIR\u73af\u5883\u53d8\u91cf\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 394}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTU5OTIwOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozOTo1NVrOGXjvqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDozOTo1NVrOGXjvqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NjA3Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                GRANT privilege_list ON resource_name TO user_identity [ROLE role_name]\n          \n          \n            \n                GRANT privilege_list ON RESOURCE resource_name TO user_identity [ROLE role_name]", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427356073", "createdAt": "2020-05-19T14:39:55Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "diffHunk": "@@ -33,6 +33,8 @@ Syntax:\n \n     GRANT privilege_list ON db_name[.tbl_name] TO user_identity [ROLE role_name]\n \n+    GRANT privilege_list ON resource_name TO user_identity [ROLE role_name]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTYwMjU5OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MDozOVrOGXjx2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MDozOVrOGXjx2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NjYzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    GRANT USAGE_PRIV ON 'spark_resource' TO 'jack'@'%';\n          \n          \n            \n                    GRANT USAGE_PRIV ON RESOURCE 'spark_resource' TO 'jack'@'%';", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427356633", "createdAt": "2020-05-19T14:40:39Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "diffHunk": "@@ -76,6 +92,18 @@ user_identity\uff1a\n \n         GRANT LOAD_PRIV ON db1.* TO ROLE 'my_role';\n \n+    4. \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237\n+\n+        GRANT USAGE_PRIV ON * TO 'jack'@'%';\n+\n+    5. \u6388\u4e88\u6307\u5b9a\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237\n+\n+        GRANT USAGE_PRIV ON 'spark_resource' TO 'jack'@'%';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTYwMzgzOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MDo1MFrOGXjymA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MDo1MFrOGXjymA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NjgyNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    GRANT USAGE_PRIV ON 'spark_resource' TO ROLE 'my_role';\n          \n          \n            \n                    GRANT USAGE_PRIV ON RESOURCE 'spark_resource' TO ROLE 'my_role';", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427356824", "createdAt": "2020-05-19T14:40:50Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/GRANT.md", "diffHunk": "@@ -76,6 +92,18 @@ user_identity\uff1a\n \n         GRANT LOAD_PRIV ON db1.* TO ROLE 'my_role';\n \n+    4. \u6388\u4e88\u6240\u6709\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237\n+\n+        GRANT USAGE_PRIV ON * TO 'jack'@'%';\n+\n+    5. \u6388\u4e88\u6307\u5b9a\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u7528\u6237\n+\n+        GRANT USAGE_PRIV ON 'spark_resource' TO 'jack'@'%';\n+\n+    6. \u6388\u4e88\u6307\u5b9a\u8d44\u6e90\u7684\u4f7f\u7528\u6743\u9650\u7ed9\u89d2\u8272\n+\n+        GRANT USAGE_PRIV ON 'spark_resource' TO ROLE 'my_role';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTYwNTI2OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/REVOKE.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MTowNlrOGXjzfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MTowNlrOGXjzfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NzA1NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    REVOKE privilege_list ON resource_name FROM user_identity [ROLE role_name]\n          \n          \n            \n                    REVOKE privilege_list ON RESOURCE resource_name FROM user_identity [ROLE role_name]", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427357054", "createdAt": "2020-05-19T14:41:06Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/REVOKE.md", "diffHunk": "@@ -30,6 +30,8 @@ under the License.\n     REVOKE \u547d\u4ee4\u7528\u4e8e\u64a4\u9500\u6307\u5b9a\u7528\u6237\u6216\u89d2\u8272\u6307\u5b9a\u7684\u6743\u9650\u3002\n     Syntax\uff1a\n         REVOKE privilege_list ON db_name[.tbl_name] FROM user_identity [ROLE role_name]\n+\n+        REVOKE privilege_list ON resource_name FROM user_identity [ROLE role_name]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTYwNjAzOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/REVOKE.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MToxM1rOGXjz8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0MToxM1rOGXjz8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM1NzE2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    REVOKE USAGE_RPIV ON 'spark_resource' FROM 'jack'@'192.%';\n          \n          \n            \n                    REVOKE USAGE_RPIV ON RESOURCE 'spark_resource' FROM 'jack'@'192.%';", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427357168", "createdAt": "2020-05-19T14:41:13Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/sql-reference/sql-statements/Account Management/REVOKE.md", "diffHunk": "@@ -43,6 +45,10 @@ under the License.\n    \n         REVOKE SELECT_PRIV ON db1.* FROM 'jack'@'192.%';\n \n+    1. \u64a4\u9500\u7528\u6237 jack \u8d44\u6e90 spark_resource \u7684\u4f7f\u7528\u6743\u9650\n+\n+        REVOKE USAGE_RPIV ON 'spark_resource' FROM 'jack'@'192.%';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTY0NDkwOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNDo0OToxM1rOGXkNGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwOTowMTozNlrOGZP9MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM2MzYwOQ==", "bodyText": "Enum class has a method valueOf(String), which is same as this fromString()", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427363609", "createdAt": "2020-05-19T14:49:13Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "diffHunk": "@@ -0,0 +1,110 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public abstract class Resource implements Writable {\n+    public enum ResourceType {\n+        UNKNOWN,\n+        SPARK;\n+\n+        public static ResourceType fromString(String resourceType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTEyOTAwOA==", "bodyText": "CaseInsensitive in fromString function and return UNKNOWN if resourceType does not exist", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429129008", "createdAt": "2020-05-22T09:01:36Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/catalog/Resource.java", "diffHunk": "@@ -0,0 +1,110 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public abstract class Resource implements Writable {\n+    public enum ResourceType {\n+        UNKNOWN,\n+        SPARK;\n+\n+        public static ResourceType fromString(String resourceType) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM2MzYwOQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTcxNTAyOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowMzo0N1rOGXk6iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowMzo0N1rOGXk6iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3NTI0Mw==", "bodyText": "Why not just use resourceMgr.write()?", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427375243", "createdAt": "2020-05-19T15:03:47Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "diffHunk": "@@ -2155,6 +2176,18 @@ public long saveLoadJobsV2(DataOutputStream out, long checksum) throws IOExcepti\n         return checksum;\n     }\n \n+    public long saveResources(DataOutputStream dos, long checksum) throws IOException {\n+        Collection<Resource> resources = resourceMgr.getResources();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTcyMDkzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowNTowNlrOGXk-Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowNTowNlrOGXk-Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3NjIxOA==", "bodyText": "I think this procNode can be created when constructing this class.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427376218", "createdAt": "2020-05-19T15:05:06Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "diffHunk": "@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.analysis.DropResourceStmt;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.common.proc.ProcNodeInterface;\n+import org.apache.doris.common.proc.ProcResult;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Maps;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+/**\n+ * Resource manager is responsible for managing external resources used by Doris.\n+ * For example, Spark/MapReduce used for ETL, Spark/GPU used for queries, HDFS/S3 used for external storage.\n+ * Now only support Spark.\n+ */\n+public class ResourceMgr {\n+    private static final Logger LOG = LogManager.getLogger(ResourceMgr.class);\n+\n+    public static final ImmutableList<String> RESOURCE_PROC_NODE_TITLE_NAMES = new ImmutableList.Builder<String>()\n+            .add(\"Name\").add(\"ResourceType\").add(\"Key\").add(\"Value\")\n+            .build();\n+\n+    // { resourceName -> Resource}\n+    private final Map<String, Resource> nameToResource = Maps.newHashMap();\n+    private final ReentrantLock lock = new ReentrantLock();\n+    private ResourceProcNode procNode = null;\n+\n+    public ResourceMgr() {\n+    }\n+\n+    public void createResource(CreateResourceStmt stmt) throws DdlException {\n+        lock.lock();\n+        try {\n+            if (stmt.getResourceType() != ResourceType.SPARK) {\n+                throw new DdlException(\"Only support Spark resource.\");\n+            }\n+\n+            String resourceName = stmt.getResourceName();\n+            if (nameToResource.containsKey(resourceName)) {\n+                throw new DdlException(\"Resource(\" + resourceName + \") already exist\");\n+            }\n+\n+            Resource resource = Resource.fromStmt(stmt);\n+            nameToResource.put(resourceName, resource);\n+            // log add\n+            Catalog.getInstance().getEditLog().logCreateResource(resource);\n+            LOG.info(\"create resource success. resource: {}\", resource);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void replayCreateResource(Resource resource) {\n+        lock.lock();\n+        try {\n+            nameToResource.put(resource.getName(), resource);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void dropResource(DropResourceStmt stmt) throws DdlException {\n+        lock.lock();\n+        try {\n+            String name = stmt.getResourceName();\n+            if (!nameToResource.containsKey(name)) {\n+                throw new DdlException(\"Resource(\" + name + \") does not exist\");\n+            }\n+\n+            nameToResource.remove(name);\n+            // log drop\n+            Catalog.getInstance().getEditLog().logDropResource(name);\n+            LOG.info(\"drop resource success. resource name: {}\", name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void replayDropResource(String name) {\n+        lock.lock();\n+        try {\n+            nameToResource.remove(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public boolean containsResource(String name) {\n+        lock.lock();\n+        try {\n+            return nameToResource.containsKey(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public Resource getResource(String name) {\n+        lock.lock();\n+        try {\n+            return nameToResource.get(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    // for catalog save image\n+    public Collection<Resource> getResources() {\n+        return nameToResource.values();\n+    }\n+\n+    public List<List<String>> getResourcesInfo() {\n+        lock.lock();\n+        try {\n+            if (procNode == null) {\n+                procNode = new ResourceProcNode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTczMDU0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowNzoxNVrOGXlEtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowNzoxNVrOGXlEtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3Nzg0Ng==", "bodyText": "I think a concurrentMap is enough. And the lock is only used when creating the resource,\nto make \"create resource\" and \"write edit log\" atomic.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427377846", "createdAt": "2020-05-19T15:07:15Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "diffHunk": "@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.analysis.DropResourceStmt;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.common.proc.ProcNodeInterface;\n+import org.apache.doris.common.proc.ProcResult;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Maps;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+/**\n+ * Resource manager is responsible for managing external resources used by Doris.\n+ * For example, Spark/MapReduce used for ETL, Spark/GPU used for queries, HDFS/S3 used for external storage.\n+ * Now only support Spark.\n+ */\n+public class ResourceMgr {\n+    private static final Logger LOG = LogManager.getLogger(ResourceMgr.class);\n+\n+    public static final ImmutableList<String> RESOURCE_PROC_NODE_TITLE_NAMES = new ImmutableList.Builder<String>()\n+            .add(\"Name\").add(\"ResourceType\").add(\"Key\").add(\"Value\")\n+            .build();\n+\n+    // { resourceName -> Resource}\n+    private final Map<String, Resource> nameToResource = Maps.newHashMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MTczOTIyOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloPrivilege.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNTowOTowOFrOGXlKGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzoxOTo0MFrOGZNJ3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3OTIyNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                USAGE_PRIV(\"Usage_priv\", 8, \"Privilege for use resource\");\n          \n          \n            \n                USAGE_PRIV(\"Usage_priv\", 8, \"Privilege for accessing resource\");", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r427379225", "createdAt": "2020-05-19T15:09:08Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloPrivilege.java", "diffHunk": "@@ -25,7 +25,8 @@\n     LOAD_PRIV(\"Load_priv\", 4, \"Privilege for loading data into tables\"),\n     ALTER_PRIV(\"Alter_priv\", 5, \"Privilege for alter database or table\"),\n     CREATE_PRIV(\"Create_priv\", 6, \"Privilege for createing database or table\"),\n-    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\");\n+    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\"),\n+    USAGE_PRIV(\"Usage_priv\", 8, \"Privilege for use resource\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0NTMxMQ==", "bodyText": "using resource\uff1f\nreference snowflake usage privilege", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r428745311", "createdAt": "2020-05-21T15:51:40Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloPrivilege.java", "diffHunk": "@@ -25,7 +25,8 @@\n     LOAD_PRIV(\"Load_priv\", 4, \"Privilege for loading data into tables\"),\n     ALTER_PRIV(\"Alter_priv\", 5, \"Privilege for alter database or table\"),\n     CREATE_PRIV(\"Create_priv\", 6, \"Privilege for createing database or table\"),\n-    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\");\n+    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\"),\n+    USAGE_PRIV(\"Usage_priv\", 8, \"Privilege for use resource\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3OTIyNQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzEwMg==", "bodyText": "ok", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429083102", "createdAt": "2020-05-22T07:19:40Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloPrivilege.java", "diffHunk": "@@ -25,7 +25,8 @@\n     LOAD_PRIV(\"Load_priv\", 4, \"Privilege for loading data into tables\"),\n     ALTER_PRIV(\"Alter_priv\", 5, \"Privilege for alter database or table\"),\n     CREATE_PRIV(\"Create_priv\", 6, \"Privilege for createing database or table\"),\n-    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\");\n+    DROP_PRIV(\"Drop_priv\", 7, \"Privilege for dropping database or table\"),\n+    USAGE_PRIV(\"Usage_priv\", 8, \"Privilege for use resource\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3OTIyNQ=="}, "originalCommit": {"oid": "6b59bc0cd9e4823a579d19133e50753db44c001b"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTg3MzAxOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/analysis/ResourcePattern.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjozMzo1N1rOGZI1IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwODo1ODoyNlrOGZP3Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxMjI1Nw==", "bodyText": "Is this isAnalyzed needed?", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429012257", "createdAt": "2020-05-22T02:33:57Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/analysis/ResourcePattern.java", "diffHunk": "@@ -0,0 +1,118 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.mysql.privilege.PaloAuth.PrivLevel;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+\n+// only the following 2 formats are allowed\n+// *\n+// resource\n+public class ResourcePattern implements Writable {\n+    private String resourceName;\n+    boolean isAnalyzed = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTEyNzQ1OQ==", "bodyText": "removed", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429127459", "createdAt": "2020-05-22T08:58:26Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/analysis/ResourcePattern.java", "diffHunk": "@@ -0,0 +1,118 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.mysql.privilege.PaloAuth.PrivLevel;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+\n+// only the following 2 formats are allowed\n+// *\n+// resource\n+public class ResourcePattern implements Writable {\n+    private String resourceName;\n+    boolean isAnalyzed = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxMjI1Nw=="}, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTg3Mzg1OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/analysis/ResourcePattern.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjozNDoyOFrOGZI1pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjozNDoyOFrOGZI1pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxMjM4OQ==", "bodyText": "Please serialize in a json format, you can refer to other class usage.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429012389", "createdAt": "2020-05-22T02:34:28Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/analysis/ResourcePattern.java", "diffHunk": "@@ -0,0 +1,118 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.analysis;\n+\n+import org.apache.doris.common.AnalysisException;\n+import org.apache.doris.common.FeNameFormat;\n+import org.apache.doris.common.io.Text;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.mysql.privilege.PaloAuth.PrivLevel;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+\n+// only the following 2 formats are allowed\n+// *\n+// resource\n+public class ResourcePattern implements Writable {\n+    private String resourceName;\n+    boolean isAnalyzed = false;\n+\n+    public static ResourcePattern ALL;\n+    static {\n+        ALL = new ResourcePattern(\"*\");\n+        try {\n+            ALL.analyze();\n+        } catch (AnalysisException e) {\n+            // will not happen\n+        }\n+    }\n+\n+    private ResourcePattern() {\n+    }\n+\n+    public ResourcePattern(String resourceName) {\n+        this.resourceName = Strings.isNullOrEmpty(resourceName) ? \"*\" : resourceName;\n+    }\n+\n+    public String getResourceName() {\n+        Preconditions.checkState(isAnalyzed);\n+        return resourceName;\n+    }\n+\n+    public PrivLevel getPrivLevel() {\n+        Preconditions.checkState(isAnalyzed);\n+        if (resourceName.equals(\"*\")) {\n+            return PrivLevel.GLOBAL;\n+        } else {\n+            return PrivLevel.RESOURCE;\n+        }\n+    }\n+\n+    public void analyze() throws AnalysisException {\n+        if (isAnalyzed) {\n+            return;\n+        }\n+        if (!resourceName.equals(\"*\")) {\n+            FeNameFormat.checkResourceName(resourceName);\n+        }\n+        isAnalyzed = true;\n+    }\n+\n+    public static ResourcePattern read(DataInput in) throws IOException {\n+        ResourcePattern resourcePattern = new ResourcePattern();\n+        resourcePattern.readFields(in);\n+        return resourcePattern;\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (!(obj instanceof ResourcePattern)) {\n+            return false;\n+        }\n+        ResourcePattern other = (ResourcePattern) obj;\n+        return resourceName.equals(other.getResourceName());\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        int result = 17;\n+        result = 31 * result + resourceName.hashCode();\n+        return result;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return resourceName;\n+    }\n+\n+    @Override\n+    public void write(DataOutput out) throws IOException {\n+        Preconditions.checkState(isAnalyzed);\n+        Text.writeString(out, resourceName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTg4MDg0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloRole.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjozOToxNlrOGZI6Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjozOToxNlrOGZI6Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxMzUzOA==", "bodyText": "Better to add \"TODO(wyb): spark-load\" to find it easily", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429013538", "createdAt": "2020-05-22T02:39:16Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/mysql/privilege/PaloRole.java", "diffHunk": "@@ -129,6 +163,16 @@ public void readFields(DataInput in) throws IOException {\n             PrivBitSet privs = PrivBitSet.read(in);\n             tblPatternToPrivs.put(tblPattern, privs);\n         }\n+        /*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MjM5NDY0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzo0NjoxNlrOGZN1DA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzo0NjoxNlrOGZN1DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA5NDE1Ng==", "bodyText": "use Gson instead.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429094156", "createdAt": "2020-05-22T07:46:16Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/ResourceMgr.java", "diffHunk": "@@ -0,0 +1,189 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.catalog;\n+\n+import org.apache.doris.analysis.CreateResourceStmt;\n+import org.apache.doris.analysis.DropResourceStmt;\n+import org.apache.doris.catalog.Resource.ResourceType;\n+import org.apache.doris.common.DdlException;\n+import org.apache.doris.common.io.Writable;\n+import org.apache.doris.common.proc.BaseProcResult;\n+import org.apache.doris.common.proc.ProcNodeInterface;\n+import org.apache.doris.common.proc.ProcResult;\n+import org.apache.doris.mysql.privilege.PrivPredicate;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Maps;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+/**\n+ * Resource manager is responsible for managing external resources used by Doris.\n+ * For example, Spark/MapReduce used for ETL, Spark/GPU used for queries, HDFS/S3 used for external storage.\n+ * Now only support Spark.\n+ */\n+public class ResourceMgr implements Writable {\n+    private static final Logger LOG = LogManager.getLogger(ResourceMgr.class);\n+\n+    public static final ImmutableList<String> RESOURCE_PROC_NODE_TITLE_NAMES = new ImmutableList.Builder<String>()\n+            .add(\"Name\").add(\"ResourceType\").add(\"Key\").add(\"Value\")\n+            .build();\n+\n+    // { resourceName -> Resource}\n+    private final Map<String, Resource> nameToResource = Maps.newHashMap();\n+    private final ReentrantLock lock = new ReentrantLock();\n+    private final ResourceProcNode procNode = new ResourceProcNode();\n+\n+    public ResourceMgr() {\n+    }\n+\n+    public void createResource(CreateResourceStmt stmt) throws DdlException {\n+        lock.lock();\n+        try {\n+            if (stmt.getResourceType() != ResourceType.SPARK) {\n+                throw new DdlException(\"Only support Spark resource.\");\n+            }\n+\n+            String resourceName = stmt.getResourceName();\n+            if (nameToResource.containsKey(resourceName)) {\n+                throw new DdlException(\"Resource(\" + resourceName + \") already exist\");\n+            }\n+\n+            Resource resource = Resource.fromStmt(stmt);\n+            nameToResource.put(resourceName, resource);\n+            // log add\n+            Catalog.getInstance().getEditLog().logCreateResource(resource);\n+            LOG.info(\"create resource success. resource: {}\", resource);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void replayCreateResource(Resource resource) {\n+        lock.lock();\n+        try {\n+            nameToResource.put(resource.getName(), resource);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void dropResource(DropResourceStmt stmt) throws DdlException {\n+        lock.lock();\n+        try {\n+            String name = stmt.getResourceName();\n+            if (!nameToResource.containsKey(name)) {\n+                throw new DdlException(\"Resource(\" + name + \") does not exist\");\n+            }\n+\n+            nameToResource.remove(name);\n+            // log drop\n+            Catalog.getInstance().getEditLog().logDropResource(name);\n+            LOG.info(\"drop resource success. resource name: {}\", name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public void replayDropResource(String name) {\n+        lock.lock();\n+        try {\n+            nameToResource.remove(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public boolean containsResource(String name) {\n+        lock.lock();\n+        try {\n+            return nameToResource.containsKey(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public Resource getResource(String name) {\n+        lock.lock();\n+        try {\n+            return nameToResource.get(name);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    public int getResourceNum() {\n+        return nameToResource.size();\n+    }\n+\n+    public List<List<String>> getResourcesInfo() {\n+        return procNode.fetchResult().getRows();\n+    }\n+\n+    public ResourceProcNode getProcNode() {\n+        return procNode;\n+    }\n+\n+    @Override\n+    public void write(DataOutput out) throws IOException {\n+        out.writeInt(nameToResource.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MjczMDQ3OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/resource-management.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwOTo0MTo0OFrOGZRHjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwMToyNToxOVrOGZmtag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE0ODA0NQ==", "bodyText": "Is \"spark.hadoop.fs.defaultFS\"  is used for load data from HDFS? Or it seems that only working_dir  is enough", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429148045", "createdAt": "2020-05-22T09:41:48Z", "author": {"login": "wangbo"}, "path": "docs/zh-CN/administrator-guide/resource-management.md", "diffHunk": "@@ -0,0 +1,125 @@\n+---\n+{\n+    \"title\": \"\u8d44\u6e90\u7ba1\u7406\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u8d44\u6e90\u7ba1\u7406\n+\n+\u4e3a\u4e86\u8282\u7701Doris\u96c6\u7fa4\u5185\u7684\u8ba1\u7b97\u3001\u5b58\u50a8\u8d44\u6e90\uff0cDoris\u9700\u8981\u5f15\u5165\u4e00\u4e9b\u5176\u4ed6\u5916\u90e8\u8d44\u6e90\u6765\u5b8c\u6210\u76f8\u5173\u7684\u5de5\u4f5c\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cSpark/MapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u8d44\u6e90\u7ba1\u7406\u673a\u5236\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\n+\n+## \u57fa\u672c\u6982\u5ff5\n+\n+\u4e00\u4e2a\u8d44\u6e90\u5305\u542b\u540d\u5b57\u3001\u7c7b\u578b\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u540d\u5b57\u4e3a\u5168\u5c40\u552f\u4e00\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u5305\u542b\u4e0d\u540c\u7684\u5c5e\u6027\uff0c\u5177\u4f53\u53c2\u8003\u5404\u8d44\u6e90\u7684\u4ecb\u7ecd\u3002\n+\n+\u8d44\u6e90\u7684\u521b\u5efa\u548c\u5220\u9664\u53ea\u80fd\u7531\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u64cd\u4f5c\u3002\u4e00\u4e2a\u8d44\u6e90\u96b6\u5c5e\u4e8e\u6574\u4e2aDoris\u96c6\u7fa4\u3002\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u53ef\u4ee5\u5c06\u4f7f\u7528\u6743\u9650`usage_priv` \u8d4b\u7ed9\u666e\u901a\u7528\u6237\u3002\u53ef\u53c2\u8003`HELP GRANT`\u6216\u8005\u6743\u9650\u6587\u6863\u3002\n+\n+\n+\n+## \u5177\u4f53\u64cd\u4f5c\n+\n+\u8d44\u6e90\u7ba1\u7406\u4e3b\u8981\u6709\u4e09\u4e2a\u547d\u4ee4\uff1a`CREATE RESOURCE`\uff0c`DROP RESOURCE` \u548c `SHOW RESOURCES`\uff0c\u5206\u522b\u4e3a\u521b\u5efa\u3001\u5220\u9664\u548c\u67e5\u770b\u8d44\u6e90\u3002\u8fd9\u4e09\u4e2a\u547d\u4ee4\u7684\u5177\u4f53\u8bed\u6cd5\u53ef\u4ee5\u901a\u8fc7MySQL\u5ba2\u6237\u7aef\u8fde\u63a5\u5230 Doris \u540e\uff0c\u6267\u884c `HELP cmd` \u7684\u65b9\u5f0f\u67e5\u770b\u5e2e\u52a9\u3002\n+\n+1. CREATE RESOURCE\n+\n+   \u8bed\u6cd5\n+\n+   ```sql\n+   CREATE [EXTERNAL] RESOURCE \"resource_name\"                                  \n+     PROPERTIES (\"key\"=\"value\", ...); \n+   ```\n+\n+   \u5728\u521b\u5efa\u8d44\u6e90\u7684\u547d\u4ee4\u4e2d\uff0c\u7528\u6237\u5fc5\u987b\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff1a\n+\n+   * `resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684\u8d44\u6e90\u7684\u540d\u5b57\u3002\n+   * `PROPERTIES` \u662f\u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+     * `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+     * \u5176\u4ed6\u53c2\u6570\u89c1\u5404\u8d44\u6e90\u4ecb\u7ecd\u3002\n+\n+2. DROP RESOURCE\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u5220\u9664\u4e00\u4e2a\u5df2\u5b58\u5728\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP DROP RESOURCE`\n+\n+3. SHOW RESOURCES\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u67e5\u770b\u7528\u6237\u6709\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP SHOW RESOURCES`\n+\n+\n+\n+## \u652f\u6301\u7684\u8d44\u6e90\n+\n+\u76ee\u524d\u4ec5\u652f\u6301Spark\u8d44\u6e90\uff0c\u5b8c\u6210ETL\u5de5\u4f5c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u90fd\u4ee5Spark\u8d44\u6e90\u4e3a\u4f8b\u3002\n+\n+### Spark\n+\n+#### \u53c2\u6570\n+\n+##### Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+\n+`spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+\n+`spark.submit.deployMode`: Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+\n+`spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+`spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+\u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\n+\n+\n+\n+##### \u5982\u679cSpark\u7528\u4e8eETL\uff0c\u8fd8\u9700\u8981\u6307\u5b9a\u4ee5\u4e0b\u53c2\u6570\uff1a\n+\n+`working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+\n+`broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002 \n+\n+  * `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\n+\n+#### \u793a\u4f8b\n+\n+\u521b\u5efa yarn cluster \u6a21\u5f0f\uff0c\u540d\u4e3a spark0 \u7684 Spark \u8d44\u6e90\u3002\n+\n+```sql\n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE2NzI2MQ==", "bodyText": "In yarn cluster deploy mode, \"spark.hadoop.fs.defaultFS\" is used in spark etl job for storing hdfs://host:port/user/xxx/.sparkStaging/appid/__spark_libs__xxx.zip and hdfs://host:port/user/xxx/.sparkStaging/appid/spark_conf.zip files", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429167261", "createdAt": "2020-05-22T10:25:13Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/resource-management.md", "diffHunk": "@@ -0,0 +1,125 @@\n+---\n+{\n+    \"title\": \"\u8d44\u6e90\u7ba1\u7406\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u8d44\u6e90\u7ba1\u7406\n+\n+\u4e3a\u4e86\u8282\u7701Doris\u96c6\u7fa4\u5185\u7684\u8ba1\u7b97\u3001\u5b58\u50a8\u8d44\u6e90\uff0cDoris\u9700\u8981\u5f15\u5165\u4e00\u4e9b\u5176\u4ed6\u5916\u90e8\u8d44\u6e90\u6765\u5b8c\u6210\u76f8\u5173\u7684\u5de5\u4f5c\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cSpark/MapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u8d44\u6e90\u7ba1\u7406\u673a\u5236\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\n+\n+## \u57fa\u672c\u6982\u5ff5\n+\n+\u4e00\u4e2a\u8d44\u6e90\u5305\u542b\u540d\u5b57\u3001\u7c7b\u578b\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u540d\u5b57\u4e3a\u5168\u5c40\u552f\u4e00\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u5305\u542b\u4e0d\u540c\u7684\u5c5e\u6027\uff0c\u5177\u4f53\u53c2\u8003\u5404\u8d44\u6e90\u7684\u4ecb\u7ecd\u3002\n+\n+\u8d44\u6e90\u7684\u521b\u5efa\u548c\u5220\u9664\u53ea\u80fd\u7531\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u64cd\u4f5c\u3002\u4e00\u4e2a\u8d44\u6e90\u96b6\u5c5e\u4e8e\u6574\u4e2aDoris\u96c6\u7fa4\u3002\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u53ef\u4ee5\u5c06\u4f7f\u7528\u6743\u9650`usage_priv` \u8d4b\u7ed9\u666e\u901a\u7528\u6237\u3002\u53ef\u53c2\u8003`HELP GRANT`\u6216\u8005\u6743\u9650\u6587\u6863\u3002\n+\n+\n+\n+## \u5177\u4f53\u64cd\u4f5c\n+\n+\u8d44\u6e90\u7ba1\u7406\u4e3b\u8981\u6709\u4e09\u4e2a\u547d\u4ee4\uff1a`CREATE RESOURCE`\uff0c`DROP RESOURCE` \u548c `SHOW RESOURCES`\uff0c\u5206\u522b\u4e3a\u521b\u5efa\u3001\u5220\u9664\u548c\u67e5\u770b\u8d44\u6e90\u3002\u8fd9\u4e09\u4e2a\u547d\u4ee4\u7684\u5177\u4f53\u8bed\u6cd5\u53ef\u4ee5\u901a\u8fc7MySQL\u5ba2\u6237\u7aef\u8fde\u63a5\u5230 Doris \u540e\uff0c\u6267\u884c `HELP cmd` \u7684\u65b9\u5f0f\u67e5\u770b\u5e2e\u52a9\u3002\n+\n+1. CREATE RESOURCE\n+\n+   \u8bed\u6cd5\n+\n+   ```sql\n+   CREATE [EXTERNAL] RESOURCE \"resource_name\"                                  \n+     PROPERTIES (\"key\"=\"value\", ...); \n+   ```\n+\n+   \u5728\u521b\u5efa\u8d44\u6e90\u7684\u547d\u4ee4\u4e2d\uff0c\u7528\u6237\u5fc5\u987b\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff1a\n+\n+   * `resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684\u8d44\u6e90\u7684\u540d\u5b57\u3002\n+   * `PROPERTIES` \u662f\u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+     * `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+     * \u5176\u4ed6\u53c2\u6570\u89c1\u5404\u8d44\u6e90\u4ecb\u7ecd\u3002\n+\n+2. DROP RESOURCE\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u5220\u9664\u4e00\u4e2a\u5df2\u5b58\u5728\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP DROP RESOURCE`\n+\n+3. SHOW RESOURCES\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u67e5\u770b\u7528\u6237\u6709\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP SHOW RESOURCES`\n+\n+\n+\n+## \u652f\u6301\u7684\u8d44\u6e90\n+\n+\u76ee\u524d\u4ec5\u652f\u6301Spark\u8d44\u6e90\uff0c\u5b8c\u6210ETL\u5de5\u4f5c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u90fd\u4ee5Spark\u8d44\u6e90\u4e3a\u4f8b\u3002\n+\n+### Spark\n+\n+#### \u53c2\u6570\n+\n+##### Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+\n+`spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+\n+`spark.submit.deployMode`: Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+\n+`spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+`spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+\u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\n+\n+\n+\n+##### \u5982\u679cSpark\u7528\u4e8eETL\uff0c\u8fd8\u9700\u8981\u6307\u5b9a\u4ee5\u4e0b\u53c2\u6570\uff1a\n+\n+`working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+\n+`broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002 \n+\n+  * `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\n+\n+#### \u793a\u4f8b\n+\n+\u521b\u5efa yarn cluster \u6a21\u5f0f\uff0c\u540d\u4e3a spark0 \u7684 Spark \u8d44\u6e90\u3002\n+\n+```sql\n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE0ODA0NQ=="}, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE3NDA2MA==", "bodyText": "For the user case which they only has one cluster(one spark cluster, one hdfs) for ETL, spark client may read the hdfs-site.xml by HADOOP_HOME, so that user needn't specify defaultFS  every time submit a spark job.\nIn this case, spark.hadoop.fs.defaultFS is not a necessary item, it should be a optional item", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429174060", "createdAt": "2020-05-22T10:41:11Z", "author": {"login": "wangbo"}, "path": "docs/zh-CN/administrator-guide/resource-management.md", "diffHunk": "@@ -0,0 +1,125 @@\n+---\n+{\n+    \"title\": \"\u8d44\u6e90\u7ba1\u7406\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u8d44\u6e90\u7ba1\u7406\n+\n+\u4e3a\u4e86\u8282\u7701Doris\u96c6\u7fa4\u5185\u7684\u8ba1\u7b97\u3001\u5b58\u50a8\u8d44\u6e90\uff0cDoris\u9700\u8981\u5f15\u5165\u4e00\u4e9b\u5176\u4ed6\u5916\u90e8\u8d44\u6e90\u6765\u5b8c\u6210\u76f8\u5173\u7684\u5de5\u4f5c\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cSpark/MapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u8d44\u6e90\u7ba1\u7406\u673a\u5236\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\n+\n+## \u57fa\u672c\u6982\u5ff5\n+\n+\u4e00\u4e2a\u8d44\u6e90\u5305\u542b\u540d\u5b57\u3001\u7c7b\u578b\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u540d\u5b57\u4e3a\u5168\u5c40\u552f\u4e00\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u5305\u542b\u4e0d\u540c\u7684\u5c5e\u6027\uff0c\u5177\u4f53\u53c2\u8003\u5404\u8d44\u6e90\u7684\u4ecb\u7ecd\u3002\n+\n+\u8d44\u6e90\u7684\u521b\u5efa\u548c\u5220\u9664\u53ea\u80fd\u7531\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u64cd\u4f5c\u3002\u4e00\u4e2a\u8d44\u6e90\u96b6\u5c5e\u4e8e\u6574\u4e2aDoris\u96c6\u7fa4\u3002\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u53ef\u4ee5\u5c06\u4f7f\u7528\u6743\u9650`usage_priv` \u8d4b\u7ed9\u666e\u901a\u7528\u6237\u3002\u53ef\u53c2\u8003`HELP GRANT`\u6216\u8005\u6743\u9650\u6587\u6863\u3002\n+\n+\n+\n+## \u5177\u4f53\u64cd\u4f5c\n+\n+\u8d44\u6e90\u7ba1\u7406\u4e3b\u8981\u6709\u4e09\u4e2a\u547d\u4ee4\uff1a`CREATE RESOURCE`\uff0c`DROP RESOURCE` \u548c `SHOW RESOURCES`\uff0c\u5206\u522b\u4e3a\u521b\u5efa\u3001\u5220\u9664\u548c\u67e5\u770b\u8d44\u6e90\u3002\u8fd9\u4e09\u4e2a\u547d\u4ee4\u7684\u5177\u4f53\u8bed\u6cd5\u53ef\u4ee5\u901a\u8fc7MySQL\u5ba2\u6237\u7aef\u8fde\u63a5\u5230 Doris \u540e\uff0c\u6267\u884c `HELP cmd` \u7684\u65b9\u5f0f\u67e5\u770b\u5e2e\u52a9\u3002\n+\n+1. CREATE RESOURCE\n+\n+   \u8bed\u6cd5\n+\n+   ```sql\n+   CREATE [EXTERNAL] RESOURCE \"resource_name\"                                  \n+     PROPERTIES (\"key\"=\"value\", ...); \n+   ```\n+\n+   \u5728\u521b\u5efa\u8d44\u6e90\u7684\u547d\u4ee4\u4e2d\uff0c\u7528\u6237\u5fc5\u987b\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff1a\n+\n+   * `resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684\u8d44\u6e90\u7684\u540d\u5b57\u3002\n+   * `PROPERTIES` \u662f\u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+     * `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+     * \u5176\u4ed6\u53c2\u6570\u89c1\u5404\u8d44\u6e90\u4ecb\u7ecd\u3002\n+\n+2. DROP RESOURCE\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u5220\u9664\u4e00\u4e2a\u5df2\u5b58\u5728\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP DROP RESOURCE`\n+\n+3. SHOW RESOURCES\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u67e5\u770b\u7528\u6237\u6709\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP SHOW RESOURCES`\n+\n+\n+\n+## \u652f\u6301\u7684\u8d44\u6e90\n+\n+\u76ee\u524d\u4ec5\u652f\u6301Spark\u8d44\u6e90\uff0c\u5b8c\u6210ETL\u5de5\u4f5c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u90fd\u4ee5Spark\u8d44\u6e90\u4e3a\u4f8b\u3002\n+\n+### Spark\n+\n+#### \u53c2\u6570\n+\n+##### Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+\n+`spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+\n+`spark.submit.deployMode`: Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+\n+`spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+`spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+\u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\n+\n+\n+\n+##### \u5982\u679cSpark\u7528\u4e8eETL\uff0c\u8fd8\u9700\u8981\u6307\u5b9a\u4ee5\u4e0b\u53c2\u6570\uff1a\n+\n+`working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+\n+`broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002 \n+\n+  * `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\n+\n+#### \u793a\u4f8b\n+\n+\u521b\u5efa yarn cluster \u6a21\u5f0f\uff0c\u540d\u4e3a spark0 \u7684 Spark \u8d44\u6e90\u3002\n+\n+```sql\n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE0ODA0NQ=="}, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTgwMg==", "bodyText": "Not all users have only one cluster, so i think we can't load configurations from single HADOOP_HOME source.\nNow users need to specify defaultFS only one time when creating a new spark resource.", "url": "https://github.com/apache/incubator-doris/pull/3418#discussion_r429501802", "createdAt": "2020-05-23T01:25:19Z", "author": {"login": "wyb"}, "path": "docs/zh-CN/administrator-guide/resource-management.md", "diffHunk": "@@ -0,0 +1,125 @@\n+---\n+{\n+    \"title\": \"\u8d44\u6e90\u7ba1\u7406\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!-- \n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u8d44\u6e90\u7ba1\u7406\n+\n+\u4e3a\u4e86\u8282\u7701Doris\u96c6\u7fa4\u5185\u7684\u8ba1\u7b97\u3001\u5b58\u50a8\u8d44\u6e90\uff0cDoris\u9700\u8981\u5f15\u5165\u4e00\u4e9b\u5176\u4ed6\u5916\u90e8\u8d44\u6e90\u6765\u5b8c\u6210\u76f8\u5173\u7684\u5de5\u4f5c\uff0c\u5982Spark/GPU\u7528\u4e8e\u67e5\u8be2\uff0cHDFS/S3\u7528\u4e8e\u5916\u90e8\u5b58\u50a8\uff0cSpark/MapReduce\u7528\u4e8eETL\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u8d44\u6e90\u7ba1\u7406\u673a\u5236\u6765\u7ba1\u7406Doris\u4f7f\u7528\u7684\u8fd9\u4e9b\u5916\u90e8\u8d44\u6e90\u3002\n+\n+\n+\n+## \u57fa\u672c\u6982\u5ff5\n+\n+\u4e00\u4e2a\u8d44\u6e90\u5305\u542b\u540d\u5b57\u3001\u7c7b\u578b\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u540d\u5b57\u4e3a\u5168\u5c40\u552f\u4e00\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u5305\u542b\u4e0d\u540c\u7684\u5c5e\u6027\uff0c\u5177\u4f53\u53c2\u8003\u5404\u8d44\u6e90\u7684\u4ecb\u7ecd\u3002\n+\n+\u8d44\u6e90\u7684\u521b\u5efa\u548c\u5220\u9664\u53ea\u80fd\u7531\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u64cd\u4f5c\u3002\u4e00\u4e2a\u8d44\u6e90\u96b6\u5c5e\u4e8e\u6574\u4e2aDoris\u96c6\u7fa4\u3002\u62e5\u6709 `admin` \u6743\u9650\u7684\u7528\u6237\u53ef\u4ee5\u5c06\u4f7f\u7528\u6743\u9650`usage_priv` \u8d4b\u7ed9\u666e\u901a\u7528\u6237\u3002\u53ef\u53c2\u8003`HELP GRANT`\u6216\u8005\u6743\u9650\u6587\u6863\u3002\n+\n+\n+\n+## \u5177\u4f53\u64cd\u4f5c\n+\n+\u8d44\u6e90\u7ba1\u7406\u4e3b\u8981\u6709\u4e09\u4e2a\u547d\u4ee4\uff1a`CREATE RESOURCE`\uff0c`DROP RESOURCE` \u548c `SHOW RESOURCES`\uff0c\u5206\u522b\u4e3a\u521b\u5efa\u3001\u5220\u9664\u548c\u67e5\u770b\u8d44\u6e90\u3002\u8fd9\u4e09\u4e2a\u547d\u4ee4\u7684\u5177\u4f53\u8bed\u6cd5\u53ef\u4ee5\u901a\u8fc7MySQL\u5ba2\u6237\u7aef\u8fde\u63a5\u5230 Doris \u540e\uff0c\u6267\u884c `HELP cmd` \u7684\u65b9\u5f0f\u67e5\u770b\u5e2e\u52a9\u3002\n+\n+1. CREATE RESOURCE\n+\n+   \u8bed\u6cd5\n+\n+   ```sql\n+   CREATE [EXTERNAL] RESOURCE \"resource_name\"                                  \n+     PROPERTIES (\"key\"=\"value\", ...); \n+   ```\n+\n+   \u5728\u521b\u5efa\u8d44\u6e90\u7684\u547d\u4ee4\u4e2d\uff0c\u7528\u6237\u5fc5\u987b\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff1a\n+\n+   * `resource_name` \u4e3a Doris \u4e2d\u914d\u7f6e\u7684\u8d44\u6e90\u7684\u540d\u5b57\u3002\n+   * `PROPERTIES` \u662f\u8d44\u6e90\u76f8\u5173\u53c2\u6570\uff0c\u5982\u4e0b\uff1a\n+     * `type`\uff1a\u8d44\u6e90\u7c7b\u578b\uff0c\u5fc5\u586b\uff0c\u76ee\u524d\u4ec5\u652f\u6301 spark\u3002\n+     * \u5176\u4ed6\u53c2\u6570\u89c1\u5404\u8d44\u6e90\u4ecb\u7ecd\u3002\n+\n+2. DROP RESOURCE\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u5220\u9664\u4e00\u4e2a\u5df2\u5b58\u5728\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP DROP RESOURCE`\n+\n+3. SHOW RESOURCES\n+\n+   \u8be5\u547d\u4ee4\u53ef\u4ee5\u67e5\u770b\u7528\u6237\u6709\u4f7f\u7528\u6743\u9650\u7684\u8d44\u6e90\u3002\u5177\u4f53\u64cd\u4f5c\u89c1\uff1a`HELP SHOW RESOURCES`\n+\n+\n+\n+## \u652f\u6301\u7684\u8d44\u6e90\n+\n+\u76ee\u524d\u4ec5\u652f\u6301Spark\u8d44\u6e90\uff0c\u5b8c\u6210ETL\u5de5\u4f5c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u90fd\u4ee5Spark\u8d44\u6e90\u4e3a\u4f8b\u3002\n+\n+### Spark\n+\n+#### \u53c2\u6570\n+\n+##### Spark \u76f8\u5173\u53c2\u6570\u5982\u4e0b\uff1a\n+\n+`spark.master`: \u5fc5\u586b\uff0c\u76ee\u524d\u652f\u6301yarn\uff0cspark://host:port\u3002\n+\n+`spark.submit.deployMode`: Spark \u7a0b\u5e8f\u7684\u90e8\u7f72\u6a21\u5f0f\uff0c\u5fc5\u586b\uff0c\u652f\u6301 cluster\uff0cclient \u4e24\u79cd\u3002\n+\n+`spark.hadoop.yarn.resourcemanager.address`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+`spark.hadoop.fs.defaultFS`: master\u4e3ayarn\u65f6\u5fc5\u586b\u3002\n+\n+\u5176\u4ed6\u53c2\u6570\u4e3a\u53ef\u9009\uff0c\u53c2\u8003http://spark.apache.org/docs/latest/configuration.html\u3002\n+\n+\n+\n+##### \u5982\u679cSpark\u7528\u4e8eETL\uff0c\u8fd8\u9700\u8981\u6307\u5b9a\u4ee5\u4e0b\u53c2\u6570\uff1a\n+\n+`working_dir`: ETL \u4f7f\u7528\u7684\u76ee\u5f55\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u4f8b\u5982\uff1ahdfs://host:port/tmp/doris\u3002\n+\n+`broker`: broker \u540d\u5b57\u3002spark\u4f5c\u4e3aETL\u8d44\u6e90\u4f7f\u7528\u65f6\u5fc5\u586b\u3002\u9700\u8981\u4f7f\u7528`ALTER SYSTEM ADD BROKER` \u547d\u4ee4\u63d0\u524d\u5b8c\u6210\u914d\u7f6e\u3002 \n+\n+  * `broker.property_key`: broker\u8bfb\u53d6ETL\u751f\u6210\u7684\u4e2d\u95f4\u6587\u4ef6\u65f6\u9700\u8981\u6307\u5b9a\u7684\u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\n+\n+\n+\n+#### \u793a\u4f8b\n+\n+\u521b\u5efa yarn cluster \u6a21\u5f0f\uff0c\u540d\u4e3a spark0 \u7684 Spark \u8d44\u6e90\u3002\n+\n+```sql\n+CREATE EXTERNAL RESOURCE \"spark0\"\n+PROPERTIES\n+(\n+  \"type\" = \"spark\",\n+  \"spark.master\" = \"yarn\",\n+  \"spark.submit.deployMode\" = \"cluster\",\n+  \"spark.jars\" = \"xxx.jar,yyy.jar\",\n+  \"spark.files\" = \"/tmp/aaa,/tmp/bbb\",\n+  \"spark.executor.memory\" = \"1g\",\n+  \"spark.yarn.queue\" = \"queue0\",\n+  \"spark.hadoop.yarn.resourcemanager.address\" = \"127.0.0.1:9999\",\n+  \"spark.hadoop.fs.defaultFS\" = \"hdfs://127.0.0.1:10000\",\n+  \"working_dir\" = \"hdfs://127.0.0.1:10000/tmp/doris\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE0ODA0NQ=="}, "originalCommit": {"oid": "d33abcf208b193d52c5c24eca59ac48608b5d51c"}, "originalPosition": 120}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1692, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}