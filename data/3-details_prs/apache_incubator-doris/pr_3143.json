{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkwNzgzMjU4", "number": 3143, "title": "Non blocking OlapTableSink", "bodyText": "Ref #2780 (comment)\nImplementaItion Notes\nNodeChannel\n\n_cur_batch -> _pending_batches: when _cur_batch is filled up, move it to _pending_batches.\nadd_row() just produce batches.\ntry_send_and_fetch_status() tries to consume one pending batch. If has in flight packet, skip send in this round.\n\nSo we can add one sender thread to be in charge of all node channels try_send.\nIndexChannel\n\ninit(), open() stay the same.\nUse for_each_node_channel() to expose the detailed changes of NodeChannel.(It's more easy to read & modify)\n\nSender thread\nSee func OlapTableSink::_send_batch_process()\nWhy use polling\uff1f\nIf we use wait/notify, it will notify when generate a new batch. We can't skip sending this batch, coz it won't notify the same batch again. So wait/notify can't avoid blocking simply.\nSo I choose polling.\nIt's wasting to continuously try_send(), but it's difficult to set the suitable polling interval. Thus, I add std::this_thread::yield() to give up the time slice, give priority to other process/threads (if there are other process/threads waiting in the queue).", "createdAt": "2020-03-19T03:58:12Z", "url": "https://github.com/apache/incubator-doris/pull/3143", "merged": true, "mergeCommit": {"oid": "94539e7120120cc0f5d0343f3c32eb3c4a946fd0"}, "closed": true, "closedAt": "2020-05-07T02:43:42Z", "author": {"login": "vagetablechicken"}, "timelineItems": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPXAtKAFqTM3ODE5NzY2MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcekxEFgFqTQwNjQxODg2OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4MTk3NjYx", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-378197661", "createdAt": "2020-03-20T01:50:46Z", "commit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMTo1MDo0NlrOF5Fwqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjoyMzoyOFrOF5GHjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwNzUzMA==", "bodyText": "Better to add some comments to explain how the work is done, which will make others understand this code easily.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395407530", "createdAt": "2020-03-20T01:50:46Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -95,72 +193,79 @@ class NodeChannel {\n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    std::atomic<bool> _rpc_error{false};\n+    std::atomic<bool> _is_cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};\n+\n+    bool _eos_is_produced{false}; // only for restricting producer behaviors\n+\n+    std::unique_ptr<RowDescriptor> _row_desc;\n+    int _batch_size = 0;\n+    std::unique_ptr<RowBatch> _cur_batch;\n+    PTabletWriterAddBatchRequest _cur_add_batch_request;\n+\n+    std::mutex _pending_batches_lock;\n+    using AddBatchReq = std::pair<std::unique_ptr<RowBatch>, PTabletWriterAddBatchRequest>;\n+    std::queue<AddBatchReq> _pending_batches;\n+    std::atomic<int> _pending_batches_num{0};\n+\n     palo::PInternalService_Stub* _stub = nullptr;\n     RefCountClosure<PTabletWriterOpenResult>* _open_closure = nullptr;\n-    RefCountClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n+    ReusableClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n \n     std::vector<TTabletWithPartition> _all_tablets;\n-    PTabletWriterAddBatchRequest _add_batch_request;\n+    std::vector<TTabletCommitInfo> _tablet_commit_infos;\n+\n+    AddBatchCounter _add_batch_counter;\n+    int64_t _queue_push_lock_ns = 0;\n+    int64_t _serialize_batch_ns = 0;\n+    int64_t _actual_consume_ns = 0;\n };\n \n class IndexChannel {\n public:\n     IndexChannel(OlapTableSink* parent, int64_t index_id, int32_t schema_hash)\n-            : _parent(parent), _index_id(index_id),\n-            _schema_hash(schema_hash) {\n-    }\n+            : _parent(parent), _index_id(index_id), _schema_hash(schema_hash) {}\n     ~IndexChannel();\n \n-    Status init(RuntimeState* state,\n-                const std::vector<TTabletWithPartition>& tablets);\n-    Status open();\n-    Status add_row(Tuple* tuple, int64_t tablet_id);\n+    Status init(RuntimeState* state, const std::vector<TTabletWithPartition>& tablets);\n \n-    Status close(RuntimeState* state);\n+    Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    void cancel();\n+    void for_each_node_channel(std::function<void(NodeChannel*)> func) {\n+        for (auto& it : _node_channels) {\n+            func(it.second);\n+        }\n+    }\n \n-private:\n-    // return true if this load can't success.\n-    bool _handle_failed_node(NodeChannel* channel);\n+    void mark_as_failed(NodeChannel* ch) { _failed_channels.insert(ch->node_id()); }\n+    bool has_intolerable_failure();\n \n private:\n     OlapTableSink* _parent;\n     int64_t _index_id;\n     int32_t _schema_hash;\n-    int _num_failed_channels = 0;\n \n     // BeId -> channel\n     std::unordered_map<int64_t, NodeChannel*> _node_channels;\n     // from tablet_id to backend channel\n     std::unordered_map<int64_t, std::vector<NodeChannel*>> _channels_by_tablet;\n-};\n-\n-// The counter of add_batch rpc of a single node\n-struct AddBatchCounter {\n-    // total execution time of a add_batch rpc\n-    int64_t add_batch_execution_time_ns = 0;\n-    // lock waiting time in a add_batch rpc\n-    int64_t add_batch_wait_lock_time_ns = 0;\n-    // number of add_batch call\n-    int64_t add_batch_num = 0;\n+    // BeId\n+    std::set<int64_t> _failed_channels;\n };\n \n // write data to Olap Table.\n // this class distributed data according to\n class OlapTableSink : public DataSink {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 281}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDM1NQ==", "bodyText": "I think should add ref count for this closure. Because this closure is created by channel, and the RPC call has this pointer. However it is not sure when the RPC will call this->Run(). If this channel is destructed before the RPC's callback, it will make invalid memory access. Otherwise it should wait until the RPC finish, which is unnecessary.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395410355", "createdAt": "2020-03-20T02:05:44Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -47,18 +48,101 @@ class ExprContext;\n class TExpr;\n \n namespace stream_load {\n- \n+\n class OlapTableSink;\n \n+// The counter of add_batch rpc of a single node\n+struct AddBatchCounter {\n+    // total execution time of a add_batch rpc\n+    int64_t add_batch_execution_time_us = 0;\n+    // lock waiting time in a add_batch rpc\n+    int64_t add_batch_wait_lock_time_us = 0;\n+    // number of add_batch call\n+    int64_t add_batch_num = 0;\n+    AddBatchCounter& operator+=(const AddBatchCounter& rhs) {\n+        add_batch_execution_time_us += rhs.add_batch_execution_time_us;\n+        add_batch_wait_lock_time_us += rhs.add_batch_wait_lock_time_us;\n+        add_batch_num += rhs.add_batch_num;\n+        return *this;\n+    }\n+    friend AddBatchCounter operator+(const AddBatchCounter& lhs, const AddBatchCounter& rhs) {\n+        AddBatchCounter sum = lhs;\n+        sum += rhs;\n+        return sum;\n+    }\n+};\n+\n+template <typename T>\n+class ReusableClosure : public google::protobuf::Closure {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMjAwMQ==", "bodyText": "I think it is better to declare all your capture other than a &. And what's more, referencing a local variable will lead to invalid memory access, because when the lambda is called, the reference is not valid.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395412001", "createdAt": "2020-03-20T02:15:33Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +127,127 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([&]() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMzM5MQ==", "bodyText": "I think most of the scenarios are still normal. better to construct strings when it is abnormal", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395413391", "createdAt": "2020-03-20T02:23:28Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +257,89 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {\n+    auto st = none_of({_rpc_error, _is_cancelled, _send_finished});\n+    if (!st.ok()) {\n+        return 0;\n     }\n \n-    SCOPED_RAW_TIMER(_parent->mutable_wait_in_flight_packet_ns());\n-    _add_batch_closure->join();\n-    _has_in_flight_packet = false;\n-    if (_add_batch_closure->cntl.Failed()) {\n-        LOG(WARNING) << \"failed to send batch, error=\"\n-            << berror(_add_batch_closure->cntl.ErrorCode())\n-            << \", error_text=\" << _add_batch_closure->cntl.ErrorText();\n-        return Status::InternalError(\"failed to send batch\");\n-    }\n+    if (!_add_batch_closure->is_packet_in_flight() && _pending_batches_num > 0) {\n+        SCOPED_RAW_TIMER(&_actual_consume_ns);\n+        AddBatchReq send_batch;\n+        {\n+            std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+            DCHECK(!_pending_batches.empty());\n+            send_batch = std::move(_pending_batches.front());\n+            _pending_batches.pop();\n+            _pending_batches_num--;\n+        }\n \n-    if (_add_batch_closure->result.has_execution_time_us()) {\n-        _parent->update_node_add_batch_counter(_node_id,\n-                _add_batch_closure->result.execution_time_us(),\n-                _add_batch_closure->result.wait_lock_time_us());\n-    }\n-    return {_add_batch_closure->result.status()};\n-}\n+        auto row_batch = std::move(send_batch.first);\n+        auto request = std::move(send_batch.second); // doesn't need to be saved in heap\n \n-Status NodeChannel::_send_cur_batch(bool eos) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n+        // tablet_ids has already set when add row\n+        request.set_packet_seq(_next_packet_seq);\n+        if (row_batch->num_rows() > 0) {\n+            SCOPED_RAW_TIMER(&_serialize_batch_ns);\n+            row_batch->serialize(request.mutable_row_batch());\n+        }\n \n-    // tablet_ids has already set when add row\n-    _add_batch_request.set_eos(eos);\n-    _add_batch_request.set_packet_seq(_next_packet_seq);\n-    if (_batch->num_rows() > 0) {\n-        SCOPED_RAW_TIMER(_parent->mutable_serialize_batch_ns());\n-        _batch->serialize(_add_batch_request.mutable_row_batch());\n-    }\n+        _add_batch_closure->reset();\n+        _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n \n-    _add_batch_closure->ref();\n-    _add_batch_closure->cntl.Reset();\n-    _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n+        if (request.eos()) {\n+            for (auto pid : _parent->_partition_ids) {\n+                request.add_partition_ids(pid);\n+            }\n \n-    if (eos) {\n-        for (auto pid : _parent->_partition_ids) {\n-            _add_batch_request.add_partition_ids(pid);\n+            // eos request must be the last request\n+            _add_batch_closure->end_mark();\n+            _send_finished = true;\n+            DCHECK(_pending_batches_num == 0);\n+            LOG(INFO) << name() << \" send finished, should wait the last repsonse\";\n         }\n-    }\n \n-    _stub->tablet_writer_add_batch(&_add_batch_closure->cntl,\n-                                   &_add_batch_request,\n-                                   &_add_batch_closure->result,\n-                                   _add_batch_closure);\n-    _add_batch_request.clear_tablet_ids();\n-    _add_batch_request.clear_row_batch();\n-    _add_batch_request.clear_partition_ids();\n+        _add_batch_closure->set_in_flight();\n+        _stub->tablet_writer_add_batch(&_add_batch_closure->cntl, &request,\n+                                       &_add_batch_closure->result, _add_batch_closure);\n \n-    _has_in_flight_packet = true;\n-    _next_packet_seq++;\n+        _next_packet_seq++;\n+    }\n \n-    _batch->reset();\n-    return Status::OK();\n+    return _send_finished ? 0 : 1;\n }\n \n-IndexChannel::~IndexChannel() {\n+Status NodeChannel::none_of(std::initializer_list<bool> vars) {\n+    bool none = true;\n+    std::string vars_str;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e917632d905951c4192bc824632fda50721efb9"}, "originalPosition": 378}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4ODgzMTI1", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-378883125", "createdAt": "2020-03-21T02:05:42Z", "commit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjowNTo0MlrOF5m86w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQwMjo0NToyOVrOF5nIPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTMzOQ==", "bodyText": "Is this log needed?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395951339", "createdAt": "2020-03-21T02:05:42Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MTgwNg==", "bodyText": "If there is no other workload, will this cause a busy-loop?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395951806", "createdAt": "2020-03-21T02:12:02Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -877,5 +920,24 @@ int OlapTableSink::_validate_data(RuntimeState* state, RowBatch* batch, Bitmap*\n     return filtered_rows;\n }\n \n+void OlapTableSink::_send_batch_process() {\n+    SCOPED_RAW_TIMER(&_non_blocking_send_ns);\n+    while (true) {\n+        int running_channels_num = 0;\n+        for (auto index_channel : _channels) {\n+            index_channel->for_each_node_channel([&](NodeChannel* ch) {\n+                running_channels_num += ch->try_send_and_fetch_status();\n+            });\n+        }\n+\n+        if (running_channels_num == 0) {\n+            LOG(INFO) << \"all node channels are stopped(maybe finished/offending/cancelled), \"\n+                         \"consumer thread exit.\";\n+            return;\n+        }\n+        std::this_thread::yield();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 806}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MzI3Mg==", "bodyText": "should remove this trace log", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395953272", "createdAt": "2020-03-21T02:31:54Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +260,90 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {\n+    auto st = none_of({_rpc_error, _is_cancelled, _send_finished});\n+    if (!st.ok()) {\n+        return 0;\n     }\n \n-    SCOPED_RAW_TIMER(_parent->mutable_wait_in_flight_packet_ns());\n-    _add_batch_closure->join();\n-    _has_in_flight_packet = false;\n-    if (_add_batch_closure->cntl.Failed()) {\n-        LOG(WARNING) << \"failed to send batch, error=\"\n-            << berror(_add_batch_closure->cntl.ErrorCode())\n-            << \", error_text=\" << _add_batch_closure->cntl.ErrorText();\n-        return Status::InternalError(\"failed to send batch\");\n-    }\n+    if (!_add_batch_closure->is_packet_in_flight() && _pending_batches_num > 0) {\n+        SCOPED_RAW_TIMER(&_actual_consume_ns);\n+        AddBatchReq send_batch;\n+        {\n+            std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+            DCHECK(!_pending_batches.empty());\n+            send_batch = std::move(_pending_batches.front());\n+            _pending_batches.pop();\n+            _pending_batches_num--;\n+        }\n \n-    if (_add_batch_closure->result.has_execution_time_us()) {\n-        _parent->update_node_add_batch_counter(_node_id,\n-                _add_batch_closure->result.execution_time_us(),\n-                _add_batch_closure->result.wait_lock_time_us());\n-    }\n-    return {_add_batch_closure->result.status()};\n-}\n+        auto row_batch = std::move(send_batch.first);\n+        auto request = std::move(send_batch.second); // doesn't need to be saved in heap\n \n-Status NodeChannel::_send_cur_batch(bool eos) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n+        // tablet_ids has already set when add row\n+        request.set_packet_seq(_next_packet_seq);\n+        if (row_batch->num_rows() > 0) {\n+            SCOPED_RAW_TIMER(&_serialize_batch_ns);\n+            row_batch->serialize(request.mutable_row_batch());\n+        }\n \n-    // tablet_ids has already set when add row\n-    _add_batch_request.set_eos(eos);\n-    _add_batch_request.set_packet_seq(_next_packet_seq);\n-    if (_batch->num_rows() > 0) {\n-        SCOPED_RAW_TIMER(_parent->mutable_serialize_batch_ns());\n-        _batch->serialize(_add_batch_request.mutable_row_batch());\n-    }\n+        _add_batch_closure->reset();\n+        _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n \n-    _add_batch_closure->ref();\n-    _add_batch_closure->cntl.Reset();\n-    _add_batch_closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n+        if (request.eos()) {\n+            for (auto pid : _parent->_partition_ids) {\n+                request.add_partition_ids(pid);\n+            }\n \n-    if (eos) {\n-        for (auto pid : _parent->_partition_ids) {\n-            _add_batch_request.add_partition_ids(pid);\n+            // eos request must be the last request\n+            _add_batch_closure->end_mark();\n+            _send_finished = true;\n+            DCHECK(_pending_batches_num == 0);\n+            LOG(INFO) << name() << \" send finished, should wait the last repsonse\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 353}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1Mzc1MQ==", "bodyText": "change  to explicit capture", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395953751", "createdAt": "2020-03-21T02:37:58Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -611,57 +633,79 @@ Status OlapTableSink::close(RuntimeState* state, Status close_status) {\n         // only if status is ok can we call this _profile->total_time_counter().\n         // if status is not ok, this sink may not be prepared, so that _profile is null\n         SCOPED_TIMER(_profile->total_time_counter());\n+        int64_t serialize_batch_ns = 0, queue_push_lock_ns = 0, actual_consume_ns = 0;\n         {\n             SCOPED_TIMER(_close_timer);\n-            for (auto channel : _channels) {\n-                status = channel->close(state);\n-                if (!status.ok()) {\n-                    LOG(WARNING) << \"close channel failed, load_id=\" << print_id(_load_id)\n-                        << \", txn_id=\" << _txn_id;\n-                }\n+            for (auto index_channel : _channels) {\n+                index_channel->for_each_node_channel(\n+                        [&](NodeChannel* ch) { WARN_IF_ERROR(ch->mark_close(), \"\"); });\n+            }\n+\n+            for (auto index_channel : _channels) {\n+                index_channel->for_each_node_channel([&](NodeChannel* ch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 638}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NDIzOQ==", "bodyText": "we should limit the length of pending_batches.\nWhen sender is blocked, this queue will consume memory without limit", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r395954239", "createdAt": "2020-03-21T02:45:29Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,55 +129,128 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _rpc_error = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, load_id=\" << _parent->_load_id\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                        LOG(INFO) << name() << \" last rpc has responsed\";\n+                    }\n+                } else {\n+                    _rpc_error = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status not ok, load_id=\"\n+                                 << _parent->_load_id << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_rpc_error, _is_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. rpc_error/cancelled/eos: \");\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5bbc429d4dd9c64ef7449338905faded909ac2"}, "originalPosition": 158}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMDUxNDY3", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-382051467", "createdAt": "2020-03-26T14:16:11Z", "commit": {"oid": "37f076de20a808a3899a10601dea8d7ea87c3160"}, "state": "DISMISSED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDoyNDowOFrOF8JY0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDoyNDowOFrOF8JY0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYxMjY5MQ==", "bodyText": "Why not using bool as return value?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r398612691", "createdAt": "2020-03-26T14:24:08Z", "author": {"login": "morningman"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -186,80 +267,89 @@ void NodeChannel::cancel() {\n \n     closure->ref();\n     closure->cntl.set_timeout_ms(_rpc_timeout_ms);\n-    _stub->tablet_writer_cancel(&closure->cntl,\n-                                &request,\n-                                &closure->result,\n-                                closure);\n+    _stub->tablet_writer_cancel(&closure->cntl, &request, &closure->result, closure);\n     request.release_id();\n \n-    // reset batch\n-    _batch.reset();\n+    // Beware of the destruct sequence. RowBatches will use mem_trackers(include ancestors).\n+    // Delete RowBatches here is a better choice to reduce the potential of dtor errors.\n+    {\n+        std::lock_guard<std::mutex> lg(_pending_batches_lock);\n+        std::queue<AddBatchReq> empty;\n+        std::swap(_pending_batches, empty);\n+        _cur_batch.reset();\n+    }\n }\n \n-Status NodeChannel::_wait_in_flight_packet() {\n-    if (!_has_in_flight_packet) {\n-        return Status::OK();\n+int NodeChannel::try_send_and_fetch_status() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f076de20a808a3899a10601dea8d7ea87c3160"}, "originalPosition": 292}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxNzkwOTUy", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-401790952", "createdAt": "2020-04-28T12:37:37Z", "commit": {"oid": "30288c47f8fbb2418b34daf92fa8264640912a45"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjozNzozOFrOGNR3yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMjo1MDo1N1rOGNSZFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjU3NzQ4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                CONF_Int32(olap_table_sink_send_interval_ms, \"10\");\n          \n          \n            \n                CONF_mInt32(olap_table_sink_send_interval_ms, \"10\");", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r416577481", "createdAt": "2020-04-28T12:37:38Z", "author": {"login": "imay"}, "path": "be/src/common/config.h", "diffHunk": "@@ -296,6 +296,8 @@ namespace config {\n     // you may need to increase this timeout if using larger 'streaming_load_max_mb',\n     // or encounter 'tablet writer write failed' error when loading.\n     // CONF_Int32(tablet_writer_rpc_timeout_sec, \"600\");\n+    // OlapTableSink sender's send interval, should be less than the real response time of a tablet writer rpc.\n+    CONF_Int32(olap_table_sink_send_interval_ms, \"10\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30288c47f8fbb2418b34daf92fa8264640912a45"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjU4NjAwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void for_each_node_channel(std::function<void(NodeChannel*)> func) {\n          \n          \n            \n                void for_each_node_channel(const std::function<void(NodeChannel*)>& func) {", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r416586004", "createdAt": "2020-04-28T12:50:57Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";\n+    }\n \n-private:\n-    Status _send_cur_batch(bool eos = false);\n-    // wait inflight packet finish, return error if inflight packet return failed\n-    Status _wait_in_flight_packet();\n-\n-    Status _close(RuntimeState* state);\n+    Status none_of(std::initializer_list<bool> vars);\n \n private:\n     OlapTableSink* _parent = nullptr;\n     int64_t _index_id = -1;\n     int64_t _node_id = -1;\n     int32_t _schema_hash = 0;\n+    std::string _load_info;\n \n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    // user cancel or get some errors\n+    std::atomic<bool> _cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};\n+\n+    bool _eos_is_produced{false}; // only for restricting producer behaviors\n+\n+    std::unique_ptr<RowDescriptor> _row_desc;\n+    int _batch_size = 0;\n+    std::unique_ptr<RowBatch> _cur_batch;\n+    PTabletWriterAddBatchRequest _cur_add_batch_request;\n+\n+    std::mutex _pending_batches_lock;\n+    using AddBatchReq = std::pair<std::unique_ptr<RowBatch>, PTabletWriterAddBatchRequest>;\n+    std::queue<AddBatchReq> _pending_batches;\n+    std::atomic<int> _pending_batches_num{0};\n+\n     palo::PInternalService_Stub* _stub = nullptr;\n     RefCountClosure<PTabletWriterOpenResult>* _open_closure = nullptr;\n-    RefCountClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n+    ReusableClosure<PTabletWriterAddBatchResult>* _add_batch_closure = nullptr;\n \n     std::vector<TTabletWithPartition> _all_tablets;\n-    PTabletWriterAddBatchRequest _add_batch_request;\n+    std::vector<TTabletCommitInfo> _tablet_commit_infos;\n+\n+    AddBatchCounter _add_batch_counter;\n+    int64_t _serialize_batch_ns = 0;\n+\n+    int64_t _mem_exceeded_block_ns = 0;\n+    int64_t _queue_push_lock_ns = 0;\n+    int64_t _actual_consume_ns = 0;\n };\n \n class IndexChannel {\n public:\n     IndexChannel(OlapTableSink* parent, int64_t index_id, int32_t schema_hash)\n-            : _parent(parent), _index_id(index_id),\n-            _schema_hash(schema_hash) {\n-    }\n+            : _parent(parent), _index_id(index_id), _schema_hash(schema_hash) {}\n     ~IndexChannel();\n \n-    Status init(RuntimeState* state,\n-                const std::vector<TTabletWithPartition>& tablets);\n-    Status open();\n-    Status add_row(Tuple* tuple, int64_t tablet_id);\n+    Status init(RuntimeState* state, const std::vector<TTabletWithPartition>& tablets);\n \n-    Status close(RuntimeState* state);\n+    Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    void cancel();\n+    void for_each_node_channel(std::function<void(NodeChannel*)> func) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30288c47f8fbb2418b34daf92fa8264640912a45"}, "originalPosition": 252}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNzU3NzU5", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-402757759", "createdAt": "2020-04-29T15:02:09Z", "commit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTowMjoxMFrOGODPlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNTo0NTowOVrOGOFNgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM4NjM4OA==", "bodyText": "If param will be modified, prefer pointer rather than reference.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417386388", "createdAt": "2020-04-29T15:02:10Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM4NzQ5OQ==", "bodyText": "Prefer strings::Substitute in gutils/strings/Substitute.h.", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417387499", "createdAt": "2020-04-29T15:03:47Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() const { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM5OTMxNw==", "bodyText": "Do we need these log?", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417399317", "createdAt": "2020-04-29T15:19:38Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.cpp", "diffHunk": "@@ -128,54 +131,136 @@ Status NodeChannel::open_wait() {\n     _open_closure = nullptr;\n \n     // add batch closure\n-    _add_batch_closure = new RefCountClosure<PTabletWriterAddBatchResult>();\n-    _add_batch_closure->ref();\n+    _add_batch_closure = ReusableClosure<PTabletWriterAddBatchResult>::create();\n+    _add_batch_closure->addFailedHandler([this]() {\n+        _cancelled = true;\n+        LOG(WARNING) << \"NodeChannel add batch req rpc failed, \" << print_load_info()\n+                     << \", node=\" << node_info()->host << \":\" << node_info()->brpc_port;\n+    });\n+\n+    _add_batch_closure->addSuccessHandler(\n+            [this](const PTabletWriterAddBatchResult& result, bool is_last_rpc) {\n+                Status status(result.status());\n+                if (status.ok()) {\n+                    if (is_last_rpc) {\n+                        for (auto& tablet : result.tablet_vec()) {\n+                            TTabletCommitInfo commit_info;\n+                            commit_info.tabletId = tablet.tablet_id();\n+                            commit_info.backendId = _node_id;\n+                            _tablet_commit_infos.emplace_back(std::move(commit_info));\n+                        }\n+                        _add_batches_finished = true;\n+                    }\n+                } else {\n+                    _cancelled = true;\n+                    LOG(WARNING) << \"NodeChannel add batch req success but status isn't ok, \"\n+                                 << print_load_info() << \", node=\" << node_info()->host << \":\"\n+                                 << node_info()->brpc_port << \", errmsg=\" << status.get_error_msg();\n+                }\n+\n+                if (result.has_execution_time_us()) {\n+                    _add_batch_counter.add_batch_execution_time_us += result.execution_time_us();\n+                    _add_batch_counter.add_batch_wait_lock_time_us += result.wait_lock_time_us();\n+                    _add_batch_counter.add_batch_num++;\n+                }\n+            });\n \n     return status;\n }\n \n Status NodeChannel::add_row(Tuple* input_tuple, int64_t tablet_id) {\n-    auto row_no = _batch->add_row();\n+    // If add_row() when _eos_is_produced==true, there must be sth wrong, we can only mark this channel as failed.\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't add_row. cancelled/eos: \");\n+    }\n+\n+    // We use OlapTableSink mem_tracker which has the same ancestor of _plan node,\n+    // so in the ideal case, mem limit is a matter for _plan node.\n+    // But there is still some unfinished things, we do mem limit here temporarily.\n+    while (_parent->_mem_tracker->any_limit_exceeded()) {\n+        SCOPED_RAW_TIMER(&_mem_exceeded_block_ns);\n+        SleepFor(MonoDelta::FromMilliseconds(10));\n+    }\n+\n+    auto row_no = _cur_batch->add_row();\n     if (row_no == RowBatch::INVALID_ROW_INDEX) {\n-        RETURN_IF_ERROR(_send_cur_batch());\n-        row_no = _batch->add_row();\n+        {\n+            SCOPED_RAW_TIMER(&_queue_push_lock_ns);\n+            std::lock_guard<std::mutex> l(_pending_batches_lock);\n+            //To simplify the add_row logic, postpone adding batch into req until the time of sending req\n+            _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+            _pending_batches_num++;\n+        }\n+\n+        _cur_batch.reset(new RowBatch(*_row_desc, _batch_size, _parent->_mem_tracker));\n+        _cur_add_batch_request.clear_tablet_ids();\n+\n+        row_no = _cur_batch->add_row();\n     }\n     DCHECK_NE(row_no, RowBatch::INVALID_ROW_INDEX);\n-    auto tuple = input_tuple->deep_copy(*_tuple_desc, _batch->tuple_data_pool());\n-    _batch->get_row(row_no)->set_tuple(0, tuple);\n-    _batch->commit_last_row();\n-    _add_batch_request.add_tablet_ids(tablet_id);\n+    auto tuple = input_tuple->deep_copy(*_tuple_desc, _cur_batch->tuple_data_pool());\n+    _cur_batch->get_row(row_no)->set_tuple(0, tuple);\n+    _cur_batch->commit_last_row();\n+    _cur_add_batch_request.add_tablet_ids(tablet_id);\n     return Status::OK();\n }\n \n-Status NodeChannel::close(RuntimeState* state) {\n-    auto st = _close(state);\n-    _batch.reset();\n-    return st;\n-}\n+Status NodeChannel::mark_close() {\n+    auto st = none_of({_cancelled, _eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, can't mark as closed. cancelled/eos: \");\n+    }\n \n-Status NodeChannel::_close(RuntimeState* state) {\n-    return _send_cur_batch(true);\n+    _cur_add_batch_request.set_eos(true);\n+    {\n+        std::lock_guard<std::mutex> l(_pending_batches_lock);\n+        _pending_batches.emplace(std::move(_cur_batch), _cur_add_batch_request);\n+        _pending_batches_num++;\n+        DCHECK(_pending_batches.back().second.eos());\n+    }\n+\n+    _eos_is_produced = true;\n+\n+    _cur_batch.reset();\n+    return Status::OK();\n }\n \n Status NodeChannel::close_wait(RuntimeState* state) {\n-    RETURN_IF_ERROR(_wait_in_flight_packet());\n-    Status status(_add_batch_closure->result.status());\n-    if (status.ok()) {\n-        for (auto& tablet : _add_batch_closure->result.tablet_vec()) {\n-            TTabletCommitInfo commit_info;\n-            commit_info.tabletId = tablet.tablet_id();\n-            commit_info.backendId = _node_id;\n-            state->tablet_commit_infos().emplace_back(std::move(commit_info));\n-        }\n+    auto st = none_of({_cancelled, !_eos_is_produced});\n+    if (!st.ok()) {\n+        return st.clone_and_prepend(\"already stopped, skip waiting for close. cancelled/!eos: \");\n     }\n-    // clear batch after sendt\n-    _batch.reset();\n-    return status;\n+\n+    // waiting for finished, it may take a long time, so we could't set a timeout\n+    // use log to make it easier\n+    LOG(INFO) << name() << \"start close_wait\";\n+    while (!_add_batches_finished && !_cancelled) {\n+        SleepFor(MonoDelta::FromMilliseconds(1));\n+    }\n+    LOG(INFO) << name() << \"close_wait done\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQxODYyNw==", "bodyText": "what's the difference between these two flags?\nShould comment to let us know", "url": "https://github.com/apache/incubator-doris/pull/3143#discussion_r417418627", "createdAt": "2020-04-29T15:45:09Z", "author": {"login": "imay"}, "path": "be/src/exec/tablet_sink.h", "diffHunk": "@@ -68,99 +154,126 @@ class NodeChannel {\n \n     Status add_row(Tuple* tuple, int64_t tablet_id);\n \n-    Status close(RuntimeState* state);\n+    // two ways to stop channel:\n+    // 1. mark_close()->close_wait() PS. close_wait() will block waiting for the last AddBatch rpc response.\n+    // 2. just cancel()\n+    Status mark_close();\n     Status close_wait(RuntimeState* state);\n \n     void cancel();\n \n-    int64_t node_id() const { return _node_id; }\n+    // return:\n+    // 0: stopped, send finished(eos request has been sent), or any internal error;\n+    // 1: running, haven't reach eos.\n+    // only allow 1 rpc in flight\n+    int try_send_and_fetch_status();\n+\n+    void time_report(std::unordered_map<int64_t, AddBatchCounter>& add_batch_counter_map,\n+                     int64_t* serialize_batch_ns, int64_t* mem_exceeded_block_ns,\n+                     int64_t* queue_push_lock_ns, int64_t* actual_consume_ns) {\n+        add_batch_counter_map[_node_id] += _add_batch_counter;\n+        *serialize_batch_ns += _serialize_batch_ns;\n+        *mem_exceeded_block_ns += _mem_exceeded_block_ns;\n+        *queue_push_lock_ns += _queue_push_lock_ns;\n+        *actual_consume_ns += _actual_consume_ns;\n+    }\n \n-    void set_failed() { _already_failed = true; }\n-    bool already_failed() const { return _already_failed; }\n+    int64_t node_id() const { return _node_id; }\n     const NodeInfo* node_info() const { return _node_info; }\n+    std::string print_load_info() const { return _load_info; }\n+    std::string name() const {\n+        return \"NodeChannel[\" + std::to_string(_index_id) + \"-\" + std::to_string(_node_id) + \"]\";\n+    }\n \n-private:\n-    Status _send_cur_batch(bool eos = false);\n-    // wait inflight packet finish, return error if inflight packet return failed\n-    Status _wait_in_flight_packet();\n-\n-    Status _close(RuntimeState* state);\n+    Status none_of(std::initializer_list<bool> vars);\n \n private:\n     OlapTableSink* _parent = nullptr;\n     int64_t _index_id = -1;\n     int64_t _node_id = -1;\n     int32_t _schema_hash = 0;\n+    std::string _load_info;\n \n     TupleDescriptor* _tuple_desc = nullptr;\n     const NodeInfo* _node_info = nullptr;\n \n-    bool _already_failed = false;\n-    bool _has_in_flight_packet = false;\n     // this should be set in init() using config\n     int _rpc_timeout_ms = 60000;\n     int64_t _next_packet_seq = 0;\n \n-    std::unique_ptr<RowBatch> _batch;\n+    // user cancel or get some errors\n+    std::atomic<bool> _cancelled{false};\n+\n+    std::atomic<bool> _send_finished{false};\n+    std::atomic<bool> _add_batches_finished{false};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e7da7f741943e0759ac7fd9c8c31f98ed9b5f9"}, "originalPosition": 202}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cdc835ba05f0c285e5fbdc6fad351d8a571c4cc4", "author": {"user": {"login": "morningman", "name": "Mingyu Chen"}}, "url": "https://github.com/apache/incubator-doris/commit/cdc835ba05f0c285e5fbdc6fad351d8a571c4cc4", "committedDate": "2020-05-06T02:33:10Z", "message": "[UT] Fix AlterTest UT failed (#3437)"}, "afterCommit": {"oid": "d13052868e20975979490d8e24369a9d49399047", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/d13052868e20975979490d8e24369a9d49399047", "committedDate": "2020-05-06T03:59:42Z", "message": "merge master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d13052868e20975979490d8e24369a9d49399047", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/d13052868e20975979490d8e24369a9d49399047", "committedDate": "2020-05-06T03:59:42Z", "message": "merge master"}, "afterCommit": {"oid": "c9c27410039559edf48f0fe7169b79343b263e4c", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/c9c27410039559edf48f0fe7169b79343b263e4c", "committedDate": "2020-05-06T04:03:03Z", "message": "merge ut fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5767ca48e0c2f328b0c5f7249248e9cc656f01c2", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/5767ca48e0c2f328b0c5f7249248e9cc656f01c2", "committedDate": "2020-05-06T06:56:44Z", "message": "[] non-blocking sink draft"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d52eba3afa0fcd12760ae65884608d9fedcbfccc", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/d52eba3afa0fcd12760ae65884608d9fedcbfccc", "committedDate": "2020-05-06T06:57:47Z", "message": "[] DEBUG LOG"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d55dd1ca5231dcc799aca35ad6d8207fdd05c62a", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/d55dd1ca5231dcc799aca35ad6d8207fdd05c62a", "committedDate": "2020-05-06T06:57:48Z", "message": "delete batches in cancel"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbd79b8602829e038729aa76102c9ef006dc731d", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/bbd79b8602829e038729aa76102c9ef006dc731d", "committedDate": "2020-05-06T06:57:48Z", "message": "[] comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0fcd9b3dbabed95e6785fb90c9997af1df79bd3", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/c0fcd9b3dbabed95e6785fb90c9997af1df79bd3", "committedDate": "2020-05-06T06:57:48Z", "message": "comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ff4c709dcce8e1b1394fdac2f6c3cc7d525a7dc", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/7ff4c709dcce8e1b1394fdac2f6c3cc7d525a7dc", "committedDate": "2020-05-06T06:58:15Z", "message": "Revert \"[] DEBUG LOG\"\n\nThis reverts commit a74eeca3574b777d15d435502f39e92920518a19."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f00f4c9ee8a50d9e6be6e4b4c702a0b1db00dda2", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/f00f4c9ee8a50d9e6be6e4b4c702a0b1db00dda2", "committedDate": "2020-05-06T06:58:15Z", "message": "fix log level"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "417c119099b17873fa8adaa2d0335d1640dea8b1", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/417c119099b17873fa8adaa2d0335d1640dea8b1", "committedDate": "2020-05-06T06:58:15Z", "message": "fix none_of & olaptablesink comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5bf4da9aff4fb612344274de3f806ef74946e054", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/5bf4da9aff4fb612344274de3f806ef74946e054", "committedDate": "2020-05-06T06:58:15Z", "message": "typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e53595f24dcd171df09ed219ad825aa1faebb7a9", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/e53595f24dcd171df09ed219ad825aa1faebb7a9", "committedDate": "2020-05-06T06:59:38Z", "message": "capture this, error returns, ut fix & comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bc93336b0c531e6995ddb5396667c7dfb7f3b04", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/7bc93336b0c531e6995ddb5396667c7dfb7f3b04", "committedDate": "2020-05-06T06:59:38Z", "message": "fixes, mem limit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3b3a217f0cd88ce2ab25bbac7a5c7830e461edb", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/c3b3a217f0cd88ce2ab25bbac7a5c7830e461edb", "committedDate": "2020-05-06T06:59:38Z", "message": "capture fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e284e73766c4d50bbda099a826add9b9aab95e7f", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/e284e73766c4d50bbda099a826add9b9aab95e7f", "committedDate": "2020-05-06T06:59:38Z", "message": "[] reduce channel status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0579af049840579a60e5e182c9ee42f46f03335d", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/0579af049840579a60e5e182c9ee42f46f03335d", "committedDate": "2020-05-06T06:59:38Z", "message": "[] reduce channel status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d74b05ff0e6015bb3004bebfc18430a588c917df", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/d74b05ff0e6015bb3004bebfc18430a588c917df", "committedDate": "2020-05-06T07:00:25Z", "message": "add row block time, send interval"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "090f1c0f0e72a38d6a7e9fd24ac7959d345bf300", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/090f1c0f0e72a38d6a7e9fd24ac7959d345bf300", "committedDate": "2020-05-06T07:00:25Z", "message": "default send interval 10ms"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e63942a9e7ff889a918544a0c8b783d24e183bd0", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/e63942a9e7ff889a918544a0c8b783d24e183bd0", "committedDate": "2020-05-06T07:00:26Z", "message": "mInt32\n\nCo-Authored-By: Zhao Chun <buaa.zhaoc@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00f3d94f4f0392aa4b4e91f7fcd87c426cc10de2", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/00f3d94f4f0392aa4b4e91f7fcd87c426cc10de2", "committedDate": "2020-05-06T07:00:26Z", "message": "std::function copy->ref\n\nCo-Authored-By: Zhao Chun <buaa.zhaoc@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63429b38531ed7c1ba63d8085ecb503855a1158c", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/63429b38531ed7c1ba63d8085ecb503855a1158c", "committedDate": "2020-05-06T07:00:26Z", "message": "use sleep in close_wait"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0888227e97ef386ec646676a66e97ce2c3f31568", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/0888227e97ef386ec646676a66e97ce2c3f31568", "committedDate": "2020-05-06T07:00:27Z", "message": "fix ac by review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f7eac818ad4a8b73e2507c10bf5878cba4edfb6", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/2f7eac818ad4a8b73e2507c10bf5878cba4edfb6", "committedDate": "2020-05-06T07:00:27Z", "message": "fix close wait time log"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c9c27410039559edf48f0fe7169b79343b263e4c", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/c9c27410039559edf48f0fe7169b79343b263e4c", "committedDate": "2020-05-06T04:03:03Z", "message": "merge ut fix"}, "afterCommit": {"oid": "2f7eac818ad4a8b73e2507c10bf5878cba4edfb6", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/2f7eac818ad4a8b73e2507c10bf5878cba4edfb6", "committedDate": "2020-05-06T07:00:27Z", "message": "fix close wait time log"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "080a648af70a038e3702bbedf82bbf3f93e338d5", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/080a648af70a038e3702bbedf82bbf3f93e338d5", "committedDate": "2020-05-06T07:03:35Z", "message": "revert brocker scan node format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b66737d1460a1d7620734f6bad0f8d354d560549", "author": {"user": null}, "url": "https://github.com/apache/incubator-doris/commit/b66737d1460a1d7620734f6bad0f8d354d560549", "committedDate": "2020-05-06T07:12:35Z", "message": "let send_interval_ms modifiable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NDE4ODY4", "url": "https://github.com/apache/incubator-doris/pull/3143#pullrequestreview-406418868", "createdAt": "2020-05-06T08:53:59Z", "commit": {"oid": "b66737d1460a1d7620734f6bad0f8d354d560549"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3324, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}