{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkwOTQwNzk4", "number": 3148, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMjo1MToyNlrODpflxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMjo1MToyNlrODpflxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODM1NzgwOnYy", "diffSide": "RIGHT", "path": "be/src/exec/hash_join_node_ir.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMjo1MToyNlrOF4s-3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMjowOToxNVrOF5F-FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAwMTU2NQ==", "bodyText": "I think these compare can be done just once when initializing the HashJoinNode, no need to judge it for every row.", "url": "https://github.com/apache/incubator-doris/pull/3148#discussion_r395001565", "createdAt": "2020-03-19T12:51:26Z", "author": {"login": "morningman"}, "path": "be/src/exec/hash_join_node_ir.cpp", "diffHunk": "@@ -137,11 +137,20 @@ int HashJoinNode::process_probe_batch(RowBatch* out_batch, RowBatch* probe_batch\n     return rows_returned;\n }\n \n+// when build table has too many duplicated rows, the collisions will be very serious,\n+// so in some case will don't need to store duplicated value in hash table, we can build an unique one\n void HashJoinNode::process_build_batch(RowBatch* build_batch) {\n     // insert build row into our hash table\n     for (int i = 0; i < build_batch->num_rows(); ++i) {\n-        _hash_tbl->insert(build_batch->get_row(i));\n+        if (_join_op == TJoinOp::LEFT_ANTI_JOIN|| _join_op == TJoinOp::RIGHT_ANTI_JOIN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55530010711c6e4a627889ce7aba79dcc90064d1"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQxMDk2NQ==", "bodyText": "done", "url": "https://github.com/apache/incubator-doris/pull/3148#discussion_r395410965", "createdAt": "2020-03-20T02:09:15Z", "author": {"login": "yangzhg"}, "path": "be/src/exec/hash_join_node_ir.cpp", "diffHunk": "@@ -137,11 +137,20 @@ int HashJoinNode::process_probe_batch(RowBatch* out_batch, RowBatch* probe_batch\n     return rows_returned;\n }\n \n+// when build table has too many duplicated rows, the collisions will be very serious,\n+// so in some case will don't need to store duplicated value in hash table, we can build an unique one\n void HashJoinNode::process_build_batch(RowBatch* build_batch) {\n     // insert build row into our hash table\n     for (int i = 0; i < build_batch->num_rows(); ++i) {\n-        _hash_tbl->insert(build_batch->get_row(i));\n+        if (_join_op == TJoinOp::LEFT_ANTI_JOIN|| _join_op == TJoinOp::RIGHT_ANTI_JOIN", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAwMTU2NQ=="}, "originalCommit": {"oid": "55530010711c6e4a627889ce7aba79dcc90064d1"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1978, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}