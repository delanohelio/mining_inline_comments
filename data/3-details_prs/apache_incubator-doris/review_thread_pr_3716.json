{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0NjEzMjg1", "number": 3716, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MjoyNVrOEAuwLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzo1ODozMlrOEGXNEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MjAxNDUyOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MjoyNVrOGcMS_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MjoyNVrOGcMS_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNDc4MA==", "bodyText": "prefer return byte[]", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432214780", "createdAt": "2020-05-29T01:52:25Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +142,326 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    public static String readBrokerFile(String path, BrokerDesc brokerDesc) throws UserException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MjAxNjAwOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MzoyOFrOGcMT9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1NDowN1rOGcMUig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNTAyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static void writeBrokerFile(byte[] data, String destFilePath, BrokerDesc brokerDesc) throws UserException {\n          \n          \n            \n                public static void writeFile(byte[] data, String destFilePath, BrokerDesc brokerDesc) throws UserException {", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432215028", "createdAt": "2020-05-29T01:53:28Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +142,326 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    public static String readBrokerFile(String path, BrokerDesc brokerDesc) throws UserException {\n+        TNetworkAddress address = getAddress(brokerDesc);\n+        TPaloBrokerService.Client client = borrowClient(address);\n+        boolean failed = true;\n+        TBrokerFD fd = null;\n+        try {\n+            // get file size\n+            TBrokerListPathRequest request = new TBrokerListPathRequest(\n+                    TBrokerVersion.VERSION_ONE, path, false, brokerDesc.getProperties());\n+            TBrokerListResponse tBrokerListResponse = null;\n+            try {\n+                tBrokerListResponse = client.listPath(request);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tBrokerListResponse = client.listPath(request);\n+            }\n+            if (tBrokerListResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker list path failed. path=\" + path + \", broker=\" + address\n+                                                + \",msg=\" + tBrokerListResponse.getOpStatus().getMessage());\n+            }\n+            List<TBrokerFileStatus> fileStatuses = tBrokerListResponse.getFiles();\n+            if (fileStatuses.size() != 1) {\n+                throw new UserException(\"Broker files num error. path=\" + path + \", broker=\" + address\n+                                                + \", files num: \" + fileStatuses.size());\n+            }\n+\n+            Preconditions.checkState(!fileStatuses.get(0).isIsDir());\n+            long fileSize = fileStatuses.get(0).getSize();\n+\n+            // open reader\n+            String clientId = FrontendOptions.getLocalHostAddress() + \":\" + Config.rpc_port;\n+            TBrokerOpenReaderRequest tOpenReaderRequest = new TBrokerOpenReaderRequest(\n+                    TBrokerVersion.VERSION_ONE, path, 0, clientId, brokerDesc.getProperties());\n+            TBrokerOpenReaderResponse tOpenReaderResponse = null;\n+            try {\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            }\n+            if (tOpenReaderResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker open reader failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tOpenReaderResponse.getOpStatus().getMessage());\n+            }\n+            fd = tOpenReaderResponse.getFd();\n+\n+            // read\n+            TBrokerPReadRequest tPReadRequest = new TBrokerPReadRequest(\n+                    TBrokerVersion.VERSION_ONE, fd, 0, fileSize);\n+            TBrokerReadResponse tReadResponse = null;\n+            try {\n+                tReadResponse = client.pread(tPReadRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tReadResponse = client.pread(tPReadRequest);\n+            }\n+            if (tReadResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker read failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tReadResponse.getOpStatus().getMessage());\n+            }\n+            failed = false;\n+            byte[] data = tReadResponse.getData();\n+            return new String(data, \"UTF-8\");\n+        } catch (TException | UnsupportedEncodingException e) {\n+            String failMsg = \"Broker read file exception. path=\" + path + \", broker=\" + address;\n+            LOG.warn(failMsg, e);\n+            throw new UserException(failMsg);\n+        } finally {\n+            // close reader\n+            if (fd != null) {\n+                failed = true;\n+                TBrokerCloseReaderRequest tCloseReaderRequest = new TBrokerCloseReaderRequest(\n+                        TBrokerVersion.VERSION_ONE, fd);\n+                TBrokerOperationStatus tOperationStatus = null;\n+                try {\n+                    tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                } catch (TException e) {\n+                    reopenClient(client);\n+                    try {\n+                        tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                    } catch (TException ex) {\n+                        LOG.warn(\"Broker close reader failed. path={}, address={}\", path, address, ex);\n+                    }\n+                }\n+                if (tOperationStatus == null || tOperationStatus.getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                    LOG.warn(\"Broker close reader failed. path={}, address={}, error={}\", path, address,\n+                             tOperationStatus.getMessage());\n+                } else {\n+                    failed = false;\n+                }\n+            }\n+\n+            // return client\n+            returnClient(client, address, failed);\n+        }\n+    }\n+\n+    public static void writeBrokerFile(byte[] data, String destFilePath, BrokerDesc brokerDesc) throws UserException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNTE3OA==", "bodyText": "should add comment for public function to help other to use it.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432215178", "createdAt": "2020-05-29T01:54:07Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +142,326 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    public static String readBrokerFile(String path, BrokerDesc brokerDesc) throws UserException {\n+        TNetworkAddress address = getAddress(brokerDesc);\n+        TPaloBrokerService.Client client = borrowClient(address);\n+        boolean failed = true;\n+        TBrokerFD fd = null;\n+        try {\n+            // get file size\n+            TBrokerListPathRequest request = new TBrokerListPathRequest(\n+                    TBrokerVersion.VERSION_ONE, path, false, brokerDesc.getProperties());\n+            TBrokerListResponse tBrokerListResponse = null;\n+            try {\n+                tBrokerListResponse = client.listPath(request);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tBrokerListResponse = client.listPath(request);\n+            }\n+            if (tBrokerListResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker list path failed. path=\" + path + \", broker=\" + address\n+                                                + \",msg=\" + tBrokerListResponse.getOpStatus().getMessage());\n+            }\n+            List<TBrokerFileStatus> fileStatuses = tBrokerListResponse.getFiles();\n+            if (fileStatuses.size() != 1) {\n+                throw new UserException(\"Broker files num error. path=\" + path + \", broker=\" + address\n+                                                + \", files num: \" + fileStatuses.size());\n+            }\n+\n+            Preconditions.checkState(!fileStatuses.get(0).isIsDir());\n+            long fileSize = fileStatuses.get(0).getSize();\n+\n+            // open reader\n+            String clientId = FrontendOptions.getLocalHostAddress() + \":\" + Config.rpc_port;\n+            TBrokerOpenReaderRequest tOpenReaderRequest = new TBrokerOpenReaderRequest(\n+                    TBrokerVersion.VERSION_ONE, path, 0, clientId, brokerDesc.getProperties());\n+            TBrokerOpenReaderResponse tOpenReaderResponse = null;\n+            try {\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            }\n+            if (tOpenReaderResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker open reader failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tOpenReaderResponse.getOpStatus().getMessage());\n+            }\n+            fd = tOpenReaderResponse.getFd();\n+\n+            // read\n+            TBrokerPReadRequest tPReadRequest = new TBrokerPReadRequest(\n+                    TBrokerVersion.VERSION_ONE, fd, 0, fileSize);\n+            TBrokerReadResponse tReadResponse = null;\n+            try {\n+                tReadResponse = client.pread(tPReadRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tReadResponse = client.pread(tPReadRequest);\n+            }\n+            if (tReadResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker read failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tReadResponse.getOpStatus().getMessage());\n+            }\n+            failed = false;\n+            byte[] data = tReadResponse.getData();\n+            return new String(data, \"UTF-8\");\n+        } catch (TException | UnsupportedEncodingException e) {\n+            String failMsg = \"Broker read file exception. path=\" + path + \", broker=\" + address;\n+            LOG.warn(failMsg, e);\n+            throw new UserException(failMsg);\n+        } finally {\n+            // close reader\n+            if (fd != null) {\n+                failed = true;\n+                TBrokerCloseReaderRequest tCloseReaderRequest = new TBrokerCloseReaderRequest(\n+                        TBrokerVersion.VERSION_ONE, fd);\n+                TBrokerOperationStatus tOperationStatus = null;\n+                try {\n+                    tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                } catch (TException e) {\n+                    reopenClient(client);\n+                    try {\n+                        tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                    } catch (TException ex) {\n+                        LOG.warn(\"Broker close reader failed. path={}, address={}\", path, address, ex);\n+                    }\n+                }\n+                if (tOperationStatus == null || tOperationStatus.getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                    LOG.warn(\"Broker close reader failed. path={}, address={}, error={}\", path, address,\n+                             tOperationStatus.getMessage());\n+                } else {\n+                    failed = false;\n+                }\n+            }\n+\n+            // return client\n+            returnClient(client, address, failed);\n+        }\n+    }\n+\n+    public static void writeBrokerFile(byte[] data, String destFilePath, BrokerDesc brokerDesc) throws UserException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNTAyOA=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 210}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MjAxNjI2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MzozOVrOGcMUJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMTo1MzozOVrOGcMUJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNTA3Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static void writeBrokerFile(String srcFilePath, String destFilePath,\n          \n          \n            \n                public static void writeFile(String srcFilePath, String destFilePath,", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432215077", "createdAt": "2020-05-29T01:53:39Z", "author": {"login": "imay"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +142,326 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    public static String readBrokerFile(String path, BrokerDesc brokerDesc) throws UserException {\n+        TNetworkAddress address = getAddress(brokerDesc);\n+        TPaloBrokerService.Client client = borrowClient(address);\n+        boolean failed = true;\n+        TBrokerFD fd = null;\n+        try {\n+            // get file size\n+            TBrokerListPathRequest request = new TBrokerListPathRequest(\n+                    TBrokerVersion.VERSION_ONE, path, false, brokerDesc.getProperties());\n+            TBrokerListResponse tBrokerListResponse = null;\n+            try {\n+                tBrokerListResponse = client.listPath(request);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tBrokerListResponse = client.listPath(request);\n+            }\n+            if (tBrokerListResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker list path failed. path=\" + path + \", broker=\" + address\n+                                                + \",msg=\" + tBrokerListResponse.getOpStatus().getMessage());\n+            }\n+            List<TBrokerFileStatus> fileStatuses = tBrokerListResponse.getFiles();\n+            if (fileStatuses.size() != 1) {\n+                throw new UserException(\"Broker files num error. path=\" + path + \", broker=\" + address\n+                                                + \", files num: \" + fileStatuses.size());\n+            }\n+\n+            Preconditions.checkState(!fileStatuses.get(0).isIsDir());\n+            long fileSize = fileStatuses.get(0).getSize();\n+\n+            // open reader\n+            String clientId = FrontendOptions.getLocalHostAddress() + \":\" + Config.rpc_port;\n+            TBrokerOpenReaderRequest tOpenReaderRequest = new TBrokerOpenReaderRequest(\n+                    TBrokerVersion.VERSION_ONE, path, 0, clientId, brokerDesc.getProperties());\n+            TBrokerOpenReaderResponse tOpenReaderResponse = null;\n+            try {\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            }\n+            if (tOpenReaderResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker open reader failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tOpenReaderResponse.getOpStatus().getMessage());\n+            }\n+            fd = tOpenReaderResponse.getFd();\n+\n+            // read\n+            TBrokerPReadRequest tPReadRequest = new TBrokerPReadRequest(\n+                    TBrokerVersion.VERSION_ONE, fd, 0, fileSize);\n+            TBrokerReadResponse tReadResponse = null;\n+            try {\n+                tReadResponse = client.pread(tPReadRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tReadResponse = client.pread(tPReadRequest);\n+            }\n+            if (tReadResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker read failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tReadResponse.getOpStatus().getMessage());\n+            }\n+            failed = false;\n+            byte[] data = tReadResponse.getData();\n+            return new String(data, \"UTF-8\");\n+        } catch (TException | UnsupportedEncodingException e) {\n+            String failMsg = \"Broker read file exception. path=\" + path + \", broker=\" + address;\n+            LOG.warn(failMsg, e);\n+            throw new UserException(failMsg);\n+        } finally {\n+            // close reader\n+            if (fd != null) {\n+                failed = true;\n+                TBrokerCloseReaderRequest tCloseReaderRequest = new TBrokerCloseReaderRequest(\n+                        TBrokerVersion.VERSION_ONE, fd);\n+                TBrokerOperationStatus tOperationStatus = null;\n+                try {\n+                    tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                } catch (TException e) {\n+                    reopenClient(client);\n+                    try {\n+                        tOperationStatus = client.closeReader(tCloseReaderRequest);\n+                    } catch (TException ex) {\n+                        LOG.warn(\"Broker close reader failed. path={}, address={}\", path, address, ex);\n+                    }\n+                }\n+                if (tOperationStatus == null || tOperationStatus.getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                    LOG.warn(\"Broker close reader failed. path={}, address={}, error={}\", path, address,\n+                             tOperationStatus.getMessage());\n+                } else {\n+                    failed = false;\n+                }\n+            }\n+\n+            // return client\n+            returnClient(client, address, failed);\n+        }\n+    }\n+\n+    public static void writeBrokerFile(byte[] data, String destFilePath, BrokerDesc brokerDesc) throws UserException {\n+        BrokerWriter writer = new BrokerWriter(destFilePath, brokerDesc);\n+        try {\n+            writer.open();\n+            ByteBuffer byteBuffer = ByteBuffer.wrap(data);\n+            writer.write(byteBuffer, data.length);\n+        } finally {\n+            writer.close();\n+        }\n+    }\n+\n+    public static void writeBrokerFile(String srcFilePath, String destFilePath,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTY1Mzg1OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjowMDowMlrOGcwBYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjowMDowMlrOGcwBYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDA5Ng==", "bodyText": "There is keysType is MaterializedIndexMeta. You can get it directly.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432800096", "createdAt": "2020-05-30T02:00:02Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "diffHunk": "@@ -530,6 +530,30 @@ public KeysType getKeysType() {\n         return keysType;\n     }\n \n+    public KeysType getKeysTypeByIndexId(long indexId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTY1NDc3OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/Pair.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjowMToxM1rOGcwB1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNjoxMDozOFrOGlg3gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDIxMw==", "bodyText": "I'am not sure this is ok, cause there is no guarantee that the F and S object can also be serialized by GSON", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432800213", "createdAt": "2020-05-30T02:01:13Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/common/Pair.java", "diffHunk": "@@ -25,7 +27,9 @@\n public class Pair<F, S> {\n     public static PairComparator<Pair<?, Comparable>> PAIR_VALUE_COMPARATOR = new PairComparator<>();\n \n+    @SerializedName(value = \"first\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM1MDk0Mw==", "bodyText": "Users guarantee this when use Pair class\uff1flike Map and List.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r433350943", "createdAt": "2020-06-01T16:33:59Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/common/Pair.java", "diffHunk": "@@ -25,7 +27,9 @@\n public class Pair<F, S> {\n     public static PairComparator<Pair<?, Comparable>> PAIR_VALUE_COMPARATOR = new PairComparator<>();\n \n+    @SerializedName(value = \"first\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDIxMw=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg3NDQ1MQ==", "bodyText": "I checked, this is not work", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r437874451", "createdAt": "2020-06-10T05:50:08Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/common/Pair.java", "diffHunk": "@@ -25,7 +27,9 @@\n public class Pair<F, S> {\n     public static PairComparator<Pair<?, Comparable>> PAIR_VALUE_COMPARATOR = new PairComparator<>();\n \n+    @SerializedName(value = \"first\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDIxMw=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk4ODk5NQ==", "bodyText": "I add a comment.\nWhen using Pair for persistence, users need to guarantee that F and S can be serialized through Gson", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r441988995", "createdAt": "2020-06-18T06:10:38Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/common/Pair.java", "diffHunk": "@@ -25,7 +27,9 @@\n public class Pair<F, S> {\n     public static PairComparator<Pair<?, Comparable>> PAIR_VALUE_COMPARATOR = new PairComparator<>();\n \n+    @SerializedName(value = \"first\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDIxMw=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTY1NTQ4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjowMjo0OVrOGcwCOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjowMjo0OVrOGcwCOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMDMxNA==", "bodyText": "add unit to name.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432800314", "createdAt": "2020-05-30T02:02:49Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -17,52 +17,59 @@\n \n package org.apache.doris.common.util;\n \n-import com.google.common.collect.Lists;\n import org.apache.doris.analysis.BrokerDesc;\n import org.apache.doris.catalog.Catalog;\n import org.apache.doris.catalog.FsBroker;\n import org.apache.doris.common.AnalysisException;\n import org.apache.doris.common.ClientPool;\n+import org.apache.doris.common.Config;\n import org.apache.doris.common.UserException;\n import org.apache.doris.service.FrontendOptions;\n+import org.apache.doris.thrift.TBrokerCloseReaderRequest;\n+import org.apache.doris.thrift.TBrokerCloseWriterRequest;\n+import org.apache.doris.thrift.TBrokerDeletePathRequest;\n+import org.apache.doris.thrift.TBrokerFD;\n import org.apache.doris.thrift.TBrokerFileStatus;\n import org.apache.doris.thrift.TBrokerListPathRequest;\n import org.apache.doris.thrift.TBrokerListResponse;\n+import org.apache.doris.thrift.TBrokerOpenMode;\n+import org.apache.doris.thrift.TBrokerOpenReaderRequest;\n+import org.apache.doris.thrift.TBrokerOpenReaderResponse;\n+import org.apache.doris.thrift.TBrokerOpenWriterRequest;\n+import org.apache.doris.thrift.TBrokerOpenWriterResponse;\n+import org.apache.doris.thrift.TBrokerOperationStatus;\n import org.apache.doris.thrift.TBrokerOperationStatusCode;\n+import org.apache.doris.thrift.TBrokerPReadRequest;\n+import org.apache.doris.thrift.TBrokerPWriteRequest;\n+import org.apache.doris.thrift.TBrokerReadResponse;\n import org.apache.doris.thrift.TBrokerVersion;\n import org.apache.doris.thrift.TNetworkAddress;\n import org.apache.doris.thrift.TPaloBrokerService;\n \n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.apache.thrift.TException;\n \n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n import java.util.Collections;\n import java.util.List;\n \n public class BrokerUtil {\n     private static final Logger LOG = LogManager.getLogger(BrokerUtil.class);\n \n+    private static int READ_BUFFER_SIZE = 1024 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTY2MzQzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjoxOToxOVrOGcwGrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQxNjozNTo0MlrOGdRs8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMTQ1Mw==", "bodyText": "How about get it from SparkEtlJob.class.getXXX()?", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432801453", "createdAt": "2020-05-30T02:19:19Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -0,0 +1,170 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.PaloFe;\n+import org.apache.doris.analysis.BrokerDesc;\n+import org.apache.doris.catalog.SparkResource;\n+import org.apache.doris.common.LoadException;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.BrokerUtil;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig;\n+import org.apache.doris.thrift.TEtlState;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.spark.launcher.SparkAppHandle;\n+import org.apache.spark.launcher.SparkAppHandle.Listener;\n+import org.apache.spark.launcher.SparkAppHandle.State;\n+import org.apache.spark.launcher.SparkLauncher;\n+\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.util.Map;\n+\n+/**\n+ * SparkEtlJobHandler is responsible for\n+ * 1. submit spark etl job\n+ * 2. get spark etl job status\n+ * 3. kill spark etl job\n+ * 4. get spark etl file paths\n+ * 5. delete etl output path\n+ */\n+public class SparkEtlJobHandler {\n+    private static final Logger LOG = LogManager.getLogger(SparkEtlJobHandler.class);\n+\n+    private static final String APP_RESOURCE_NAME = \"palo-fe.jar\";\n+    private static final String CONFIG_FILE_NAME = \"jobconfig.json\";\n+    private static final String APP_RESOURCE_LOCAL_PATH = PaloFe.DORIS_HOME_DIR + \"/lib/\" + APP_RESOURCE_NAME;\n+    private static final String JOB_CONFIG_DIR = \"configs\";\n+    private static final String MAIN_CLASS = \"org.apache.doris.load.loadv2.etl.SparkEtlJob\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM1MTkyMw==", "bodyText": "ok, I comment and will replace with it when SparkEtlJob class is merged.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r433351923", "createdAt": "2020-06-01T16:35:42Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -0,0 +1,170 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.PaloFe;\n+import org.apache.doris.analysis.BrokerDesc;\n+import org.apache.doris.catalog.SparkResource;\n+import org.apache.doris.common.LoadException;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.BrokerUtil;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig;\n+import org.apache.doris.thrift.TEtlState;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.spark.launcher.SparkAppHandle;\n+import org.apache.spark.launcher.SparkAppHandle.Listener;\n+import org.apache.spark.launcher.SparkAppHandle.State;\n+import org.apache.spark.launcher.SparkLauncher;\n+\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.util.Map;\n+\n+/**\n+ * SparkEtlJobHandler is responsible for\n+ * 1. submit spark etl job\n+ * 2. get spark etl job status\n+ * 3. kill spark etl job\n+ * 4. get spark etl file paths\n+ * 5. delete etl output path\n+ */\n+public class SparkEtlJobHandler {\n+    private static final Logger LOG = LogManager.getLogger(SparkEtlJobHandler.class);\n+\n+    private static final String APP_RESOURCE_NAME = \"palo-fe.jar\";\n+    private static final String CONFIG_FILE_NAME = \"jobconfig.json\";\n+    private static final String APP_RESOURCE_LOCAL_PATH = PaloFe.DORIS_HOME_DIR + \"/lib/\" + APP_RESOURCE_NAME;\n+    private static final String JOB_CONFIG_DIR = \"configs\";\n+    private static final String MAIN_CLASS = \"org.apache.doris.load.loadv2.etl.SparkEtlJob\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMTQ1Mw=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTY2NDU4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjoyMToxNlrOGcwHOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQxNjozNzoxMlrOGdRv-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMTU5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            throw new LoadException(errMsg + \"wait too much time for getting appid. spark app state: \"\n          \n          \n            \n                            throw new LoadException(errMsg + \" wait too much time for getting appi d. spark app state: \"", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r432801595", "createdAt": "2020-05-30T02:21:16Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -0,0 +1,170 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.PaloFe;\n+import org.apache.doris.analysis.BrokerDesc;\n+import org.apache.doris.catalog.SparkResource;\n+import org.apache.doris.common.LoadException;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.BrokerUtil;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig;\n+import org.apache.doris.thrift.TEtlState;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.spark.launcher.SparkAppHandle;\n+import org.apache.spark.launcher.SparkAppHandle.Listener;\n+import org.apache.spark.launcher.SparkAppHandle.State;\n+import org.apache.spark.launcher.SparkLauncher;\n+\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.util.Map;\n+\n+/**\n+ * SparkEtlJobHandler is responsible for\n+ * 1. submit spark etl job\n+ * 2. get spark etl job status\n+ * 3. kill spark etl job\n+ * 4. get spark etl file paths\n+ * 5. delete etl output path\n+ */\n+public class SparkEtlJobHandler {\n+    private static final Logger LOG = LogManager.getLogger(SparkEtlJobHandler.class);\n+\n+    private static final String APP_RESOURCE_NAME = \"palo-fe.jar\";\n+    private static final String CONFIG_FILE_NAME = \"jobconfig.json\";\n+    private static final String APP_RESOURCE_LOCAL_PATH = PaloFe.DORIS_HOME_DIR + \"/lib/\" + APP_RESOURCE_NAME;\n+    private static final String JOB_CONFIG_DIR = \"configs\";\n+    private static final String MAIN_CLASS = \"org.apache.doris.load.loadv2.etl.SparkEtlJob\";\n+    private static final String ETL_JOB_NAME = \"doris__%s\";\n+    // 5min\n+    private static final int GET_APPID_MAX_RETRY_TIMES = 300;\n+    private static final int GET_APPID_SLEEP_MS = 1000;\n+\n+    class SparkAppListener implements Listener {\n+        @Override\n+        public void stateChanged(SparkAppHandle sparkAppHandle) {}\n+\n+        @Override\n+        public void infoChanged(SparkAppHandle sparkAppHandle) {}\n+    }\n+\n+    public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobConfig, SparkResource resource,\n+                             BrokerDesc brokerDesc, SparkPendingTaskAttachment attachment) throws LoadException {\n+        // delete outputPath\n+        deleteEtlOutputPath(etlJobConfig.outputPath, brokerDesc);\n+\n+        // upload app resource and jobconfig to hdfs\n+        String configsHdfsDir = etlJobConfig.outputPath + \"/\" + JOB_CONFIG_DIR + \"/\";\n+        String appResourceHdfsPath = configsHdfsDir + APP_RESOURCE_NAME;\n+        String jobConfigHdfsPath = configsHdfsDir + CONFIG_FILE_NAME;\n+        try {\n+            BrokerUtil.writeBrokerFile(APP_RESOURCE_LOCAL_PATH, appResourceHdfsPath, brokerDesc);\n+            byte[] configData = etlJobConfig.configToJson().getBytes(\"UTF-8\");\n+            BrokerUtil.writeBrokerFile(configData, jobConfigHdfsPath, brokerDesc);\n+        } catch (UserException | UnsupportedEncodingException e) {\n+            throw new LoadException(e.getMessage());\n+        }\n+\n+        SparkLauncher launcher = new SparkLauncher();\n+        // master      |  deployMode\n+        // ------------|-------------\n+        // yarn        |  cluster\n+        // spark://xx  |  client\n+        launcher.setMaster(resource.getMaster())\n+                .setDeployMode(resource.getDeployMode().name().toLowerCase())\n+                .setAppResource(appResourceHdfsPath)\n+                .setMainClass(MAIN_CLASS)\n+                .setAppName(String.format(ETL_JOB_NAME, loadLabel))\n+                .addAppArgs(jobConfigHdfsPath);\n+        // spark configs\n+        for (Map.Entry<String, String> entry : resource.getSparkConfigs().entrySet()) {\n+            launcher.setConf(entry.getKey(), entry.getValue());\n+        }\n+\n+        // start app\n+        SparkAppHandle handle = null;\n+        State state = null;\n+        String appId = null;\n+        int retry = 0;\n+        String errMsg = \"start spark app failed. error: \";\n+        try {\n+            handle = launcher.startApplication(new SparkAppListener());\n+        } catch (IOException e) {\n+            LOG.warn(errMsg, e);\n+            throw new LoadException(errMsg + e.getMessage());\n+        }\n+\n+        while (retry++ < GET_APPID_MAX_RETRY_TIMES) {\n+            appId = handle.getAppId();\n+            if (appId != null) {\n+                break;\n+            }\n+\n+            // check state and retry\n+            state = handle.getState();\n+            if (fromSparkState(state) == TEtlState.CANCELLED) {\n+                throw new LoadException(errMsg + \"spark app state: \" + state.toString());\n+            }\n+            if (retry >= GET_APPID_MAX_RETRY_TIMES) {\n+                throw new LoadException(errMsg + \"wait too much time for getting appid. spark app state: \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM1MjY5Nw==", "bodyText": "errMsg already have a space at the end.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r433352697", "createdAt": "2020-06-01T16:37:12Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -0,0 +1,170 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.PaloFe;\n+import org.apache.doris.analysis.BrokerDesc;\n+import org.apache.doris.catalog.SparkResource;\n+import org.apache.doris.common.LoadException;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.common.util.BrokerUtil;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig;\n+import org.apache.doris.thrift.TEtlState;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.spark.launcher.SparkAppHandle;\n+import org.apache.spark.launcher.SparkAppHandle.Listener;\n+import org.apache.spark.launcher.SparkAppHandle.State;\n+import org.apache.spark.launcher.SparkLauncher;\n+\n+import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.util.Map;\n+\n+/**\n+ * SparkEtlJobHandler is responsible for\n+ * 1. submit spark etl job\n+ * 2. get spark etl job status\n+ * 3. kill spark etl job\n+ * 4. get spark etl file paths\n+ * 5. delete etl output path\n+ */\n+public class SparkEtlJobHandler {\n+    private static final Logger LOG = LogManager.getLogger(SparkEtlJobHandler.class);\n+\n+    private static final String APP_RESOURCE_NAME = \"palo-fe.jar\";\n+    private static final String CONFIG_FILE_NAME = \"jobconfig.json\";\n+    private static final String APP_RESOURCE_LOCAL_PATH = PaloFe.DORIS_HOME_DIR + \"/lib/\" + APP_RESOURCE_NAME;\n+    private static final String JOB_CONFIG_DIR = \"configs\";\n+    private static final String MAIN_CLASS = \"org.apache.doris.load.loadv2.etl.SparkEtlJob\";\n+    private static final String ETL_JOB_NAME = \"doris__%s\";\n+    // 5min\n+    private static final int GET_APPID_MAX_RETRY_TIMES = 300;\n+    private static final int GET_APPID_SLEEP_MS = 1000;\n+\n+    class SparkAppListener implements Listener {\n+        @Override\n+        public void stateChanged(SparkAppHandle sparkAppHandle) {}\n+\n+        @Override\n+        public void infoChanged(SparkAppHandle sparkAppHandle) {}\n+    }\n+\n+    public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobConfig, SparkResource resource,\n+                             BrokerDesc brokerDesc, SparkPendingTaskAttachment attachment) throws LoadException {\n+        // delete outputPath\n+        deleteEtlOutputPath(etlJobConfig.outputPath, brokerDesc);\n+\n+        // upload app resource and jobconfig to hdfs\n+        String configsHdfsDir = etlJobConfig.outputPath + \"/\" + JOB_CONFIG_DIR + \"/\";\n+        String appResourceHdfsPath = configsHdfsDir + APP_RESOURCE_NAME;\n+        String jobConfigHdfsPath = configsHdfsDir + CONFIG_FILE_NAME;\n+        try {\n+            BrokerUtil.writeBrokerFile(APP_RESOURCE_LOCAL_PATH, appResourceHdfsPath, brokerDesc);\n+            byte[] configData = etlJobConfig.configToJson().getBytes(\"UTF-8\");\n+            BrokerUtil.writeBrokerFile(configData, jobConfigHdfsPath, brokerDesc);\n+        } catch (UserException | UnsupportedEncodingException e) {\n+            throw new LoadException(e.getMessage());\n+        }\n+\n+        SparkLauncher launcher = new SparkLauncher();\n+        // master      |  deployMode\n+        // ------------|-------------\n+        // yarn        |  cluster\n+        // spark://xx  |  client\n+        launcher.setMaster(resource.getMaster())\n+                .setDeployMode(resource.getDeployMode().name().toLowerCase())\n+                .setAppResource(appResourceHdfsPath)\n+                .setMainClass(MAIN_CLASS)\n+                .setAppName(String.format(ETL_JOB_NAME, loadLabel))\n+                .addAppArgs(jobConfigHdfsPath);\n+        // spark configs\n+        for (Map.Entry<String, String> entry : resource.getSparkConfigs().entrySet()) {\n+            launcher.setConf(entry.getKey(), entry.getValue());\n+        }\n+\n+        // start app\n+        SparkAppHandle handle = null;\n+        State state = null;\n+        String appId = null;\n+        int retry = 0;\n+        String errMsg = \"start spark app failed. error: \";\n+        try {\n+            handle = launcher.startApplication(new SparkAppListener());\n+        } catch (IOException e) {\n+            LOG.warn(errMsg, e);\n+            throw new LoadException(errMsg + e.getMessage());\n+        }\n+\n+        while (retry++ < GET_APPID_MAX_RETRY_TIMES) {\n+            appId = handle.getAppId();\n+            if (appId != null) {\n+                break;\n+            }\n+\n+            // check state and retry\n+            state = handle.getState();\n+            if (fromSparkState(state) == TEtlState.CANCELLED) {\n+                throw new LoadException(errMsg + \"spark app state: \" + state.toString());\n+            }\n+            if (retry >= GET_APPID_MAX_RETRY_TIMES) {\n+                throw new LoadException(errMsg + \"wait too much time for getting appid. spark app state: \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMTU5NQ=="}, "originalCommit": {"oid": "90de0a81e22aa950ed0c219c8d501ac18a79beaf"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MTAwODg1OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzo0NDozOVrOGlGc9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNjowNzo1M1rOGlgz6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU1NjIxNA==", "bodyText": "broker's pread() method does not guarantee to read the specified length of data currently.\nBut #3881 is trying to solve this problem. Just for remind.", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r441556214", "createdAt": "2020-06-17T13:44:39Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +148,352 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    /**\n+     * Read binary data from path with broker\n+     * @param path\n+     * @param brokerDesc\n+     * @return byte[]\n+     * @throws UserException if broker op failed or not only one file\n+     */\n+    public static byte[] readFile(String path, BrokerDesc brokerDesc) throws UserException {\n+        TNetworkAddress address = getAddress(brokerDesc);\n+        TPaloBrokerService.Client client = borrowClient(address);\n+        boolean failed = true;\n+        TBrokerFD fd = null;\n+        try {\n+            // get file size\n+            TBrokerListPathRequest request = new TBrokerListPathRequest(\n+                    TBrokerVersion.VERSION_ONE, path, false, brokerDesc.getProperties());\n+            TBrokerListResponse tBrokerListResponse = null;\n+            try {\n+                tBrokerListResponse = client.listPath(request);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tBrokerListResponse = client.listPath(request);\n+            }\n+            if (tBrokerListResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker list path failed. path=\" + path + \", broker=\" + address\n+                                                + \",msg=\" + tBrokerListResponse.getOpStatus().getMessage());\n+            }\n+            List<TBrokerFileStatus> fileStatuses = tBrokerListResponse.getFiles();\n+            if (fileStatuses.size() != 1) {\n+                throw new UserException(\"Broker files num error. path=\" + path + \", broker=\" + address\n+                                                + \", files num: \" + fileStatuses.size());\n+            }\n+\n+            Preconditions.checkState(!fileStatuses.get(0).isIsDir());\n+            long fileSize = fileStatuses.get(0).getSize();\n+\n+            // open reader\n+            String clientId = FrontendOptions.getLocalHostAddress() + \":\" + Config.rpc_port;\n+            TBrokerOpenReaderRequest tOpenReaderRequest = new TBrokerOpenReaderRequest(\n+                    TBrokerVersion.VERSION_ONE, path, 0, clientId, brokerDesc.getProperties());\n+            TBrokerOpenReaderResponse tOpenReaderResponse = null;\n+            try {\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            }\n+            if (tOpenReaderResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker open reader failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tOpenReaderResponse.getOpStatus().getMessage());\n+            }\n+            fd = tOpenReaderResponse.getFd();\n+\n+            // read\n+            TBrokerPReadRequest tPReadRequest = new TBrokerPReadRequest(\n+                    TBrokerVersion.VERSION_ONE, fd, 0, fileSize);\n+            TBrokerReadResponse tReadResponse = null;\n+            try {\n+                tReadResponse = client.pread(tPReadRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tReadResponse = client.pread(tPReadRequest);\n+            }\n+            if (tReadResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker read failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tReadResponse.getOpStatus().getMessage());\n+            }\n+            failed = false;\n+            return tReadResponse.getData();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc7a607af6a17103fc078501f4f579386310cd6e"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk4ODA3NQ==", "bodyText": "ok", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r441988075", "createdAt": "2020-06-18T06:07:53Z", "author": {"login": "wyb"}, "path": "fe/src/main/java/org/apache/doris/common/util/BrokerUtil.java", "diffHunk": "@@ -139,4 +148,352 @@ public static String printBroker(String brokerName, TNetworkAddress address) {\n         return Lists.newArrayList(columns);\n     }\n \n+    /**\n+     * Read binary data from path with broker\n+     * @param path\n+     * @param brokerDesc\n+     * @return byte[]\n+     * @throws UserException if broker op failed or not only one file\n+     */\n+    public static byte[] readFile(String path, BrokerDesc brokerDesc) throws UserException {\n+        TNetworkAddress address = getAddress(brokerDesc);\n+        TPaloBrokerService.Client client = borrowClient(address);\n+        boolean failed = true;\n+        TBrokerFD fd = null;\n+        try {\n+            // get file size\n+            TBrokerListPathRequest request = new TBrokerListPathRequest(\n+                    TBrokerVersion.VERSION_ONE, path, false, brokerDesc.getProperties());\n+            TBrokerListResponse tBrokerListResponse = null;\n+            try {\n+                tBrokerListResponse = client.listPath(request);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tBrokerListResponse = client.listPath(request);\n+            }\n+            if (tBrokerListResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker list path failed. path=\" + path + \", broker=\" + address\n+                                                + \",msg=\" + tBrokerListResponse.getOpStatus().getMessage());\n+            }\n+            List<TBrokerFileStatus> fileStatuses = tBrokerListResponse.getFiles();\n+            if (fileStatuses.size() != 1) {\n+                throw new UserException(\"Broker files num error. path=\" + path + \", broker=\" + address\n+                                                + \", files num: \" + fileStatuses.size());\n+            }\n+\n+            Preconditions.checkState(!fileStatuses.get(0).isIsDir());\n+            long fileSize = fileStatuses.get(0).getSize();\n+\n+            // open reader\n+            String clientId = FrontendOptions.getLocalHostAddress() + \":\" + Config.rpc_port;\n+            TBrokerOpenReaderRequest tOpenReaderRequest = new TBrokerOpenReaderRequest(\n+                    TBrokerVersion.VERSION_ONE, path, 0, clientId, brokerDesc.getProperties());\n+            TBrokerOpenReaderResponse tOpenReaderResponse = null;\n+            try {\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tOpenReaderResponse = client.openReader(tOpenReaderRequest);\n+            }\n+            if (tOpenReaderResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker open reader failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tOpenReaderResponse.getOpStatus().getMessage());\n+            }\n+            fd = tOpenReaderResponse.getFd();\n+\n+            // read\n+            TBrokerPReadRequest tPReadRequest = new TBrokerPReadRequest(\n+                    TBrokerVersion.VERSION_ONE, fd, 0, fileSize);\n+            TBrokerReadResponse tReadResponse = null;\n+            try {\n+                tReadResponse = client.pread(tPReadRequest);\n+            } catch (TException e) {\n+                reopenClient(client);\n+                tReadResponse = client.pread(tPReadRequest);\n+            }\n+            if (tReadResponse.getOpStatus().getStatusCode() != TBrokerOperationStatusCode.OK) {\n+                throw new UserException(\"Broker read failed. path=\" + path + \", broker=\" + address\n+                                                + \", msg=\" + tReadResponse.getOpStatus().getMessage());\n+            }\n+            failed = false;\n+            return tReadResponse.getData();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU1NjIxNA=="}, "originalCommit": {"oid": "dc7a607af6a17103fc078501f4f579386310cd6e"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MTA3MDkwOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkLoadJob.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzo1ODozMlrOGlHFwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzo1ODozMlrOGlHFwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU2NjY1Ng==", "bodyText": "Print a log for tracing the state changing", "url": "https://github.com/apache/incubator-doris/pull/3716#discussion_r441566656", "createdAt": "2020-06-17T13:58:32Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/load/loadv2/SparkLoadJob.java", "diffHunk": "@@ -127,6 +140,76 @@ private void setResourceInfo() throws DdlException {\n         brokerDesc = new BrokerDesc(sparkResource.getBroker(), brokerProperties);\n     }\n \n+    @Override\n+    public void beginTxn()\n+            throws LabelAlreadyUsedException, BeginTransactionException, AnalysisException, DuplicatedRequestException {\n+       transactionId = Catalog.getCurrentGlobalTransactionMgr()\n+                .beginTransaction(dbId, Lists.newArrayList(fileGroupAggInfo.getAllTableIds()), label, null,\n+                                  new TxnCoordinator(TxnSourceType.FE, FrontendOptions.getLocalHostAddress()),\n+                                  LoadJobSourceType.FRONTEND, id, timeoutSecond);\n+    }\n+\n+    @Override\n+    protected void unprotectedExecuteJob() throws LoadException {\n+        // create pending task\n+        LoadTask task = new SparkLoadPendingTask(this, fileGroupAggInfo.getAggKeyToFileGroups(),\n+                                                 sparkResource, brokerDesc);\n+        task.init();\n+        idToTasks.put(task.getSignature(), task);\n+        Catalog.getCurrentCatalog().getLoadTaskScheduler().submit(task);\n+    }\n+\n+    @Override\n+    public void onTaskFinished(TaskAttachment attachment) {\n+        if (attachment instanceof SparkPendingTaskAttachment) {\n+            onPendingTaskFinished((SparkPendingTaskAttachment) attachment);\n+        }\n+    }\n+\n+    private void onPendingTaskFinished(SparkPendingTaskAttachment attachment) {\n+        writeLock();\n+        try {\n+            // check if job has been cancelled\n+            if (isTxnDone()) {\n+                LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)\n+                                 .add(\"state\", state)\n+                                 .add(\"error_msg\", \"this task will be ignored when job is: \" + state)\n+                                 .build());\n+                return;\n+            }\n+\n+            if (finishedTaskIds.contains(attachment.getTaskId())) {\n+                LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)\n+                                 .add(\"task_id\", attachment.getTaskId())\n+                                 .add(\"error_msg\", \"this is a duplicated callback of pending task \"\n+                                         + \"when broker already has loading task\")\n+                                 .build());\n+                return;\n+            }\n+\n+            // add task id into finishedTaskIds\n+            finishedTaskIds.add(attachment.getTaskId());\n+\n+            sparkAppHandle = attachment.getHandle();\n+            appId = attachment.getAppId();\n+            etlOutputPath = attachment.getOutputPath();\n+\n+            executeEtl();\n+            // log etl state\n+            unprotectedLogUpdateStateInfo();\n+        } finally {\n+            writeUnlock();\n+        }\n+    }\n+\n+    /**\n+     * update etl start time and state in spark load job\n+     */\n+    private void executeEtl() {\n+        etlStartTimestamp = System.currentTimeMillis();\n+        state = JobState.ETL;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc7a607af6a17103fc078501f4f579386310cd6e"}, "originalPosition": 125}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1655, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}