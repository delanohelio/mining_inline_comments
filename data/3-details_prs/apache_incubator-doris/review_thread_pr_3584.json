{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3Mzc2MDA0", "number": 3584, "reviewThreads": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMjoyODo0N1rOD9ORKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxMzoxNDo0N1rOD_MnSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTIzNDk5OnYy", "diffSide": "RIGHT", "path": "be/src/exec/parquet_writer.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMjoyODo0N1rOGWl0hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowMDoyNFrOGXPCXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTUwOQ==", "bodyText": "why not ARROW_RETURN_NOT_OK(st)", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426341509", "createdAt": "2020-05-18T02:28:47Z", "author": {"login": "yangzhg"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNjc5Ng==", "bodyText": "Actually, ParquetOutputStream is not implemented yet. I will modify this class in next PR.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427016796", "createdAt": "2020-05-19T04:00:24Z", "author": {"login": "morningman"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTUwOQ=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTIzNzUyOnYy", "diffSide": "RIGHT", "path": "be/src/exec/parquet_writer.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMjozMDozOVrOGWl19Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowMDoyN1rOGXPCZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTg3Nw==", "bodyText": "why not ARROW_RETURN_NOT_OK(st)", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426341877", "createdAt": "2020-05-18T02:30:39Z", "author": {"login": "yangzhg"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {\n+        return arrow::Status::IOError(st.get_error_msg());\n+    }\n+    _cur_pos += written_len;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Tell(int64_t* position) const {\n+    *position = _cur_pos;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Close() {\n+    Status st = _file_writer->close();\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNjgwNw==", "bodyText": "ParquetOutputStream is not implemented", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427016807", "createdAt": "2020-05-19T04:00:27Z", "author": {"login": "morningman"}, "path": "be/src/exec/parquet_writer.cpp", "diffHunk": "@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"exec/parquet_writer.h\"\n+\n+#include <time.h>\n+#include <arrow/status.h>\n+#include <arrow/array.h>\n+\n+#include \"exec/file_writer.h\"\n+#include \"common/logging.h\"\n+#include \"gen_cpp/PaloBrokerService_types.h\"\n+#include \"gen_cpp/TPaloBrokerService.h\"\n+#include \"runtime/broker_mgr.h\"\n+#include \"runtime/client_cache.h\"\n+#include \"runtime/exec_env.h\"\n+#include \"runtime/tuple.h\"\n+#include \"runtime/descriptors.h\"\n+#include \"runtime/mem_pool.h\"\n+#include \"util/thrift_util.h\"\n+\n+namespace doris {\n+\n+/// ParquetOutputStream\n+ParquetOutputStream::ParquetOutputStream(FileWriter* file_writer): _file_writer(file_writer) {\n+    set_mode(arrow::io::FileMode::WRITE);\n+}\n+\n+ParquetOutputStream::~ParquetOutputStream() {\n+    Close();\n+}\n+\n+arrow::Status ParquetOutputStream::Write(const void* data, int64_t nbytes) {\n+    size_t written_len = 0;\n+    Status st = _file_writer->write(reinterpret_cast<const uint8_t*>(data), nbytes, &written_len);\n+    if (!st.ok()) {\n+        return arrow::Status::IOError(st.get_error_msg());\n+    }\n+    _cur_pos += written_len;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Tell(int64_t* position) const {\n+    *position = _cur_pos;\n+    return arrow::Status::OK();\n+}\n+\n+arrow::Status ParquetOutputStream::Close() {\n+    Status st = _file_writer->close();\n+    if (!st.ok()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0MTg3Nw=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI3NzIyOnYy", "diffSide": "RIGHT", "path": "be/src/runtime/file_result_writer.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzowMzoyMVrOGWmNzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowMDo1N1rOGXPC1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0Nzk4MQ==", "bodyText": "_file_writer seems owned by  ParquetWriterWrapper  by not realeased in ParquetOutputStream or ParquetWriterWrapper how about create and own it in ParquetWriterWrapper, and use use unique_prt to handle  _file_writer, _parquet_writer in this class", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426347981", "createdAt": "2020-05-18T03:03:21Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNjkxOA==", "bodyText": "ParquetOutputStream is not implemented.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427016918", "createdAt": "2020-05-19T04:00:57Z", "author": {"login": "morningman"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0Nzk4MQ=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI4MjA4OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/file_result_writer.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzowODowMVrOGWmQuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowMjo0MVrOGXPEGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0ODcyOQ==", "bodyText": "why not nullptr", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426348729", "createdAt": "2020-05-18T03:08:01Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNzI0Mg==", "bodyText": "Modified", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427017242", "createdAt": "2020-05-19T04:02:41Z", "author": {"login": "morningman"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0ODcyOQ=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI4NzgzOnYy", "diffSide": "RIGHT", "path": "be/src/runtime/file_result_writer.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzoxMjo0OFrOGWmUFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowMzoyNFrOGXPEtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0OTU5MA==", "bodyText": "????", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426349590", "createdAt": "2020-05-18T03:12:48Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {\n+        return Status::OK();\n+    }\n+\n+    SCOPED_TIMER(_append_row_batch_timer);\n+    if (_parquet_writer != nullptr) {\n+        RETURN_IF_ERROR(_parquet_writer->write(*batch));\n+    } else {\n+        RETURN_IF_ERROR(_write_csv_file(*batch));\n+    }\n+\n+    _written_rows += batch->num_rows();\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_write_csv_file(const RowBatch& batch) {\n+    int num_rows = batch.num_rows();\n+    for (int i = 0; i < num_rows; ++i) {\n+        TupleRow* row = batch.get_row(i);\n+        RETURN_IF_ERROR(_write_one_row_as_csv(row));\n+    }\n+    _flush_plain_text_outstream(true);\n+    return Status::OK();\n+}\n+\n+// actually, this logic is same as `ExportSink::gen_row_buffer`\n+// TODO(cmy): find a way to unify them.\n+Status FileResultWriter::_write_one_row_as_csv(TupleRow* row) {\n+    {\n+        SCOPED_TIMER(_convert_tuple_timer);\n+        int num_columns = _output_expr_ctxs.size();\n+        for (int i = 0; i < num_columns; ++i) {\n+            void* item = _output_expr_ctxs[i]->get_value(row);\n+\n+            if (item == nullptr) {\n+                _plain_text_outstream << NULL_IN_CSV;\n+                continue;\n+            }\n+\n+            switch (_output_expr_ctxs[i]->root()->type().type) {\n+                case TYPE_BOOLEAN:\n+                case TYPE_TINYINT:\n+                    _plain_text_outstream << (int)*static_cast<int8_t*>(item);\n+                    break;\n+                case TYPE_SMALLINT:\n+                    _plain_text_outstream << *static_cast<int16_t*>(item);\n+                    break;\n+                case TYPE_INT:\n+                    _plain_text_outstream << *static_cast<int32_t*>(item);\n+                    break;\n+                case TYPE_BIGINT:\n+                    _plain_text_outstream << *static_cast<int64_t*>(item);\n+                    break;\n+                case TYPE_LARGEINT:\n+                    _plain_text_outstream << reinterpret_cast<PackedInt128*>(item)->value;\n+                    break;\n+                case TYPE_FLOAT: {\n+                    char buffer[MAX_FLOAT_STR_LENGTH + 2];\n+                    float float_value = *static_cast<float*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = FloatToBuffer(float_value, MAX_FLOAT_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt float failed, float value=\" << float_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DOUBLE: {\n+                    // To prevent loss of precision on float and double types,\n+                    // they are converted to strings before output.\n+                    // For example: For a double value 27361919854.929001,\n+                    // the direct output of using std::stringstream is 2.73619e+10,\n+                    // and after conversion to a string, it outputs 27361919854.929001\n+                    char buffer[MAX_DOUBLE_STR_LENGTH + 2];\n+                    double double_value = *static_cast<double*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = DoubleToBuffer(double_value, MAX_DOUBLE_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt double failed, double value=\" << double_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DATE:\n+                case TYPE_DATETIME: {\n+                    char buf[64];\n+                    const DateTimeValue* time_val = (const DateTimeValue*)(item);\n+                    time_val->to_string(buf);\n+                    _plain_text_outstream << buf;\n+                    break;\n+                }\n+                case TYPE_VARCHAR:\n+                case TYPE_CHAR: {\n+                    const StringValue* string_val = (const StringValue*)(item);\n+                    if (string_val->ptr == NULL) {\n+                        if (string_val->len != 0) {\n+                            _plain_text_outstream << NULL_IN_CSV;\n+                        }\n+                    } else {\n+                        _plain_text_outstream << std::string(string_val->ptr, string_val->len);\n+                    }\n+                    break;\n+                }\n+                case TYPE_DECIMAL: {\n+                    const DecimalValue* decimal_val = reinterpret_cast<const DecimalValue*>(item);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val->to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val->to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                case TYPE_DECIMALV2: {\n+                    const DecimalV2Value decimal_val(reinterpret_cast<const PackedInt128*>(item)->value);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val.to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val.to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                default: {\n+                    // not supported type, like BITMAP, HLL, just export null\n+                    _plain_text_outstream << NULL_IN_CSV;\n+                }\n+            }\n+            if (i < num_columns - 1) {\n+                _plain_text_outstream << _file_opts->column_separator;\n+            }\n+        } // end for columns\n+        _plain_text_outstream << _file_opts->line_delimiter;\n+    }\n+\n+    // write one line to file\n+    return _flush_plain_text_outstream(false);\n+}\n+\n+Status FileResultWriter::_flush_plain_text_outstream(bool eos) {\n+    SCOPED_TIMER(_file_write_timer);\n+    size_t pos = _plain_text_outstream.tellp();\n+    if (pos == 0 || (pos < OUTSTREAM_BUFFER_SIZE_BYTES && !eos)) {\n+        return Status::OK();\n+    }\n+    \n+    const std::string& buf = _plain_text_outstream.str();\n+    size_t written_len = 0;\n+    RETURN_IF_ERROR(_file_writer->write(reinterpret_cast<const uint8_t*>(buf.c_str()),\n+            buf.size(), &written_len));\n+    COUNTER_UPDATE(_written_data_bytes, written_len);\n+    _current_written_bytes += written_len;\n+\n+    // clear the stream\n+    _plain_text_outstream.str(\"\");\n+    _plain_text_outstream.clear();\n+\n+    // split file if exceed limit\n+    RETURN_IF_ERROR(_create_new_file_if_exceed_size());\n+\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_create_new_file_if_exceed_size() {\n+    if (_current_written_bytes < _file_opts->max_file_size_bytes) {\n+        return Status::OK();\n+    }\n+    // current file size exceed the max file size. close this file\n+    // and create new one\n+    RETURN_IF_ERROR(_close_file_writer(false));\n+    _current_written_bytes = 0;\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_close_file_writer(bool done) {\n+    SCOPED_TIMER(_writer_close_timer);\n+    if (_parquet_writer != nullptr) {\n+        _parquet_writer->close();\n+        delete _parquet_writer;\n+        _parquet_writer = nullptr;\n+        if (!done) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNzM5Ng==", "bodyText": "I will add a TODO here", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427017396", "createdAt": "2020-05-19T04:03:24Z", "author": {"login": "morningman"}, "path": "be/src/runtime/file_result_writer.cpp", "diffHunk": "@@ -0,0 +1,319 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"runtime/file_result_writer.h\"\n+\n+#include \"exec/broker_writer.h\"\n+#include \"exec/local_file_writer.h\"\n+#include \"exec/parquet_writer.h\"\n+#include \"exprs/expr.h\"\n+#include \"runtime/primitive_type.h\"\n+#include \"runtime/row_batch.h\"\n+#include \"runtime/tuple_row.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"util/types.h\"\n+#include \"util/date_func.h\"\n+#include \"util/uid_util.h\"\n+\n+#include \"gen_cpp/PaloInternalService_types.h\"\n+\n+namespace doris {\n+\n+const size_t FileResultWriter::OUTSTREAM_BUFFER_SIZE_BYTES = 1024 * 1024;\n+\n+FileResultWriter::FileResultWriter(\n+        const ResultFileOptions* file_opts,\n+        const std::vector<ExprContext*>& output_expr_ctxs,\n+        RuntimeProfile* parent_profile) :\n+            _file_opts(file_opts),\n+            _output_expr_ctxs(output_expr_ctxs),\n+            _parent_profile(parent_profile) {\n+}\n+\n+FileResultWriter::~FileResultWriter() {\n+    close();\n+}\n+\n+Status FileResultWriter::init(RuntimeState* state) {\n+    _state = state;\n+    _init_profile();\n+\n+    RETURN_IF_ERROR(_create_file_writer());\n+    return Status::OK();\n+}\n+\n+void FileResultWriter::_init_profile() {\n+    RuntimeProfile* profile = _parent_profile->create_child(\"FileResultWriter\", true, true);\n+    _append_row_batch_timer = ADD_TIMER(profile, \"AppendBatchTime\");\n+    _convert_tuple_timer = ADD_CHILD_TIMER(profile, \"TupleConvertTime\", \"AppendBatchTime\");\n+    _file_write_timer = ADD_CHILD_TIMER(profile, \"FileWriteTime\", \"AppendBatchTime\");\n+    _writer_close_timer = ADD_TIMER(profile, \"FileWriterCloseTime\");\n+    _written_rows_counter = ADD_COUNTER(profile, \"NumWrittenRows\", TUnit::UNIT);\n+    _written_data_bytes = ADD_COUNTER(profile, \"WrittenDataBytes\", TUnit::BYTES);\n+}\n+\n+Status FileResultWriter::_create_file_writer() {\n+    std::string file_name = _get_next_file_name();\n+    if (_file_opts->is_local_file) {\n+        _file_writer = new LocalFileWriter(file_name, 0 /* start offset */);\n+    } else {\n+        _file_writer = new BrokerWriter(_state->exec_env(),\n+                _file_opts->broker_addresses,\n+                _file_opts->broker_properties,\n+                file_name,\n+                0 /*start offset*/);\n+    }\n+    RETURN_IF_ERROR(_file_writer->open());\n+\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            // just use file writer is enough\n+            break;\n+        case TFileFormatType::FORMAT_PARQUET:\n+            _parquet_writer = new ParquetWriterWrapper(_file_writer, _output_expr_ctxs);\n+            break;\n+        default:\n+            return Status::InternalError(strings::Substitute(\"unsupport file format: $0\", _file_opts->file_format));\n+    }\n+    LOG(INFO) << \"create file for exporting query result. file name: \" << file_name\n+            << \". query id: \" << print_id(_state->query_id());\n+    return Status::OK();\n+}\n+\n+// file name format as: my_prefix_0.csv\n+std::string FileResultWriter::_get_next_file_name() {\n+    std::stringstream ss;\n+    ss << _file_opts->file_path << \"_\" << (_file_idx++) << \".\" << _file_format_to_name();\n+    return ss.str();\n+}\n+\n+std::string FileResultWriter::_file_format_to_name() {\n+    switch (_file_opts->file_format) {\n+        case TFileFormatType::FORMAT_CSV_PLAIN:\n+            return \"csv\";\n+        case TFileFormatType::FORMAT_PARQUET:\n+            return \"parquet\";\n+        default:\n+            return \"unknown\";\n+    }\n+}\n+\n+Status FileResultWriter::append_row_batch(const RowBatch* batch) {\n+    if (NULL == batch || 0 == batch->num_rows()) {\n+        return Status::OK();\n+    }\n+\n+    SCOPED_TIMER(_append_row_batch_timer);\n+    if (_parquet_writer != nullptr) {\n+        RETURN_IF_ERROR(_parquet_writer->write(*batch));\n+    } else {\n+        RETURN_IF_ERROR(_write_csv_file(*batch));\n+    }\n+\n+    _written_rows += batch->num_rows();\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_write_csv_file(const RowBatch& batch) {\n+    int num_rows = batch.num_rows();\n+    for (int i = 0; i < num_rows; ++i) {\n+        TupleRow* row = batch.get_row(i);\n+        RETURN_IF_ERROR(_write_one_row_as_csv(row));\n+    }\n+    _flush_plain_text_outstream(true);\n+    return Status::OK();\n+}\n+\n+// actually, this logic is same as `ExportSink::gen_row_buffer`\n+// TODO(cmy): find a way to unify them.\n+Status FileResultWriter::_write_one_row_as_csv(TupleRow* row) {\n+    {\n+        SCOPED_TIMER(_convert_tuple_timer);\n+        int num_columns = _output_expr_ctxs.size();\n+        for (int i = 0; i < num_columns; ++i) {\n+            void* item = _output_expr_ctxs[i]->get_value(row);\n+\n+            if (item == nullptr) {\n+                _plain_text_outstream << NULL_IN_CSV;\n+                continue;\n+            }\n+\n+            switch (_output_expr_ctxs[i]->root()->type().type) {\n+                case TYPE_BOOLEAN:\n+                case TYPE_TINYINT:\n+                    _plain_text_outstream << (int)*static_cast<int8_t*>(item);\n+                    break;\n+                case TYPE_SMALLINT:\n+                    _plain_text_outstream << *static_cast<int16_t*>(item);\n+                    break;\n+                case TYPE_INT:\n+                    _plain_text_outstream << *static_cast<int32_t*>(item);\n+                    break;\n+                case TYPE_BIGINT:\n+                    _plain_text_outstream << *static_cast<int64_t*>(item);\n+                    break;\n+                case TYPE_LARGEINT:\n+                    _plain_text_outstream << reinterpret_cast<PackedInt128*>(item)->value;\n+                    break;\n+                case TYPE_FLOAT: {\n+                    char buffer[MAX_FLOAT_STR_LENGTH + 2];\n+                    float float_value = *static_cast<float*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = FloatToBuffer(float_value, MAX_FLOAT_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt float failed, float value=\" << float_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DOUBLE: {\n+                    // To prevent loss of precision on float and double types,\n+                    // they are converted to strings before output.\n+                    // For example: For a double value 27361919854.929001,\n+                    // the direct output of using std::stringstream is 2.73619e+10,\n+                    // and after conversion to a string, it outputs 27361919854.929001\n+                    char buffer[MAX_DOUBLE_STR_LENGTH + 2];\n+                    double double_value = *static_cast<double*>(item);\n+                    buffer[0] = '\\0';\n+                    int length = DoubleToBuffer(double_value, MAX_DOUBLE_STR_LENGTH, buffer);\n+                    DCHECK(length >= 0) << \"gcvt double failed, double value=\" << double_value;\n+                    _plain_text_outstream << buffer;\n+                    break;\n+                }\n+                case TYPE_DATE:\n+                case TYPE_DATETIME: {\n+                    char buf[64];\n+                    const DateTimeValue* time_val = (const DateTimeValue*)(item);\n+                    time_val->to_string(buf);\n+                    _plain_text_outstream << buf;\n+                    break;\n+                }\n+                case TYPE_VARCHAR:\n+                case TYPE_CHAR: {\n+                    const StringValue* string_val = (const StringValue*)(item);\n+                    if (string_val->ptr == NULL) {\n+                        if (string_val->len != 0) {\n+                            _plain_text_outstream << NULL_IN_CSV;\n+                        }\n+                    } else {\n+                        _plain_text_outstream << std::string(string_val->ptr, string_val->len);\n+                    }\n+                    break;\n+                }\n+                case TYPE_DECIMAL: {\n+                    const DecimalValue* decimal_val = reinterpret_cast<const DecimalValue*>(item);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val->to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val->to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                case TYPE_DECIMALV2: {\n+                    const DecimalV2Value decimal_val(reinterpret_cast<const PackedInt128*>(item)->value);\n+                    std::string decimal_str;\n+                    int output_scale = _output_expr_ctxs[i]->root()->output_scale();\n+                    if (output_scale > 0 && output_scale <= 30) {\n+                        decimal_str = decimal_val.to_string(output_scale);\n+                    } else {\n+                        decimal_str = decimal_val.to_string();\n+                    }\n+                    _plain_text_outstream << decimal_str;\n+                    break;\n+                }\n+                default: {\n+                    // not supported type, like BITMAP, HLL, just export null\n+                    _plain_text_outstream << NULL_IN_CSV;\n+                }\n+            }\n+            if (i < num_columns - 1) {\n+                _plain_text_outstream << _file_opts->column_separator;\n+            }\n+        } // end for columns\n+        _plain_text_outstream << _file_opts->line_delimiter;\n+    }\n+\n+    // write one line to file\n+    return _flush_plain_text_outstream(false);\n+}\n+\n+Status FileResultWriter::_flush_plain_text_outstream(bool eos) {\n+    SCOPED_TIMER(_file_write_timer);\n+    size_t pos = _plain_text_outstream.tellp();\n+    if (pos == 0 || (pos < OUTSTREAM_BUFFER_SIZE_BYTES && !eos)) {\n+        return Status::OK();\n+    }\n+    \n+    const std::string& buf = _plain_text_outstream.str();\n+    size_t written_len = 0;\n+    RETURN_IF_ERROR(_file_writer->write(reinterpret_cast<const uint8_t*>(buf.c_str()),\n+            buf.size(), &written_len));\n+    COUNTER_UPDATE(_written_data_bytes, written_len);\n+    _current_written_bytes += written_len;\n+\n+    // clear the stream\n+    _plain_text_outstream.str(\"\");\n+    _plain_text_outstream.clear();\n+\n+    // split file if exceed limit\n+    RETURN_IF_ERROR(_create_new_file_if_exceed_size());\n+\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_create_new_file_if_exceed_size() {\n+    if (_current_written_bytes < _file_opts->max_file_size_bytes) {\n+        return Status::OK();\n+    }\n+    // current file size exceed the max file size. close this file\n+    // and create new one\n+    RETURN_IF_ERROR(_close_file_writer(false));\n+    _current_written_bytes = 0;\n+    return Status::OK();\n+}\n+\n+Status FileResultWriter::_close_file_writer(bool done) {\n+    SCOPED_TIMER(_writer_close_timer);\n+    if (_parquet_writer != nullptr) {\n+        _parquet_writer->close();\n+        delete _parquet_writer;\n+        _parquet_writer = nullptr;\n+        if (!done) {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM0OTU5MA=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 297}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI5Mjg4OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/mysql_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzoxNzoyOFrOGWmXMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowNDo0NlrOGXPF8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDM4Ng==", "bodyText": "why two private, and add_one_row not start with _", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426350386", "createdAt": "2020-05-18T03:17:28Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxNzcxNA==", "bodyText": "I moved the add_on_row method to the first private.\nfirst private is for private methods. second is for members.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427017714", "createdAt": "2020-05-19T04:04:46Z", "author": {"login": "morningman"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDM4Ng=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI5NDQxOnYy", "diffSide": "RIGHT", "path": "be/src/runtime/mysql_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzoxODo1OVrOGWmYIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowNjoxNVrOGXPHQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDYyNw==", "bodyText": "why not use unique_ptr", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426350627", "createdAt": "2020-05-18T03:18:59Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);\n+\n+    // The expressions that are run to create tuples to be written to hbase.\n+    BufferControlBlock* _sinker;\n+    const std::vector<ExprContext*>& _output_expr_ctxs;\n+    MysqlRowBuffer* _row_buffer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxODA0OA==", "bodyText": "I didn't change the logic here. This is just copied from the old result_writer.\nSince it works well for a long time, I think better not changing it.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427018048", "createdAt": "2020-05-19T04:06:15Z", "author": {"login": "morningman"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+\n+private:\n+    // convert one tuple row\n+    Status add_one_row(TupleRow* row);\n+\n+    // The expressions that are run to create tuples to be written to hbase.\n+    BufferControlBlock* _sinker;\n+    const std::vector<ExprContext*>& _output_expr_ctxs;\n+    MysqlRowBuffer* _row_buffer;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MDYyNw=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTI5OTY4OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/result_sink.cpp", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzoyMzozNVrOGWmbSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwOTozNDo0NlrOGYDVxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MTQzNA==", "bodyText": "|| sink.type == TResultSinkType::MYSQL_PROTOCAL is unnecessary", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426351434", "createdAt": "2020-05-18T03:23:35Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/result_sink.cpp", "diffHunk": "@@ -35,6 +36,17 @@ ResultSink::ResultSink(const RowDescriptor& row_desc, const std::vector<TExpr>&\n     : _row_desc(row_desc),\n       _t_output_expr(t_output_expr),\n       _buf_size(buffer_size) {\n+\n+    if (!sink.__isset.type || sink.type == TResultSinkType::MYSQL_PROTOCAL) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxODQzOQ==", "bodyText": "sink.type is a newly added field of TResultSink.\nSo for the request from the old FE planner, this field is not set.\nAnd for the request from the new FE planner, this field may be set to MYSQL_PROTOCAL.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427018439", "createdAt": "2020-05-19T04:07:50Z", "author": {"login": "morningman"}, "path": "be/src/runtime/result_sink.cpp", "diffHunk": "@@ -35,6 +36,17 @@ ResultSink::ResultSink(const RowDescriptor& row_desc, const std::vector<TExpr>&\n     : _row_desc(row_desc),\n       _t_output_expr(t_output_expr),\n       _buf_size(buffer_size) {\n+\n+    if (!sink.__isset.type || sink.type == TResultSinkType::MYSQL_PROTOCAL) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MTQzNA=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzg3MzczMg==", "bodyText": "It's better to add a comments here", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427873732", "createdAt": "2020-05-20T09:34:46Z", "author": {"login": "yangzhg"}, "path": "be/src/runtime/result_sink.cpp", "diffHunk": "@@ -35,6 +36,17 @@ ResultSink::ResultSink(const RowDescriptor& row_desc, const std::vector<TExpr>&\n     : _row_desc(row_desc),\n       _t_output_expr(t_output_expr),\n       _buf_size(buffer_size) {\n+\n+    if (!sink.__isset.type || sink.type == TResultSinkType::MYSQL_PROTOCAL) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MTQzNA=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTMwNjYzOnYy", "diffSide": "RIGHT", "path": "build.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzoyOToyNlrOGWmfdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDowNzo1NlrOGXPI5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MjUwMA==", "bodyText": "forget to removed ?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426352500", "createdAt": "2020-05-18T03:29:26Z", "author": {"login": "yangzhg"}, "path": "build.sh", "diffHunk": "@@ -42,6 +42,7 @@ if [[ ! -f ${DORIS_THIRDPARTY}/installed/lib/libs2.a ]]; then\n fi\n \n PARALLEL=$[$(nproc)/4+1]\n+PARALLEL=12", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxODQ2OA==", "bodyText": "Removed", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427018468", "createdAt": "2020-05-19T04:07:56Z", "author": {"login": "morningman"}, "path": "build.sh", "diffHunk": "@@ -42,6 +42,7 @@ if [[ ! -f ${DORIS_THIRDPARTY}/installed/lib/libs2.a ]]; then\n fi\n \n PARALLEL=$[$(nproc)/4+1]\n+PARALLEL=12", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1MjUwMA=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTMwOTAyOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwMzozMTowOFrOGWmg2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNDoxMDowMVrOGXPLEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1Mjg1Nw==", "bodyText": "\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6 \u66f4\u597d\u4e00\u70b9", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r426352857", "createdAt": "2020-05-18T03:31:08Z", "author": {"login": "yangzhg"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u67e5\u8be2\u7ed3\u679c\u96c6\u5bfc\u51fa\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxOTAyNA==", "bodyText": "ok", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427019024", "createdAt": "2020-05-19T04:10:01Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u67e5\u8be2\u7ed3\u679c\u96c6\u5bfc\u51fa\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM1Mjg1Nw=="}, "originalCommit": {"oid": "08b19d6113e174989501e4253a1feb04f63cef58"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1OTgwMjAxOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjowNVrOGXSClw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxMzozNzowM1rOGXgzPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA2NjAwNw==", "bodyText": "OUTFILE?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427066007", "createdAt": "2020-05-19T06:46:05Z", "author": {"login": "zhangy5"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUFILE \"file_path\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ad42a03b8322017499ea1fa3cb23ca6b8b9dcb"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzMwNzgzNw==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r427307837", "createdAt": "2020-05-19T13:37:03Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUFILE \"file_path\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA2NjAwNw=="}, "originalCommit": {"oid": "43ad42a03b8322017499ea1fa3cb23ca6b8b9dcb"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQxMDE5OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjowNjoxM1rOGYTHYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDo0NjowNVrOGYmCmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzMjE5Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n          \n          \n            \n            \u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428132193", "createdAt": "2020-05-20T16:06:13Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0MjI2Nw==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428442267", "createdAt": "2020-05-21T04:46:05Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzMjE5Mw=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQyNDc5OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjowOTo1NlrOGYTQ8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNToyNDo1MlrOGYmlfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDY0Mw==", "bodyText": "\u662f\u5426\u4ea7\u751f\u7a7a\u6587\u4ef6\u5e94\u8be5\u662f\u53ef\u914d\u7f6e\u7684\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428134643", "createdAt": "2020-05-20T16:09:56Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u4e0d\u4f1a\u68c0\u67e5\u6587\u4ef6\u53ca\u6587\u4ef6\u8def\u5f84\u662f\u5426\u5b58\u5728\u3002\u662f\u5426\u4f1a\u81ea\u52a8\u521b\u5efa\u8def\u5f84\u3001\u6216\u662f\u5426\u4f1a\u8986\u76d6\u5df2\u5b58\u5728\u6587\u4ef6\uff0c\u5b8c\u5168\u7531\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u7684\u8bed\u4e49\u51b3\u5b9a\u3002\n+* \u5982\u679c\u5728\u5bfc\u51fa\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef\uff0c\u53ef\u80fd\u4f1a\u6709\u5bfc\u51fa\u6587\u4ef6\u6b8b\u7559\u5728\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e0a\u3002Doris \u4e0d\u4f1a\u6e05\u7406\u8fd9\u4e9b\u6587\u4ef6\u3002\u9700\u8981\u7528\u6237\u624b\u52a8\u6e05\u7406\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u7684\u8d85\u65f6\u65f6\u95f4\u540c\u67e5\u8be2\u7684\u8d85\u65f6\u65f6\u95f4\u3002\u53ef\u4ee5\u901a\u8fc7 `SET query_timeout=xxx` \u8fdb\u884c\u8bbe\u7f6e\u3002\n+* \u5bf9\u4e8e\u7ed3\u679c\u96c6\u4e3a\u7a7a\u7684\u67e5\u8be2\uff0c\u4f9d\u7136\u540e\u4ea7\u751f\u4e00\u4e2a\u5927\u5c0f\u4e3a0\u7684\u6587\u4ef6\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0MjY4OA==", "bodyText": "\u611f\u89c9\u8fd9\u79cd\u914d\u7f6e\u610f\u4e49\u4e0d\u5927\uff1f\u589e\u52a0\u4e86\u529f\u80fd\u590d\u6742\u5ea6\u3002\n\u4ea7\u51fa\u4e00\u4e2a\u7a7a\u6587\u4ef6\uff0c\u81f3\u5c11\u8bf4\u660e\u201c\u8fd0\u884c\u8fc7\u201d\uff0c\u7528\u6237\u53ef\u68c0\u67e5\u7ed3\u679c\u96c6\u662f\u5426\u7684\u786e\u4e3a\u7a7a\u3002\u5982\u679c\u65e0\u4efb\u4f55\u4ea7\u51fa\uff0c\u65e0\u6cd5\u6392\u9664\u662f\u4e2d\u95f4\u8fc7\u7a0b\u51fa\u4e86bug\uff0c\u8fd8\u662f\u7ed3\u679c\u96c6\u7684\u786e\u4e3a\u7a7a\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428442688", "createdAt": "2020-05-21T04:48:07Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u4e0d\u4f1a\u68c0\u67e5\u6587\u4ef6\u53ca\u6587\u4ef6\u8def\u5f84\u662f\u5426\u5b58\u5728\u3002\u662f\u5426\u4f1a\u81ea\u52a8\u521b\u5efa\u8def\u5f84\u3001\u6216\u662f\u5426\u4f1a\u8986\u76d6\u5df2\u5b58\u5728\u6587\u4ef6\uff0c\u5b8c\u5168\u7531\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u7684\u8bed\u4e49\u51b3\u5b9a\u3002\n+* \u5982\u679c\u5728\u5bfc\u51fa\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef\uff0c\u53ef\u80fd\u4f1a\u6709\u5bfc\u51fa\u6587\u4ef6\u6b8b\u7559\u5728\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e0a\u3002Doris \u4e0d\u4f1a\u6e05\u7406\u8fd9\u4e9b\u6587\u4ef6\u3002\u9700\u8981\u7528\u6237\u624b\u52a8\u6e05\u7406\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u7684\u8d85\u65f6\u65f6\u95f4\u540c\u67e5\u8be2\u7684\u8d85\u65f6\u65f6\u95f4\u3002\u53ef\u4ee5\u901a\u8fc7 `SET query_timeout=xxx` \u8fdb\u884c\u8bbe\u7f6e\u3002\n+* \u5bf9\u4e8e\u7ed3\u679c\u96c6\u4e3a\u7a7a\u7684\u67e5\u8be2\uff0c\u4f9d\u7136\u540e\u4ea7\u751f\u4e00\u4e2a\u5927\u5c0f\u4e3a0\u7684\u6587\u4ef6\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDY0Mw=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ1MTE5Ng==", "bodyText": "\u53ea\u662f\u8bb0\u5f97MapReduce writer \u662f\u652f\u6301\u8fd9\u79cd\u914d\u7f6e\u7684\uff0c\u56e0\u4e3a\u8fd9\u79cd\u9700\u6c42\u53ef\u80fd\u662f\u5b58\u5728\u7684\u3002\u4e0d\u8fc7\u53ef\u4ee5\u540e\u671f\u7528\u6237\u6709\u771f\u5b9e\u9700\u6c42\u4e86\u518d\u652f\u6301\uff0c\u8fd9\u4e2aPR\u5c31\u4e0d\u8003\u8651\u4e86\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428451196", "createdAt": "2020-05-21T05:24:52Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u4e0d\u4f1a\u68c0\u67e5\u6587\u4ef6\u53ca\u6587\u4ef6\u8def\u5f84\u662f\u5426\u5b58\u5728\u3002\u662f\u5426\u4f1a\u81ea\u52a8\u521b\u5efa\u8def\u5f84\u3001\u6216\u662f\u5426\u4f1a\u8986\u76d6\u5df2\u5b58\u5728\u6587\u4ef6\uff0c\u5b8c\u5168\u7531\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u7684\u8bed\u4e49\u51b3\u5b9a\u3002\n+* \u5982\u679c\u5728\u5bfc\u51fa\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef\uff0c\u53ef\u80fd\u4f1a\u6709\u5bfc\u51fa\u6587\u4ef6\u6b8b\u7559\u5728\u8fdc\u7aef\u5b58\u50a8\u7cfb\u7edf\u4e0a\u3002Doris \u4e0d\u4f1a\u6e05\u7406\u8fd9\u4e9b\u6587\u4ef6\u3002\u9700\u8981\u7528\u6237\u624b\u52a8\u6e05\u7406\u3002\n+* \u5bfc\u51fa\u547d\u4ee4\u7684\u8d85\u65f6\u65f6\u95f4\u540c\u67e5\u8be2\u7684\u8d85\u65f6\u65f6\u95f4\u3002\u53ef\u4ee5\u901a\u8fc7 `SET query_timeout=xxx` \u8fdb\u884c\u8bbe\u7f6e\u3002\n+* \u5bf9\u4e8e\u7ed3\u679c\u96c6\u4e3a\u7a7a\u7684\u67e5\u8be2\uff0c\u4f9d\u7136\u540e\u4ea7\u751f\u4e00\u4e2a\u5927\u5c0f\u4e3a0\u7684\u6587\u4ef6\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDY0Mw=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQyNjc0OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoxMDoyMVrOGYTSMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNToyNDo1OVrOGYmlkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDk2MQ==", "bodyText": "\u4e4b\u540e\u4f1a\u652f\u6301\u591a\u7ebf\u7a0b\u5417\uff1f", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428134961", "createdAt": "2020-05-20T16:10:21Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0MzgyNw==", "bodyText": "\u8fd9\u91cc\u76ee\u524d\u53ea\u662f\u7b80\u5355\u590d\u7528\u4e86\u67e5\u8be2\u8fd4\u56de\u7ed3\u679c\u7684\u903b\u8f91\u3002\n\u591a\u7ebf\u7a0b\u7684\u652f\u6301\u4f1a\u9ebb\u70e6\u4e00\u70b9\u3002\u6bd4\u5982\u9700\u8981\u5224\u65adselect\u8bed\u53e5\u662f\u5426\u5305\u542border by \u7b49\u4fe1\u606f\u3002\u5982\u679c\u5305\u542b\uff0c\u5219\u53ea\u80fd\u4f7f\u7528\u5355\u7ebf\u7a0b\u987a\u5e8f\u5199\uff08\u56e0\u4e3a\u7ed3\u679c\u662f\u987a\u5e8f\u8fd4\u56de\u7684\uff09\u3002\n\u5373\u4f7f\u4e0d\u5305\u542border by\uff0c\u76ee\u524d\u67e5\u8be2\u6846\u67b6\u7ed3\u679c\u8fd8\u662f\u5355\u7ebf\u7a0b\u8fd4\u56de\u7684\uff0c\u6700\u591a\u662f\u6539\u6210\u591a\u7ebf\u7a0b\u5199\u6587\u4ef6\u3002\u4f46\u662f\u5f88\u591a\u8fdc\u7aef\u7cfb\u7edf\u4e0d\u652f\u6301\u6307\u5b9aoffset\u5199\uff0c\u6240\u4ee5\u591a\u4e2a\u7ebf\u7a0b\u53ea\u80fd\u5199\u5230\u591a\u4e2a\u6587\u4ef6\u91cc\u3002\u4e5f\u6bd4\u8f83\u9ebb\u70e6\u3002\n\u4e0d\u592a\u786e\u5b9a\u5176\u4ed6\u7cfb\u7edf\u5bf9\u4e8eselect\u7ed3\u679c\u7684\u5bfc\u51fa\u5177\u4f53\u662f\u600e\u4e48\u5b9e\u73b0\u7684\u3002", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428443827", "createdAt": "2020-05-21T04:53:30Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDk2MQ=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ1MTIxOQ==", "bodyText": "OK.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428451219", "createdAt": "2020-05-21T05:24:59Z", "author": {"login": "kangkaisen"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u5165\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 100MB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 100MB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+\n+2. \u793a\u4f8b2\n+\n+    \u5c06 CTE \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u9ed8\u8ba4\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002\u4f7f\u7528\u9ed8\u8ba4\u7684\u884c\u5217\u5206\u9694\u7b26\u3002\n+\n+    ```\n+    WITH\n+    x1 AS\n+    (SELECT k1, k2 FROM tbl1),\n+    x2 AS\n+    (SELECT k3 FROM tbl2)\n+    SELEC k1 FROM x1 UNION SELECT k3 FROM x2\n+    INTO OUTFILE \"hdfs:/path/to/result.txt\"\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"username\"=\"user\",\n+        \"password\"=\"passwd\",\n+        \"dfs.nameservices\" = \"my_ha\",\n+        \"dfs.ha.namenodes.my_ha\" = \"my_namenode1, my_namenode2\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode1\" = \"nn1_host:rpc_port\",\n+        \"dfs.namenode.rpc-address.my_ha.my_namenode2\" = \"nn2_host:rpc_port\",\n+        \"dfs.client.failover.proxy.provider\" = \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"\n+    );\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.csv`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.csv, result_1.csv, ...`\u3002\n+    \n+3. \u793a\u4f8b3\n+\n+    \u5c06 UNION \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `bos://bucket/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a PARQUET\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e hdfs \u9ad8\u53ef\u7528\u4fe1\u606f\u3002PARQUET \u683c\u5f0f\u65e0\u9700\u6307\u5b9a\u5217\u5206\u5272\u7b26\u3002\n+    \n+    ```\n+    SELECT k1 FROM tbl1 UNION SELECT k2 FROM tbl1\n+    INTO OUTFILE \"bos://bucket/result.txt\"\n+    FORMAT AS PARQUET\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"bos_endpoint\" = \"http://bj.bcebos.com\",\n+        \"bos_accesskey\" = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+        \"bos_secret_accesskey\" = \"yyyyyyyyyyyyyyyyyyyyyyyyyy\"\n+    )\n+    ```\n+    \n+    \u6700\u7ec8\u751f\u6210\u6587\u4ef6\u5982\u5982\u679c\u4e0d\u5927\u4e8e 1GB\uff0c\u5219\u4e3a\uff1a`result_0.parquet`\u3002\n+    \n+    \u5982\u679c\u5927\u4e8e 1GB\uff0c\u5219\u53ef\u80fd\u4e3a `result_0.parquet, result_1.parquet, ...`\u3002\n+    \n+## \u8fd4\u56de\u7ed3\u679c\n+\n+\u5bfc\u51fa\u547d\u4ee4\u4e3a\u540c\u6b65\u547d\u4ee4\u3002\u547d\u4ee4\u8fd4\u56de\uff0c\u5373\u8868\u793a\u64cd\u4f5c\u7ed3\u675f\u3002\n+\n+\u5982\u679c\u6b63\u5e38\u5bfc\u51fa\u5e76\u8fd4\u56de\uff0c\u5219\u7ed3\u679c\u5982\u4e0b\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                Query OK, 100000 row affected (5.86 sec)\n+```\n+\n+\u5176\u4e2d `100000 row affected` \u8868\u793a\u5bfc\u51fa\u7684\u7ed3\u679c\u96c6\u884c\u6570\u3002\n+\n+\u5982\u679c\u6267\u884c\u9519\u8bef\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\uff0c\u5982\uff1a\n+\n+```\n+mysql> SELECT * FROM tbl INTO OUTFILE ...                                                                                                                                                                                                                                                                  ERROR 1064 (HY000): errCode = 2, detailMessage = Open broker writer failed ...\n+```\n+\n+## \u6ce8\u610f\u4e8b\u9879\n+\n+* \u67e5\u8be2\u7ed3\u679c\u662f\u7531\u5355\u4e2a BE \u8282\u70b9\uff0c\u5355\u7ebf\u7a0b\u5bfc\u51fa\u7684\u3002\u56e0\u6b64\u5bfc\u51fa\u65f6\u95f4\u548c\u5bfc\u51fa\u7ed3\u679c\u96c6\u5927\u5c0f\u6b63\u76f8\u5173\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNDk2MQ=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQ0Mzg0OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/mysql_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoxNDozOFrOGYTdIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDo1NDowMlrOGYmJOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNzc2MA==", "bodyText": "Hbase?  Remove it.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428137760", "createdAt": "2020-05-20T16:14:38Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+    // convert one tuple row\n+    Status _add_one_row(TupleRow* row);\n+\n+private:\n+    // The expressions that are run to create tuples to be written to hbase.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0Mzk2Mw==", "bodyText": "Removed", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428443963", "createdAt": "2020-05-21T04:54:02Z", "author": {"login": "morningman"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {\n+public:\n+    MysqlResultWriter(BufferControlBlock* sinker,\n+            const std::vector<ExprContext*>& output_expr_ctxs,\n+            RuntimeProfile* parent_profile);\n+    virtual ~MysqlResultWriter();\n+\n+    virtual Status init(RuntimeState* state) override;\n+    // convert one row batch to mysql result and\n+    // append this batch to the result sink\n+    virtual Status append_row_batch(const RowBatch* batch) override;\n+\n+    virtual Status close() override;\n+\n+private:\n+    void _init_profile();\n+    // convert one tuple row\n+    Status _add_one_row(TupleRow* row);\n+\n+private:\n+    // The expressions that are run to create tuples to be written to hbase.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzNzc2MA=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQ0NzA4OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/mysql_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoxNToyMVrOGYTfEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDo1NTo0MVrOGYmKsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzODI1OA==", "bodyText": "Should mark final.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428138258", "createdAt": "2020-05-20T16:15:21Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0NDMzOQ==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428444339", "createdAt": "2020-05-21T04:55:41Z", "author": {"login": "morningman"}, "path": "be/src/runtime/mysql_result_writer.h", "diffHunk": "@@ -0,0 +1,70 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+\n+namespace doris {\n+\n+class TupleRow;\n+class RowBatch;\n+class ExprContext;\n+class MysqlRowBuffer;\n+class BufferControlBlock;\n+class RuntimeProfile;\n+\n+// convert the row batch to mysql protol row\n+class MysqlResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEzODI1OA=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQ2Mzc1OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/file_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoxOTozMVrOGYTpyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDo1NTo0NFrOGYmKvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTAwMw==", "bodyText": "unordered_map?", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428141003", "createdAt": "2020-05-20T16:19:31Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0NDM0OA==", "bodyText": "this map will be assigned from a thrift map object. If use unordered_map here, I have to\nconvert it.\nAnd this properties only has few elements, so i think its not a big deal.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428444348", "createdAt": "2020-05-21T04:55:44Z", "author": {"login": "morningman"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTAwMw=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjQ2NzA0OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/file_result_writer.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNjoyMDoxMFrOGYTrtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDo1NjowM1rOGYmK-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTQ5Mg==", "bodyText": "Should mark final.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428141492", "createdAt": "2020-05-20T16:20:10Z", "author": {"login": "kangkaisen"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;\n+\n+    ResultFileOptions(const TResultFileSinkOptions& t_opt) {\n+        file_path = t_opt.file_path;\n+        file_format = t_opt.file_format;\n+        column_separator = t_opt.__isset.column_separator ? t_opt.column_separator : \"\\t\";\n+        line_delimiter = t_opt.__isset.line_delimiter ? t_opt.line_delimiter : \"\\n\";\n+        max_file_size_bytes = t_opt.__isset.max_file_size_bytes ?\n+                t_opt.max_file_size_bytes : max_file_size_bytes;\n+\n+        is_local_file = true;\n+        if (t_opt.__isset.broker_addresses) {\n+            broker_addresses = t_opt.broker_addresses;\n+            is_local_file = false;\n+        }\n+        if (t_opt.__isset.broker_properties) {\n+            broker_properties = t_opt.broker_properties;\n+        }\n+    }\n+};\n+\n+// write result to file\n+class FileResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ0NDQwOQ==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r428444409", "createdAt": "2020-05-21T04:56:03Z", "author": {"login": "morningman"}, "path": "be/src/runtime/file_result_writer.h", "diffHunk": "@@ -0,0 +1,132 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"runtime/result_writer.h\"\n+#include \"runtime/runtime_state.h\"\n+#include \"gen_cpp/DataSinks_types.h\"\n+\n+namespace doris {\n+\n+class ExprContext;\n+class FileWriter;\n+class ParquetWriterWrapper;\n+class RowBatch;\n+class RuntimeProfile;\n+class TupleRow;\n+\n+struct ResultFileOptions {\n+    bool is_local_file;\n+    std::string file_path;\n+    TFileFormatType::type file_format;\n+    std::string column_separator;\n+    std::string line_delimiter;\n+    size_t max_file_size_bytes = 1 * 1024 * 1024 * 1024; // 1GB\n+    std::vector<TNetworkAddress> broker_addresses;\n+    std::map<std::string, std::string> broker_properties;\n+\n+    ResultFileOptions(const TResultFileSinkOptions& t_opt) {\n+        file_path = t_opt.file_path;\n+        file_format = t_opt.file_format;\n+        column_separator = t_opt.__isset.column_separator ? t_opt.column_separator : \"\\t\";\n+        line_delimiter = t_opt.__isset.line_delimiter ? t_opt.line_delimiter : \"\\n\";\n+        max_file_size_bytes = t_opt.__isset.max_file_size_bytes ?\n+                t_opt.max_file_size_bytes : max_file_size_bytes;\n+\n+        is_local_file = true;\n+        if (t_opt.__isset.broker_addresses) {\n+            broker_addresses = t_opt.broker_addresses;\n+            is_local_file = false;\n+        }\n+        if (t_opt.__isset.broker_properties) {\n+            broker_properties = t_opt.broker_properties;\n+        }\n+    }\n+};\n+\n+// write result to file\n+class FileResultWriter : public ResultWriter {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE0MTQ5Mg=="}, "originalCommit": {"oid": "0615bfa4f2ceb902035f3e8cd38937a85e737ff3"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTg5MTQ3OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjo0NjowN1rOGZJAhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTozODoxNVrOGZbjig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTE3Mw==", "bodyText": "max_file_size\u66f4\u597d\u4e00\u4e9b\uff0c\u56e0\u4e3a\u540e\u9762\u53ef\u4ee5\u6307\u5b9a\u5355\u4f4d\u4e86", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429015173", "createdAt": "2020-05-22T02:46:07Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMxOTA1MA==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429319050", "createdAt": "2020-05-22T15:38:15Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv\n+    my_file_1.csv\n+    my_file_2.csv\n+    ```\n+\n+* `[format_as]`\n+\n+    ```\n+    FORMAT AS CSV\n+    ```\n+    \n+    \u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u3002\u9ed8\u8ba4\u4e3a CSV\u3002\n+\n+* `[broker_properties]`\n+\n+    ```\n+    (\"broker_prop_key\" = \"broker_prop_val\", ...)\n+    ``` \n+\n+    Broker \u76f8\u5173\u7684\u4e00\u4e9b\u53c2\u6570\uff0c\u5982 HDFS \u7684 \u8ba4\u8bc1\u4fe1\u606f\u7b49\u3002\u5177\u4f53\u53c2\u9605[Broker \u6587\u6863](./broker.html)\u3002\n+\n+* `[other_properties]`\n+\n+    ```\n+    (\"key1\" = \"val1\", \"key2\" = \"val2\", ...)\n+    ```\n+\n+    \u5176\u4ed6\u5c5e\u6027\uff0c\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u5c5e\u6027\uff1a\n+\n+    * `column_separator`\uff1a\u5217\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\t`\u3002\n+    * `line_delimiter`\uff1a\u884c\u5206\u9694\u7b26\uff0c\u4ec5\u5bf9 CSV \u683c\u5f0f\u9002\u7528\u3002\u9ed8\u8ba4\u4e3a `\\n`\u3002\n+    * `max_file_size_bytes`\uff1a\u5355\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u9ed8\u8ba4\u4e3a 1GB\u3002\u53d6\u503c\u8303\u56f4\u5728 5MB \u5230 2GB \u4e4b\u95f4\u3002\u8d85\u8fc7\u8fd9\u4e2a\u5927\u5c0f\u7684\u6587\u4ef6\u5c06\u4f1a\u88ab\u5207\u5206\u3002\n+\n+1. \u793a\u4f8b1\n+\n+    \u5c06\u7b80\u5355\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6 `hdfs:/path/to/result.txt`\u3002\u6307\u5b9a\u5bfc\u51fa\u683c\u5f0f\u4e3a CSV\u3002\u4f7f\u7528 `my_broker` \u5e76\u8bbe\u7f6e kerberos \u8ba4\u8bc1\u4fe1\u606f\u3002\u6307\u5b9a\u5217\u5206\u9694\u7b26\u4e3a `,`\uff0c\u884c\u5206\u9694\u7b26\u4e3a `\\n`\u3002\n+\n+    ```\n+    SELECT * FROM tbl\n+    INTO OUTFILE \"hdfs:/path/to/result\"\n+    FORMAT AS CSV\n+    WITH BROKER \"my_broker\"\n+    (\n+        \"hadoop.security.authentication\" = \"kerberos\",\n+        \"kerberos_principal\" = \"doris@YOUR.COM\",\n+        \"kerberos_keytab\" = \"/home/doris/my.keytab\"\n+    )\n+    PROPERTIELS\n+    (\n+        \"column_separator\" = \",\",\n+        \"line_delimiter\" = \"\\n\",\n+        \"max_file_size_bytes\" = \"100MB\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTE3Mw=="}, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTg5MzA0OnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjo0NzoxN1rOGZJBgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTozODoxOVrOGZbjuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTQyNA==", "bodyText": "\u6211\u89c9\u5f97\u53ef\u4ee5\u662fmy_file0.csv\u5427\uff0c\u7528\u6237\u5982\u679c\u60f3\u5bfc\u5165my_file_0.csv\uff0c\u90a3\u4e48\u8f93\u5165\u7684\u53c2\u6570\u662f\u201chdfs://path/to/my_file_\u201d\u5c31\u53ef\u4ee5\u8fbe\u5230\u4e86", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429015424", "createdAt": "2020-05-22T02:47:17Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMxOTA5Ng==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429319096", "createdAt": "2020-05-22T15:38:19Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`\n+[broker_properties]\n+[other_properties]\n+```\n+\n+* `file_path`\n+\n+    `file_path` \u6307\u5411\u6587\u4ef6\u5b58\u50a8\u7684\u8def\u5f84\u4ee5\u53ca\u6587\u4ef6\u524d\u7f00\u3002\u5982 `hdfs://path/to/my_file`\u3002\n+    \n+    \u6700\u7ec8\u7684\u6587\u4ef6\u540d\u5c06\u7531 `my_file`\uff0c\u6587\u4ef6\u5e8f\u53f7\u4ee5\u53ca\u6587\u4ef6\u683c\u5f0f\u540e\u7f00\u7ec4\u6210\u3002\u5176\u4e2d\u6587\u4ef6\u5e8f\u53f7\u75310\u5f00\u59cb\uff0c\u6570\u91cf\u4e3a\u6587\u4ef6\u88ab\u5206\u5272\u7684\u6570\u91cf\u3002\u5982\uff1a\n+    \n+    ```\n+    my_file_0.csv", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNTQyNA=="}, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTkwMzYyOnYy", "diffSide": "RIGHT", "path": "docs/zh-CN/administrator-guide/outfile.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwMjo1NDo1NFrOGZJIKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTozODoyNFrOGZbj6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNzEyOA==", "bodyText": "\u6211\u89c9\u5f97broker\u672a\u6765\u53ef\u80fd\u5e76\u4e0d\u662f\u4e00\u4e2a\u5fc5\u5907\u9009\u9879\u3002\u6240\u4ee5\u4e0d\u5efa\u8bae\u628awith broker\u663e\u793a\u7684\u5199\u5728\u8bed\u6cd5\u4e2d\u3002\n\u662f\u4e0d\u662f\u53ef\u4ee5\u628abroker\u4fe1\u606f\u90fd\u653e\u5230property\u91cc\u9762\u5462\uff1f\u589e\u52a0\u4e0b\u9762\u7c7b\u4f3c\u7684\u914d\u7f6e\uff1f\n\"broker\" = \"\"\n\"broker.username\" = \"\n\"broker.password\" = \"\"", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429017128", "createdAt": "2020-05-22T02:54:54Z", "author": {"login": "imay"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMxOTE0Nw==", "bodyText": "OK,\u65b0\u7684\u8bed\u6cd5\u66f4\u65b0\u5728\u4e86proposal\u91cc", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429319147", "createdAt": "2020-05-22T15:38:24Z", "author": {"login": "morningman"}, "path": "docs/zh-CN/administrator-guide/outfile.md", "diffHunk": "@@ -0,0 +1,183 @@\n+---\n+{\n+    \"title\": \"\u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\",\n+    \"language\": \"zh-CN\"\n+}\n+---\n+\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# \u5bfc\u51fa\u67e5\u8be2\u7ed3\u679c\u96c6\n+\n+\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 `SELECT INTO OUTFILE` \u547d\u4ee4\u8fdb\u884c\u67e5\u8be2\u7ed3\u679c\u7684\u5bfc\u51fa\u64cd\u4f5c\u3002\n+\n+## \u8bed\u6cd5\n+\n+`SELECT INTO OUTFILE` \u8bed\u53e5\u53ef\u4ee5\u5c06\u67e5\u8be2\u7ed3\u679c\u5bfc\u51fa\u5230\u6587\u4ef6\u4e2d\u3002\u76ee\u524d\u4ec5\u652f\u6301\u901a\u8fc7 Broker \u8fdb\u7a0b\u5bfc\u51fa\u5230\u8fdc\u7aef\u5b58\u50a8\uff0c\u5982 HDFS\uff0cS3\uff0cBOS \u4e0a\u3002\u8bed\u6cd5\u5982\u4e0b\n+\n+```\n+query_stmt\n+INTO OUTFILE \"file_path\"\n+[format_as]\n+WITH BROKER `broker_name`", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAxNzEyOA=="}, "originalCommit": {"oid": "aa9e6a6fc54d2e627627e9fc76fadfb1379d7187"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NTkzNTQ2OnYy", "diffSide": "RIGHT", "path": "be/src/runtime/query_statistics.h", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxMzoxNDo0N1rOGZu3pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzo1OTowMVrOGZ4PRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTYzNTQ5NA==", "bodyText": "better to give a default value.", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429635494", "createdAt": "2020-05-24T13:14:47Z", "author": {"login": "imay"}, "path": "be/src/runtime/query_statistics.h", "diffHunk": "@@ -71,6 +77,9 @@ class QueryStatistics {\n \n     int64_t scan_rows;\n     int64_t scan_bytes;\n+    // number rows returned by query.\n+    // only set once by result sink when closing.\n+    int64_t returned_rows;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc4ODk5OA==", "bodyText": "Done", "url": "https://github.com/apache/incubator-doris/pull/3584#discussion_r429788998", "createdAt": "2020-05-25T07:59:01Z", "author": {"login": "morningman"}, "path": "be/src/runtime/query_statistics.h", "diffHunk": "@@ -71,6 +77,9 @@ class QueryStatistics {\n \n     int64_t scan_rows;\n     int64_t scan_bytes;\n+    // number rows returned by query.\n+    // only set once by result sink when closing.\n+    int64_t returned_rows;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTYzNTQ5NA=="}, "originalCommit": {"oid": "4a6a21cdb0252bef71dd7526650b816f53134530"}, "originalPosition": 30}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1556, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}