{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyODk0MDQw", "number": 3186, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNDo0MjozM1rODq0qkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzozNzo1NlrODrDYvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MjI5NjQ5OnYy", "diffSide": "RIGHT", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNDo0MjozM1rOF6ziWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMjozNjo1MVrOF7KJkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIwNjEwNQ==", "bodyText": "whether we can use a fixed array which size = rowCount or batch_size with a size flag?", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397206105", "createdAt": "2020-03-24T14:42:33Z", "author": {"login": "wuyunfeng"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;\n     private int readRowCount = 0;\n     private List<Row> rowBatch = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU3NjU5NA==", "bodyText": "We could get the fixed array size by add all rows of Arrow batch through arrowStreamReader.loadNextBatch(), in this case, we might as well use List as we do now", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397576594", "createdAt": "2020-03-25T02:36:51Z", "author": {"login": "Youngwb"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;\n     private int readRowCount = 0;\n     private List<Row> rowBatch = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIwNjEwNQ=="}, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDY5NTg0OnYy", "diffSide": "RIGHT", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzoyOTo0MFrOF7K_YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwOTozNjoyN1rOF7SwUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MDM2OA==", "bodyText": "function close could be removed and move its content to finally, since read all data from arrow here.", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397590368", "createdAt": "2020-03-25T03:29:40Z", "author": {"login": "vinson0526"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -87,50 +88,39 @@ public RowBatch(TScanBatchResult nextResult, Schema schema) throws DorisExceptio\n                 new ByteArrayInputStream(nextResult.getRows()),\n                 rootAllocator\n                 );\n+        this.offsetInRowBatch = 0;\n         try {\n             this.root = arrowStreamReader.getVectorSchemaRoot();\n+            while (arrowStreamReader.loadNextBatch()) {\n+                fieldVectors = root.getFieldVectors();\n+                if (fieldVectors.size() != schema.size()) {\n+                    logger.error(\"Schema size '{}' is not equal to arrow field size '{}'.\",\n+                            fieldVectors.size(), schema.size());\n+                    throw new DorisException(\"Load Doris data failed, schema size of fetch data is wrong.\");\n+                }\n+                if (fieldVectors.size() == 0 || root.getRowCount() == 0) {\n+                    logger.debug(\"One batch in arrow has no data.\");\n+                    continue;\n+                }\n+                rowCountInOneBatch = root.getRowCount();\n+                // init the rowBatch\n+                for (int i = 0; i < rowCountInOneBatch; ++i) {\n+                    rowBatch.add(new Row(fieldVectors.size()));\n+                }\n+                convertArrowToRowBatch();\n+                readRowCount += root.getRowCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxNzU4NA==", "bodyText": "OK,Done", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397717584", "createdAt": "2020-03-25T09:36:27Z", "author": {"login": "Youngwb"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -87,50 +88,39 @@ public RowBatch(TScanBatchResult nextResult, Schema schema) throws DorisExceptio\n                 new ByteArrayInputStream(nextResult.getRows()),\n                 rootAllocator\n                 );\n+        this.offsetInRowBatch = 0;\n         try {\n             this.root = arrowStreamReader.getVectorSchemaRoot();\n+            while (arrowStreamReader.loadNextBatch()) {\n+                fieldVectors = root.getFieldVectors();\n+                if (fieldVectors.size() != schema.size()) {\n+                    logger.error(\"Schema size '{}' is not equal to arrow field size '{}'.\",\n+                            fieldVectors.size(), schema.size());\n+                    throw new DorisException(\"Load Doris data failed, schema size of fetch data is wrong.\");\n+                }\n+                if (fieldVectors.size() == 0 || root.getRowCount() == 0) {\n+                    logger.debug(\"One batch in arrow has no data.\");\n+                    continue;\n+                }\n+                rowCountInOneBatch = root.getRowCount();\n+                // init the rowBatch\n+                for (int i = 0; i < rowCountInOneBatch; ++i) {\n+                    rowBatch.add(new Row(fieldVectors.size()));\n+                }\n+                convertArrowToRowBatch();\n+                readRowCount += root.getRowCount();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MDM2OA=="}, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDcwODQ2OnYy", "diffSide": "RIGHT", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzozNzo1NlrOF7LG3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwOToyODoyN1rOF7SdCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MjI4NA==", "bodyText": "rowCountInOneBatch could be a local variable\uff1f", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397592284", "createdAt": "2020-03-25T03:37:56Z", "author": {"login": "vinson0526"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxMjY1MA==", "bodyText": "rowCountInOneBatch is also used in addValueToRow and convertArrowToRowBatch, so I think this is better for now", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397712650", "createdAt": "2020-03-25T09:28:27Z", "author": {"login": "Youngwb"}, "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MjI4NA=="}, "originalCommit": {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2002, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}