{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3ODE4MDk1", "number": 4524, "title": "[SparkDpp] Support complete types", "bodyText": "Proposed changes\nsee #4525\nFor[Spark Load]\n1 support decimal andl largeint\n2 add validate logic for char/varchar/decimal\n3 check data load from hive with strict mode\n4 support decimal/date/datetime aggregator\nTypes of changes\nWhat types of changes does your code introduce to Doris?\nPut an x in the boxes that apply\n\n[] Bugfix (non-breaking change which fixes an issue)\n New feature (non-breaking change which adds functionality)\n[] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n[] Documentation Update (if none of the other choices apply)\n[] Code refactor (Modify the code structure, format the code, etc...)\n\nChecklist\nPut an x in the boxes that apply. You can also fill these out after creating the PR. If you're unsure about any of them, don't hesitate to ask. We're here to help! This is simply a reminder of what we are going to look for before merging your code.\n\n I have create an issue on (Fix #4525), and have described the bug/feature there in detail\n Compiling and unit tests pass locally with my changes\n[] I have added tests that prove my fix is effective or that my feature works\n[] If this change need a document change, I have updated the document\n Any dependent changes have been merged", "createdAt": "2020-09-02T13:24:04Z", "url": "https://github.com/apache/incubator-doris/pull/4524", "merged": true, "mergeCommit": {"oid": "2c24fe80fa76d4afbeeecaacbb11e29e07e84fd9"}, "closed": true, "closedAt": "2020-09-13T03:57:34Z", "author": {"login": "wangbo"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdE72QyAH2gAyNDc3ODE4MDk1OjA3OTQyYWMzNjRkMTg1OTA2ZmI1ZDJhNmU3NDhhMmIwMWYzN2Y0ZDI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdIFaSWAFqTQ4NzIxMzYzMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "author": {"user": {"login": "wangbo", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/07942ac364d185906fb5d2a6e748a2b01f37f4d2", "committedDate": "2020-09-02T13:16:36Z", "message": "support complete types"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzMDQyNzky", "url": "https://github.com/apache/incubator-doris/pull/4524#pullrequestreview-483042792", "createdAt": "2020-09-05T09:09:13Z", "commit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwOTowOToxM1rOHNgx_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwOToxODoxOFrOHNg00w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMDYyMA==", "bodyText": "If the column definition is k1 decimal(4,3), than the value range of k1 should be\n[-9.999, 9.999]\nAnd your code will give: [-9999.999, 9999.999], which is not right.", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483930620", "createdAt": "2020-09-05T09:09:13Z", "author": {"login": "morningman"}, "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/ColumnParser.java", "diffHunk": "@@ -186,4 +192,61 @@ public boolean parse(String value) {\n             throw new RuntimeException(\"string check failed \", e);\n         }\n     }\n+}\n+\n+class DecimalParser extends ColumnParser {\n+\n+    public static int PRECISION = 27;\n+    public static int SCALE = 9;\n+\n+    private BigDecimal maxValue;\n+    private BigDecimal minValue;\n+\n+    public DecimalParser(EtlJobConfig.EtlColumn etlColumn) {\n+        StringBuilder precisionStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.precision; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMTM0Nw==", "bodyText": "missing DEFAULT?", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483931347", "createdAt": "2020-09-05T09:18:18Z", "author": {"login": "morningman"}, "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/SparkDpp.java", "diffHunk": "@@ -358,12 +362,44 @@ private void processRollupTree(RollupTreeNode rootNode,\n         return Pair.of(keyMap.toArray(new Integer[keyMap.size()]), valueMap.toArray(new Integer[valueMap.size()]));\n     }\n \n-    // repartition dataframe by partitionid_bucketid\n-    // so data in the same bucket will be consecutive.\n-    private JavaPairRDD<List<Object>, Object[]> fillTupleWithPartitionColumn(SparkSession spark, Dataset<Row> dataframe,\n+    /**\n+     *   check decimal,char/varchar\n+     */\n+    private boolean validateData(Object srcValue, EtlJobConfig.EtlColumn etlColumn, ColumnParser columnParser,Row row) {\n+\n+        switch (etlColumn.columnType.toUpperCase()) {\n+            case \"DECIMALV2\":\n+                // TODO(wb):  support decimal round; see be DecimalV2Value::round\n+                DecimalParser decimalParser = (DecimalParser) columnParser;\n+                BigDecimal srcBigDecimal = (BigDecimal) srcValue;\n+                if (srcValue != null && (decimalParser.getMaxValue().compareTo(srcBigDecimal) < 0 || decimalParser.getMinValue().compareTo(srcBigDecimal) > 0)) {\n+                    LOG.warn(String.format(\"decimal value is not valid for defination, column=%s, value=%s,precision=%s,scale=%s\",\n+                            etlColumn.columnName, srcValue.toString(), srcBigDecimal.precision(), srcBigDecimal.scale()));\n+                    abnormalRowAcc.add(1);\n+                    return false;\n+                }\n+                break;\n+            case \"CHAR\":\n+            case \"VARCHAR\":\n+                // TODO(wb) padding char type\n+                if (srcValue != null && srcValue.toString().length() > etlColumn.stringLength) {\n+                    LOG.warn(String.format(\"the length of input is too long than schema. column_name:%s,input_str[%s],schema length:%s,actual length:%s\",\n+                            etlColumn.columnName, row.toString(), etlColumn.stringLength, srcValue.toString().length()));\n+                    return false;\n+                }\n+                break;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzMDQ2MDY0", "url": "https://github.com/apache/incubator-doris/pull/4524#pullrequestreview-483046064", "createdAt": "2020-09-05T10:16:30Z", "commit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQxMDoxNjozMFrOHNhHZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQxMDoxNjozMFrOHNhHZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzNjEwMg==", "bodyText": "Check largeint type range", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483936102", "createdAt": "2020-09-05T10:16:30Z", "author": {"login": "wyb"}, "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/ColumnParser.java", "diffHunk": "@@ -186,4 +192,61 @@ public boolean parse(String value) {\n             throw new RuntimeException(\"string check failed \", e);\n         }\n     }\n+}\n+\n+class DecimalParser extends ColumnParser {\n+\n+    public static int PRECISION = 27;\n+    public static int SCALE = 9;\n+\n+    private BigDecimal maxValue;\n+    private BigDecimal minValue;\n+\n+    public DecimalParser(EtlJobConfig.EtlColumn etlColumn) {\n+        StringBuilder precisionStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.precision; i++) {\n+            precisionStr.append(\"9\");\n+        }\n+        StringBuilder scaleStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.scale; i++) {\n+            scaleStr.append(\"9\");\n+        }\n+        maxValue = new BigDecimal(precisionStr.toString() + \".\" + scaleStr.toString());\n+        minValue = new BigDecimal(\"-\" + precisionStr.toString() + \".\" + scaleStr.toString());\n+    }\n+\n+    @Override\n+    public boolean parse(String value) {\n+        try {\n+            BigDecimal bigDecimal = new BigDecimal(value);\n+            return bigDecimal.precision() - bigDecimal.scale() <= PRECISION - SCALE && bigDecimal.scale() <= SCALE;\n+        } catch (NumberFormatException e) {\n+            return false;\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"decimal parse failed \", e);\n+        }\n+    }\n+\n+    public BigDecimal getMaxValue() {\n+        return maxValue;\n+    }\n+\n+    public BigDecimal getMinValue() {\n+        return minValue;\n+    }\n+}\n+\n+class LargeIntParser extends ColumnParser {\n+\n+    @Override\n+    public boolean parse(String value) {\n+        try {\n+            BigInteger bigInteger = new BigInteger(value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzMTM4ODY5", "url": "https://github.com/apache/incubator-doris/pull/4524#pullrequestreview-483138869", "createdAt": "2020-09-06T12:27:05Z", "commit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNlQxMjoyNzowNVrOHNo6XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNlQxMjoyNzowNVrOHNo6XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDA2MzgzNg==", "bodyText": "byte length", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484063836", "createdAt": "2020-09-06T12:27:05Z", "author": {"login": "wyb"}, "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/SparkDpp.java", "diffHunk": "@@ -358,12 +362,44 @@ private void processRollupTree(RollupTreeNode rootNode,\n         return Pair.of(keyMap.toArray(new Integer[keyMap.size()]), valueMap.toArray(new Integer[valueMap.size()]));\n     }\n \n-    // repartition dataframe by partitionid_bucketid\n-    // so data in the same bucket will be consecutive.\n-    private JavaPairRDD<List<Object>, Object[]> fillTupleWithPartitionColumn(SparkSession spark, Dataset<Row> dataframe,\n+    /**\n+     *   check decimal,char/varchar\n+     */\n+    private boolean validateData(Object srcValue, EtlJobConfig.EtlColumn etlColumn, ColumnParser columnParser,Row row) {\n+\n+        switch (etlColumn.columnType.toUpperCase()) {\n+            case \"DECIMALV2\":\n+                // TODO(wb):  support decimal round; see be DecimalV2Value::round\n+                DecimalParser decimalParser = (DecimalParser) columnParser;\n+                BigDecimal srcBigDecimal = (BigDecimal) srcValue;\n+                if (srcValue != null && (decimalParser.getMaxValue().compareTo(srcBigDecimal) < 0 || decimalParser.getMinValue().compareTo(srcBigDecimal) > 0)) {\n+                    LOG.warn(String.format(\"decimal value is not valid for defination, column=%s, value=%s,precision=%s,scale=%s\",\n+                            etlColumn.columnName, srcValue.toString(), srcBigDecimal.precision(), srcBigDecimal.scale()));\n+                    abnormalRowAcc.add(1);\n+                    return false;\n+                }\n+                break;\n+            case \"CHAR\":\n+            case \"VARCHAR\":\n+                // TODO(wb) padding char type\n+                if (srcValue != null && srcValue.toString().length() > etlColumn.stringLength) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2"}, "originalPosition": 52}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fa0b36bc80afd1f6b0266ec20862844ec0147f9", "author": {"user": {"login": "wangbo", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/3fa0b36bc80afd1f6b0266ec20862844ec0147f9", "committedDate": "2020-09-08T06:03:29Z", "message": "1 add ut\n2 some fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NTkyNjIw", "url": "https://github.com/apache/incubator-doris/pull/4524#pullrequestreview-484592620", "createdAt": "2020-09-09T01:16:03Z", "commit": {"oid": "3fa0b36bc80afd1f6b0266ec20862844ec0147f9"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "155d3df799e8d339089d39f85f6299040e12f389", "author": {"user": {"login": "wangbo", "name": null}}, "url": "https://github.com/apache/incubator-doris/commit/155d3df799e8d339089d39f85f6299040e12f389", "committedDate": "2020-09-09T02:54:26Z", "message": "remove useless import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3MjEzNjMy", "url": "https://github.com/apache/incubator-doris/pull/4524#pullrequestreview-487213632", "createdAt": "2020-09-12T08:06:52Z", "commit": {"oid": "155d3df799e8d339089d39f85f6299040e12f389"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4933, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}