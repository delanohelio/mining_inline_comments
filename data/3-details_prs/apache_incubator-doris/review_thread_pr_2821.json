{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1MTQ5MTAy", "number": 2821, "reviewThreads": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo0MjoyMlrODasoXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoyNjoxOVrODimuWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIwNzk2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo0MjoyMlrOFhyMMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODozNTo1MVrOFlvZ_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTY1MQ==", "bodyText": "you can disable it in analysis phase of CreateMaterializedViewStmt.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370969651", "createdAt": "2020-01-26T02:42:22Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "diffHunk": "@@ -4791,8 +4791,10 @@ public void alterView(AlterViewStmt stmt) throws DdlException, UserException {\n \n     public void createMaterializedView(CreateMaterializedViewStmt stmt) throws AnalysisException, DdlException {\n         // TODO(ml): remove it\n-        throw new AnalysisException(\"The materialized view is coming soon\");\n-//        this.alter.processCreateMaterializedView(stmt);\n+        if (!ConnectContext.get().getSessionVariable().getTestMaterializedView()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODMzNA==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375118334", "createdAt": "2020-02-05T08:35:51Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "diffHunk": "@@ -4791,8 +4791,10 @@ public void alterView(AlterViewStmt stmt) throws DdlException, UserException {\n \n     public void createMaterializedView(CreateMaterializedViewStmt stmt) throws AnalysisException, DdlException {\n         // TODO(ml): remove it\n-        throw new AnalysisException(\"The materialized view is coming soon\");\n-//        this.alter.processCreateMaterializedView(stmt);\n+        if (!ConnectContext.get().getSessionVariable().getTestMaterializedView()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTY1MQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIwOTA4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo0NjozOVrOFhyMtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0MToyM1rOFlvjKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTc4MA==", "bodyText": "Why treat base index schema separately here?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370969780", "createdAt": "2020-01-26T02:46:39Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "diffHunk": "@@ -292,6 +292,10 @@ public void setIndexStorageType(Long indexId, TStorageType newStorageType) {\n     public void rebuildFullSchema() {\n         fullSchema.clear();\n         nameToColumn.clear();\n+        for (Column baseColumn : indexIdToSchema.get(baseIndexId)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMDY4Mw==", "bodyText": "The order of the table structure in this map is not necessarily. However those two attributes fullSchema and nameToColumn must contain the base schema of table.\nSo we need to add the base schema into those attributes firstly.\nThen I supplement those temporary columns caused by the schema change.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375120683", "createdAt": "2020-02-05T08:41:23Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "diffHunk": "@@ -292,6 +292,10 @@ public void setIndexStorageType(Long indexId, TStorageType newStorageType) {\n     public void rebuildFullSchema() {\n         fullSchema.clear();\n         nameToColumn.clear();\n+        for (Column baseColumn : indexIdToSchema.get(baseIndexId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTc4MA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMDU4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo1NDowOFrOFhyNgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMjozODo0OVrOFmwwDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTk4Ng==", "bodyText": "How about: enable_materialized_view ?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370969986", "createdAt": "2020-01-26T02:54:08Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "diffHunk": "@@ -90,6 +90,8 @@\n     public static final String LOAD_MEM_LIMIT = \"load_mem_limit\";\n     public static final String DEFAULT_ROWSET_TYPE = \"default_rowset_type\";\n     public static final String USE_V2_ROLLUP = \"use_v2_rollup\";\n+    public static final String TEST_MATERIALIZED_VIEW = \"test_materialized_view\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjkzNA==", "bodyText": "This properties has two functions.\nOne is enable the Create Materialized View Stmt.\nThe another effect is that if the index selected by the new selector is inconsistent with the old one, an error is reported during the test.\nSo which name is better?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375122934", "createdAt": "2020-02-05T08:46:31Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "diffHunk": "@@ -90,6 +90,8 @@\n     public static final String LOAD_MEM_LIMIT = \"load_mem_limit\";\n     public static final String DEFAULT_ROWSET_TYPE = \"default_rowset_type\";\n     public static final String USE_V2_ROLLUP = \"use_v2_rollup\";\n+    public static final String TEST_MATERIALIZED_VIEW = \"test_materialized_view\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTk4Ng=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE4ODk0MQ==", "bodyText": "You should add a config in Config.java named enable_materialized_view to enable or disable the create view stmt.\nAnd leave TEST_MATERIALIZED_VIEW here to control whether to check the selected index id.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r376188941", "createdAt": "2020-02-07T02:38:49Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "diffHunk": "@@ -90,6 +90,8 @@\n     public static final String LOAD_MEM_LIMIT = \"load_mem_limit\";\n     public static final String DEFAULT_ROWSET_TYPE = \"default_rowset_type\";\n     public static final String USE_V2_ROLLUP = \"use_v2_rollup\";\n+    public static final String TEST_MATERIALIZED_VIEW = \"test_materialized_view\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTk4Ng=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMDYxOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo1NDozMVrOFhyNhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NzoxM1rOFlvtLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTk5MA==", "bodyText": "How about enable_new_mv_selector ?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370969990", "createdAt": "2020-01-26T02:54:31Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "diffHunk": "@@ -90,6 +90,8 @@\n     public static final String LOAD_MEM_LIMIT = \"load_mem_limit\";\n     public static final String DEFAULT_ROWSET_TYPE = \"default_rowset_type\";\n     public static final String USE_V2_ROLLUP = \"use_v2_rollup\";\n+    public static final String TEST_MATERIALIZED_VIEW = \"test_materialized_view\";\n+    public static final String USE_OLD_MV_SELECTOR = \"use_old_mv_selector\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMzI0NA==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375123244", "createdAt": "2020-02-05T08:47:13Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/qe/SessionVariable.java", "diffHunk": "@@ -90,6 +90,8 @@\n     public static final String LOAD_MEM_LIMIT = \"load_mem_limit\";\n     public static final String DEFAULT_ROWSET_TYPE = \"default_rowset_type\";\n     public static final String USE_V2_ROLLUP = \"use_v2_rollup\";\n+    public static final String TEST_MATERIALIZED_VIEW = \"test_materialized_view\";\n+    public static final String USE_OLD_MV_SELECTOR = \"use_old_mv_selector\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk2OTk5MA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMTI0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo1NzoxNlrOFhyN1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwOToxNDoyMFrOFlweIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDA2OA==", "bodyText": "Add comment of this method.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970068", "createdAt": "2020-01-26T02:57:16Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,66 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    public void updateScanRangeInfo(long selectedIndexId, boolean isPreAggregation, String reasonOfDisable)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEzNTc3OA==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375135778", "createdAt": "2020-02-05T09:14:20Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,66 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    public void updateScanRangeInfo(long selectedIndexId, boolean isPreAggregation, String reasonOfDisable)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDA2OA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMTkwOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo1OTo1OFrOFhyOJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMjo1OTo1OFrOFhyOJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDE1MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                                                + \"test_materialized_view is true.\"\n          \n          \n            \n                                                                + \"test_materialized_view is true. \"", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970150", "createdAt": "2020-01-26T02:59:58Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,66 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    public void updateScanRangeInfo(long selectedIndexId, boolean isPreAggregation, String reasonOfDisable)\n+            throws UserException {\n+        if (selectedIndexId == this.selectedIndexId && isPreAggregation == this.isPreAggregation) {\n+            return;\n+        }\n+        StringBuilder stringBuilder = new StringBuilder(\"The new selected index id \")\n+                .append(selectedIndexId)\n+                .append(\", pre aggregation tag \").append(isPreAggregation)\n+                .append(\", reason \").append(reasonOfDisable == null ? \"null\" : reasonOfDisable)\n+                .append(\". The old selected index id \").append(this.selectedIndexId)\n+                .append(\" pre aggregation tag \").append(this.isPreAggregation)\n+                .append(\" reason \").append(this.reasonOfPreAggregation == null ? \"null\" : this.reasonOfPreAggregation);\n+        String scanRangeInfo = stringBuilder.toString();\n+        boolean updateScanRangeInfo;\n+        String situation;\n+        CHECK:\n+        {\n+            if (olapTable.getKeysType() == KeysType.DUP_KEYS) {\n+                updateScanRangeInfo = true;\n+                situation = \"The key type of table is duplicate.\";\n+                break CHECK;\n+            }\n+            if (ConnectContext.get() == null) {\n+                updateScanRangeInfo = true;\n+                situation = \"Connection context is null\";\n+                break CHECK;\n+            }\n+            SessionVariable sessionVariable = ConnectContext.get().getSessionVariable();\n+            if (sessionVariable.getTestMaterializedView()) {\n+                throw new AnalysisException(\"The old scan range info is different from the new one when \"\n+                                                    + \"test_materialized_view is true.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMjMzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzowMTozNFrOFhyOYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwOToyMDoxM1rOFlwpdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDIxMA==", "bodyText": "what is SPJ<->SPJG? Is that mean convert SPJ to SPJG, and vise versa?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970210", "createdAt": "2020-01-26T03:01:34Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEzODY3OA==", "bodyText": "Yes, you are right. I also add some comments.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375138678", "createdAt": "2020-02-05T09:20:13Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDIxMA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxMjgzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzowNDoyMFrOFhyOqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwOTozMjo1MlrOFlxC1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDI4MQ==", "bodyText": "Better add comments about map's key and values", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970281", "createdAt": "2020-01-26T03:04:20Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE0NTE3Mg==", "bodyText": "Added", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375145172", "createdAt": "2020-02-05T09:32:52Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDI4MQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxNjU4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzoxOTozMFrOFhyQaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxMjo1MVrOFt8IEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDcyOQ==", "bodyText": "Why it can be null?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970729", "createdAt": "2020-01-26T03:19:30Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {\n+                candidateIndexIdToSchema.put(index.getKey(), index.getValue());\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void init() {\n+        // Step1: compute the columns in compensating predicates\n+        Expr whereClause = selectStmt.getWhereClause();\n+        if (whereClause != null) {\n+            whereClause.getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+        for (TableRef tableRef : selectStmt.getTableRefs()) {\n+            if (tableRef.getOnClause() == null) {\n+                continue;\n+            }\n+            tableRef.getOnClause().getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+\n+        if (selectStmt.getAggInfo() == null) {\n+            isSPJQuery = true;\n+        } else {\n+            // Step2: compute the columns in group by expr\n+            if (selectStmt.getAggInfo().getGroupingExprs() != null) {\n+                List<Expr> groupingExprs = selectStmt.getAggInfo().getGroupingExprs();\n+                for (Expr expr : groupingExprs) {\n+                    expr.getTableNameToColumnNames(columnNamesInGrouping);\n+                }\n+            }\n+            // Step3: compute the aggregation function\n+            for (FunctionCallExpr aggExpr : selectStmt.getAggInfo().getAggregateExprs()) {\n+                // Only sum, min, max function could appear in materialized views.\n+                // The number of children in these functions is one.\n+                if (aggExpr.getChildren().size() != 1) {\n+                    reasonOfDisable = \"aggExpr has more than one child\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                Expr aggChild0 = aggExpr.getChild(0);\n+                if (aggChild0 instanceof SlotRef) {\n+                    SlotRef slotRef = (SlotRef) aggChild0;\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 389}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE0NzYyMA==", "bodyText": "Some SlotRef comes from the inline view or upper tuple. The table is null in those tuple descriptor.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375147620", "createdAt": "2020-02-05T09:37:48Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {\n+                candidateIndexIdToSchema.put(index.getKey(), index.getValue());\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void init() {\n+        // Step1: compute the columns in compensating predicates\n+        Expr whereClause = selectStmt.getWhereClause();\n+        if (whereClause != null) {\n+            whereClause.getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+        for (TableRef tableRef : selectStmt.getTableRefs()) {\n+            if (tableRef.getOnClause() == null) {\n+                continue;\n+            }\n+            tableRef.getOnClause().getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+\n+        if (selectStmt.getAggInfo() == null) {\n+            isSPJQuery = true;\n+        } else {\n+            // Step2: compute the columns in group by expr\n+            if (selectStmt.getAggInfo().getGroupingExprs() != null) {\n+                List<Expr> groupingExprs = selectStmt.getAggInfo().getGroupingExprs();\n+                for (Expr expr : groupingExprs) {\n+                    expr.getTableNameToColumnNames(columnNamesInGrouping);\n+                }\n+            }\n+            // Step3: compute the aggregation function\n+            for (FunctionCallExpr aggExpr : selectStmt.getAggInfo().getAggregateExprs()) {\n+                // Only sum, min, max function could appear in materialized views.\n+                // The number of children in these functions is one.\n+                if (aggExpr.getChildren().size() != 1) {\n+                    reasonOfDisable = \"aggExpr has more than one child\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                Expr aggChild0 = aggExpr.getChild(0);\n+                if (aggChild0 instanceof SlotRef) {\n+                    SlotRef slotRef = (SlotRef) aggChild0;\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDcyOQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 389}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE5Mjc0MA==", "bodyText": "Add it to the comment", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r376192740", "createdAt": "2020-02-07T02:56:59Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {\n+                candidateIndexIdToSchema.put(index.getKey(), index.getValue());\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void init() {\n+        // Step1: compute the columns in compensating predicates\n+        Expr whereClause = selectStmt.getWhereClause();\n+        if (whereClause != null) {\n+            whereClause.getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+        for (TableRef tableRef : selectStmt.getTableRefs()) {\n+            if (tableRef.getOnClause() == null) {\n+                continue;\n+            }\n+            tableRef.getOnClause().getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+\n+        if (selectStmt.getAggInfo() == null) {\n+            isSPJQuery = true;\n+        } else {\n+            // Step2: compute the columns in group by expr\n+            if (selectStmt.getAggInfo().getGroupingExprs() != null) {\n+                List<Expr> groupingExprs = selectStmt.getAggInfo().getGroupingExprs();\n+                for (Expr expr : groupingExprs) {\n+                    expr.getTableNameToColumnNames(columnNamesInGrouping);\n+                }\n+            }\n+            // Step3: compute the aggregation function\n+            for (FunctionCallExpr aggExpr : selectStmt.getAggInfo().getAggregateExprs()) {\n+                // Only sum, min, max function could appear in materialized views.\n+                // The number of children in these functions is one.\n+                if (aggExpr.getChildren().size() != 1) {\n+                    reasonOfDisable = \"aggExpr has more than one child\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                Expr aggChild0 = aggExpr.getChild(0);\n+                if (aggChild0 instanceof SlotRef) {\n+                    SlotRef slotRef = (SlotRef) aggChild0;\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDcyOQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 389}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxNTM0NQ==", "bodyText": "Add it to the comment", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383715345", "createdAt": "2020-02-25T08:12:51Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {\n+                candidateIndexIdToSchema.put(index.getKey(), index.getValue());\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void init() {\n+        // Step1: compute the columns in compensating predicates\n+        Expr whereClause = selectStmt.getWhereClause();\n+        if (whereClause != null) {\n+            whereClause.getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+        for (TableRef tableRef : selectStmt.getTableRefs()) {\n+            if (tableRef.getOnClause() == null) {\n+                continue;\n+            }\n+            tableRef.getOnClause().getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+\n+        if (selectStmt.getAggInfo() == null) {\n+            isSPJQuery = true;\n+        } else {\n+            // Step2: compute the columns in group by expr\n+            if (selectStmt.getAggInfo().getGroupingExprs() != null) {\n+                List<Expr> groupingExprs = selectStmt.getAggInfo().getGroupingExprs();\n+                for (Expr expr : groupingExprs) {\n+                    expr.getTableNameToColumnNames(columnNamesInGrouping);\n+                }\n+            }\n+            // Step3: compute the aggregation function\n+            for (FunctionCallExpr aggExpr : selectStmt.getAggInfo().getAggregateExprs()) {\n+                // Only sum, min, max function could appear in materialized views.\n+                // The number of children in these functions is one.\n+                if (aggExpr.getChildren().size() != 1) {\n+                    reasonOfDisable = \"aggExpr has more than one child\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                Expr aggChild0 = aggExpr.getChild(0);\n+                if (aggChild0 instanceof SlotRef) {\n+                    SlotRef slotRef = (SlotRef) aggChild0;\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDcyOQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 389}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIxNzc2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzoyMzoyOFrOFhyQ8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMDowNjo1OFrOFlyIvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDg2NQ==", "bodyText": "How about move the olapScanNode.updateScanRangeInfo() outside the MaterializedViewSelector?\nI think we should let the caller to decide how to use the selected mv.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370970865", "createdAt": "2020-01-26T03:23:28Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE2MzA2OQ==", "bodyText": "I will change it.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375163069", "createdAt": "2020-02-05T10:06:58Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MDg2NQ=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyMDQ5OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzozNTozNlrOFhySXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMjo1NToyMFrOFmw9mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTIyOA==", "bodyText": "Can aggregatedColumnsInQueryOutput be null or empty here? For example, there is no agg info in query.\nIf so, I think it can be checked and return directly to save time.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971228", "createdAt": "2020-01-26T03:35:36Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE2MzA3MQ==", "bodyText": "No, it can't.\nIf the aggregatedColumnInQueryOutput is null or empty, the query will be a SPJ.\nBut the candidate index such as SPJG should be filter in the following code.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375163071", "createdAt": "2020-02-05T10:06:58Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTIyOA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE5MjQwOA==", "bodyText": "So what is this in the following while loop?\n            // The query is SPJG. The candidate index is SPJG too.\n            if (aggregatedColumnsInQueryOutput == null) {\n                continue;\n            }\n\nif aggregatedColumnsInQueryOutput is null, the following while loop is useless.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r376192408", "createdAt": "2020-02-07T02:55:20Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTIyOA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 290}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyMTU0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzozOTowMVrOFhyS1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzozOTowMVrOFhyS1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTM1MQ==", "bodyText": "Override the hashCode() method as well.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971351", "createdAt": "2020-01-26T03:39:01Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {\n+                candidateIndexIdToSchema.put(index.getKey(), index.getValue());\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void init() {\n+        // Step1: compute the columns in compensating predicates\n+        Expr whereClause = selectStmt.getWhereClause();\n+        if (whereClause != null) {\n+            whereClause.getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+        for (TableRef tableRef : selectStmt.getTableRefs()) {\n+            if (tableRef.getOnClause() == null) {\n+                continue;\n+            }\n+            tableRef.getOnClause().getTableNameToColumnNames(columnNamesInPredicates);\n+        }\n+\n+        if (selectStmt.getAggInfo() == null) {\n+            isSPJQuery = true;\n+        } else {\n+            // Step2: compute the columns in group by expr\n+            if (selectStmt.getAggInfo().getGroupingExprs() != null) {\n+                List<Expr> groupingExprs = selectStmt.getAggInfo().getGroupingExprs();\n+                for (Expr expr : groupingExprs) {\n+                    expr.getTableNameToColumnNames(columnNamesInGrouping);\n+                }\n+            }\n+            // Step3: compute the aggregation function\n+            for (FunctionCallExpr aggExpr : selectStmt.getAggInfo().getAggregateExprs()) {\n+                // Only sum, min, max function could appear in materialized views.\n+                // The number of children in these functions is one.\n+                if (aggExpr.getChildren().size() != 1) {\n+                    reasonOfDisable = \"aggExpr has more than one child\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                Expr aggChild0 = aggExpr.getChild(0);\n+                if (aggChild0 instanceof SlotRef) {\n+                    SlotRef slotRef = (SlotRef) aggChild0;\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {\n+                        continue;\n+                    }\n+                    addAggregatedColumn(slotRef.getColumnName(), aggExpr.getFnName().getFunction(),\n+                                        table.getName());\n+                } else if ((aggChild0 instanceof CastExpr) && (aggChild0.getChild(0) instanceof SlotRef)) {\n+                    SlotRef slotRef = (SlotRef) aggChild0.getChild(0);\n+                    Preconditions.checkState(slotRef.getColumnName() != null);\n+                    Table table = slotRef.getDesc().getParent().getTable();\n+                    if (table == null) {\n+                        continue;\n+                    }\n+                    addAggregatedColumn(slotRef.getColumnName(), aggExpr.getFnName().getFunction(),\n+                                        table.getName());\n+                } else {\n+                    reasonOfDisable = \"aggExpr.getChild(0)[\" + aggExpr.getChild(0).debugString()\n+                            + \"] is not SlotRef or CastExpr|CaseExpr\";\n+                    disableSPJGView = true;\n+                    break;\n+                }\n+                // TODO(ml): select rollup by case expr\n+            }\n+        }\n+\n+        // Step4: compute the output column\n+        for (Expr resultExpr : selectStmt.getResultExprs()) {\n+            resultExpr.getTableNameToColumnNames(columnNamesInQueryOutput);\n+        }\n+    }\n+\n+    private void addAggregatedColumn(String columnName, String functionName, String tableName) {\n+        AggregatedColumn newAggregatedColumn = new AggregatedColumn(columnName, functionName);\n+        Set<AggregatedColumn> aggregatedColumns = aggregateColumnsInQuery.get(tableName);\n+        if (aggregatedColumns == null) {\n+            aggregatedColumns = Sets.newHashSet();\n+            aggregateColumnsInQuery.put(tableName, aggregatedColumns);\n+        }\n+        aggregatedColumns.add(newAggregatedColumn);\n+    }\n+\n+    class AggregatedColumn {\n+        private String columnName;\n+        private String aggFunctionName;\n+\n+        public AggregatedColumn(String columnName, String aggFunctionName) {\n+            this.columnName = columnName;\n+            this.aggFunctionName = aggFunctionName;\n+        }\n+\n+        @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 438}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyMjAxOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo0MToyM1rOFhyTEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo0MToyM1rOFhyTEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTQwOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                             int sizeOfBaseIndex) {\n          \n          \n            \n                                             int sizeOfBaseIndexSchema) {", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971408", "createdAt": "2020-01-26T03:41:23Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 340}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyMjc3OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo0NDowNlrOFhyTag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMDo0NDo0OFrOFlzT_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTQ5OA==", "bodyText": "What does this judgement mean? index.getValue().size() == sizeOfBaseIndex", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971498", "createdAt": "2020-01-26T03:44:06Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 344}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE4MjMzMg==", "bodyText": "If the key of table is aggregated and the schema size of index is same as the schema size of base index, the columns in candidate indexes will be complete. It means that all of columns belongs to base index appear in the candidate index.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375182332", "createdAt": "2020-02-05T10:44:48Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;\n+        Long v2RollupIndex = olapTable.getIndexIdByName(v2RollupIndexName);\n+        long baseIndexId = olapTable.getBaseIndexId();\n+        ConnectContext connectContext = ConnectContext.get();\n+        boolean useV2Rollup = false;\n+        if (connectContext != null) {\n+            useV2Rollup = connectContext.getSessionVariable().getUseV2Rollup();\n+        }\n+        if (baseIndexId == selectedIndexId && v2RollupIndex != null && useV2Rollup) {\n+            // if the selectedIndexId is baseIndexId\n+            // check whether there is a V2 rollup index and useV2Rollup flag is true,\n+            // if both true, use v2 rollup index\n+            selectedIndexId = v2RollupIndex;\n+        }\n+        if (!useV2Rollup && v2RollupIndex != null && v2RollupIndex == selectedIndexId) {\n+            // if the selectedIndexId is v2RollupIndex\n+            // but useV2Rollup is false, use baseIndexId as selectedIndexId\n+            // just make sure to use baseIndex instead of v2RollupIndex if the useV2Rollup is false\n+            selectedIndexId = baseIndexId;\n+        }\n+        return selectedIndexId;\n+    }\n+\n+    private void checkCompensatingPredicates(Set<String> columnsInPredicates,\n+                                             Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // When the query statement does not contain any columns in predicates, all candidate index can pass this check\n+        if (columnsInPredicates == null) {\n+            return;\n+        }\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            entry.getValue().stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInPredicates)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of compensating predicates:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    /**\n+     * View      Query        result\n+     * SPJ       SPJG OR SPJ  pass\n+     * SPJG      SPJ          fail\n+     * SPJG      SPJG         pass\n+     * 1. grouping columns in query is subset of grouping columns in view\n+     * 2. the empty grouping columns in query is subset of all of views\n+     *\n+     * @param columnsInGrouping\n+     * @param candidateIndexIdToSchema\n+     */\n+\n+    private void checkGrouping(Set<String> columnsInGrouping, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexNonAggregatedColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> !column.isAggregated())\n+                    .forEach(column -> indexNonAggregatedColumnNames.add(column.getName()));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexNonAggregatedColumnNames.size() == candidateIndexSchema.size()) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            // The grouping columns in query is empty. For example: select sum(A) from T\n+            if (columnsInGrouping == null) {\n+                continue;\n+            }\n+            // The grouping columns in query must be subset of the grouping columns in view\n+            if (!indexNonAggregatedColumnNames.containsAll(columnsInGrouping)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of grouping:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkAggregationFunction(Set<AggregatedColumn> aggregatedColumnsInQueryOutput,\n+                                          Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            List<AggregatedColumn> indexAggregatedColumns = Lists.newArrayList();\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().filter(column -> column.isAggregated())\n+                    .forEach(column -> indexAggregatedColumns.add(\n+                            new AggregatedColumn(column.getName(), column.getAggregationType().name())));\n+            // When the candidate index is SPJ type, it passes the verification directly\n+            if (indexAggregatedColumns.size() == 0) {\n+                continue;\n+            }\n+            // When the query is SPJ type but the candidate index is SPJG type, it will not pass directly.\n+            if (isSPJQuery || disableSPJGView) {\n+                iterator.remove();\n+                continue;\n+            }\n+            // The query is SPJG. The candidate index is SPJG too.\n+            if (aggregatedColumnsInQueryOutput == null) {\n+                continue;\n+            }\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexAggregatedColumns.containsAll(aggregatedColumnsInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of aggregation function:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void checkOutputColumns(Set<String> columnNamesInQueryOutput,\n+                                    Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        Iterator<Map.Entry<Long, List<Column>>> iterator = candidateIndexIdToSchema.entrySet().iterator();\n+        while (iterator.hasNext()) {\n+            Map.Entry<Long, List<Column>> entry = iterator.next();\n+            Set<String> indexColumnNames = new TreeSet<>(String.CASE_INSENSITIVE_ORDER);\n+            List<Column> candidateIndexSchema = entry.getValue();\n+            candidateIndexSchema.stream().forEach(column -> indexColumnNames.add(column.getName()));\n+            // The aggregated columns in query output must be subset of the aggregated columns in view\n+            if (!indexColumnNames.containsAll(columnNamesInQueryOutput)) {\n+                iterator.remove();\n+            }\n+        }\n+        LOG.debug(\"Those mv pass the test of output columns:\"\n+                          + Joiner.on(\",\").join(candidateIndexIdToSchema.keySet()));\n+    }\n+\n+    private void compensateIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                 Map<Long, List<Column>> allVisibleIndexes,\n+                                 int sizeOfBaseIndex) {\n+        isPreAggregation = false;\n+        reasonOfDisable = \"The aggregate operator does not match\";\n+        for (Map.Entry<Long, List<Column>> index : allVisibleIndexes.entrySet()) {\n+            if (index.getValue().size() == sizeOfBaseIndex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTQ5OA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 344}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyMjg0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo0NDo0MVrOFhyTcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMjo1MDoxNlrOFmw5aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTUwNg==", "bodyText": "Can you explain why table.getKeysType() == KeysType.AGG_KEYS is judged?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971506", "createdAt": "2020-01-26T03:44:41Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE4MjMzNA==", "bodyText": "Because we currently support query on aggregate tables directly.\nSuch as\nAggregate table A (c1, c2, c3) . c1 and c2 is key while c3 is value. The aggregate function of c3 is sum.\nThe query is select c1, c2, c3 from A. The query equals select c1, c2, sum(c3) from A group by c1, c2.\nHowever, selector filters out all indexes including the base index of table.\nThe reason is that base index is select c1 ,c2 ,sum(c3) from A. It could not be selected.\nFor selector, only origin data like A' (c1,c2,c3) while c3 is key also, could match those condition.\nSo here, we need special treatment for aggregate tables.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375182334", "createdAt": "2020-02-05T10:44:48Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTUwNg=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE5MTMzNw==", "bodyText": "And this to the comment~", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r376191337", "createdAt": "2020-02-07T02:50:16Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTUwNg=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyNTE0OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo1NDoxMVrOFhyUfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo1NDoxMVrOFhyUfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTc3NA==", "bodyText": "getChildren.size() is better for code reading.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971774", "createdAt": "2020-01-26T03:54:11Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -497,4 +571,107 @@ public static OlapScanNode createOlapScanNodeByLocation(\n \n         return olapScanNode;\n     }\n+\n+    public void collectColumns(Analyzer analyzer, Set<String> equivalenceColumns, Set<String> unequivalenceColumns) {\n+        // 1. Get columns which has predicate on it.\n+        for (Expr expr : conjuncts) {\n+            if (!isPredicateUsedForPrefixIndex(expr, false)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                if (expr.isBound(slot.getId())) {\n+                    if (!isEquivalenceExpr(expr)) {\n+                        unequivalenceColumns.add(slot.getColumn().getName());\n+                    } else {\n+                        equivalenceColumns.add(slot.getColumn().getName());\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+\n+        // 2. Equal join predicates when pushing inner child.\n+        List<Expr> eqJoinPredicate = analyzer.getEqJoinConjuncts(desc.getId());\n+        for (Expr expr : eqJoinPredicate) {\n+            if (!isPredicateUsedForPrefixIndex(expr, true)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                for (int i = 0; i < 2; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyNTg2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo1NzozNVrOFhyU1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwMzo1NzozNVrOFhyU1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTg2MQ==", "bodyText": "Can indexesMatchingBestPrefixIndex be empty here?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971861", "createdAt": "2020-01-26T03:57:35Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5MzIyNjUxOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwNDowMDo0MVrOFhyVJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwNDowMDo0MVrOFhyVJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk3MTk0Mw==", "bodyText": "\"_v2\" should be defined as a CONST variable somewhere.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r370971943", "createdAt": "2020-01-26T04:00:41Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates\n+        Map<Long, List<Column>> candidateIndexIdToSchema = scanNode.getOlapTable().getVisibleIndexes();\n+        OlapTable table = scanNode.getOlapTable();\n+        Preconditions.checkState(table != null);\n+        String tableName = table.getName();\n+        // Step2: check all columns in compensating predicates are available in the view output\n+        checkCompensatingPredicates(columnNamesInPredicates.get(tableName), candidateIndexIdToSchema);\n+        // Step3: group by list in query is the subset of group by list in view or view contains no aggregation\n+        checkGrouping(columnNamesInGrouping.get(tableName), candidateIndexIdToSchema);\n+        // Step4: aggregation functions are available in the view output\n+        checkAggregationFunction(aggregateColumnsInQuery.get(tableName), candidateIndexIdToSchema);\n+        // Step5: columns required to compute output expr are available in the view output\n+        checkOutputColumns(columnNamesInQueryOutput.get(tableName), candidateIndexIdToSchema);\n+        // Step6: if table type is aggregate and the candidateIndexIdToSchema is empty,\n+        if (table.getKeysType() == KeysType.AGG_KEYS && candidateIndexIdToSchema.size() == 0) {\n+            // the base index will be added in the candidateIndexIdToSchema.\n+            compensateIndex(candidateIndexIdToSchema, scanNode.getOlapTable().getVisibleIndexes(),\n+                            table.getSchemaByIndexId(table.getBaseIndexId()).size());\n+        }\n+        return candidateIndexIdToSchema;\n+    }\n+\n+    private long priorities(OlapScanNode scanNode, Map<Long, List<Column>> candidateIndexIdToSchema) {\n+        // Step1: the candidate indexes that satisfies the most prefix index\n+        final Set<String> equivalenceColumns = Sets.newHashSet();\n+        final Set<String> unequivalenceColumns = Sets.newHashSet();\n+        scanNode.collectColumns(analyzer, equivalenceColumns, unequivalenceColumns);\n+        Set<Long> indexesMatchingBestPrefixIndex =\n+                matchBestPrefixIndex(candidateIndexIdToSchema, equivalenceColumns, unequivalenceColumns);\n+        if (indexesMatchingBestPrefixIndex.isEmpty()) {\n+            indexesMatchingBestPrefixIndex = candidateIndexIdToSchema.keySet();\n+        }\n+\n+        // Step2: the best index that satisfies the least number of rows\n+        return selectBestRowCountIndex(indexesMatchingBestPrefixIndex, scanNode.getOlapTable(), scanNode\n+                .getSelectedPartitionIds());\n+    }\n+\n+    private Set<Long> matchBestPrefixIndex(Map<Long, List<Column>> candidateIndexIdToSchema,\n+                                           Set<String> equivalenceColumns,\n+                                           Set<String> unequivalenceColumns) {\n+        if (equivalenceColumns.size() == 0 && unequivalenceColumns.size() == 0) {\n+            return candidateIndexIdToSchema.keySet();\n+        }\n+        Set<Long> indexesMatchingBestPrefixIndex = Sets.newHashSet();\n+        int maxPrefixMatchCount = 0;\n+        for (Map.Entry<Long, List<Column>> entry : candidateIndexIdToSchema.entrySet()) {\n+            int prefixMatchCount = 0;\n+            long indexId = entry.getKey();\n+            List<Column> indexSchema = entry.getValue();\n+            for (Column col : indexSchema) {\n+                if (equivalenceColumns.contains(col.getName())) {\n+                    prefixMatchCount++;\n+                } else if (unequivalenceColumns.contains(col.getName())) {\n+                    // Unequivalence predicate's columns can match only first column in rollup.\n+                    prefixMatchCount++;\n+                    break;\n+                } else {\n+                    break;\n+                }\n+            }\n+\n+            if (prefixMatchCount == maxPrefixMatchCount) {\n+                LOG.debug(\"find a equal prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            } else if (prefixMatchCount > maxPrefixMatchCount) {\n+                LOG.debug(\"find a better prefix match index {}. match count: {}\", indexId, prefixMatchCount);\n+                maxPrefixMatchCount = prefixMatchCount;\n+                indexesMatchingBestPrefixIndex.clear();\n+                indexesMatchingBestPrefixIndex.add(indexId);\n+            }\n+        }\n+        LOG.debug(\"Those mv match the best prefix index:\" + Joiner.on(\",\").join(indexesMatchingBestPrefixIndex));\n+        return indexesMatchingBestPrefixIndex;\n+    }\n+\n+    private long selectBestRowCountIndex(Set<Long> indexesMatchingBestPrefixIndex, OlapTable olapTable,\n+                                         Collection<Long> partitionIds) {\n+        long minRowCount = Long.MAX_VALUE;\n+        long selectedIndexId = 0;\n+        for (Long indexId : indexesMatchingBestPrefixIndex) {\n+            long rowCount = 0;\n+            for (Long partitionId : partitionIds) {\n+                rowCount += olapTable.getPartition(partitionId).getIndex(indexId).getRowCount();\n+            }\n+            LOG.debug(\"rowCount={} for table={}\", rowCount, indexId);\n+            if (rowCount < minRowCount) {\n+                minRowCount = rowCount;\n+                selectedIndexId = indexId;\n+            } else if (rowCount == minRowCount) {\n+                // check column number, select one minimum column number\n+                int selectedColumnSize = olapTable.getIndexIdToSchema().get(selectedIndexId).size();\n+                int currColumnSize = olapTable.getIndexIdToSchema().get(indexId).size();\n+                if (currColumnSize < selectedColumnSize) {\n+                    selectedIndexId = indexId;\n+                }\n+            }\n+        }\n+        String tableName = olapTable.getName();\n+        String v2RollupIndexName = \"__v2_\" + tableName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 203}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjQ2ODI4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzowMDoxN1rOFkn0tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzowMjoyMlrOFl26cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk0NTUyNg==", "bodyText": "What is the meaning of compensating predicates here?  Is it same with compensating predicates in Optimizing Queries Using Materialized Views:A Practical, Scalable Solution paper?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r373945526", "createdAt": "2020-02-03T07:00:17Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE5NDE5Mg==", "bodyText": "Yes, it same as the compensating predicates in Optimizing Queries Using Materialized Views:A Practical, Scalable Solution paper.\nIn the present, doris could not support the materialized view which has predicates.\nSo all of predicates in query is compensating predicates directly.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375194192", "createdAt": "2020-02-05T11:10:25Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk0NTUyNg=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI0MTMzMA==", "bodyText": "OK. I see.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375241330", "createdAt": "2020-02-05T13:02:22Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,\n+     * the best MV is selected.\n+     *\n+     * @param scanNode\n+     * @return\n+     */\n+    public void selectBestMV(ScanNode scanNode) throws UserException {\n+        long start = System.currentTimeMillis();\n+        Preconditions.checkState(scanNode instanceof OlapScanNode);\n+        OlapScanNode olapScanNode = (OlapScanNode) scanNode;\n+        Map<Long, List<Column>> candidateIndexIdToSchema = predicates(olapScanNode);\n+        long bestIndexId = priorities(olapScanNode, candidateIndexIdToSchema);\n+        LOG.info(\"The best materialized view is {} for scan node {} in query {}, cost {}\",\n+                 bestIndexId, scanNode.getId(), selectStmt.toSql(), (System.currentTimeMillis() - start));\n+        olapScanNode.updateScanRangeInfo(bestIndexId, isPreAggregation, reasonOfDisable);\n+    }\n+\n+    private Map<Long, List<Column>> predicates(OlapScanNode scanNode) {\n+        // Step1: all of predicates is compensating predicates", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk0NTUyNg=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjQ5ODEyOnYy", "diffSide": "RIGHT", "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewSelectorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzoyMDowNlrOFkoGnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzoyMDowNlrOFkoGnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk1MDEwOQ==", "bodyText": "I think after #2826 merge.\nWe could porting most of test case from Calcite MaterializedView tests. Current test case is not enough", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r373950109", "createdAt": "2020-02-03T07:20:06Z", "author": {"login": "kangkaisen"}, "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewSelectorTest.java", "diffHunk": "@@ -0,0 +1,409 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.AggregateInfo;\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotDescriptor;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableName;\n+import org.apache.doris.analysis.TupleDescriptor;\n+import org.apache.doris.catalog.AggregateType;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.catalog.Type;\n+import org.apache.doris.common.jmockit.Deencapsulation;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import mockit.Expectations;\n+import mockit.Injectable;\n+import mockit.Mocked;\n+\n+public class MaterializedViewSelectorTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjUxMDg4OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzoyNjoyOFrOFkoNoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzowMzo1M1rOFl29Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk1MTkwNA==", "bodyText": "I think method name predicates and priorities couldn't describe what we do, and we should change it.\nSuch as computeCandidateMVs, computeBestMVByCost.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r373951904", "createdAt": "2020-02-03T07:26:28Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIwOTMwNg==", "bodyText": "Actually, the predicates and priorities are carbonized from the kubernetes node selector.\nThese two names are more abstract.\nMaybe I can add more comments to introduce it.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375209306", "createdAt": "2020-02-05T11:46:13Z", "author": {"login": "EmmyMiao87"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk1MTkwNA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI0MTk4Nw==", "bodyText": "OK", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375241987", "createdAt": "2020-02-05T13:03:53Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/MaterializedViewSelector.java", "diffHunk": "@@ -0,0 +1,453 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.analysis.Analyzer;\n+import org.apache.doris.analysis.CastExpr;\n+import org.apache.doris.analysis.Expr;\n+import org.apache.doris.analysis.FunctionCallExpr;\n+import org.apache.doris.analysis.SelectStmt;\n+import org.apache.doris.analysis.SlotRef;\n+import org.apache.doris.analysis.TableRef;\n+import org.apache.doris.catalog.Column;\n+import org.apache.doris.catalog.KeysType;\n+import org.apache.doris.catalog.OlapTable;\n+import org.apache.doris.catalog.Table;\n+import org.apache.doris.common.UserException;\n+import org.apache.doris.qe.ConnectContext;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+/**\n+ * The new materialized view selector supports SPJ<->SPJG.\n+ * At the same time, it is compatible with all the features of the old version.\n+ * The SPJ query is \"Select Projection and Join\" such as:\n+ *     select t1.c1 from t1, t2 where t1.c2=t2.c2 and t1.c3=1;\n+ * The SPJG query is \"Select Projection Join and Group-by\" such as:\n+ *     select t1.c1, sum(t2.c1) from t1, t2 where t1.c2=t2.c2 and t1.c3=1 group by t1.c1;\n+ */\n+public class MaterializedViewSelector {\n+    private static final Logger LOG = LogManager.getLogger(MaterializedViewSelector.class);\n+\n+    private final SelectStmt selectStmt;\n+    private final Analyzer analyzer;\n+\n+    private Map<String, Set<String>> columnNamesInPredicates = Maps.newHashMap();\n+    private boolean isSPJQuery;\n+    private Map<String, Set<String>> columnNamesInGrouping = Maps.newHashMap();\n+    private Map<String, Set<AggregatedColumn>> aggregateColumnsInQuery = Maps.newHashMap();\n+    private Map<String, Set<String>> columnNamesInQueryOutput = Maps.newHashMap();\n+\n+    private boolean disableSPJGView;\n+    private String reasonOfDisable;\n+    private boolean isPreAggregation = true;\n+\n+    public MaterializedViewSelector(SelectStmt selectStmt, Analyzer analyzer) {\n+        this.selectStmt = selectStmt;\n+        this.analyzer = analyzer;\n+        init();\n+    }\n+\n+    /**\n+     * There are two stages to choosing the best MV.\n+     * Phase 1: Predicates\n+     * According to aggregation and column information in the select stmt,\n+     * the candidate MVs that meets the query conditions are selected.\n+     * Phase 2: Priorities\n+     * According to prefix index and row count in candidate MVs,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk1MTkwNA=="}, "originalCommit": {"oid": "82fc8e19fd725c3c927921dbb73a3fb76a098842"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDgxNjgwOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzoyNzozOVrOFl3oOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzoyNzozOVrOFl3oOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI1MzA0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public Map<Long, List<Column>> getVisibleIndexes() {\n          \n          \n            \n                public Map<Long, List<Column>> getVisibleIndexesSchema() {", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375253048", "createdAt": "2020-02-05T13:27:39Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/catalog/OlapTable.java", "diffHunk": "@@ -334,6 +339,16 @@ public String getIndexNameById(long indexId) {\n         return null;\n     }\n \n+    public Map<Long, List<Column>> getVisibleIndexes() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDgxNzQ3OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/analysis/Analyzer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzoyNzo1M1rOFl3omw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzoyNzo1M1rOFl3omw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI1MzE0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public List<Expr> getAllConjunct(TupleId id) {\n          \n          \n            \n                public List<Expr> getAllConjuncts(TupleId id) {", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375253147", "createdAt": "2020-02-05T13:27:53Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/analysis/Analyzer.java", "diffHunk": "@@ -1063,23 +1063,16 @@ public Catalog getCatalog() {\n         return uniqueTableAliasSet_;\n     }\n \n-    public List<Expr> getAllConjunt(TupleId id) {\n+    public List<Expr> getAllConjunct(TupleId id) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDg1MDk1OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzozODoxM1rOFl39QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzozODoxM1rOFl39QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI1ODQzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * If it is set to false, the result of the new version selector will be selected.\n          \n          \n            \n                 * If it is set to true, the result of the new version selector will be selected.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375258433", "createdAt": "2020-02-05T13:38:13Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,90 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    /**\n+     * This method is mainly used to update scan range info in OlapScanNode by the new materialized selector.\n+     * Situation1:\n+     * If the new scan range is same as the old scan range which determined by the old materialized selector,\n+     * the scan range will not be changed.\n+     * <p>\n+     * Situation2: Scan range is difference. The type of table is duplicated.\n+     * The new scan range is used directly.\n+     * The reason is that the old selector does not support SPJ<->SPJG, so the result of old one must be incorrect.\n+     * <p>\n+     * Situation3: Scan range is difference. The type of table is aggregated.\n+     * The new scan range is different from the old one.\n+     * If the test_materialized_view is set to true, an error will be reported.\n+     * The query will be cancelled.\n+     * <p>\n+     * Situation4: Scan range is difference. The type of table is aggregated. `test_materialized_view` is set to false.\n+     * If the enable_new_mv_selector is set to false, the result of the old version selector will be selected.\n+     * If it is set to false, the result of the new version selector will be selected.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMTAzOTE3OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxNDozMDoyMlrOFl5xKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxNTo0OVrOFt8NEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI4ODEwNg==", "bodyText": "I think we would better move following function to Expr related class, and change the method name more general for xxxForPrefixIndex methods. Because I think these function is useful when we implement new Cascades query optimizer.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r375288106", "createdAt": "2020-02-05T14:30:22Z", "author": {"login": "kangkaisen"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -497,4 +596,108 @@ public static OlapScanNode createOlapScanNodeByLocation(\n \n         return olapScanNode;\n     }\n+\n+    public void collectColumns(Analyzer analyzer, Set<String> equivalenceColumns, Set<String> unequivalenceColumns) {\n+        // 1. Get columns which has predicate on it.\n+        for (Expr expr : conjuncts) {\n+            if (!isPredicateUsedForPrefixIndex(expr, false)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                if (expr.isBound(slot.getId())) {\n+                    if (!isEquivalenceExpr(expr)) {\n+                        unequivalenceColumns.add(slot.getColumn().getName());\n+                    } else {\n+                        equivalenceColumns.add(slot.getColumn().getName());\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+\n+        // 2. Equal join predicates when pushing inner child.\n+        List<Expr> eqJoinPredicate = analyzer.getEqJoinConjuncts(desc.getId());\n+        for (Expr expr : eqJoinPredicate) {\n+            if (!isPredicateUsedForPrefixIndex(expr, true)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                Preconditions.checkState(expr.getChildren().size() == 2);\n+                for (Expr child : expr.getChildren()) {\n+                    if (child.isBound(slot.getId())) {\n+                        equivalenceColumns.add(slot.getColumn().getName());\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 274}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxNjYyNg==", "bodyText": "Why not move them?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383716626", "createdAt": "2020-02-25T08:15:49Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -497,4 +596,108 @@ public static OlapScanNode createOlapScanNodeByLocation(\n \n         return olapScanNode;\n     }\n+\n+    public void collectColumns(Analyzer analyzer, Set<String> equivalenceColumns, Set<String> unequivalenceColumns) {\n+        // 1. Get columns which has predicate on it.\n+        for (Expr expr : conjuncts) {\n+            if (!isPredicateUsedForPrefixIndex(expr, false)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                if (expr.isBound(slot.getId())) {\n+                    if (!isEquivalenceExpr(expr)) {\n+                        unequivalenceColumns.add(slot.getColumn().getName());\n+                    } else {\n+                        equivalenceColumns.add(slot.getColumn().getName());\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+\n+        // 2. Equal join predicates when pushing inner child.\n+        List<Expr> eqJoinPredicate = analyzer.getEqJoinConjuncts(desc.getId());\n+        for (Expr expr : eqJoinPredicate) {\n+            if (!isPredicateUsedForPrefixIndex(expr, true)) {\n+                continue;\n+            }\n+            for (SlotDescriptor slot : desc.getMaterializedSlots()) {\n+                Preconditions.checkState(expr.getChildren().size() == 2);\n+                for (Expr child : expr.getChildren()) {\n+                    if (child.isBound(slot.getId())) {\n+                        equivalenceColumns.add(slot.getColumn().getName());\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI4ODEwNg=="}, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 274}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNjc4MjIyOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMzowMTowNlrOFmxCJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMzowMTowNlrOFmxCJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE5MzU3Mg==", "bodyText": "In situation4, i think if enable_new_mv_selector is set to false, this updateScanRangeInfo() method won' t be called at all. And even the MaterializedViewSelector won't be called at all.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r376193572", "createdAt": "2020-02-07T03:01:06Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,90 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    /**\n+     * This method is mainly used to update scan range info in OlapScanNode by the new materialized selector.\n+     * Situation1:\n+     * If the new scan range is same as the old scan range which determined by the old materialized selector,\n+     * the scan range will not be changed.\n+     * <p>\n+     * Situation2: Scan range is difference. The type of table is duplicated.\n+     * The new scan range is used directly.\n+     * The reason is that the old selector does not support SPJ<->SPJG, so the result of old one must be incorrect.\n+     * <p>\n+     * Situation3: Scan range is difference. The type of table is aggregated.\n+     * The new scan range is different from the old one.\n+     * If the test_materialized_view is set to true, an error will be reported.\n+     * The query will be cancelled.\n+     * <p>\n+     * Situation4: Scan range is difference. The type of table is aggregated. `test_materialized_view` is set to false.\n+     * If the enable_new_mv_selector is set to false, the result of the old version selector will be selected.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be869caaf63e62b2eb48ca8c21c5ffa2ca053055"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjA4NjU2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxMjoxOVrOFt8HPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxMjoxOVrOFt8HPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxNTEzMg==", "bodyText": "LOG.info(\"Using the new scan range info instead of the old one. {}, {}\", situation, scanRangeInfo);", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383715132", "createdAt": "2020-02-25T08:12:19Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,83 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    /**\n+     * This method is mainly used to update scan range info in OlapScanNode by the new materialized selector.\n+     * Situation1:\n+     * If the new scan range is same as the old scan range which determined by the old materialized selector,\n+     * the scan range will not be changed.\n+     * <p>\n+     * Situation2: Scan range is difference. The type of table is duplicated.\n+     * The new scan range is used directly.\n+     * The reason is that the old selector does not support SPJ<->SPJG, so the result of old one must be incorrect.\n+     * <p>\n+     * Situation3: Scan range is difference. The type of table is aggregated.\n+     * The new scan range is different from the old one.\n+     * If the test_materialized_view is set to true, an error will be reported.\n+     * The query will be cancelled.\n+     * <p>\n+     * Situation4: Scan range is difference. The type of table is aggregated. `test_materialized_view` is set to false.\n+     * The result of the old version selector will be selected. Print the warning log\n+     *\n+     * @param selectedIndexId\n+     * @param isPreAggregation\n+     * @param reasonOfDisable\n+     * @throws UserException\n+     */\n+    public void updateScanRangeInfoByNewMVSelector(long selectedIndexId, boolean isPreAggregation, String\n+            reasonOfDisable)\n+            throws UserException {\n+        if (selectedIndexId == this.selectedIndexId && isPreAggregation == this.isPreAggregation) {\n+            return;\n+        }\n+        StringBuilder stringBuilder = new StringBuilder(\"The new selected index id \")\n+                .append(selectedIndexId)\n+                .append(\", pre aggregation tag \").append(isPreAggregation)\n+                .append(\", reason \").append(reasonOfDisable == null ? \"null\" : reasonOfDisable)\n+                .append(\". The old selected index id \").append(this.selectedIndexId)\n+                .append(\" pre aggregation tag \").append(this.isPreAggregation)\n+                .append(\" reason \").append(this.reasonOfPreAggregation == null ? \"null\" : this.reasonOfPreAggregation);\n+        String scanRangeInfo = stringBuilder.toString();\n+        String situation;\n+        boolean update;\n+        CHECK:\n+        {\n+            if (olapTable.getKeysType() == KeysType.DUP_KEYS) {\n+                situation = \"The key type of table is duplicate.\";\n+                update = true;\n+                break CHECK;\n+            }\n+            if (ConnectContext.get() == null) {\n+                situation = \"Connection context is null\";\n+                update = true;\n+                break CHECK;\n+            }\n+            SessionVariable sessionVariable = ConnectContext.get().getSessionVariable();\n+            if (sessionVariable.getTestMaterializedView()) {\n+                throw new AnalysisException(\"The old scan range info is different from the new one when \"\n+                                                    + \"test_materialized_view is true. \"\n+                                                    + scanRangeInfo);\n+            }\n+            situation = \"The key type of table is aggregated.\";\n+            update = false;\n+            break CHECK;\n+        }\n+\n+        if (update) {\n+            this.selectedIndexId = selectedIndexId;\n+            this.isPreAggregation = isPreAggregation;\n+            this.reasonOfPreAggregation = reasonOfDisable;\n+            computeTabletInfo();\n+            LOG.info(\"Using the new scan range info instead of the old one. \" + situation + scanRangeInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjA4NzMzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxMjozN1rOFt8Htg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxMjozN1rOFt8Htg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxNTI1NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        LOG.warn(\"Using the old scan range info instead of the new one. \" + situation + scanRangeInfo);\n          \n          \n            \n                        LOG.warn(\"Using the old scan range info instead of the new one. {}, {}\", situation, scanRangeInfo);", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383715254", "createdAt": "2020-02-25T08:12:37Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/OlapScanNode.java", "diffHunk": "@@ -130,6 +138,83 @@ public void setForceOpenPreAgg(boolean forceOpenPreAgg) {\n         this.forceOpenPreAgg = forceOpenPreAgg;\n     }\n \n+    public Collection<Long> getSelectedPartitionIds() {\n+        return selectedPartitionIds;\n+    }\n+\n+    /**\n+     * This method is mainly used to update scan range info in OlapScanNode by the new materialized selector.\n+     * Situation1:\n+     * If the new scan range is same as the old scan range which determined by the old materialized selector,\n+     * the scan range will not be changed.\n+     * <p>\n+     * Situation2: Scan range is difference. The type of table is duplicated.\n+     * The new scan range is used directly.\n+     * The reason is that the old selector does not support SPJ<->SPJG, so the result of old one must be incorrect.\n+     * <p>\n+     * Situation3: Scan range is difference. The type of table is aggregated.\n+     * The new scan range is different from the old one.\n+     * If the test_materialized_view is set to true, an error will be reported.\n+     * The query will be cancelled.\n+     * <p>\n+     * Situation4: Scan range is difference. The type of table is aggregated. `test_materialized_view` is set to false.\n+     * The result of the old version selector will be selected. Print the warning log\n+     *\n+     * @param selectedIndexId\n+     * @param isPreAggregation\n+     * @param reasonOfDisable\n+     * @throws UserException\n+     */\n+    public void updateScanRangeInfoByNewMVSelector(long selectedIndexId, boolean isPreAggregation, String\n+            reasonOfDisable)\n+            throws UserException {\n+        if (selectedIndexId == this.selectedIndexId && isPreAggregation == this.isPreAggregation) {\n+            return;\n+        }\n+        StringBuilder stringBuilder = new StringBuilder(\"The new selected index id \")\n+                .append(selectedIndexId)\n+                .append(\", pre aggregation tag \").append(isPreAggregation)\n+                .append(\", reason \").append(reasonOfDisable == null ? \"null\" : reasonOfDisable)\n+                .append(\". The old selected index id \").append(this.selectedIndexId)\n+                .append(\" pre aggregation tag \").append(this.isPreAggregation)\n+                .append(\" reason \").append(this.reasonOfPreAggregation == null ? \"null\" : this.reasonOfPreAggregation);\n+        String scanRangeInfo = stringBuilder.toString();\n+        String situation;\n+        boolean update;\n+        CHECK:\n+        {\n+            if (olapTable.getKeysType() == KeysType.DUP_KEYS) {\n+                situation = \"The key type of table is duplicate.\";\n+                update = true;\n+                break CHECK;\n+            }\n+            if (ConnectContext.get() == null) {\n+                situation = \"Connection context is null\";\n+                update = true;\n+                break CHECK;\n+            }\n+            SessionVariable sessionVariable = ConnectContext.get().getSessionVariable();\n+            if (sessionVariable.getTestMaterializedView()) {\n+                throw new AnalysisException(\"The old scan range info is different from the new one when \"\n+                                                    + \"test_materialized_view is true. \"\n+                                                    + scanRangeInfo);\n+            }\n+            situation = \"The key type of table is aggregated.\";\n+            update = false;\n+            break CHECK;\n+        }\n+\n+        if (update) {\n+            this.selectedIndexId = selectedIndexId;\n+            this.isPreAggregation = isPreAggregation;\n+            this.reasonOfPreAggregation = reasonOfDisable;\n+            computeTabletInfo();\n+            LOG.info(\"Using the new scan range info instead of the old one. \" + situation + scanRangeInfo);\n+        } else {\n+            LOG.warn(\"Using the old scan range info instead of the new one. \" + situation + scanRangeInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjEwMDc2OnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/SingleNodePlanner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxNzo0NFrOFt8QBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxNzo0NFrOFt8QBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxNzM4Mg==", "bodyText": "Can SelectStmt be the key of a Map?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383717382", "createdAt": "2020-02-25T08:17:44Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/SingleNodePlanner.java", "diffHunk": "@@ -81,6 +81,7 @@\n \n     private final PlannerContext ctx_;\n     private final ArrayList<ScanNode> scanNodes = Lists.newArrayList();\n+    private Map<SelectStmt, List<ScanNode>> selectStmtToScanNodes = Maps.newHashMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjEwNTEzOnYy", "diffSide": "RIGHT", "path": "fe/src/main/java/org/apache/doris/planner/SingleNodePlanner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxOToyMVrOFt8S4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoxOToyMVrOFt8S4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxODExMg==", "bodyText": "move selectStmtToScanNodes.put(selectStmt, scanNodeList); to the above if clause.", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383718112", "createdAt": "2020-02-25T08:19:21Z", "author": {"login": "morningman"}, "path": "fe/src/main/java/org/apache/doris/planner/SingleNodePlanner.java", "diffHunk": "@@ -1328,6 +1362,12 @@ private PlanNode createScanNode(Analyzer analyzer, TableRef tblRef)\n         analyzer.materializeSlots(scanNode.getConjuncts());\n \n         scanNodes.add(scanNode);\n+        List<ScanNode> scanNodeList = selectStmtToScanNodes.get(selectStmt);\n+        if (scanNodeList == null) {\n+            scanNodeList = Lists.newArrayList();\n+        }\n+        scanNodeList.add(scanNode);\n+        selectStmtToScanNodes.put(selectStmt, scanNodeList);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjExMjQ0OnYy", "diffSide": "RIGHT", "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewFunctionTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoyMTo0M1rOFt8XOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoyMTo0M1rOFt8XOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcxOTIyNQ==", "bodyText": "No need to drop it. But instead you need to remove the dir: runningDir", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383719225", "createdAt": "2020-02-25T08:21:43Z", "author": {"login": "morningman"}, "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewFunctionTest.java", "diffHunk": "@@ -0,0 +1,562 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.utframe.DorisAssert;\n+import org.apache.doris.utframe.UtFrameUtils;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.util.UUID;\n+\n+public class MaterializedViewFunctionTest {\n+    private static String runningDir = \"fe/mocked/DemoTest/\" + UUID.randomUUID().toString() + \"/\";\n+    private static final String EMPS_TABLE_NAME = \"emps\";\n+    private static final String EMPS_MV_NAME = \"emps_mv\";\n+    private static final String HR_DB_NAME = \"db1\";\n+    private static final String QUERY_USE_EMPS_MV = \"rollup: \" + EMPS_MV_NAME;\n+    private static final String QUERY_USE_EMPS = \"rollup: \" + EMPS_TABLE_NAME;\n+    private static final String DEPTS_TABLE_NAME = \"depts\";\n+    private static final String DEPTS_MV_NAME = \"depts_mv\";\n+    private static final String QUERY_USE_DEPTS_MV = \"rollup: \" + DEPTS_MV_NAME;\n+    private static final String QUERY_USE_DEPTS = \"rollup: \" + DEPTS_TABLE_NAME;\n+    private static DorisAssert dorisAssert;\n+\n+    @BeforeClass\n+    public static void beforeClass() throws Exception {\n+        UtFrameUtils.createMinDorisCluster(runningDir);\n+        dorisAssert = new DorisAssert();\n+        dorisAssert.withEnableMV().withDatabase(HR_DB_NAME).useDatabase(HR_DB_NAME);\n+    }\n+\n+    @Before\n+    public void beforeMethod() throws Exception {\n+        String createTableSQL = \"create table \" + HR_DB_NAME + \".\" + EMPS_TABLE_NAME + \" (empid int, name varchar, \"\n+                + \"deptno int, salary int, commission int) \" + \"distributed by hash(empid) buckets 3 properties('replication_num' = '1');\";\n+        dorisAssert.withTable(createTableSQL);\n+        createTableSQL = \"create table \" + HR_DB_NAME + \".\" + DEPTS_TABLE_NAME + \" (deptno int, name varchar, cost \"\n+                + \"int) \" + \"distributed by hash(deptno) buckets 3 properties('replication_num' = '1');\";\n+        dorisAssert.withTable(createTableSQL);\n+    }\n+\n+    @After\n+    public void afterMethod() throws Exception {\n+        dorisAssert.dropTable(EMPS_TABLE_NAME);\n+        dorisAssert.dropTable(DEPTS_TABLE_NAME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjEyNjM0OnYy", "diffSide": "RIGHT", "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewFunctionTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoyNjoxOVrOFt8ffg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODoyNjoxOVrOFt8ffg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzcyMTM0Mg==", "bodyText": "Why there are lots of \"\" in sql?", "url": "https://github.com/apache/incubator-doris/pull/2821#discussion_r383721342", "createdAt": "2020-02-25T08:26:19Z", "author": {"login": "morningman"}, "path": "fe/src/test/java/org/apache/doris/planner/MaterializedViewFunctionTest.java", "diffHunk": "@@ -0,0 +1,562 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.planner;\n+\n+import org.apache.doris.utframe.DorisAssert;\n+import org.apache.doris.utframe.UtFrameUtils;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.util.UUID;\n+\n+public class MaterializedViewFunctionTest {\n+    private static String runningDir = \"fe/mocked/DemoTest/\" + UUID.randomUUID().toString() + \"/\";\n+    private static final String EMPS_TABLE_NAME = \"emps\";\n+    private static final String EMPS_MV_NAME = \"emps_mv\";\n+    private static final String HR_DB_NAME = \"db1\";\n+    private static final String QUERY_USE_EMPS_MV = \"rollup: \" + EMPS_MV_NAME;\n+    private static final String QUERY_USE_EMPS = \"rollup: \" + EMPS_TABLE_NAME;\n+    private static final String DEPTS_TABLE_NAME = \"depts\";\n+    private static final String DEPTS_MV_NAME = \"depts_mv\";\n+    private static final String QUERY_USE_DEPTS_MV = \"rollup: \" + DEPTS_MV_NAME;\n+    private static final String QUERY_USE_DEPTS = \"rollup: \" + DEPTS_TABLE_NAME;\n+    private static DorisAssert dorisAssert;\n+\n+    @BeforeClass\n+    public static void beforeClass() throws Exception {\n+        UtFrameUtils.createMinDorisCluster(runningDir);\n+        dorisAssert = new DorisAssert();\n+        dorisAssert.withEnableMV().withDatabase(HR_DB_NAME).useDatabase(HR_DB_NAME);\n+    }\n+\n+    @Before\n+    public void beforeMethod() throws Exception {\n+        String createTableSQL = \"create table \" + HR_DB_NAME + \".\" + EMPS_TABLE_NAME + \" (empid int, name varchar, \"\n+                + \"deptno int, salary int, commission int) \" + \"distributed by hash(empid) buckets 3 properties('replication_num' = '1');\";\n+        dorisAssert.withTable(createTableSQL);\n+        createTableSQL = \"create table \" + HR_DB_NAME + \".\" + DEPTS_TABLE_NAME + \" (deptno int, name varchar, cost \"\n+                + \"int) \" + \"distributed by hash(deptno) buckets 3 properties('replication_num' = '1');\";\n+        dorisAssert.withTable(createTableSQL);\n+    }\n+\n+    @After\n+    public void afterMethod() throws Exception {\n+        dorisAssert.dropTable(EMPS_TABLE_NAME);\n+        dorisAssert.dropTable(DEPTS_TABLE_NAME);\n+    }\n+\n+    @Test\n+    public void testProjectionMV1() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, empid from \"\n+                + EMPS_TABLE_NAME + \" order by deptno;\";\n+        String query = \"select empid, deptno from \" + EMPS_TABLE_NAME + \";\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    @Test\n+    public void testProjectionMV2() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, empid from \"\n+                + EMPS_TABLE_NAME + \" order by deptno;\";\n+        String query1 = \"select empid + 1 from \" + EMPS_TABLE_NAME + \" where deptno = 10;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query1).explainContains(QUERY_USE_EMPS_MV);\n+        String query2 = \"select name from \" + EMPS_TABLE_NAME + \" where deptno -10 = 0;\";\n+        dorisAssert.query(query2).explainWithout(QUERY_USE_EMPS_MV);\n+\n+    }\n+\n+    @Test\n+    public void testProjectionMV3() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, empid, name from \"\n+                + EMPS_TABLE_NAME + \" order by deptno;\";\n+        String query1 = \"select empid +1, name from \" + EMPS_TABLE_NAME + \" where deptno = 10;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query1).explainContains(QUERY_USE_EMPS_MV);\n+        String query2 = \"select name from \" + EMPS_TABLE_NAME + \" where deptno - 10 = 0;\";\n+        dorisAssert.query(query2).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    @Test\n+    public void testProjectionMV4() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select name, deptno, salary from \"\n+                + EMPS_TABLE_NAME + \";\";\n+        String query1 = \"select name from \" + EMPS_TABLE_NAME + \" where deptno > 30 and salary > 3000;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query1).explainContains(QUERY_USE_EMPS_MV);\n+        String query2 = \"select empid from \" + EMPS_TABLE_NAME + \" where deptno > 30 and empid > 10;\";\n+        dorisAssert.query(query2).explainWithout(QUERY_USE_EMPS_MV);\n+    }\n+\n+    @Test\n+    public void testUnionQueryOnProjectionMV() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, empid from \" +\n+                EMPS_TABLE_NAME + \" order by deptno;\";\n+        String union = \"select empid from \" + EMPS_TABLE_NAME + \" where deptno > 300\" + \" union all select empid from\"\n+                + \" \" + EMPS_TABLE_NAME + \" where deptno < 200\";\n+        dorisAssert.withMaterializedView(createMVSQL).query(union).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    @Test\n+    public void testAggQueryOnAggMV1() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, sum(salary), max\" + \"\"\n+                + \"(salary) from \" + EMPS_TABLE_NAME + \" group by deptno;\";\n+        String query = \"select sum(salary), deptno from \" + EMPS_TABLE_NAME + \" group by deptno;\";\n+        dorisAssert.withMaterializedView(createMVSQL).query(query).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    @Test\n+    public void testAggQueryOnAggMV2() throws Exception {\n+        String agg = \"select deptno, sum(salary) from \" + EMPS_TABLE_NAME + \" group by deptno\";\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as \" + agg + \";\";\n+        String query = \"select * from (select deptno, sum(salary) as sum_salary from \" + EMPS_TABLE_NAME + \" group \"\n+                + \"by\" + \" deptno) a where (sum_salary * 2) > 3;\";\n+        dorisAssert.withMaterializedView(createMVSQL).query(query).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    /*\n+    TODO\n+    The deduplicate materialized view is not yet supported\n+    @Test\n+    public void testAggQueryOnDeduplicatedMV() throws Exception {\n+        String deduplicateSQL = \"select deptno, empid, name, salary, commission from \" + EMPS_TABLE_NAME + \" group \"\n+                + \"by\" + \" deptno, empid, name, salary, commission\";\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as \" + deduplicateSQL + \";\";\n+        String query1 = \"select deptno, sum(salary) from (\" + deduplicateSQL + \") A group by deptno;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query1).explainContains(QUERY_USE_EMPS_MV);\n+        String query2 = \"select deptno, empid from \" + EMPS_TABLE_NAME + \";\";\n+        dorisAssert.query(query2).explainWithout(QUERY_USE_EMPS_MV);\n+    }\n+    */\n+\n+    @Test\n+    public void testAggQueryOnAggMV3() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, commission, sum(salary)\"\n+                + \" from \" + EMPS_TABLE_NAME + \" group by deptno, commission;\";\n+        String query = \"select commission, sum(salary) from \" + EMPS_TABLE_NAME + \" where commission * (deptno + \"\n+                + \"commission) = 100 group by commission;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    /**\n+     * Matching failed because the filtering condition under Aggregate\n+     * references columns for aggregation.\n+     */\n+    @Test\n+    public void testAggQueryOnAggMV4() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, commission, sum(salary)\"\n+                + \" from \" + EMPS_TABLE_NAME + \" group by deptno, commission;\";\n+        String query = \"select deptno, sum(salary) from \" + EMPS_TABLE_NAME + \" where salary>1000 group by deptno;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query).explainWithout(QUERY_USE_EMPS_MV);\n+    }\n+\n+    /**\n+     * There will be a compensating Project added after matching of the Aggregate.\n+     */\n+    @Test\n+    public void testAggQuqeryOnAggMV5() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, commission, sum(salary)\"\n+                + \" from \" + EMPS_TABLE_NAME + \" group by deptno, commission;\";\n+        String query = \"select * from (select deptno, sum(salary) as sum_salary from \" + EMPS_TABLE_NAME + \" group \"\n+                + \"by\" + \" deptno) a where sum_salary>10;\";\n+        dorisAssert.withMaterializedView(createMVSQL);\n+        dorisAssert.query(query).explainContains(QUERY_USE_EMPS_MV);\n+    }\n+\n+    /**\n+     * There will be a compensating Project + Filter added after matching of the Aggregate.\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testAggQuqeryOnAggMV6() throws Exception {\n+        String createMVSQL = \"create materialized view \" + EMPS_MV_NAME + \" as select deptno, commission, sum(salary)\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \" from \" + EMPS_TABLE_NAME + \" \" + \"group by\" + \" deptno, commission;\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd224343ff3cd70d7f92cfcf5729f34210ac4098"}, "originalPosition": 194}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2168, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}