{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwNDE2OTI3", "number": 1132, "title": "(CDAP-17080) Add Data Cacher Plugin", "bodyText": "https://issues.cask.co/browse/CDAP-17080", "createdAt": "2020-07-16T18:41:15Z", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132", "merged": true, "mergeCommit": {"oid": "bf2a7865086bc13f37fad4f4303980932afdce69"}, "closed": true, "closedAt": "2020-07-23T20:24:15Z", "author": {"login": "MEseifan"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc1kHrLAFqTQ1MDEzMjM1OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3xo3VABqjM1ODA2NzQzNzk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMTMyMzU4", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#pullrequestreview-450132358", "createdAt": "2020-07-16T19:04:44Z", "commit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNDo0NFrOGy4jgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowODozN1rOGy4rng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwODU3OQ==", "bodyText": "Wrong year", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456008579", "createdAt": "2020-07-16T19:04:44Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTE5OQ==", "bodyText": "Missing copyright comment", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456009199", "createdAt": "2020-07-16T19:05:55Z", "author": {"login": "chtyim"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,27 @@\n+# Data Cacher", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTgzOA==", "bodyText": "A better line breaking:\npublic JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext pluginContext,\n                                           JavaRDD<StructuredRecord> javaRDD) throws Exception {", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456009838", "createdAt": "2020-07-16T19:07:09Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA==", "bodyText": "This should be a validation error that should be checked at deployment time.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010088", "createdAt": "2020-07-16T19:07:34Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDY1NA==", "bodyText": "You can just check for empty string since the config is not optional (i.e. doesn't have @Nullable annotation)", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010654", "createdAt": "2020-07-16T19:08:37Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    @Name(\"StorageLevel\")\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    StorageLevel getStorageLevel() {\n+      if (Strings.isNullOrEmpty(storageLevel)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 70}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/125793ea217804652049d3167db2429229fd07fd", "committedDate": "2020-07-16T18:40:27Z", "message": "Added Data Cacher Plugin"}, "afterCommit": {"oid": "e33bdd9b738fd2e3141868047a33756fe1065ad8", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/e33bdd9b738fd2e3141868047a33756fe1065ad8", "committedDate": "2020-07-16T19:38:36Z", "message": "Added Data Cacher Plugin"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMjg3MzI2", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#pullrequestreview-450287326", "createdAt": "2020-07-16T23:45:43Z", "commit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzo0NTo0M1rOGzAgjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzo0NzozNFrOGzAiqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODg5NA==", "bodyText": "Use a Set\nSet<String> allowed = new HashSet<>(Arrays.asList(\n  \"DISK_ONLY\",\n  \"DISK_ONLY_2\",\n  ...\n));", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456138894", "createdAt": "2020-07-16T23:45:43Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA1Mw==", "bodyText": "I don't think this check is needed", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139053", "createdAt": "2020-07-16T23:46:13Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQzNQ==", "bodyText": "Instead of saying dropdown, it would be better to have the list of allowed values in the suggestive action, since this API can be used in REST API (imagine when someone export and import a pipeline, and due to future version change, some of the value might no longer be valid).", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139435", "createdAt": "2020-07-16T23:47:34Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {\n+        collector.addFailure(\"Storage level is a required value. \", \"Please select the desired storage level.\")\n+                 .withConfigProperty(STORAGE_LEVEL);\n+      } else if (!Arrays.asList(allowedStrings).contains(storageLevel.toUpperCase())) {\n+        collector\n+          .addFailure(\"Invalid value for Storage Level \", \"Please select one of the valid values from the dropdown.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMzE1MTUw", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#pullrequestreview-450315150", "createdAt": "2020-07-17T01:19:59Z", "commit": {"oid": "428ca6aefd6d12b1e54030ac10a74fbbfb76e22c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "428ca6aefd6d12b1e54030ac10a74fbbfb76e22c", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/428ca6aefd6d12b1e54030ac10a74fbbfb76e22c", "committedDate": "2020-07-17T00:25:22Z", "message": "Addressed more comments:"}, "afterCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/e8d986898f7036d44029100cacab8de04fa1283d", "committedDate": "2020-07-17T16:24:34Z", "message": "Added Data Cacher Plugin"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15728bab0d4aadbee2b42c8317f3e1c64edb34d1", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/15728bab0d4aadbee2b42c8317f3e1c64edb34d1", "committedDate": "2020-07-17T16:29:11Z", "message": "oops"}, "afterCommit": {"oid": "0f6dab41b36f1f53ed799b51d5660d01f8722f36", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/0f6dab41b36f1f53ed799b51d5660d01f8722f36", "committedDate": "2020-07-17T16:29:33Z", "message": "Added Data Cacher Plugin"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNzk1NTcy", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#pullrequestreview-450795572", "createdAt": "2020-07-17T16:27:22Z", "commit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjoyNzoyMlrOGzZZLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjoyODozMVrOGzZbWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NjYwNg==", "bodyText": "are -> at", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456546606", "createdAt": "2020-07-17T16:27:22Z", "author": {"login": "albertshau"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,42 @@\n+<!--- \n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ -->\n+ \n+# Data Cacher\n+\n+Description\n+-----------\n+Data cacher plugin will cache any record that is passed through it. This is \n+useful for pipelines that have auto-caching disabled but would still like to cache \n+records are certain points in the pipeline. Spark caching prevents unnecessary", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NzE2MA==", "bodyText": "do these not show up in the markdown doc?\nI guess we haven't been putting copyrights in these doc files, don't know that they're really needed here though.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456547160", "createdAt": "2020-07-17T16:28:31Z", "author": {"login": "albertshau"}, "path": "spark-plugins/docs/File-streamingsource.md", "diffHunk": "@@ -1,3 +1,18 @@\n+<!--- ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 1}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b7296cd07b18e4ed49e81202b45dd2de074e0217", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/b7296cd07b18e4ed49e81202b45dd2de074e0217", "committedDate": "2020-07-21T18:32:17Z", "message": "Add icon"}, "afterCommit": {"oid": "19fa031fc4e074939980e2d49bd944a0e02230fa", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/19fa031fc4e074939980e2d49bd944a0e02230fa", "committedDate": "2020-07-21T18:33:22Z", "message": "Added Data Cacher Plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "committedDate": "2020-07-23T16:01:45Z", "message": "Added Data Cacher Plugin"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "19fa031fc4e074939980e2d49bd944a0e02230fa", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/19fa031fc4e074939980e2d49bd944a0e02230fa", "committedDate": "2020-07-21T18:33:22Z", "message": "Added Data Cacher Plugin"}, "afterCommit": {"oid": "99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "author": {"user": {"login": "MEseifan", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "committedDate": "2020-07-23T16:01:45Z", "message": "Added Data Cacher Plugin"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1557, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}