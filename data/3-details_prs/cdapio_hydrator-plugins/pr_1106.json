{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3NDkyNTM4", "number": 1106, "title": "CDAP-16875 changed joiner plugin to use new auto-join API", "bodyText": "Changed the joiner to use the new AutoJoiner API to take\nadvantage of the performance improvements it allows in Spark\npipelines.\nIntroduced two new optional properties. The first determines\nwhether the join will use null safe equality, and the second\nprovides hint to the execution engine about which input datasets\nshould be broadcast to perform an in-memory join.\nRemoved much of the existing join logic because it has been moved\ninto the application code. Updated the documentation to use\nthe property names that show up in the UI, to display the properties\nin the same order that they appear in the UI, and to include\ndescriptions of the two new properties.", "createdAt": "2020-06-03T22:44:55Z", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106", "merged": true, "mergeCommit": {"oid": "c580f60a3b27f36003cfa1ff714b98303f5dcb7a"}, "closed": true, "closedAt": "2020-06-08T23:50:11Z", "author": {"login": "albertshau"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoVRR6AFqTQyNTQ0MzQ5Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcpTUVXgBqjM0MjEwMzg4Nzg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQzNDky", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106#pullrequestreview-425443492", "createdAt": "2020-06-05T16:19:55Z", "commit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoxOTo1NVrOGf096g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyOTo0OFrOGf1Sjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNjg1OA==", "bodyText": "Should this be 2 and next line be 3?", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106#discussion_r436026858", "createdAt": "2020-06-05T16:19:55Z", "author": {"login": "yaojiefeng"}, "path": "core-plugins/docs/Joiner-batchjoiner.md", "diffHunk": "@@ -1,49 +1,91 @@\n # Joiner\n \n-\n Description\n -----------\n-Joins records from one or more input based on join keys. Supports `inner` and `outer` joins, selection and renaming of output fields.  \n-\n-Use Case\n---------\n-The transform is used when you want to combine fields from one or more input, similar to the joins in SQL.\n+Joins records from one or more input based on join key equality.\n+Supports `inner` and `outer` joins, selection and renaming of output fields.\n+The plugin is used when you want to combine fields from one or more inputs, similar to joins in SQL.\n \n Properties\n ----------\n-**joinKeys:** List of keys to perform the join operation. The list is separated by `&`. \n+**Fields:** List of fields from each input that should be included in the output. \n+Output field names must be unique. If the same field name exists in more than one input,\n+each field must be aliased (renamed) to a unique output name.\n+\n+**Join Type:** Type of join to perform.\n+A join between two required input is an inner join. A join between a required input and an optional\n+input is a left outer join. A join between two optional inputs is an outer join.\n+\n+A join of more than two inputs is logically equivalent to performing inner joins over all the\n+required inputs, followed by left outer joins on the optional inputs.\n+\n+**Join Condition:** List of keys to perform the join operation. The list is separated by `&`. \n Join key from each input stage will be prefixed with `<stageName>.` and the relation among join keys from different inputs is represented by `=`. \n For example: customers.customer_id=items.c_id&customers.customer_name=items.c_name means the join key is a composite key\n of customer id and customer name from customers and items input stages and join will be performed on equality \n of the join keys. This transform only supports equality for joins.\n \n-**selectedFields:** Comma-separated list of fields to be selected and renamed in join output from each input stage. \n-Each selected field that should be present in the output must be prefixed with '<input_stage_name>'. \n-The syntax for specifying alias for each selected field is similar to sql. \n-For example: customers.id as customer_id, customer.name as customer_name, item.id as item_id, <stageName>.inputFieldName as alias. \n-The output will have same order of fields as selected in selectedFields. There must not be any duplicate fields in output.\n-\n-**requiredInputs:** Comma-separated list of stages. Required input stages decide the type of the join. \n-If all the input stages are present in required inputs, inner join will be performed. \n-Otherwise, outer join will be performed considering non-required inputs as optional.\n-\n-**numPartitions:** Number of partitions to use when grouping fields. If not specified, the execution\n+**Inputs to Load in Memory:** Hint to the underlying execution engine that the specified input data should be\n+loaded into memory to perform an in-memory join. This is ignored by the MapReduce engine and passed onto the Spark engine.\n+An in-memory join performs well when one side of the join is small (for example, under 1gb). Be sure to set\n+Spark executor memory to a number large enough to load all of these datasets into memory. This is most commonly\n+used when a large input is being joined to a small input and will lead to much better performance in such scenarios.\n+\n+**Join on Null Keys:** Whether to join rows together if both of their key values are null.\n+For example, suppose the join is on a 'purchases' input that contains:\n+\n+| purchase_id | customer_name | item   |\n+| ----------- | ------------- | ------ |\n+| 1           | alice         | donut  |\n+| 2           |               | coffee | \n+| 3           | bob           | water  |\n+\n+and a 'customers' input that contains:\n+\n+| customer_id | name   |\n+| ----------- | ------ |\n+| 1           | alice  |\n+| 2           |        |\n+| 3           | bob    |\n+\n+The join is a left outer join on purchases.customer_name = customers.name.\n+If this property is set to true, the joined output would be:\n+\n+| purchase_id | customer_name | item   | customer_id | name  |\n+| ----------- | ------------- | ------ | ----------- | ----- |\n+| 1           | alice         | donut  | 1           | alice |\n+| 2           |               | coffee | 2           |       |\n+| 2           |               | coffee | 3           |       |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNzAzNw==", "bodyText": "Here the customer_id should be 2 right?", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106#discussion_r436027037", "createdAt": "2020-06-05T16:20:14Z", "author": {"login": "yaojiefeng"}, "path": "core-plugins/docs/Joiner-batchjoiner.md", "diffHunk": "@@ -1,49 +1,91 @@\n # Joiner\n \n-\n Description\n -----------\n-Joins records from one or more input based on join keys. Supports `inner` and `outer` joins, selection and renaming of output fields.  \n-\n-Use Case\n---------\n-The transform is used when you want to combine fields from one or more input, similar to the joins in SQL.\n+Joins records from one or more input based on join key equality.\n+Supports `inner` and `outer` joins, selection and renaming of output fields.\n+The plugin is used when you want to combine fields from one or more inputs, similar to joins in SQL.\n \n Properties\n ----------\n-**joinKeys:** List of keys to perform the join operation. The list is separated by `&`. \n+**Fields:** List of fields from each input that should be included in the output. \n+Output field names must be unique. If the same field name exists in more than one input,\n+each field must be aliased (renamed) to a unique output name.\n+\n+**Join Type:** Type of join to perform.\n+A join between two required input is an inner join. A join between a required input and an optional\n+input is a left outer join. A join between two optional inputs is an outer join.\n+\n+A join of more than two inputs is logically equivalent to performing inner joins over all the\n+required inputs, followed by left outer joins on the optional inputs.\n+\n+**Join Condition:** List of keys to perform the join operation. The list is separated by `&`. \n Join key from each input stage will be prefixed with `<stageName>.` and the relation among join keys from different inputs is represented by `=`. \n For example: customers.customer_id=items.c_id&customers.customer_name=items.c_name means the join key is a composite key\n of customer id and customer name from customers and items input stages and join will be performed on equality \n of the join keys. This transform only supports equality for joins.\n \n-**selectedFields:** Comma-separated list of fields to be selected and renamed in join output from each input stage. \n-Each selected field that should be present in the output must be prefixed with '<input_stage_name>'. \n-The syntax for specifying alias for each selected field is similar to sql. \n-For example: customers.id as customer_id, customer.name as customer_name, item.id as item_id, <stageName>.inputFieldName as alias. \n-The output will have same order of fields as selected in selectedFields. There must not be any duplicate fields in output.\n-\n-**requiredInputs:** Comma-separated list of stages. Required input stages decide the type of the join. \n-If all the input stages are present in required inputs, inner join will be performed. \n-Otherwise, outer join will be performed considering non-required inputs as optional.\n-\n-**numPartitions:** Number of partitions to use when grouping fields. If not specified, the execution\n+**Inputs to Load in Memory:** Hint to the underlying execution engine that the specified input data should be\n+loaded into memory to perform an in-memory join. This is ignored by the MapReduce engine and passed onto the Spark engine.\n+An in-memory join performs well when one side of the join is small (for example, under 1gb). Be sure to set\n+Spark executor memory to a number large enough to load all of these datasets into memory. This is most commonly\n+used when a large input is being joined to a small input and will lead to much better performance in such scenarios.\n+\n+**Join on Null Keys:** Whether to join rows together if both of their key values are null.\n+For example, suppose the join is on a 'purchases' input that contains:\n+\n+| purchase_id | customer_name | item   |\n+| ----------- | ------------- | ------ |\n+| 1           | alice         | donut  |\n+| 2           |               | coffee | \n+| 3           | bob           | water  |\n+\n+and a 'customers' input that contains:\n+\n+| customer_id | name   |\n+| ----------- | ------ |\n+| 1           | alice  |\n+| 2           |        |\n+| 3           | bob    |\n+\n+The join is a left outer join on purchases.customer_name = customers.name.\n+If this property is set to true, the joined output would be:\n+\n+| purchase_id | customer_name | item   | customer_id | name  |\n+| ----------- | ------------- | ------ | ----------- | ----- |\n+| 1           | alice         | donut  | 1           | alice |\n+| 2           |               | coffee | 2           |       |\n+| 2           |               | coffee | 3           |       |\n+| 3           | bob           | water  |             |       |\n+\n+Note that the rows with a null customer name were joined together.\n+If this property is set to false, the joined output would be:\n+\n+| purchase_id | customer_name | item   | customer_id | name  |\n+| ----------- | ------------- | ------ | ----------- | ----- |\n+| 1           | alice         | donut  | 1           | alice |\n+| 2           |               | coffee |             |       |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTMwNQ==", "bodyText": "Just curious - is the schema name useful for the output schema? I believe the builder will use its own schema name if this is not provided, and because different plugins seem to give different schema name, and the name basically is not used anywhere. Is it important and worth to pay attention when developing a plugin in the future?", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106#discussion_r436031305", "createdAt": "2020-06-05T16:28:05Z", "author": {"login": "yaojiefeng"}, "path": "core-plugins/src/main/java/io/cdap/plugin/batch/joiner/Joiner.java", "diffHunk": "@@ -58,40 +60,83 @@\n   \"required inputs, inner join will be performed. Otherwise inner join will be performed on required inputs and \" +\n   \"records from non-required inputs will only be present if they match join criteria. If there are no required \" +\n   \"inputs, outer join will be performed\")\n-public class Joiner extends BatchJoiner<StructuredRecord, StructuredRecord, StructuredRecord> {\n+public class Joiner extends BatchAutoJoiner {\n \n   static final String JOIN_OPERATION_DESCRIPTION = \"Used as a key in a join\";\n   static final String IDENTITY_OPERATION_DESCRIPTION = \"Unchanged as part of a join\";\n   static final String RENAME_OPERATION_DESCRIPTION = \"Renamed as a part of a join\";\n \n   private final JoinerConfig conf;\n-  private Schema outputSchema;\n-  private Map<String, List<String>> perStageJoinKeys;\n-  private Table<String, String, String> perStageSelectedFields;\n-  private JoinConfig joinConfig;\n-  private Map<String, Schema> keySchemas = new HashMap<>();\n \n   public Joiner(JoinerConfig conf) {\n     this.conf = conf;\n   }\n \n+  @Nullable\n   @Override\n-  public void configurePipeline(MultiInputPipelineConfigurer pipelineConfigurer) {\n-    MultiInputStageConfigurer stageConfigurer = pipelineConfigurer.getMultiInputStageConfigurer();\n-    Map<String, Schema> inputSchemas = stageConfigurer.getInputSchemas();\n-    FailureCollector collector = pipelineConfigurer.getMultiInputStageConfigurer().getFailureCollector();\n-    init(inputSchemas, collector);\n-    collector.getOrThrowException();\n-    if (!conf.inputSchemasAvailable(inputSchemas) && !conf.containsMacro(JoinerConfig.OUTPUT_SCHEMA) &&\n+  public JoinDefinition define(AutoJoinerContext context) {\n+    FailureCollector collector = context.getFailureCollector();\n+\n+    boolean hasUnknownInputSchema = context.getInputStages().values().stream().anyMatch(Objects::isNull);\n+    if (hasUnknownInputSchema && !conf.containsMacro(JoinerConfig.OUTPUT_SCHEMA) &&\n       conf.getOutputSchema(collector) == null) {\n       // If input schemas are unknown, an output schema must be provided.\n       collector.addFailure(\"Output schema must be specified\", null).withConfigProperty(JoinerConfig.OUTPUT_SCHEMA);\n     }\n \n-    Schema outputSchema = getOutputSchema(inputSchemas, collector);\n-    if (outputSchema != null) {\n-      // Set output schema if it's not a macro.\n-      stageConfigurer.setOutputSchema(outputSchema);\n+    if (conf.requiredPropertiesContainMacros()) {\n+      return null;\n+    }\n+\n+    Set<String> requiredStages = conf.getRequiredInputs();\n+    Set<String> broadcastStages = conf.getBroadcastInputs();\n+    List<JoinStage> inputs = new ArrayList<>(context.getInputStages().size());\n+    boolean useOutputSchema = false;\n+    for (JoinStage joinStage : context.getInputStages().values()) {\n+      inputs.add(JoinStage.builder(joinStage)\n+        .setRequired(requiredStages.contains(joinStage.getStageName()))\n+        .setBroadcast(broadcastStages.contains(joinStage.getStageName()))\n+        .build());\n+      useOutputSchema = useOutputSchema || joinStage.getSchema() == null;\n+    }\n+\n+    try {\n+      JoinDefinition.Builder joinBuilder = JoinDefinition.builder()\n+        .select(conf.getSelectedFields(collector))\n+        .from(inputs)\n+        .on(JoinCondition.onKeys()\n+              .setKeys(conf.getJoinKeys(collector))\n+              .setNullSafe(conf.isNullSafe())\n+              .build());\n+      if (useOutputSchema) {\n+        joinBuilder.setOutputSchema(conf.getOutputSchema(collector));\n+      } else {\n+        joinBuilder.setOutputSchemaName(\"join.output\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMjE0Mg==", "bodyText": "nit - remove this line", "url": "https://github.com/cdapio/hydrator-plugins/pull/1106#discussion_r436032142", "createdAt": "2020-06-05T16:29:48Z", "author": {"login": "yaojiefeng"}, "path": "pom.xml", "diffHunk": "@@ -837,7 +837,7 @@\n         <module>google-cloud</module>\n         <module>kafka-plugins</module>\n         <module>amazon-s3-plugins</module>\n-        <module>azure</module>\n+        <!--module>azure</module-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "125a302abc98048232e8699412d9443cf63eb3ea", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/125a302abc98048232e8699412d9443cf63eb3ea", "committedDate": "2020-06-08T16:47:08Z", "message": "CDAP-16875 changed joiner plugin to use new auto-join API\n\nChanged the joiner to use the new AutoJoiner API to take\nadvantage of the performance improvements it allows in Spark\npipelines.\n\nIntroduced two new optional properties. The first determines\nwhether the join will use null safe equality, and the second\nprovides hint to the execution engine about which input datasets\nshould be broadcast to perform an in-memory join.\n\nRemoved much of the existing join logic because it has been moved\ninto the application code. Updated the documentation to use\nthe property names that show up in the UI, to display the properties\nin the same order that they appear in the UI, and to include\ndescriptions of the two new properties."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4a898449ba115f8f0bd4eb7bf39962980dac6c05", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/4a898449ba115f8f0bd4eb7bf39962980dac6c05", "committedDate": "2020-06-03T22:44:22Z", "message": "CDAP-16875 changed joiner plugin to use new auto-join API\n\nChanged the joiner to use the new AutoJoiner API to take\nadvantage of the performance improvements it allows in Spark\npipelines.\n\nIntroduced two new optional properties. The first determines\nwhether the join will use null safe equality, and the second\nprovides hint to the execution engine about which input datasets\nshould be broadcast to perform an in-memory join.\n\nRemoved much of the existing join logic because it has been moved\ninto the application code. Updated the documentation to use\nthe property names that show up in the UI, to display the properties\nin the same order that they appear in the UI, and to include\ndescriptions of the two new properties."}, "afterCommit": {"oid": "125a302abc98048232e8699412d9443cf63eb3ea", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/hydrator-plugins/commit/125a302abc98048232e8699412d9443cf63eb3ea", "committedDate": "2020-06-08T16:47:08Z", "message": "CDAP-16875 changed joiner plugin to use new auto-join API\n\nChanged the joiner to use the new AutoJoiner API to take\nadvantage of the performance improvements it allows in Spark\npipelines.\n\nIntroduced two new optional properties. The first determines\nwhether the join will use null safe equality, and the second\nprovides hint to the execution engine about which input datasets\nshould be broadcast to perform an in-memory join.\n\nRemoved much of the existing join logic because it has been moved\ninto the application code. Updated the documentation to use\nthe property names that show up in the UI, to display the properties\nin the same order that they appear in the UI, and to include\ndescriptions of the two new properties."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1545, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}