{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwNDE2OTI3", "number": 1132, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNDo0NFrOEPQ3xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjoyODozMVrOEPmT-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQwNTE2OnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNDo0NFrOGy4jgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMjo1NzowMlrOGy_kHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwODU3OQ==", "bodyText": "Wrong year", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456008579", "createdAt": "2020-07-16T19:04:44Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyMzQyMA==", "bodyText": "Fixed", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456123420", "createdAt": "2020-07-16T22:57:02Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwODU3OQ=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQwOTQ0OnYy", "diffSide": "RIGHT", "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNTo1NVrOGy4l7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzoxNjoyNVrOGy_8eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTE5OQ==", "bodyText": "Missing copyright comment", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456009199", "createdAt": "2020-07-16T19:05:55Z", "author": {"login": "chtyim"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,27 @@\n+# Data Cacher", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNDQ4NA==", "bodyText": "Do we add copyright comments to markdown files? I dont see the copyright comment in any of the other plugin docs", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456124484", "createdAt": "2020-07-16T23:00:10Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,27 @@\n+# Data Cacher", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTE5OQ=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNjQ3MQ==", "bodyText": "I think we should have copyright in all files in the source repo", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456126471", "createdAt": "2020-07-16T23:06:11Z", "author": {"login": "chtyim"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,27 @@\n+# Data Cacher", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTE5OQ=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyOTY1OA==", "bodyText": "ok, added copyright to this doc and the rest of the docs", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456129658", "createdAt": "2020-07-16T23:16:25Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,27 @@\n+# Data Cacher", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTE5OQ=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQxMzQxOnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNzowOVrOGy4obg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzowMTo1M1rOGy_qbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTgzOA==", "bodyText": "A better line breaking:\npublic JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext pluginContext,\n                                           JavaRDD<StructuredRecord> javaRDD) throws Exception {", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456009838", "createdAt": "2020-07-16T19:07:09Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTAzNw==", "bodyText": "done", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125037", "createdAt": "2020-07-16T23:01:53Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTgzOA=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQxNTEyOnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowNzozNFrOGy4paA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzoxMjoyMVrOGy_3Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA==", "bodyText": "This should be a validation error that should be checked at deployment time.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010088", "createdAt": "2020-07-16T19:07:34Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTQ5NA==", "bodyText": "We cant check at deployment time because the spark classes are not available during deployment/validation. I dont think this is a big problem because the plugin uses a dropdown to specify the storage level so the only way the user can pass an incorrect value is using a macro which we cant check during deployment anyway.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125494", "createdAt": "2020-07-16T23:03:20Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNjY1Mw==", "bodyText": "Maybe check that the string value is in one of the allowed value.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456126653", "createdAt": "2020-07-16T23:06:47Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyODMyNg==", "bodyText": "Sure, done.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456128326", "createdAt": "2020-07-16T23:12:21Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQxODcyOnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTowODozN1rOGy4rng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzowMzozNlrOGy_sgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDY1NA==", "bodyText": "You can just check for empty string since the config is not optional (i.e. doesn't have @Nullable annotation)", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010654", "createdAt": "2020-07-16T19:08:37Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    @Name(\"StorageLevel\")\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    StorageLevel getStorageLevel() {\n+      if (Strings.isNullOrEmpty(storageLevel)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTU3MQ==", "bodyText": "Fixed", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125571", "createdAt": "2020-07-16T23:03:36Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    @Name(\"StorageLevel\")\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    StorageLevel getStorageLevel() {\n+      if (Strings.isNullOrEmpty(storageLevel)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDY1NA=="}, "originalCommit": {"oid": "125793ea217804652049d3167db2429229fd07fd"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTI0NjY2OnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzo0NTo0M1rOGzAgjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDoxNDoxNVrOGzBBlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODg5NA==", "bodyText": "Use a Set\nSet<String> allowed = new HashSet<>(Arrays.asList(\n  \"DISK_ONLY\",\n  \"DISK_ONLY_2\",\n  ...\n));", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456138894", "createdAt": "2020-07-16T23:45:43Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NzM1MQ==", "bodyText": "done", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456147351", "createdAt": "2020-07-17T00:14:15Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODg5NA=="}, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTI0NzYxOnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzo0NjoxM1rOGzAhLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDoxNjo0M1rOGzBEpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA1Mw==", "bodyText": "I don't think this check is needed", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139053", "createdAt": "2020-07-16T23:46:13Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0ODEzNQ==", "bodyText": "removed", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456148135", "createdAt": "2020-07-17T00:16:43Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA1Mw=="}, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTI0OTkzOnYy", "diffSide": "RIGHT", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzo0NzozNFrOGzAiqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDoxNjo1NFrOGzBE4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQzNQ==", "bodyText": "Instead of saying dropdown, it would be better to have the list of allowed values in the suggestive action, since this API can be used in REST API (imagine when someone export and import a pipeline, and due to future version change, some of the value might no longer be valid).", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139435", "createdAt": "2020-07-16T23:47:34Z", "author": {"login": "chtyim"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {\n+        collector.addFailure(\"Storage level is a required value. \", \"Please select the desired storage level.\")\n+                 .withConfigProperty(STORAGE_LEVEL);\n+      } else if (!Arrays.asList(allowedStrings).contains(storageLevel.toUpperCase())) {\n+        collector\n+          .addFailure(\"Invalid value for Storage Level \", \"Please select one of the valid values from the dropdown.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0ODE5NA==", "bodyText": "done", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456148194", "createdAt": "2020-07-17T00:16:54Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {\n+        collector.addFailure(\"Storage level is a required value. \", \"Please select the desired storage level.\")\n+                 .withConfigProperty(STORAGE_LEVEL);\n+      } else if (!Arrays.asList(allowedStrings).contains(storageLevel.toUpperCase())) {\n+        collector\n+          .addFailure(\"Invalid value for Storage Level \", \"Please select one of the valid values from the dropdown.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQzNQ=="}, "originalCommit": {"oid": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzkxNDU3OnYy", "diffSide": "RIGHT", "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjoyNzoyMlrOGzZZLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxOToxOToyMVrOGzefrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NjYwNg==", "bodyText": "are -> at", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456546606", "createdAt": "2020-07-17T16:27:22Z", "author": {"login": "albertshau"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,42 @@\n+<!--- \n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ -->\n+ \n+# Data Cacher\n+\n+Description\n+-----------\n+Data cacher plugin will cache any record that is passed through it. This is \n+useful for pipelines that have auto-caching disabled but would still like to cache \n+records are certain points in the pipeline. Spark caching prevents unnecessary", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYzMDE4OQ==", "bodyText": "whoops..good catch", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456630189", "createdAt": "2020-07-17T19:19:21Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/docs/DataCacher-sparkcompute.md", "diffHunk": "@@ -0,0 +1,42 @@\n+<!--- \n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ -->\n+ \n+# Data Cacher\n+\n+Description\n+-----------\n+Data cacher plugin will cache any record that is passed through it. This is \n+useful for pipelines that have auto-caching disabled but would still like to cache \n+records are certain points in the pipeline. Spark caching prevents unnecessary", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NjYwNg=="}, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzkxODAyOnYy", "diffSide": "RIGHT", "path": "spark-plugins/docs/File-streamingsource.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjoyODozMVrOGzZbWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxOToyMzoyNFrOGzemQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NzE2MA==", "bodyText": "do these not show up in the markdown doc?\nI guess we haven't been putting copyrights in these doc files, don't know that they're really needed here though.", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456547160", "createdAt": "2020-07-17T16:28:31Z", "author": {"login": "albertshau"}, "path": "spark-plugins/docs/File-streamingsource.md", "diffHunk": "@@ -1,3 +1,18 @@\n+<!--- ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYzMTg3Mg==", "bodyText": "I've confirmed that they dont show up.\nI'm not sure if its needed but it was requested in one of the previous review comments", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456631872", "createdAt": "2020-07-17T19:23:24Z", "author": {"login": "MEseifan"}, "path": "spark-plugins/docs/File-streamingsource.md", "diffHunk": "@@ -1,3 +1,18 @@\n+<!--- ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0NzE2MA=="}, "originalCommit": {"oid": "e8d986898f7036d44029100cacab8de04fa1283d"}, "originalPosition": 1}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2463, "cost": 1, "resetAt": "2021-11-12T18:49:56Z"}}}