{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3ODQzNDgz", "number": 8850, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjozOTo0MVrOEY6Lrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNjozMTowOFrOEZVIvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0NTU0NTQzOnYy", "diffSide": "RIGHT", "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjozOTo0MVrOHBbbQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMjo0MjoxOVrOHBnHBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1OTk2OA==", "bodyText": "As everything is returned as a Stream anyway in the end, I started to wonder if there would be a good way to not collect each page into a list to get the size. It seems that the only (?) way to do that without a terminal operation for a stream would be to use a builder, atomic boolean and a consumer. While this is a bit on the \"premature optimization\" side of things, at least we could avoid the collection this way.\nBuilder<T> builder = Stream.builder();\nAtomicBoolean pageHasItems= new AtomicBoolean(true);\nConsumer<T> consumer = item -> {\n    builder.add(item);\n    pageHasItems.set(true);\n}\nfor (int page = 0; page < pages && pageHasItems.getAndSet(false); page++) {\n  ...\n  getDataProvider().fetch(query).forEach(consumer);\n}\n...\nstream = builder.build();\nWhat do you think? I know it adds a bit complexity but it would avoid collecting items.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471259968", "createdAt": "2020-08-17T06:39:41Z", "author": {"login": "pleku"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -723,20 +725,24 @@ protected Object getFilter() {\n                  * Requested range is split to several pages, and queried from\n                  * backend page by page\n                  */\n+                final Collection<T> fetchedPages = new LinkedList<>();\n                 for (int page = 0; page < pages; page++) {\n                     final int newOffset = offset + page * pageSize;\n                     query = new QueryTrace(newOffset, pageSize, backEndSorting,\n                             inMemorySorting, filter);\n-                    /*\n-                    * TODO: DataProvider is still queried for next pages\n-                    * even when backend returns empty pages/partial page.\n-                    * This should be improved so as to analyze the returned\n-                    * page item count and stop if it's empty/partial.\n-                    * See https://github.com/vaadin/flow/issues/8844\n-                    */\n-                    stream = Stream.concat(stream,\n-                            getDataProvider().fetch(query));\n+                    Stream<T> fetchedPageStream =\n+                            getDataProvider().fetch(query);\n+                    List<T> fetchedPage =\n+                            fetchedPageStream.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d659820c1f5ab098ae9f160cfce42e499db04d3"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTM3MDU4OQ==", "bodyText": "Could be fine, but if this is added then I would like to have the whole if in its own method, even if it means returning a holder object as the query is needed for checks at the end.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471370589", "createdAt": "2020-08-17T09:56:54Z", "author": {"login": "caalador"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -723,20 +725,24 @@ protected Object getFilter() {\n                  * Requested range is split to several pages, and queried from\n                  * backend page by page\n                  */\n+                final Collection<T> fetchedPages = new LinkedList<>();\n                 for (int page = 0; page < pages; page++) {\n                     final int newOffset = offset + page * pageSize;\n                     query = new QueryTrace(newOffset, pageSize, backEndSorting,\n                             inMemorySorting, filter);\n-                    /*\n-                    * TODO: DataProvider is still queried for next pages\n-                    * even when backend returns empty pages/partial page.\n-                    * This should be improved so as to analyze the returned\n-                    * page item count and stop if it's empty/partial.\n-                    * See https://github.com/vaadin/flow/issues/8844\n-                    */\n-                    stream = Stream.concat(stream,\n-                            getDataProvider().fetch(query));\n+                    Stream<T> fetchedPageStream =\n+                            getDataProvider().fetch(query);\n+                    List<T> fetchedPage =\n+                            fetchedPageStream.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1OTk2OA=="}, "originalCommit": {"oid": "0d659820c1f5ab098ae9f160cfce42e499db04d3"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ0NTIxMw==", "bodyText": "The drawback of this approach is that the next page will always be requested even if the previous page has partial number of items (returned item count < page size). I'm getting try to rework it so as to get rid of this.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471445213", "createdAt": "2020-08-17T12:30:24Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -723,20 +725,24 @@ protected Object getFilter() {\n                  * Requested range is split to several pages, and queried from\n                  * backend page by page\n                  */\n+                final Collection<T> fetchedPages = new LinkedList<>();\n                 for (int page = 0; page < pages; page++) {\n                     final int newOffset = offset + page * pageSize;\n                     query = new QueryTrace(newOffset, pageSize, backEndSorting,\n                             inMemorySorting, filter);\n-                    /*\n-                    * TODO: DataProvider is still queried for next pages\n-                    * even when backend returns empty pages/partial page.\n-                    * This should be improved so as to analyze the returned\n-                    * page item count and stop if it's empty/partial.\n-                    * See https://github.com/vaadin/flow/issues/8844\n-                    */\n-                    stream = Stream.concat(stream,\n-                            getDataProvider().fetch(query));\n+                    Stream<T> fetchedPageStream =\n+                            getDataProvider().fetch(query);\n+                    List<T> fetchedPage =\n+                            fetchedPageStream.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1OTk2OA=="}, "originalCommit": {"oid": "0d659820c1f5ab098ae9f160cfce42e499db04d3"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ0Nzg0Nw==", "bodyText": "Yes that is a drawback. If the page request crosses a network boundary then it will be probably a bigger impact than the collecting items. However you can rework my naive approach by using an atomicInteger instead and comparing that to page size.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471447847", "createdAt": "2020-08-17T12:35:35Z", "author": {"login": "pleku"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -723,20 +725,24 @@ protected Object getFilter() {\n                  * Requested range is split to several pages, and queried from\n                  * backend page by page\n                  */\n+                final Collection<T> fetchedPages = new LinkedList<>();\n                 for (int page = 0; page < pages; page++) {\n                     final int newOffset = offset + page * pageSize;\n                     query = new QueryTrace(newOffset, pageSize, backEndSorting,\n                             inMemorySorting, filter);\n-                    /*\n-                    * TODO: DataProvider is still queried for next pages\n-                    * even when backend returns empty pages/partial page.\n-                    * This should be improved so as to analyze the returned\n-                    * page item count and stop if it's empty/partial.\n-                    * See https://github.com/vaadin/flow/issues/8844\n-                    */\n-                    stream = Stream.concat(stream,\n-                            getDataProvider().fetch(query));\n+                    Stream<T> fetchedPageStream =\n+                            getDataProvider().fetch(query);\n+                    List<T> fetchedPage =\n+                            fetchedPageStream.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1OTk2OA=="}, "originalCommit": {"oid": "0d659820c1f5ab098ae9f160cfce42e499db04d3"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ1MTM5Ng==", "bodyText": "Yes, that's exactly I'm gonna do", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471451396", "createdAt": "2020-08-17T12:42:19Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -723,20 +725,24 @@ protected Object getFilter() {\n                  * Requested range is split to several pages, and queried from\n                  * backend page by page\n                  */\n+                final Collection<T> fetchedPages = new LinkedList<>();\n                 for (int page = 0; page < pages; page++) {\n                     final int newOffset = offset + page * pageSize;\n                     query = new QueryTrace(newOffset, pageSize, backEndSorting,\n                             inMemorySorting, filter);\n-                    /*\n-                    * TODO: DataProvider is still queried for next pages\n-                    * even when backend returns empty pages/partial page.\n-                    * This should be improved so as to analyze the returned\n-                    * page item count and stop if it's empty/partial.\n-                    * See https://github.com/vaadin/flow/issues/8844\n-                    */\n-                    stream = Stream.concat(stream,\n-                            getDataProvider().fetch(query));\n+                    Stream<T> fetchedPageStream =\n+                            getDataProvider().fetch(query);\n+                    List<T> fetchedPage =\n+                            fetchedPageStream.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1OTk2OA=="}, "originalCommit": {"oid": "0d659820c1f5ab098ae9f160cfce42e499db04d3"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0OTk1NDQ5OnYy", "diffSide": "RIGHT", "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNjoyODoxOVrOHCFGcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMToxNjoxOVrOHCOwww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mjc2OA==", "bodyText": "When the query is split to pages we only check that the last query has getLimit/getPageSize and getOffset/getPage called ? It feels weird to me that we have to add this new class here to just check the last query. If we insist on keeping the check, which I suppose might help some users, why shouldn't it be checked consistently for each page query and not just the last one? Or how is the last one so significant - is it enough indication on whether or not the user has called the methods ? If this has been decided on purpose, it is not visible on the code and should be documented so in a comment.\nI would not add this extra class, I would just instead maybe move the checking part to its own method and call it directly here. It seems fine to move the checking before the size verification and parallel stream check even for the other queries (in the method calling this method).", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471942768", "createdAt": "2020-08-18T06:28:19Z", "author": {"login": "pleku"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;\n+            query = new QueryTrace(newOffset, pageSize, backEndSorting,\n+                    inMemorySorting, filter);\n+            getDataProvider().fetch(query).forEach(addItemAndCheckConsumer);\n+        } while (page < pages && fetchedPerPage.getAndSet(0) == pageSize);\n+\n+        return new PagesFetchResult<>(streamBuilder.build(), query);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4MzU1OQ==", "bodyText": "Oh, yes. I overlooked that. All the queries should be checked, not only the last one. Will fix that.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r472083559", "createdAt": "2020-08-18T10:40:24Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;\n+            query = new QueryTrace(newOffset, pageSize, backEndSorting,\n+                    inMemorySorting, filter);\n+            getDataProvider().fetch(query).forEach(addItemAndCheckConsumer);\n+        } while (page < pages && fetchedPerPage.getAndSet(0) == pageSize);\n+\n+        return new PagesFetchResult<>(streamBuilder.build(), query);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mjc2OA=="}, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMTA1OQ==", "bodyText": "done", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r472101059", "createdAt": "2020-08-18T11:16:19Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;\n+            query = new QueryTrace(newOffset, pageSize, backEndSorting,\n+                    inMemorySorting, filter);\n+            getDataProvider().fetch(query).forEach(addItemAndCheckConsumer);\n+        } while (page < pages && fetchedPerPage.getAndSet(0) == pageSize);\n+\n+        return new PagesFetchResult<>(streamBuilder.build(), query);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mjc2OA=="}, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0OTk2MTU4OnYy", "diffSide": "RIGHT", "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNjozMTowOFrOHCFKsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMToxNzowM1rOHCOyKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mzg1OA==", "bodyText": "Non-blocking comment while you are making changes: I would not mind having the page++; on its own line in the end of the loop, it is just cleaner that way IMO.", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r471943858", "createdAt": "2020-08-18T06:31:08Z", "author": {"login": "pleku"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4Mzc3Mg==", "bodyText": "Agree. Will do", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r472083772", "createdAt": "2020-08-18T10:40:45Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mzg1OA=="}, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMTQxOA==", "bodyText": "done", "url": "https://github.com/vaadin/flow/pull/8850#discussion_r472101418", "createdAt": "2020-08-18T11:17:03Z", "author": {"login": "mshabarov"}, "path": "flow-data/src/main/java/com/vaadin/flow/data/provider/DataCommunicator.java", "diffHunk": "@@ -1116,6 +1101,29 @@ private JsonValue generateJson(T item) {\n         return json;\n     }\n \n+    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+    private PagesFetchResult<T> fetchPages(int pages, int offset) {\n+        QueryTrace query;\n+        final Stream.Builder<T> streamBuilder = Stream.builder();\n+\n+        final AtomicInteger fetchedPerPage = new AtomicInteger(0);\n+        Consumer<T> addItemAndCheckConsumer = item -> {\n+            streamBuilder.add(item);\n+            fetchedPerPage.getAndIncrement();\n+        };\n+        // Keep fetching the pages until we get empty/partial page,\n+        // or run out of pages to request\n+        int page = 0;\n+        do {\n+            final int newOffset = offset + (page++) * pageSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0Mzg1OA=="}, "originalCommit": {"oid": "029cabba6beedf5065ed916702807b00858f5531"}, "originalPosition": 92}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3189, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}