{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5NjIxMDc2", "number": 4460, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo0Nzo1NlrOEPNwYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMTozMzo0N1rOEPUC6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Mzg5NDc1OnYy", "diffSide": "RIGHT", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/HdfsFileIo.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo0Nzo1NlrOGyznaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMToxNDoyMlrOGy9BQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyNzY1Nw==", "bodyText": "Is this needed? We don't other delete calls.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455927657", "createdAt": "2020-07-16T16:47:56Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/HdfsFileIo.java", "diffHunk": "@@ -44,26 +41,24 @@ public HdfsFileIo(HdfsEnvironment environment, HdfsContext context)\n     @Override\n     public InputFile newInputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopInputFile.fromLocation(path, configuration);\n+        return new PrestoHadoopInputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public OutputFile newOutputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopOutputFile.fromPath(new Path(path), configuration);\n+        return new PrestoHadoopOutputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public void deleteFile(String pathString)\n     {\n         Path path = new Path(pathString);\n         try {\n-            environment.getFileSystem(context, path).delete(path, false);\n+            environment.doAs(context.getIdentity().getUser(), () -> environment.getFileSystem(context, path).delete(path, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk2MjE3NQ==", "bodyText": "I think whether we should wrap a call is not super clear, and it'd be safer to wrap everything than not. We had a discussion in https://prestosql.slack.com/archives/CP1MUNEUX/p1593662755069900.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455962175", "createdAt": "2020-07-16T17:45:17Z", "author": {"login": "lxynov"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/HdfsFileIo.java", "diffHunk": "@@ -44,26 +41,24 @@ public HdfsFileIo(HdfsEnvironment environment, HdfsContext context)\n     @Override\n     public InputFile newInputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopInputFile.fromLocation(path, configuration);\n+        return new PrestoHadoopInputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public OutputFile newOutputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopOutputFile.fromPath(new Path(path), configuration);\n+        return new PrestoHadoopOutputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public void deleteFile(String pathString)\n     {\n         Path path = new Path(pathString);\n         try {\n-            environment.getFileSystem(context, path).delete(path, false);\n+            environment.doAs(context.getIdentity().getUser(), () -> environment.getFileSystem(context, path).delete(path, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyNzY1Nw=="}, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA4MTcyOQ==", "bodyText": "I believe for delete operation it is not required, but +1 for be consistent for all operations.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456081729", "createdAt": "2020-07-16T21:14:22Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/HdfsFileIo.java", "diffHunk": "@@ -44,26 +41,24 @@ public HdfsFileIo(HdfsEnvironment environment, HdfsContext context)\n     @Override\n     public InputFile newInputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopInputFile.fromLocation(path, configuration);\n+        return new PrestoHadoopInputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public OutputFile newOutputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopOutputFile.fromPath(new Path(path), configuration);\n+        return new PrestoHadoopOutputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public void deleteFile(String pathString)\n     {\n         Path path = new Path(pathString);\n         try {\n-            environment.getFileSystem(context, path).delete(path, false);\n+            environment.doAs(context.getIdentity().getUser(), () -> environment.getFileSystem(context, path).delete(path, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyNzY1Nw=="}, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Mzg5ODQxOnYy", "diffSide": "RIGHT", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo0ODo1OVrOGyzpxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNzo0NToyOFrOGy1utw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyODI2MQ==", "bodyText": "Same, we don't do this for OrcFileWriterFactory", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455928261", "createdAt": "2020-07-16T16:48:59Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -186,9 +186,9 @@ private IcebergFileWriter createOrcWriter(\n                     try {\n                         return new HdfsOrcDataSource(\n                                 new OrcDataSourceId(outputPath.toString()),\n-                                fileSystem.getFileStatus(outputPath).getLen(),\n+                                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.getFileStatus(outputPath).getLen()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk2MjI5NQ==", "bodyText": "Same above", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455962295", "createdAt": "2020-07-16T17:45:28Z", "author": {"login": "lxynov"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -186,9 +186,9 @@ private IcebergFileWriter createOrcWriter(\n                     try {\n                         return new HdfsOrcDataSource(\n                                 new OrcDataSourceId(outputPath.toString()),\n-                                fileSystem.getFileStatus(outputPath).getLen(),\n+                                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.getFileStatus(outputPath).getLen()),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyODI2MQ=="}, "originalCommit": null, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0MzkzMDYxOnYy", "diffSide": "RIGHT", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo1NzoyNVrOGyz9yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo1NzoyNVrOGyz9yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkzMzM4Nw==", "bodyText": "We could name this HdfsInputFile to match HdfsFileIo", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455933387", "createdAt": "2020-07-16T16:57:25Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import io.prestosql.plugin.hive.HdfsEnvironment;\n+import io.prestosql.plugin.hive.HdfsEnvironment.HdfsContext;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.SeekableInputStream;\n+\n+import java.io.IOException;\n+\n+import static io.prestosql.plugin.iceberg.IcebergErrorCode.ICEBERG_FILESYSTEM_ERROR;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoHadoopInputFile", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0MzkzMjgyOnYy", "diffSide": "RIGHT", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo1Nzo1MlrOGyz_LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo1Nzo1MlrOGyz_LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkzMzc0MA==", "bodyText": "toString() not needed for concatenation", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455933740", "createdAt": "2020-07-16T16:57:52Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import io.prestosql.plugin.hive.HdfsEnvironment;\n+import io.prestosql.plugin.hive.HdfsEnvironment.HdfsContext;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.SeekableInputStream;\n+\n+import java.io.IOException;\n+\n+import static io.prestosql.plugin.iceberg.IcebergErrorCode.ICEBERG_FILESYSTEM_ERROR;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoHadoopInputFile\n+        implements InputFile\n+{\n+    private final InputFile delegate;\n+    private final HdfsEnvironment environment;\n+    private final String user;\n+\n+    public PrestoHadoopInputFile(Path path, HdfsEnvironment environment, HdfsContext context)\n+    {\n+        requireNonNull(path, \"path is null\");\n+        this.environment = requireNonNull(environment, \"environment is null\");\n+        requireNonNull(context, \"context is null\");\n+        try {\n+            this.delegate = HadoopInputFile.fromPath(path, environment.getFileSystem(context, path), environment.getConfiguration(context, path));\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(ICEBERG_FILESYSTEM_ERROR, \"Failed to create input file: \" + path.toString(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDkyNTIwOnYy", "diffSide": "RIGHT", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "isResolved": true, "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMTozMzo0N1rOGy9kXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMzoxNDo0MFrOG5NdZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ==", "bodyText": "should we also add recoverAction to IcebergRecordFileWriter  created-at\nas otherwise.\n[this] (https://github.com/prestosql/presto/blob/master/presto-hive/src/main/java/io/prestosql/plugin/hive/RecordFileWriter.java#L197) might fail as its running with Authentication ( doAs )", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456090719", "createdAt": "2020-07-16T21:33:47Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MTAwNg==", "bodyText": "Sorry for commenting bit late.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456091006", "createdAt": "2020-07-16T21:34:26Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5NDkxOQ==", "bodyText": "2nd comment is:\nNot sure, if that can create problem.\nthe same above problem could occur at this point as well in RecordFileWriter: code\nfinalWrittenBytes = path.getFileSystem(conf).getFileStatus(path).getLen();\nFlow to reach this methods are like HiveWriter1,\nHiveWrtier2\nand IcebergPageSink", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456094919", "createdAt": "2020-07-16T21:42:57Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEwNzI2Nw==", "bodyText": "Hmm makes sense. We can add a rollbackAction in RecordFileWriter like what we have in OrcFileWriter. It actually depends on whether we should wrap deletes in doAs. I feel we can do it in a separate PR.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456107267", "createdAt": "2020-07-16T22:10:55Z", "author": {"login": "lxynov"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0Mjg2OA==", "bodyText": "Sure, though but we are wrapping deletes in doAs, thats why I pointed.\nalso in the second comment,  path.getFileSystem(conf).getFileStatus(path).getLen(); is called without doAs. So, that can also be a problem. WDYT ?", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456142868", "createdAt": "2020-07-16T23:58:42Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYyODY3Ng==", "bodyText": "If the above case is not true, and we don't need to use doAs.\nThen its LG for me, and thanks for working on this !!", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456628676", "createdAt": "2020-07-17T19:15:51Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5MTM4Mw==", "bodyText": "@manishmalhotrawork Thanks for letting us know. I think we can do the fix in a separate PR as it involves changes in presto-hive, so we're good for merging this one as of now.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r457591383", "createdAt": "2020-07-20T17:57:03Z", "author": {"login": "lxynov"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MDk1OQ==", "bodyText": "@lxynov thanks.\nbut if we see: #4460 (comment)\nthat flow is being called from IcebergSink as well.\nSo, iceberg writes can still create problem.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r457770959", "createdAt": "2020-07-21T00:47:49Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODE4Ng==", "bodyText": "@electrum can you please see my comment as well, and if it's not a problem( or can be taken care in future).\nthen can we please merge this fix.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r461188186", "createdAt": "2020-07-27T21:44:00Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxNDA0MQ==", "bodyText": "We can follow up if it's a problem.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r462614041", "createdAt": "2020-07-29T21:58:33Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY0MjUzMg==", "bodyText": "@electrum thanks !", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r462642532", "createdAt": "2020-07-29T23:14:40Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ=="}, "originalCommit": null, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3643, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}