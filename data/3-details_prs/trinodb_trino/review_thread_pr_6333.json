{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM5MzU2NzE0", "number": 6333, "reviewThreads": {"totalCount": 53, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMjo0MDo1NVrOFE9n7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMzo0NlrOFKD__Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNzQ4MjcxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMjo0MDo1NVrOIFOlVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo1ODoxOFrOIJokdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw==", "bodyText": "We should have equivalent of @LegacyConfig for session toggles.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r542352727", "createdAt": "2020-12-14T12:40:55Z", "author": {"login": "findepi"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjYyMzA5MA==", "bodyText": "@findepi, are you saying that we have an equivalent of @LegacyConfig, and that we should use it for this PR? Or that someone should implement an equivalent at some point?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r542623090", "createdAt": "2020-12-14T18:36:23Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc4MzA4MA==", "bodyText": "i am not aware that we have", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r542783080", "createdAt": "2020-12-14T21:03:18Z", "author": {"login": "findepi"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzODc4OA==", "bodyText": "Yea, that's what I understood too, but wasn't sure if I missed something. It sounds like a reasonable feature request. Would you think that this blocks any of this PR? If not, we can file an issue for that.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r543638788", "createdAt": "2020-12-15T19:47:30Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDIzMTQ3Ng==", "bodyText": "I don't think it blocks here. But would be nice to have. Would you be able to implement this?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544231476", "createdAt": "2020-12-16T11:43:06Z", "author": {"login": "findepi"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk3Mjc5MQ==", "bodyText": "I might take a look at this if I get some time, but no guarantees", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546972791", "createdAt": "2020-12-21T22:58:18Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTE1MjI5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNTo1Nzo1MlrOIHMgEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQwMDo1NjoxNlrOII3SVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA==", "bodyText": "could that have negative performance impact? Currently on CPU cache miss just sequential data row needs to be loaded. With two arrays, that might mean one more RAM read and worse data locality", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544415760", "createdAt": "2020-12-16T15:57:52Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3OTU2Nw==", "bodyText": "Yes, definitely will be worse from cache locality perspective, and I really didn't want to do this. The main challenge here is that these arrays need to be filled with potentially different default values for the hash table to work. If we have another generalized way to handle this filling, that would be ideal. That or we need to force the parts of the keys to have the same default value for all users. Any ideas? I'm not very happy with this, but I didn't think of anything better at the time.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544479567", "createdAt": "2020-12-16T17:19:16Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg4MDYxOA==", "bodyText": "Could you describe what does key1 and key2 store?\nIt seems that when guard value collide with actual values it might lead to some odd issues. How did it work when when (0, 0) was both guard and real value?\nIn join (io.prestosql.operator.PagesHash) we use double level addressing (with compact hash io.prestosql.operator.PagesHash#positionToHashes for performance). IIRC flattening join hash did not help performance. Maybe we should have something similar here?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545880618", "createdAt": "2020-12-18T14:50:15Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NTMzMg==", "bodyText": "Yea, this is definitely a bit confusing at first glance, and I had to stare a bit at this to figure out why it works. Apparently this is how all the fastutil hash tables work.\nBasically, in a normal fastutil hash table, there is just a key array. In the LongLong ported variant, we have 128bit keys represented either inline of a double length long array, or 2 long arrays. This array(s) are pre-filled with a default null representation (fastutil uses the zero values). What fastutil does is to store a separate boolean indicating whether (0, 0) or guard value representation actually contains a real value. And this one-off check against the guard value being overloaded is done first manually for every single lookup. The actual value mapping to this guard value is stored at the n index, which is why all the key and value arrays have n+1 size.\n\nIn join (io.prestosql.operator.PagesHash) we use double level addressing (with compact hash io.prestosql.operator.PagesHash#positionToHashes for performance). IIRC flattening join hash did not help performance. Maybe we should have something similar here?\n\nThere is definitely TONS of room for optimization in the hash table here. It's definitely the slowest part. Let's sync up on this.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546165332", "createdAt": "2020-12-19T00:56:16Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTE3MjI2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNjowMTo0M1rOIHMsMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMzowMzowMFrOIHdBug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxODg2NQ==", "bodyText": "Can we just assume that (0, 0) are special keys? Why do we have to make it selective?\nIn what way HashStrategy can be more clever regarding to special keys? Does that introduce additional branching for CPU?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544418865", "createdAt": "2020-12-16T16:01:43Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -108,6 +109,13 @@\n      */\n     protected long defRetValue;\n \n+    /**\n+     * The two-part value denoting unmapped keys (or null keys). These values may be passed back via the HashStrategy callback\n+     * during equality checks, even though no keys with these values have been added.\n+     */\n+    protected final long nullKey1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4Mjk3Ng==", "bodyText": "The fastutil code previously assumes (0,0) are actually special keys, which is a problem for us since all of our IDs are actually 0 index based, and overlaps in the numerical space. We won't be able to tell them apart from real entries.\nThe way we end up using this later like this: c22eb4d#diff-ed97f2619a0070f10f22c87f1cb1b5218c741a0e3eff94feb178d6eed616be24R103\nWe really don't want to expose internal non-allocated keys to our ID buffers. I can explain a bit more if you would like.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544482976", "createdAt": "2020-12-16T17:24:03Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -108,6 +109,13 @@\n      */\n     protected long defRetValue;\n \n+    /**\n+     * The two-part value denoting unmapped keys (or null keys). These values may be passed back via the HashStrategy callback\n+     * during equality checks, even though no keys with these values have been added.\n+     */\n+    protected final long nullKey1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxODg2NQ=="}, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDY4NjUyMg==", "bodyText": "The special null keys are not so much about performance as they are about having the HashStrategy providers be able to distinguish true null keys from keys that have already been submitted. (0, 0) actually is the default in fastutil, but the challenge here is that it overlaps with the key space we currently have -- and we need it to be more predictable to give the right answers. This is how we end up using this later:\nc22eb4d#diff-ed97f2619a0070f10f22c87f1cb1b5218c741a0e3eff94feb178d6eed616be24R103", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544686522", "createdAt": "2020-12-16T23:03:00Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -108,6 +109,13 @@\n      */\n     protected long defRetValue;\n \n+    /**\n+     * The two-part value denoting unmapped keys (or null keys). These values may be passed back via the HashStrategy callback\n+     * during equality checks, even though no keys with these values have been added.\n+     */\n+    protected final long nullKey1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxODg2NQ=="}, "originalCommit": null, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTQ5MjkwOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMjo1N1rOIHPpvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMjo1N1rOIHPpvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzM5MQ==", "bodyText": "it's fine to use RankingType from TopNRankingNode. That should simplify imports", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467391", "createdAt": "2020-12-16T17:02:57Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "diffHunk": "@@ -42,9 +43,17 @@\n     public static class TopNRankingOperatorFactory\n             implements OperatorFactory\n     {\n+        public enum RankingType", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTQ5Mzg2OnYy", "diffSide": "LEFT", "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMzowOVrOIHPqSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMzowOVrOIHPqSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzUyOA==", "bodyText": "nit: separate commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467528", "createdAt": "2020-12-16T17:03:09Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "diffHunk": "@@ -201,20 +215,29 @@ public TopNRankingOperator(\n                     expectedPositions,\n                     isDictionaryAggregationEnabled(operatorContext.getSession()),\n                     joinCompiler,\n-                     blockTypeOperators,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTQ5NTY0OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/LocalExecutionPlanner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMzozN1rOIHPrdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMzozN1rOIHPrdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzgzMA==", "bodyText": "If there is just one RankingType, you could static import all of these", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467830", "createdAt": "2020-12-16T17:03:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/LocalExecutionPlanner.java", "diffHunk": "@@ -924,6 +925,20 @@ public PhysicalOperation visitTopNRanking(TopNRankingNode node, LocalExecutionPl\n             return new PhysicalOperation(operatorFactory, makeLayout(node), context, source);\n         }\n \n+        private TopNRankingOperator.TopNRankingOperatorFactory.RankingType toOperatorRankingType(TopNRankingNode.RankingType rankingType)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTQ5OTYzOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/PlanNodeDecorrelator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDoyN1rOIHPt_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDoyN1rOIHPt_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODQ3OA==", "bodyText": "static import ROW_NUMBER", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468478", "createdAt": "2020-12-16T17:04:27Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/PlanNodeDecorrelator.java", "diffHunk": "@@ -322,6 +323,7 @@ public PlanNodeDecorrelator(Metadata metadata, SymbolAllocator symbolAllocator,\n                                 new Specification(\n                                         ImmutableList.copyOf(childDecorrelationResult.symbolsToPropagate),\n                                         Optional.of(orderingScheme)),\n+                                RankingType.ROW_NUMBER,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTUwMDIzOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDozN1rOIHPuYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDozN1rOIHPuYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODU3Nw==", "bodyText": "static import ROW_NUMBER", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468577", "createdAt": "2020-12-16T17:04:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "diffHunk": "@@ -143,6 +144,7 @@ public Result apply(FilterNode filter, Captures captures, Context context)\n                 window.getId(),\n                 window.getSource(),\n                 window.getSpecification(),\n+                RankingType.ROW_NUMBER,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTUwMTYxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDo1MVrOIHPvMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDo1MVrOIHPvMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODc4Ng==", "bodyText": "static import (here and other places)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468786", "createdAt": "2020-12-16T17:04:51Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -157,7 +158,7 @@ else if (source instanceof WindowNode && canOptimizeWindowFunction((WindowNode)\n                 WindowNode windowNode = (WindowNode) source;\n                 // verify that unordered row_number window functions are replaced by RowNumberNode\n                 verify(windowNode.getOrderingScheme().isPresent());\n-                TopNRankingNode topNRankingNode = convertToTopNRanking(windowNode, limit);\n+                TopNRankingNode topNRankingNode = convertToTopNRanking(windowNode, RankingType.ROW_NUMBER, limit);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTE4NjI2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNTowMzoyNFrOIIms3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQwMDo1Nzo0MlrOII3TSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5MzU5OA==", "bodyText": "Is this a hash map? Do we need to initialize every position to -1. Do we expect positions to be \"freed\"?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545893598", "createdAt": "2020-12-18T15:03:24Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 624}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NTU3OQ==", "bodyText": "No, this is just a straight array with groupId as indexes, and we don't need to free anything here because of how groupIds are defined in Presto: once a groupId N exists, it guarantees that all groupIds 0..N also exist.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546165579", "createdAt": "2020-12-19T00:57:42Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5MzU5OA=="}, "originalCommit": null, "originalPosition": 624}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTE5NDU3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNTowNTozN1rOIImxyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMzo0NToxNlrOIK66zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NDg1Nw==", "bodyText": "We could consider int here. Do we expect queries to actually limit rank/row number above 2^32? This could save a lot of mem.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545894857", "createdAt": "2020-12-18T15:05:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 628}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NjkxNg==", "bodyText": "Yes big savings here if we can limit to Integer size. I put it this way because the original Grouped TopN for row number implementation seemed to allow LONG output sizes for row number. But other than that, I don't see a real problem capping max rank at 32 bits.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546166916", "createdAt": "2020-12-19T01:05:18Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NDg1Nw=="}, "originalCommit": null, "originalPosition": 628}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0NTkxMw==", "bodyText": "@sopel39, also if we change this, we have to change some of the other metrics stored in other data structures to also be int to match. That would cause additional cache misses to pull them into a different data structure. I think it will be fine either way, but I know you care about that, so just want to check what your preference is here. I don't mind either way since these are not the main bottlenecks right now.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547545913", "createdAt": "2020-12-22T22:54:40Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NDg1Nw=="}, "originalCommit": null, "originalPosition": 628}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODMyMTk5Ng==", "bodyText": "ping @sopel39 on this one", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548321996", "createdAt": "2020-12-23T23:45:16Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NDg1Nw=="}, "originalCommit": null, "originalPosition": 628}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTIwMTQ0OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNTowNzoxN1rOIIm14w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQwMTowMTo1NlrOII3WBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NTkwNw==", "bodyText": "Could we observe N and then N+10 and then N+5?\nnit: static import max", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545895907", "createdAt": "2020-12-18T15:07:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 640}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NjI3OQ==", "bodyText": "Yes, we can observe N, N+10, and then N+5, but when you observe N+10, that means groups 0...N+10 exist also.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546166279", "createdAt": "2020-12-19T01:01:56Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NTkwNw=="}, "originalCommit": null, "originalPosition": 640}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTIyMzM0OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxMjozNVrOIInCmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQwMTowMDo1NVrOII3VXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5OTE2MQ==", "bodyText": "Should heapIndexBuffer and metricsBuffer be merged together? Do we expect these to be used independently? If they are part of same array, then we could save on memory access from CPU", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545899161", "createdAt": "2020-12-18T15:12:35Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 623}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NjExMA==", "bodyText": "So, the only reason I split the arrays is because they need to be initialized to different initial values. But otherwise, totally agree.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546166110", "createdAt": "2020-12-19T01:00:55Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5OTE2MQ=="}, "originalCommit": null, "originalPosition": 623}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTI0NjQ5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxODoyMVrOIInQLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxODoyMVrOIInQLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwMjYzOA==", "bodyText": "Could you extract constants like 4 as a static final variables, e.g:\nPOSITIONS_PER_ENTRY", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545902638", "createdAt": "2020-12-18T15:18:21Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 739}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTI1MTM5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxOTo0M1rOIInTEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxOTo0M1rOIInTEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwMzM3OA==", "bodyText": "ditto. You could also extract PEER_GROUP_COUNT_OFFSET, LEFT_CHILD_HEAP_INDEX_OFFSET", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545903378", "createdAt": "2020-12-18T15:19:43Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);\n+            }\n+\n+            setPeerGroupIndex(newHeapIndex, peerGroupIndex);\n+            setPeerGroupCount(newHeapIndex, peerGroupCount);\n+            setLeftChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+            setRightChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+\n+            return newHeapIndex;\n+        }\n+\n+        public void deallocate(long index)\n+        {\n+            emptySlots.enqueue(index);\n+        }\n+\n+        public long getActiveNodeCount()\n+        {\n+            return capacity - emptySlots.longSize();\n+        }\n+\n+        public long getPeerGroupIndex(long index)\n+        {\n+            return buffer.get(index * 4);\n+        }\n+\n+        public void setPeerGroupIndex(long index, long peerGroupIndex)\n+        {\n+            buffer.set(index * 4, peerGroupIndex);\n+        }\n+\n+        public long getPeerGroupCount(long index)\n+        {\n+            return buffer.get(index * 4 + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 772}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMTI4MTY4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToyNjoxOFrOIInkmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToyNjoxOFrOIInkmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwNzg2Nw==", "bodyText": "Extract:\nprivate static final int POSITIONS_PER_ENTRY=2\n\n?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545907867", "createdAt": "2020-12-18T15:26:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);\n+            }\n+\n+            setPeerGroupIndex(newHeapIndex, peerGroupIndex);\n+            setPeerGroupCount(newHeapIndex, peerGroupCount);\n+            setLeftChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+            setRightChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+\n+            return newHeapIndex;\n+        }\n+\n+        public void deallocate(long index)\n+        {\n+            emptySlots.enqueue(index);\n+        }\n+\n+        public long getActiveNodeCount()\n+        {\n+            return capacity - emptySlots.longSize();\n+        }\n+\n+        public long getPeerGroupIndex(long index)\n+        {\n+            return buffer.get(index * 4);\n+        }\n+\n+        public void setPeerGroupIndex(long index, long peerGroupIndex)\n+        {\n+            buffer.set(index * 4, peerGroupIndex);\n+        }\n+\n+        public long getPeerGroupCount(long index)\n+        {\n+            return buffer.get(index * 4 + 1);\n+        }\n+\n+        public void setPeerGroupCount(long index, long peerGroupCount)\n+        {\n+            buffer.set(index * 4 + 1, peerGroupCount);\n+        }\n+\n+        public void incrementPeerGroupCount(long index)\n+        {\n+            buffer.increment(index * 4 + 1);\n+        }\n+\n+        public void addPeerGroupCount(long index, long delta)\n+        {\n+            buffer.add(index * 4 + 1, delta);\n+        }\n+\n+        public long getLeftChildHeapIndex(long index)\n+        {\n+            return buffer.get(index * 4 + 2);\n+        }\n+\n+        public void setLeftChildHeapIndex(long index, long childHeapIndex)\n+        {\n+            buffer.set(index * 4 + 2, childHeapIndex);\n+        }\n+\n+        public long getRightChildHeapIndex(long index)\n+        {\n+            return buffer.get(index * 4 + 3);\n+        }\n+\n+        public void setRightChildHeapIndex(long index, long childHeapIndex)\n+        {\n+            buffer.set(index * 4 + 3, childHeapIndex);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + buffer.sizeOf() + emptySlots.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of peer groups as linked chains of matching values. Peer groups are referenced by\n+     * their node index for operations.\n+     */\n+    private static class PeerGroupBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(PeerGroupBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] rowId1, [LONG] nextPeerIndex1,\n+         *  [LONG] rowId2, [LONG] nextPeerIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new peer group node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long rowId, long nextPeerIndex)\n+        {\n+            long newPeerIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newPeerIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newPeerIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 850}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjU3MDA1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0MzoxN1rOIIzmJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0MzoxN1rOIIzmJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNDg2OA==", "bodyText": "some comment what it represents exactly would be great", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546104868", "createdAt": "2020-12-18T21:43:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjU4MTg1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0ODowN1rOIIzs2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0ODowN1rOIIzs2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNjU4Ng==", "bodyText": "What exactly is rowId? Is it address as in PagesIndex?\nWhy nullRowId needs to be parametrized? Can it be some special constant?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546106586", "createdAt": "2020-12-18T21:48:07Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjU4MjcxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0ODoyOVrOIIztWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0ODoyOVrOIIztWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNjcxMw==", "bodyText": "nit: each arg in newline", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546106713", "createdAt": "2020-12-18T21:48:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjU4NDg4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0OToxOVrOIIzujw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0OToxOVrOIIzujw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNzAyMw==", "bodyText": "nit: 0 also doesn't make sense, but it's detail", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546107023", "createdAt": "2020-12-18T21:49:19Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjU4NjczOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo1MDowOVrOIIzvpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQwMDo1ODo1N1rOII3ULA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNzMwMw==", "bodyText": "Can that be part of constructor? I see that Long2LongOpenCustomHashMap doesn't have such method", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546107303", "createdAt": "2020-12-18T21:50:09Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE2NTgwNA==", "bodyText": "It could be in the constructor, but this is just following fastutil existing structure of how they manage default values.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546165804", "createdAt": "2020-12-19T00:58:57Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNzMwMw=="}, "originalCommit": null, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjYwODE3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo1OToxN1rOIIz8nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo1OToxN1rOIIz8nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExMDYyMA==", "bodyText": "move method below usage", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546110620", "createdAt": "2020-12-18T21:59:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjYyMDY3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMjowNDoyOFrOII0D7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMjowNDoyOFrOII0D7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExMjQ5NA==", "bodyText": "move private methods below public", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546112494", "createdAt": "2020-12-18T22:04:28Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODcyODAxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMTo0NDoxMFrOIJm2vA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMTo0NDoxMFrOIJm2vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk0NDcwMA==", "bodyText": "add some comment why it has to be false", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546944700", "createdAt": "2020-12-21T21:44:10Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTI3MDk4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMjo0Njo0NlrOIKjvdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMDo1NToxNFrOIK1SJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0MjI2MQ==", "bodyText": "Can we assume nullRowId to be -1 for simplicity? It seems to be inline with RowReferencePageManager", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547942261", "createdAt": "2020-12-23T12:46:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIyOTY3MQ==", "bodyText": "Actually no, the reserved value happens to be -2, since -1 carries special meaning elsewhere (unknown, rather than null).", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548229671", "createdAt": "2020-12-23T20:55:14Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0MjI2MQ=="}, "originalCommit": null, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTI4MTc2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMjo1MToxM1rOIKj10A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMjo1MToxM1rOIKj10A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0Mzg4OA==", "bodyText": "you could inline peerGroupBuffer.getRowId(peerGroupIndex)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547943888", "createdAt": "2020-12-23T12:51:13Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 224}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTMxNzY5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzowNDo1MVrOIKkKjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzowNDo1MVrOIKkKjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0OTE5Ng==", "bodyText": "this is neat idea!", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547949196", "createdAt": "2020-12-23T13:04:51Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 318}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTMyOTg4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzowOToyNVrOIKkRUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMToxNjozMlrOIK2O6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1MDkzMA==", "bodyText": "I think it would be simpler if you handled that explicitly at the beginning of the method:\nlong heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\nif (heapSize == 1) {\n  // last insertion leaf was the root node\n  ...\n  return heapRootNodeIndex;\n}\n\nthen the code here would simplify:\nsetChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\ngroupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\ngroupIdToHeapBuffer.addHeapSize(groupId, -1);\nreturn currentNodeIndex;", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547950930", "createdAt": "2020-12-23T13:09:25Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIzMzEzOQ==", "bodyText": "I think I still have a preference for this structure, because it makes it obvious what happens to the case when the previousNodeIndex value is not changed through certain paths through the while condition. Otherwise, readers have to make the mental connection of what happens when size == 1 vs previousNodeIndex value and heap traversal. Otherwise, afterwards, you still probably want to assert that previousNodeIndex != UNKNOWN_INDEX and give an explanation about the relationship with another condition above. To me this seems like less implict assumptions in code.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548233139", "createdAt": "2020-12-23T20:59:41Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1MDkzMA=="}, "originalCommit": null, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0NTIyNA==", "bodyText": "Up to you. Generally, I prefer to keep special cases isolated (preferably early on) and have main/happy path unconditional. Extra validate(previousNodeIndex != UNKNOWN_INDEX) doesn't seem that bad IMO.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548245224", "createdAt": "2020-12-23T21:16:32Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1MDkzMA=="}, "originalCommit": null, "originalPosition": 341}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTM5MDkyOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzozMTo0NVrOIKk0sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMTo1NjowNFrOIK3-VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1OTk4NA==", "bodyText": "Once this condition is true it will stay being true until end of traversal. You could save some potentially expensive comparisons by setting some:\nrowSwapped = true\n\nand changing this if to:\nif (rowSwapped || rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n ...\n}", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547959984", "createdAt": "2020-12-23T13:31:45Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 389}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI3Mzc0OA==", "bodyText": "great observation", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548273748", "createdAt": "2020-12-23T21:56:04Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1OTk4NA=="}, "originalCommit": null, "originalPosition": 389}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTQwOTE3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzozODoxM1rOIKk_hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMTowMDozNFrOIK1hcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk2Mjc1OQ==", "bodyText": "nit: heapInsert is always called with newPeerGroupCount=1", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547962759", "createdAt": "2020-12-23T13:38:13Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIzMzU4Nw==", "bodyText": "I feel like this is probably ok IMO, since it always makes sense to carry the peer group with the count in this context -- especially given how all the other heap methods are set up.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548233587", "createdAt": "2020-12-23T21:00:34Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk2Mjc1OQ=="}, "originalCommit": null, "originalPosition": 364}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTU3MTU1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozMzowNVrOIKmeEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozMzowNVrOIKmeEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4Njk2MQ==", "bodyText": "static import abs", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547986961", "createdAt": "2020-12-23T14:33:05Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 573}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTU3NzAxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozNDo1NVrOIKmhQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozNDo1NVrOIKmhQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4Nzc3Nw==", "bodyText": "static import max", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547987777", "createdAt": "2020-12-23T14:34:55Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 576}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTYxMTE3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDo0NjoxOFrOIKm1Kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDo0NjoxOFrOIKm1Kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5Mjg3NQ==", "bodyText": "use dataProvider instead, e.g:\n    @DataProvider(name = \"parameters\")\n    public static Object[][] parameters()\n    {\n        List<Integer> topNs = Arrays.asList(1, 2, 3);\n        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n        List<Object[]> parameters = new ArrayList();\n        for (int topN : topNs) {\n            for (int valueCount : valueCounts) {\n                for (int groupCount : groupCounts) {\n                    for (boolean drainWithRanking : drainWithRankings) {\n                         parameters.add(new Object[] {topN, valueCount, groupCount, drainWithRanking});\n                    }\n                }\n            }\n        }\n       return parameters.toArray(new Object[0][]);\n    }\n\nand then in test:\n    @Test(dataProvider = \"parameters\")\n    public void testSinglePeerGroupInsert(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n    {\n      ....\n    }", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547992875", "createdAt": "2020-12-23T14:46:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRankAccumulator.RowComparisonStrategy;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertNotEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankAccumulator\n+{\n+    private static final long NULL_ROW_ID = Long.MIN_VALUE;\n+    private static final RowComparisonStrategy ROW_COMPARISON_STRATEGY = new RowComparisonStrategy()\n+    {\n+        @Override\n+        public int compare(long leftRowId, long rightRowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(leftRowId, NULL_ROW_ID);\n+            assertNotEquals(rightRowId, NULL_ROW_ID);\n+            return Long.compare(leftRowId, rightRowId);\n+        }\n+\n+        @Override\n+        public long hashCode(long rowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(rowId, NULL_ROW_ID);\n+            return rowId;\n+        }\n+    };\n+\n+    @Test\n+    public void testSinglePeerGroupInsert()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTYzMjA2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDo1Mjo1NVrOIKnBTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDo1Mjo1NVrOIKnBTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5NTk4MQ==", "bodyText": "extract from the loop", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547995981", "createdAt": "2020-12-23T14:52:55Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRankAccumulator.RowComparisonStrategy;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertNotEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankAccumulator\n+{\n+    private static final long NULL_ROW_ID = Long.MIN_VALUE;\n+    private static final RowComparisonStrategy ROW_COMPARISON_STRATEGY = new RowComparisonStrategy()\n+    {\n+        @Override\n+        public int compare(long leftRowId, long rightRowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(leftRowId, NULL_ROW_ID);\n+            assertNotEquals(rightRowId, NULL_ROW_ID);\n+            return Long.compare(leftRowId, rightRowId);\n+        }\n+\n+        @Override\n+        public long hashCode(long rowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(rowId, NULL_ROW_ID);\n+            return rowId;\n+        }\n+    };\n+\n+    @Test\n+    public void testSinglePeerGroupInsert()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);\n+        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n+        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n+        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n+\n+        for (int topN : topNs) {\n+            for (int valueCount : valueCounts) {\n+                for (int groupCount : groupCounts) {\n+                    for (boolean drainWithRanking : drainWithRankings) {\n+                        assertSinglePeerGroupInsert(topN, valueCount, groupCount, drainWithRanking);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void assertSinglePeerGroupInsert(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n+    {\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRankAccumulator accumulator = new GroupedTopNRankAccumulator(ROW_COMPARISON_STRATEGY, NULL_ROW_ID, topN, evicted::add);\n+        accumulator.verifyIntegrity();\n+\n+        // Add the same value repeatedly, so everything should be accepted, and all results will have a rank of 1\n+        int rowId = -1;\n+\n+        for (int i = 0; i < valueCount; i++) {\n+            for (int groupId = 0; groupId < groupCount; groupId++) {\n+                assertTrue(accumulator.add(groupId, rowId));\n+                accumulator.verifyIntegrity();\n+\n+                // No evictions because rank does not change for the same input\n+                assertTrue(evicted.isEmpty());\n+            }\n+        }\n+\n+        for (int groupId = 0; groupId < groupCount; groupId++) {\n+            LongBigArray rowIdOutput = new LongBigArray();\n+            LongBigArray rankingOutput = new LongBigArray();\n+            if (drainWithRanking) {\n+                assertEquals(accumulator.drainTo(groupId, rowIdOutput, rankingOutput), valueCount);\n+            }\n+            else {\n+                assertEquals(accumulator.drainTo(groupId, rowIdOutput), valueCount);\n+            }\n+            accumulator.verifyIntegrity();\n+\n+            for (int i = 0; i < valueCount; i++) {\n+                assertEquals(rowIdOutput.get(i), rowId);\n+                if (drainWithRanking) {\n+                    // Everything should have a rank of 1\n+                    assertEquals(rankingOutput.get(i), 1);\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testIncreasingAllUniqueValues()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);\n+        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n+        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n+        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n+\n+        for (int topN : topNs) {\n+            for (int valueCount : valueCounts) {\n+                for (int groupCount : groupCounts) {\n+                    for (boolean drainWithRanking : drainWithRankings) {\n+                        assertIncreasingAllUniqueValues(topN, valueCount, groupCount, drainWithRanking);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void assertIncreasingAllUniqueValues(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n+    {\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRankAccumulator accumulator = new GroupedTopNRankAccumulator(ROW_COMPARISON_STRATEGY, NULL_ROW_ID, topN, evicted::add);\n+        accumulator.verifyIntegrity();\n+\n+        for (int rowId = 0; rowId < valueCount; rowId++) {\n+            for (int groupId = 0; groupId < groupCount; groupId++) {\n+                // Since rowIds are in increasing order, only the first topN will be accepted\n+                assertEquals(accumulator.add(groupId, rowId), rowId < topN);\n+                accumulator.verifyIntegrity();\n+\n+                // No evictions because all results should be rejected at add()\n+                assertTrue(evicted.isEmpty());\n+            }\n+        }\n+\n+        for (int groupId = 0; groupId < groupCount; groupId++) {\n+            LongBigArray rowIdOutput = new LongBigArray();\n+            LongBigArray rankingOutput = new LongBigArray();\n+            long expectedResultCount = Math.min(valueCount, topN);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY1NjQ1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowMDoxNlrOIKnPsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMDo1Mjo1MlrOIK1LEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5OTY2NA==", "bodyText": "Do we need this method at all since we have compare? That would simplify it.\nIs compare consistent with equals regarding nulls? I believe it's consistent regarding NaN, but please double check.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547999664", "createdAt": "2020-12-23T15:00:16Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIyNzg1OA==", "bodyText": "Yes, it is consistent, and must be by definition of grouping ordering/equality", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548227858", "createdAt": "2020-12-23T20:52:52Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5OTY2NA=="}, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY2MDM4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/PageWithPositionEqualsAndHash.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowMToyNlrOIKnSCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMjoxNTo0N1rOIK4yVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDI2Nw==", "bodyText": "Could we limit scope of this interface to just PagesWithPositionHash? PageWithPositionComparator already deals with equality", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548000267", "createdAt": "2020-12-23T15:01:26Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/PageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+\n+/**\n+ * Equals and hash evaluated at the specified page positions. Implementations need to be hash table friendly.\n+ *\n+ * Note: this usage is likely to be megamorphic, so use at your own risk!\n+ */\n+public interface PageWithPositionEqualsAndHash", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI4NzA2Mg==", "bodyText": "There are more optimizations that exist when doing equals than compare (such as variable length values). Given that the hash lookups are the hotspot in this code, it makes sense to give it every chance for speed up -- just as in many ways java objects still implement equals when there is a compareTo available.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548287062", "createdAt": "2020-12-23T22:15:47Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/PageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+\n+/**\n+ * Equals and hash evaluated at the specified page positions. Implementations need to be hash table friendly.\n+ *\n+ * Note: this usage is likely to be megamorphic, so use at your own risk!\n+ */\n+public interface PageWithPositionEqualsAndHash", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDI2Nw=="}, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY2MzY4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowMjoyOVrOIKnT9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMDo1MjoxMFrOIK1J6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDc1Ng==", "bodyText": "static import, but I would just assume -1 is the special value. I don't expect GroupedTopNRankAccumulator to be used in any other context.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548000756", "createdAt": "2020-12-23T15:02:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return equalsAndHash.equals(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public long hashCode(long rowId)\n+                    {\n+                        Page page = pageManager.getPage(rowId);\n+                        int position = pageManager.getPosition(rowId);\n+                        return equalsAndHash.hashCode(page, position);\n+                    }\n                 },\n+                RowReferencePageManager.RESERVED_UNUSED_ROW_ID,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIyNzU2Mw==", "bodyText": "Actually the special is -2, since -1 is already reserved for the unknown row id", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548227563", "createdAt": "2020-12-23T20:52:10Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return equalsAndHash.equals(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public long hashCode(long rowId)\n+                    {\n+                        Page page = pageManager.getPage(rowId);\n+                        int position = pageManager.getPosition(rowId);\n+                        return equalsAndHash.hashCode(page, position);\n+                    }\n                 },\n+                RowReferencePageManager.RESERVED_UNUSED_ROW_ID,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDc1Ng=="}, "originalCommit": null, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY3NTk2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowNjoxOFrOIKnbBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMjowNzo0OVrOIK4dwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMjU2NQ==", "bodyText": "Is it possible to optimize this loop to avoid allocation of row id?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548002565", "createdAt": "2020-12-23T15:06:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -93,56 +120,41 @@ public long getEstimatedSizeInBytes()\n         return INSTANCE_SIZE\n                 + groupByHash.getEstimatedSize()\n                 + pageManager.sizeOf()\n-                + groupedTopNRowNumberAccumulator.sizeOf();\n+                + groupedTopNRankAccumulator.sizeOf();\n     }\n \n     private void processPage(Page newPage, GroupByIdBlock groupIds)\n     {\n         try (LoadCursor loadCursor = pageManager.add(newPage)) {\n-            GroupedTopNRowNumberAccumulator.RowReference rowReferenceView = asRowReferenceView(loadCursor);\n             for (int position = 0; position < newPage.getPositionCount(); position++) {\n                 long groupId = groupIds.getGroupId(position);\n                 loadCursor.advance();\n-                groupedTopNRowNumberAccumulator.add(groupId, rowReferenceView);\n+                long rowId = loadCursor.allocateRowId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI4MTc5Mg==", "bodyText": "You'll notice that we did this optimization in the topNRowNumber because it was possible. I didn't do it here because we hit the LongLong map first, which makes it pointless. I have some downstream changes that might improve this, but it is quite destructive to a lot of this structure, so I didn't want to put that in quite yet.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548281792", "createdAt": "2020-12-23T22:07:49Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -93,56 +120,41 @@ public long getEstimatedSizeInBytes()\n         return INSTANCE_SIZE\n                 + groupByHash.getEstimatedSize()\n                 + pageManager.sizeOf()\n-                + groupedTopNRowNumberAccumulator.sizeOf();\n+                + groupedTopNRankAccumulator.sizeOf();\n     }\n \n     private void processPage(Page newPage, GroupByIdBlock groupIds)\n     {\n         try (LoadCursor loadCursor = pageManager.add(newPage)) {\n-            GroupedTopNRowNumberAccumulator.RowReference rowReferenceView = asRowReferenceView(loadCursor);\n             for (int position = 0; position < newPage.getPositionCount(); position++) {\n                 long groupId = groupIds.getGroupId(position);\n                 loadCursor.advance();\n-                groupedTopNRowNumberAccumulator.add(groupId, rowReferenceView);\n+                long rowId = loadCursor.allocateRowId();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMjU2NQ=="}, "originalCommit": null, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY4NzQwOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowOTo0NVrOIKnhkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMjowNToyM1rOIK4Wtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDI0MQ==", "bodyText": "Double.NaN are also not distinct from each other. Did you check standard how rank() function should be implemented? Or is it DB implementation detail?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548004241", "createdAt": "2020-12-23T15:09:45Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI3OTk5MA==", "bodyText": "NaN behavior is actually not specified in SQL. @dain has a series of PR to try to modify it however due to some user suggestions, but apparently unspecified in spec. The policy here is just to go with whatever we do from grouping.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548279990", "createdAt": "2020-12-23T22:05:23Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDI0MQ=="}, "originalCommit": null, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTY5MDU3OnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNToxMDo1M1rOIKnjkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMToyMTozMVrOIK2d2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDc1Mw==", "bodyText": "Make sure you test peer groups with nulls and NaN", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548004753", "createdAt": "2020-12-23T15:10:53Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIyNjYzMg==", "bodyText": "This actually wouldn't test GroupedTopNRankBuilder since GroupedTopNRankBuilder takes in the comparison and equality strategies as inputs out of its control. We'd be better off testing the whole query if that's the concern.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548226632", "createdAt": "2020-12-23T20:50:37Z", "author": {"login": "erichwang"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDc1Mw=="}, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0OTA0OQ==", "bodyText": "Given that we use:\n        typeOperators = new TypeOperators();\n        blockTypeOperators = new BlockTypeOperators(typeOperators);\n\nI think some basic test here would also work since it would use same comparators, equals as non-test code (just not compiled version)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548249049", "createdAt": "2020-12-23T21:21:31Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDc1Mw=="}, "originalCommit": null, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTcwMjc1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNToxNDo1MlrOIKnqkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMzoyMjo1N1rOIK6njA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNjU0NA==", "bodyText": "this can be compiled (io.prestosql.sql.gen.OrderingCompiler#internalCompilePageWithPositionComparator), so maybe equals should default to compare?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548006544", "createdAt": "2020-12-23T15:14:52Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODMxNzA2OA==", "bodyText": "The equals and hash both need to be compiled actually too. Haven't prioritized that yet since for some reason it isn't the dominant bottleneck here.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548317068", "createdAt": "2020-12-23T23:22:57Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNjU0NA=="}, "originalCommit": null, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTczNTAwOnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNToyNToxNlrOIKn9-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQyMDozOTo1OVrOIMBnfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxMTUxNQ==", "bodyText": "Could you extract this into separate method, e.g:\nvoid assertAccumulatorOutput(GroupedTopNBuilder builder, boolean produceRanking, Page result) {\n   ...\n}\n\nThen you could use it:\nassertAccumulatorOutput(\n  groupedTopNBuilder,\n  produceRankings,\n  rowPageBuilder(types)\n   .row(0L, 0.1)\n   .row(1L, 0.2)\n   .row(0L, 0.3)\n   .row(0L, 0.2)\n   .row(1L, 0.5)\n   .row(1L, 0.4)\n   .row(1L, 0.3)\n   .row(1L, 0.3)\n   .build())", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548011515", "createdAt": "2020-12-23T15:25:16Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder\n+{\n+    private TypeOperators typeOperators;\n+    private BlockTypeOperators blockTypeOperators;\n+\n+    @BeforeMethod\n+    public void setUp()\n+    {\n+        typeOperators = new TypeOperators();\n+        blockTypeOperators = new BlockTypeOperators(typeOperators);\n+    }\n+\n+    @DataProvider\n+    public static Object[][] produceRanking()\n+    {\n+        return new Object[][] {{true}, {false}};\n+    }\n+\n+    @Test\n+    public void testEmptyInput()\n+    {\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                ImmutableList.of(BIGINT),\n+                (left, leftPosition, right, rightPosition) -> {\n+                    throw new UnsupportedOperationException();\n+                },\n+                new PageWithPositionEqualsAndHash()\n+                {\n+                    @Override\n+                    public boolean equals(Page left, int leftPosition, Page right, int rightPosition)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+\n+                    @Override\n+                    public long hashCode(Page page, int position)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+                },\n+                5,\n+                false,\n+                new NoChannelGroupByHash());\n+        assertFalse(groupedTopNBuilder.buildResult().hasNext());\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testSingleGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(DOUBLE);\n+\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(0), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(0), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                new NoChannelGroupByHash());\n+\n+        // Expected effect: [0.2 x 1 => rank=1, 0.3 x 2 => rank=2]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.3)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because single value 0.4 is too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.4)\n+                        .build()).process());\n+\n+        // Next page should cause 0.3 values to be evicted (first page will be compacted)\n+        // Expected effect: [0.1 x 2 => rank 1, 0.2 x 3 => rank 3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.1)\n+                        .row(0.2)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .row(0.1)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {\n+            Page expected = rowPageBuilder(DOUBLE, BIGINT)\n+                    .row(0.1, 1)\n+                    .row(0.1, 1)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE, BIGINT), getOnlyElement(output), expected);\n+        }\n+        else {\n+            Page expected = rowPageBuilder(DOUBLE)\n+                    .row(0.1)\n+                    .row(0.1)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE), getOnlyElement(output), expected);\n+        }\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testMultiGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(BIGINT, DOUBLE);\n+\n+        GroupByHash groupByHash = createGroupByHash(ImmutableList.of(types.get(0)), ImmutableList.of(0), NOOP);\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(1), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(1), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                groupByHash);\n+\n+        // Expected effect:\n+        // Group 0 [0.2 x 1 => rank=1, 0.3 x 3 => rank=2]\n+        // Group 1 [0.2 x 1 => rank=1]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because all values too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.4)\n+                        .row(1L, 0.4)\n+                        .build()).process());\n+\n+        // Next page should cause evict 0.3 from group 0, which should cause the first page to be compacted\n+        // Expected effect:\n+        // Group 0 [0.1 x 1 => rank=1, 0.2 x 2 => rank=2]\n+        // Group 1 [0.2 x 2 => rank=1, 0.3 x 2 => rank=3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.1)\n+                        .row(1L, 0.2)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.5)\n+                        .row(1L, 0.4)\n+                        .row(1L, 0.3)\n+                        .row(1L, 0.3)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM0MDE2Nw==", "bodyText": "Actually, this doesn't save anything since the code bulk comes from building the expected page results based on produceRankings, and not very much from the actual assertion itself.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548340167", "createdAt": "2020-12-24T01:19:00Z", "author": {"login": "erichwang"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder\n+{\n+    private TypeOperators typeOperators;\n+    private BlockTypeOperators blockTypeOperators;\n+\n+    @BeforeMethod\n+    public void setUp()\n+    {\n+        typeOperators = new TypeOperators();\n+        blockTypeOperators = new BlockTypeOperators(typeOperators);\n+    }\n+\n+    @DataProvider\n+    public static Object[][] produceRanking()\n+    {\n+        return new Object[][] {{true}, {false}};\n+    }\n+\n+    @Test\n+    public void testEmptyInput()\n+    {\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                ImmutableList.of(BIGINT),\n+                (left, leftPosition, right, rightPosition) -> {\n+                    throw new UnsupportedOperationException();\n+                },\n+                new PageWithPositionEqualsAndHash()\n+                {\n+                    @Override\n+                    public boolean equals(Page left, int leftPosition, Page right, int rightPosition)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+\n+                    @Override\n+                    public long hashCode(Page page, int position)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+                },\n+                5,\n+                false,\n+                new NoChannelGroupByHash());\n+        assertFalse(groupedTopNBuilder.buildResult().hasNext());\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testSingleGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(DOUBLE);\n+\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(0), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(0), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                new NoChannelGroupByHash());\n+\n+        // Expected effect: [0.2 x 1 => rank=1, 0.3 x 2 => rank=2]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.3)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because single value 0.4 is too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.4)\n+                        .build()).process());\n+\n+        // Next page should cause 0.3 values to be evicted (first page will be compacted)\n+        // Expected effect: [0.1 x 2 => rank 1, 0.2 x 3 => rank 3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.1)\n+                        .row(0.2)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .row(0.1)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {\n+            Page expected = rowPageBuilder(DOUBLE, BIGINT)\n+                    .row(0.1, 1)\n+                    .row(0.1, 1)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE, BIGINT), getOnlyElement(output), expected);\n+        }\n+        else {\n+            Page expected = rowPageBuilder(DOUBLE)\n+                    .row(0.1)\n+                    .row(0.1)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE), getOnlyElement(output), expected);\n+        }\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testMultiGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(BIGINT, DOUBLE);\n+\n+        GroupByHash groupByHash = createGroupByHash(ImmutableList.of(types.get(0)), ImmutableList.of(0), NOOP);\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(1), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(1), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                groupByHash);\n+\n+        // Expected effect:\n+        // Group 0 [0.2 x 1 => rank=1, 0.3 x 3 => rank=2]\n+        // Group 1 [0.2 x 1 => rank=1]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because all values too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.4)\n+                        .row(1L, 0.4)\n+                        .build()).process());\n+\n+        // Next page should cause evict 0.3 from group 0, which should cause the first page to be compacted\n+        // Expected effect:\n+        // Group 0 [0.1 x 1 => rank=1, 0.2 x 2 => rank=2]\n+        // Group 1 [0.2 x 2 => rank=1, 0.3 x 2 => rank=3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.1)\n+                        .row(1L, 0.2)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.5)\n+                        .row(1L, 0.4)\n+                        .row(1L, 0.3)\n+                        .row(1L, 0.3)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxMTUxNQ=="}, "originalCommit": null, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MDMxNg==", "bodyText": "List<Page> expectedPages = pages.stream()\n  .map(page -> page.getColumns(0))\n  .collect(toImmutableList())", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549480316", "createdAt": "2020-12-28T20:39:59Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder\n+{\n+    private TypeOperators typeOperators;\n+    private BlockTypeOperators blockTypeOperators;\n+\n+    @BeforeMethod\n+    public void setUp()\n+    {\n+        typeOperators = new TypeOperators();\n+        blockTypeOperators = new BlockTypeOperators(typeOperators);\n+    }\n+\n+    @DataProvider\n+    public static Object[][] produceRanking()\n+    {\n+        return new Object[][] {{true}, {false}};\n+    }\n+\n+    @Test\n+    public void testEmptyInput()\n+    {\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                ImmutableList.of(BIGINT),\n+                (left, leftPosition, right, rightPosition) -> {\n+                    throw new UnsupportedOperationException();\n+                },\n+                new PageWithPositionEqualsAndHash()\n+                {\n+                    @Override\n+                    public boolean equals(Page left, int leftPosition, Page right, int rightPosition)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+\n+                    @Override\n+                    public long hashCode(Page page, int position)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+                },\n+                5,\n+                false,\n+                new NoChannelGroupByHash());\n+        assertFalse(groupedTopNBuilder.buildResult().hasNext());\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testSingleGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(DOUBLE);\n+\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(0), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(0), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                new NoChannelGroupByHash());\n+\n+        // Expected effect: [0.2 x 1 => rank=1, 0.3 x 2 => rank=2]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.3)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because single value 0.4 is too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.4)\n+                        .build()).process());\n+\n+        // Next page should cause 0.3 values to be evicted (first page will be compacted)\n+        // Expected effect: [0.1 x 2 => rank 1, 0.2 x 3 => rank 3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.1)\n+                        .row(0.2)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .row(0.1)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {\n+            Page expected = rowPageBuilder(DOUBLE, BIGINT)\n+                    .row(0.1, 1)\n+                    .row(0.1, 1)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE, BIGINT), getOnlyElement(output), expected);\n+        }\n+        else {\n+            Page expected = rowPageBuilder(DOUBLE)\n+                    .row(0.1)\n+                    .row(0.1)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE), getOnlyElement(output), expected);\n+        }\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testMultiGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(BIGINT, DOUBLE);\n+\n+        GroupByHash groupByHash = createGroupByHash(ImmutableList.of(types.get(0)), ImmutableList.of(0), NOOP);\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(1), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(1), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                groupByHash);\n+\n+        // Expected effect:\n+        // Group 0 [0.2 x 1 => rank=1, 0.3 x 3 => rank=2]\n+        // Group 1 [0.2 x 1 => rank=1]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because all values too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.4)\n+                        .row(1L, 0.4)\n+                        .build()).process());\n+\n+        // Next page should cause evict 0.3 from group 0, which should cause the first page to be compacted\n+        // Expected effect:\n+        // Group 0 [0.1 x 1 => rank=1, 0.2 x 2 => rank=2]\n+        // Group 1 [0.2 x 2 => rank=1, 0.3 x 2 => rank=3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.1)\n+                        .row(1L, 0.2)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.5)\n+                        .row(1L, 0.4)\n+                        .row(1L, 0.3)\n+                        .row(1L, 0.3)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxMTUxNQ=="}, "originalCommit": null, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTc1MzY0OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/analyzer/FeaturesConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozMToyNFrOIKoJMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMTo1MzoyMVrOIK32IQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNDM4Ng==", "bodyText": "You should remove optimizeTopNRowNumber feature config too (and add it to @DefunctConfig list)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548014386", "createdAt": "2020-12-23T15:31:24Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/analyzer/FeaturesConfig.java", "diffHunk": "@@ -444,6 +445,19 @@ public FeaturesConfig setOptimizeTopNRowNumber(boolean optimizeTopNRowNumber)\n         return this;\n     }\n \n+    public boolean isOptimizeTopNRanking()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIyNDkyMg==", "bodyText": "Can't move to DefunctConfig list quite yet. We probably need a minimal transition period for people to be warned that the old config is being deprecated in the future.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548224922", "createdAt": "2020-12-23T20:48:29Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/sql/analyzer/FeaturesConfig.java", "diffHunk": "@@ -444,6 +445,19 @@ public FeaturesConfig setOptimizeTopNRowNumber(boolean optimizeTopNRowNumber)\n         return this;\n     }\n \n+    public boolean isOptimizeTopNRanking()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNDM4Ng=="}, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI3MTY0OQ==", "bodyText": "isOptimizeTopNRowNumber is not used after this commit, so you effectively defunc it.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548271649", "createdAt": "2020-12-23T21:53:21Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/analyzer/FeaturesConfig.java", "diffHunk": "@@ -444,6 +445,19 @@ public FeaturesConfig setOptimizeTopNRowNumber(boolean optimizeTopNRowNumber)\n         return this;\n     }\n \n+    public boolean isOptimizeTopNRanking()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNDM4Ng=="}, "originalCommit": null, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTc1ODkzOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozMzoyMVrOIKoMYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozMzoyMVrOIKoMYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNTIwMA==", "bodyText": "this rename belongs to previous commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548015200", "createdAt": "2020-12-23T15:33:21Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -215,7 +215,7 @@ private PlanNode rewriteFilterSource(FilterNode filterNode, PlanNode source, Sym\n             ExtractionResult extractionResult = fromPredicate(metadata, typeOperators, session, filterNode.getPredicate(), types);\n             TupleDomain<Symbol> tupleDomain = extractionResult.getTupleDomain();\n \n-            if (!allValuesInDomain(tupleDomain, rankingSymbol, upperBound)) {\n+            if (!allRankingValuesInDomain(tupleDomain, rankingSymbol, upperBound)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTc2MTQ2OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozNDowMFrOIKoNyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozNDowMFrOIKoNyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNTU2MQ==", "bodyText": "Is it possible to write a test?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548015561", "createdAt": "2020-12-23T15:34:00Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -241,7 +241,7 @@ private static boolean allValuesInDomain(TupleDomain<Symbol> tupleDomain, Symbol\n             if (domain == null) {\n                 return true;\n             }\n-            return domain.getValues().contains(ValueSet.ofRanges(range(domain.getType(), 0L, true, upperBound, true)));\n+            return domain.getValues().contains(ValueSet.ofRanges(range(domain.getType(), 1L, true, upperBound, true)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTc4MjQwOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MDoyN1rOIKoaWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MDoyN1rOIKoaWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxODc3Ng==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548018776", "createdAt": "2020-12-23T15:40:27Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "diffHunk": "@@ -95,19 +98,30 @@ public PushPredicateThroughProjectIntoWindow(Metadata metadata, TypeOperators ty\n                         .matching(ProjectNode::isIdentity)\n                         .capturedAs(PROJECT)\n                         .with(source().matching(window()\n-                                .matching(window -> {\n-                                    if (window.getOrderingScheme().isEmpty()) {\n-                                        return false;\n-                                    }\n-                                    if (window.getWindowFunctions().size() != 1) {\n-                                        return false;\n-                                    }\n-                                    FunctionId functionId = getOnlyElement(window.getWindowFunctions().values()).getResolvedFunction().getFunctionId();\n-                                    return functionId.equals(metadata.resolveFunction(QualifiedName.of(\"row_number\"), ImmutableList.of()).getFunctionId());\n-                                })\n+                                .matching(window -> toRankingType(metadata, window) != null)\n                                 .capturedAs(WINDOW)))));\n     }\n \n+    @Nullable\n+    private static RankingType toRankingType(Metadata metadata, WindowNode window)\n+    {\n+        if (window.getOrderingScheme().isEmpty()) {\n+            return null;\n+        }\n+        if (window.getWindowFunctions().size() != 1) {\n+            return null;\n+        }\n+\n+        FunctionId functionId = getOnlyElement(window.getWindowFunctions().values()).getResolvedFunction().getFunctionId();\n+        if (functionId.equals(metadata.resolveFunction(QualifiedName.of(\"row_number\"), ImmutableList.of()).getFunctionId())) {\n+            return RankingType.ROW_NUMBER;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NTc4NTM5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MTozN1rOIKocNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MTozN1rOIKocNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxOTI1Mw==", "bodyText": "return Optional here", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548019253", "createdAt": "2020-12-23T15:41:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -298,16 +306,29 @@ private TopNRankingNode convertToTopNRanking(WindowNode windowNode, RankingType\n \n         private boolean canReplaceWithRowNumber(WindowNode node)\n         {\n-            return canOptimizeWindowFunction(node) && node.getOrderingScheme().isEmpty();\n+            if (node.getWindowFunctions().size() != 1) {\n+                return false;\n+            }\n+            Symbol rankingSymbol = getOnlyElement(node.getWindowFunctions().entrySet()).getKey();\n+            FunctionId functionId = node.getWindowFunctions().get(rankingSymbol).getResolvedFunction().getFunctionId();\n+            return functionId.equals(rowNumberFunctionId) && node.getOrderingScheme().isEmpty();\n         }\n \n-        private boolean canOptimizeWindowFunction(WindowNode node)\n+        @Nullable\n+        private RankingType toTopNRankingType(WindowNode node)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0NzMxOTIxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/sql/planner/optimizations/TestWindowFilterPushDown.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMTo1MDoxNFrOIK3t3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yNFQwMTozNTo1N1rOIK8O1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI2OTUzMg==", "bodyText": "static import format", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548269532", "createdAt": "2020-12-23T21:50:14Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/sql/planner/optimizations/TestWindowFilterPushDown.java", "diffHunk": "@@ -101,74 +158,81 @@ public void testFilterAboveWindow()\n \n         // remove subplan if predicate on row number symbol can't be satisfied\n         assertPlanWithSession(\n-                \"SELECT * FROM (SELECT name, row_number() OVER(ORDER BY name) FROM nation) t(name, row_number) WHERE row_number < 0\",\n+                String.format(\"SELECT * FROM (SELECT name, %s() OVER(ORDER BY name) FROM nation) t(name, ranking) WHERE ranking < 0\", rankingFunction),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM0MzUxMQ==", "bodyText": "I forgot how much we like to static import everything in this project =).", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548343511", "createdAt": "2020-12-24T01:35:57Z", "author": {"login": "erichwang"}, "path": "presto-main/src/test/java/io/prestosql/sql/planner/optimizations/TestWindowFilterPushDown.java", "diffHunk": "@@ -101,74 +158,81 @@ public void testFilterAboveWindow()\n \n         // remove subplan if predicate on row number symbol can't be satisfied\n         assertPlanWithSession(\n-                \"SELECT * FROM (SELECT name, row_number() OVER(ORDER BY name) FROM nation) t(name, row_number) WHERE row_number < 0\",\n+                String.format(\"SELECT * FROM (SELECT name, %s() OVER(ORDER BY name) FROM nation) t(name, ranking) WHERE ranking < 0\", rankingFunction),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI2OTUzMg=="}, "originalCommit": null, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ1NzYyODU1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRankingOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMTowMzozOFrOIMMyJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMTowMzozOFrOIMMyJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MzI3MQ==", "bodyText": "static import ASC_NULLS_FIRST", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549663271", "createdAt": "2020-12-29T11:03:38Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRankingOperator.java", "diffHunk": "@@ -243,4 +244,57 @@ public void testMemoryReservationYield()\n         }\n         assertEquals(count, 1_000 * 500);\n     }\n+\n+    @Test\n+    public void testRankNullAndNan()\n+    {\n+        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(BIGINT, DOUBLE);\n+        List<Page> input = rowPagesBuilder\n+                .row(1L, null)\n+                .row(2L, 0.2)\n+                .row(2L, Double.NaN)\n+                .row(3L, 0.1)\n+                .row(3L, 0.91)\n+                .pageBreak()\n+                .row(1L, 0.4)\n+                .pageBreak()\n+                .row(1L, 0.5)\n+                .row(1L, null)\n+                .row(1L, 0.6)\n+                .row(2L, 0.7)\n+                .row(2L, Double.NaN)\n+                .build();\n+\n+        TopNRankingOperatorFactory operatorFactory = new TopNRankingOperatorFactory(\n+                0,\n+                new PlanNodeId(\"test\"),\n+                RANK,\n+                ImmutableList.of(BIGINT, DOUBLE),\n+                Ints.asList(1, 0),\n+                Ints.asList(0),\n+                ImmutableList.of(BIGINT),\n+                Ints.asList(1),\n+                ImmutableList.of(SortOrder.ASC_NULLS_FIRST),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ1NzY5MzU5OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMTozNzoxMFrOIMNWaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxNzo1Nzo1NlrOIMU4Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY3MjU1Mw==", "bodyText": "window operator behaves differently regarding NaNs (#6462). They are not equal there because window operator uses io.prestosql.operator.PagesHashStrategy#rowEqualsRow (which treats nulls as equal, but not NaNs)\nI think we should use equality here too. It should be fine to have two rows non-equal but compare=0. Essentially, such rows will be placed next to each other in absolute ordering, but they will still form different peer groups", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549672553", "createdAt": "2020-12-29T11:37:10Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5NTkwNw==", "bodyText": "For reference, had a discussion with @sopel39 on slack, and the correct SQL standard is to treat the rows using IS DISTINCT FROM as they are here. But we will revert to the prior incorrect behavior in this PR, to handle migration in another PR.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549795907", "createdAt": "2020-12-29T17:57:56Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY3MjU1Mw=="}, "originalCommit": null, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MDk1MjA0OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMTozNlrOIMrQng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQyMjo0NTozMlrOIM2lFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjU5MA==", "bodyText": "Let's remove HACK from commit message. It's just maintaining current semantics. In fact, I would just squash it, but if it would make it easier to revert later on, we could keep it as separate commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550162590", "createdAt": "2020-12-30T11:31:36Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -577,11 +577,11 @@ private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n         verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI4NTM1Mg==", "bodyText": "While it is maintaining current semantics, it is completely at odds with the established design invariants of this class's data structure and API, and it NEEDS to be rolled back asap for this class to become reasonable and cohesive. It happens to work today, but only accidentally. All comments and standard programming expectations on relationship between equals and compare are silently violated here in unexpected ways. The other classes don't have this problem because they use a single comparison method and data structure -- here we need two coordinated data structures that don't agree anymore, and hence my apprehension about this. It can be very error prone, which is why I added the integrity checks to the system to enforce these invariants.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550285352", "createdAt": "2020-12-30T18:23:50Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -577,11 +577,11 @@ private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n         verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjU5MA=="}, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDMyNzQ3Ng==", "bodyText": "All comments and standard programming expectations on relationship between equals and compare are silently violated here in unexpected ways\n\nHard relationship is only between equals and hashCode. compare and equals do not have strict relationship. Consider example, nulls:\n\nare nulls equal? no (equals(null, null)==false)\nare nulls placed in same place in global ordering? yes (compare(null, null)==0)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550327476", "createdAt": "2020-12-30T21:07:47Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -577,11 +577,11 @@ private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n         verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjU5MA=="}, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDM0ODA1Mg==", "bodyText": "Sorry, what i mean is that the design of this specific data structure optimization has this requirement to make sense. In plain java, you are correct, but in this case, the strategies need to be consistent for any input we are providing to this optimization.\nAnyways, I can change the commit message, but we need to get out of this state asap, because I don't even trust myself adding more code here until the invariants are re-established.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550348052", "createdAt": "2020-12-30T22:45:32Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -577,11 +577,11 @@ private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n         verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjU5MA=="}, "originalCommit": null, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MDk1NDI1OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/io/prestosql/operator/TopNRowNumberOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMjo1NFrOIMrR6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxODowMzoyNVrOIMyacA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjkyMA==", "bodyText": "Please create separate PR. This commit is unrelated to rank improvements", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550162920", "createdAt": "2020-12-30T11:32:54Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRowNumberOperator.java", "diffHunk": "@@ -33,7 +33,6 @@\n import static com.google.common.base.Preconditions.checkState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3OTc5Mg==", "bodyText": "@sopel39, this is a prerequisite for this refactor. The rank changes are dependent on these changes to function correctly in the Builder refactor.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550279792", "createdAt": "2020-12-30T18:03:25Z", "author": {"login": "erichwang"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRowNumberOperator.java", "diffHunk": "@@ -33,7 +33,6 @@\n import static com.google.common.base.Preconditions.checkState;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjkyMA=="}, "originalCommit": null, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MDk1NjEzOnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRowNumberOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMzo0NlrOIMrS8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxODowNTowNFrOIMycPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MzE4NA==", "bodyText": "Why would that fail with previous TopNRowNumberOperatorCode code? Was it because BIGINT and DOUBLE comparisons were compatible?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550163184", "createdAt": "2020-12-30T11:33:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRowNumberOperator.java", "diffHunk": "@@ -93,30 +94,30 @@ public void tearDown()\n     @Test(dataProvider = \"hashEnabledValues\")\n     public void testPartitioned(boolean hashEnabled)\n     {\n-        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), BIGINT, DOUBLE);\n+        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), VARCHAR, DOUBLE);\n         List<Page> input = rowPagesBuilder\n-                .row(1L, 0.3)\n-                .row(2L, 0.2)\n-                .row(3L, 0.1)\n-                .row(3L, 0.91)\n+                .row(\"a\", 0.3)\n+                .row(\"b\", 0.2)\n+                .row(\"c\", 0.1)\n+                .row(\"c\", 0.91)\n                 .pageBreak()\n-                .row(1L, 0.4)\n+                .row(\"a\", 0.4)\n                 .pageBreak()\n-                .row(1L, 0.5)\n-                .row(1L, 0.6)\n-                .row(2L, 0.7)\n-                .row(2L, 0.8)\n+                .row(\"a\", 0.5)\n+                .row(\"a\", 0.6)\n+                .row(\"b\", 0.7)\n+                .row(\"b\", 0.8)\n                 .pageBreak()\n-                .row(2L, 0.9)\n+                .row(\"b\", 0.9)\n                 .build();\n \n         TopNRowNumberOperatorFactory operatorFactory = new TopNRowNumberOperatorFactory(\n                 0,\n                 new PlanNodeId(\"test\"),\n-                ImmutableList.of(BIGINT, DOUBLE),\n+                ImmutableList.of(VARCHAR, DOUBLE),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI4MDI1NA==", "bodyText": "This did not fail before, which was the problem -- when it should have. BIGINT and DOUBLE comparisons at the binary are entirely the same, except when it comes to the special Double values like NaN etc. It was previously using BIGINT to process DOUBLE data, and silently succeeding. VARCHAR makes this much more apparent.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550280254", "createdAt": "2020-12-30T18:05:04Z", "author": {"login": "erichwang"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRowNumberOperator.java", "diffHunk": "@@ -93,30 +94,30 @@ public void tearDown()\n     @Test(dataProvider = \"hashEnabledValues\")\n     public void testPartitioned(boolean hashEnabled)\n     {\n-        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), BIGINT, DOUBLE);\n+        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), VARCHAR, DOUBLE);\n         List<Page> input = rowPagesBuilder\n-                .row(1L, 0.3)\n-                .row(2L, 0.2)\n-                .row(3L, 0.1)\n-                .row(3L, 0.91)\n+                .row(\"a\", 0.3)\n+                .row(\"b\", 0.2)\n+                .row(\"c\", 0.1)\n+                .row(\"c\", 0.91)\n                 .pageBreak()\n-                .row(1L, 0.4)\n+                .row(\"a\", 0.4)\n                 .pageBreak()\n-                .row(1L, 0.5)\n-                .row(1L, 0.6)\n-                .row(2L, 0.7)\n-                .row(2L, 0.8)\n+                .row(\"a\", 0.5)\n+                .row(\"a\", 0.6)\n+                .row(\"b\", 0.7)\n+                .row(\"b\", 0.8)\n                 .pageBreak()\n-                .row(2L, 0.9)\n+                .row(\"b\", 0.9)\n                 .build();\n \n         TopNRowNumberOperatorFactory operatorFactory = new TopNRowNumberOperatorFactory(\n                 0,\n                 new PlanNodeId(\"test\"),\n-                ImmutableList.of(BIGINT, DOUBLE),\n+                ImmutableList.of(VARCHAR, DOUBLE),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MzE4NA=="}, "originalCommit": null, "originalPosition": 44}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4334, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}