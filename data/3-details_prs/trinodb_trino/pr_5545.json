{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAyNDY2OTgx", "number": 5545, "title": "Add PagesSerdeContext abstraction to enable temporary buffer reuse", "bodyText": "Reduces the allocation rate of PagesSerde when multiple pages are serialized or deserialized in a batch by reusing byte array buffers and DynamicSliceOutput instances through the new PagesSerdeContext.\nBenchmark Run with GC Profiling Results\nThe above benchmarks for deserialization are no longer valid after identifying an issue of unsafe slice sharing, updated reference:\nBenchmarks with commit 51cff0b7", "createdAt": "2020-10-13T15:27:33Z", "url": "https://github.com/trinodb/trino/pull/5545", "merged": true, "mergeCommit": {"oid": "b9b71612f2a78a29bd95a044c186acfbd8ea7079"}, "closed": true, "closedAt": "2020-11-06T00:19:30Z", "author": {"login": "pettyjamesm"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdSLRGFABqjM4NzIzOTIxMjA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZrr2EgFqTUyNDc3MTYwMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEwNjk3NTI4", "url": "https://github.com/trinodb/trino/pull/5545#pullrequestreview-510697528", "createdAt": "2020-10-16T18:09:23Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQxODowOToyM1rOHjLEDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQyMjowNToyNVrOHlS3jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY0MzQ2OA==", "bodyText": "Don't abbreviate variable names.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r506643468", "createdAt": "2020-10-16T18:09:23Z", "author": {"login": "martint"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY1NDEwNg==", "bodyText": "Capitalize constant: ROW_TYPE", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r506654106", "createdAt": "2020-10-16T18:31:16Z", "author": {"login": "martint"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)\n+    {\n+        Page[] pages = data.dataPages;\n+        PagesSerde serde = data.serde;\n+        for (Page p : pages) {\n+            bh.consume(serde.serialize(p));\n+        }\n+    }\n+\n+    @Benchmark\n+    public void deserialize(BenchmarkData data, Blackhole bh)\n+    {\n+        SerializedPage[] pages = data.serializedPages;\n+        PagesSerde serde = data.serde;\n+        for (SerializedPage p : pages) {\n+            bh.consume(serde.deserialize(p));\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BenchmarkData\n+    {\n+        private static final int ROW_COUNT = 10000;\n+        private static final RowType rowType = RowType.anonymous(ImmutableList.of(VARCHAR, VARCHAR, VARCHAR, VARCHAR));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY1ODM0OQ==", "bodyText": "It seems like this is now used only by tests. We should be able to get rid of it or turn it into a utility method to discourage inadvertent use of it.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r506658349", "createdAt": "2020-10-16T18:40:29Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,213 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()\n+    {\n+        return new PagesSerdeContext();\n+    }\n+\n     public SerializedPage serialize(Page page)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg2ODQ5NA==", "bodyText": "The first time a buffer is released, largerBuffer will be set unconditionally. The second time it's released, smallerBuffer will be set unconditionally. If the second buffer is larger than the first one, we end up with the variables tracking the opposite buffers they should be tracking:\nPagesSerdeContext context = new PagesSerdeContext();\n\ncontext.releaseBuffer(context.acquireBuffer(5));\ncontext.releaseBuffer(context.acquireBuffer(10));\n\nSystem.out.println(\"smaller: \" + context.smallerBuffer.length);\nSystem.out.println(\"larger:  \" + context.largerBuffer.length);\nproduces:\nsmaller: 10\nlarger:  5", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r508868494", "createdAt": "2020-10-20T22:05:25Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,225 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()\n+    {\n+        return new PagesSerdeContext();\n+    }\n+\n     public SerializedPage serialize(Page page)\n     {\n-        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n-        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n-        Slice slice = serializationBuffer.slice();\n-        int uncompressedSize = serializationBuffer.size();\n-        MarkerSet markers = MarkerSet.empty();\n-\n-        if (compressor.isPresent()) {\n-            byte[] compressed = new byte[compressor.get().maxCompressedLength(uncompressedSize)];\n-            int compressedSize = compressor.get().compress(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    uncompressedSize,\n-                    compressed,\n-                    0,\n-                    compressed.length);\n-\n-            if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n-                slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n-                markers.add(COMPRESSED);\n-            }\n+        try (PagesSerdeContext context = newContext()) {\n+            return serialize(context, page);\n         }\n+    }\n \n-        if (spillCipher.isPresent()) {\n-            byte[] encrypted = new byte[spillCipher.get().encryptedMaxLength(slice.length())];\n-            int encryptedSize = spillCipher.get().encrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    encrypted,\n-                    0);\n-\n-            slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n-            markers.add(ENCRYPTED);\n-        }\n+    public SerializedPage serialize(PagesSerdeContext context, Page page)\n+    {\n+        DynamicSliceOutput serializationBuffer = context.acquireSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            writeRawPage(page, serializationBuffer, blockEncodingSerde);\n+            Slice slice = serializationBuffer.slice();\n+            int uncompressedSize = serializationBuffer.size();\n+            MarkerSet markers = MarkerSet.empty();\n \n-        if (!slice.isCompact()) {\n-            slice = Slices.copyOf(slice);\n-        }\n+            if (compressor.isPresent()) {\n+                byte[] compressed = context.acquireBuffer(compressor.get().maxCompressedLength(uncompressedSize));\n+                int compressedSize = compressor.get().compress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        uncompressedSize,\n+                        compressed,\n+                        0,\n+                        compressed.length);\n+\n+                if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n+                    slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n+                    markers.add(COMPRESSED);\n+                    inUseTempBuffer = compressed; // Track the compression buffer as in use\n+                }\n+                else {\n+                    // Eager release of the compression buffer to enable reusing it for encryption without an extra allocation\n+                    context.releaseBuffer(compressed);\n+                }\n+            }\n+\n+            if (spillCipher.isPresent()) {\n+                byte[] encrypted = context.acquireBuffer(spillCipher.get().encryptedMaxLength(slice.length()));\n+                int encryptedSize = spillCipher.get().encrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        encrypted,\n+                        0);\n \n-        return new SerializedPage(slice, markers, page.getPositionCount(), uncompressedSize);\n+                slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n+                markers.add(ENCRYPTED);\n+                //  Previous buffer is no longer in use and can be released\n+                if (inUseTempBuffer != null) {\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = encrypted;\n+            }\n+            //  Resulting slice *must* be copied to ensure the shared buffers aren't referenced after method exit\n+            return new SerializedPage(Slices.copyOf(slice), markers, page.getPositionCount(), uncompressedSize);\n+        }\n+        finally {\n+            context.releaseSliceOutput(serializationBuffer);\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n     }\n \n     public Page deserialize(SerializedPage serializedPage)\n+    {\n+        try (PagesSerdeContext context = newContext()) {\n+            return deserialize(context, serializedPage);\n+        }\n+    }\n+\n+    public Page deserialize(PagesSerdeContext context, SerializedPage serializedPage)\n     {\n         checkArgument(serializedPage != null, \"serializedPage is null\");\n \n         Slice slice = serializedPage.getSlice();\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            if (serializedPage.isEncrypted()) {\n+                checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+\n+                byte[] decrypted = context.acquireBuffer(spillCipher.get().decryptedMaxLength(slice.length()));\n+                int decryptedSize = spillCipher.get().decrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decrypted,\n+                        0);\n+\n+                slice = Slices.wrappedBuffer(decrypted, 0, decryptedSize);\n+                inUseTempBuffer = decrypted;\n+            }\n+\n+            if (serializedPage.isCompressed()) {\n+                checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n+\n+                int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n+                byte[] decompressed = context.acquireBuffer(uncompressedSize);\n+                checkState(decompressor.get().decompress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decompressed,\n+                        0,\n+                        uncompressedSize) == uncompressedSize);\n \n-        if (serializedPage.isEncrypted()) {\n-            checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+                slice = Slices.wrappedBuffer(decompressed, 0, uncompressedSize);\n+                if (inUseTempBuffer != null) {\n+                    //  Previous buffer is no longer in use\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = decompressed;\n+            }\n+\n+            return readRawPage(serializedPage.getPositionCount(), slice.getInput(), blockEncodingSerde);\n+        }\n+        finally {\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n+    }\n \n-            byte[] decrypted = new byte[spillCipher.get().decryptedMaxLength(slice.length())];\n-            int decryptedSize = spillCipher.get().decrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    decrypted,\n-                    0);\n+    public static final class PagesSerdeContext\n+            implements AutoCloseable\n+    {\n+        //  Limit retained buffers to 4x the default max page size\n+        private static final int MAX_BUFFER_RETAINED_SIZE = DEFAULT_MAX_PAGE_SIZE_IN_BYTES * 4;\n+\n+        private DynamicSliceOutput sliceOutput;\n+        //  Wraps two buffers since encryption + decryption will use at most 2 buffers at once. Buffers are kept in relative order\n+        //  based on length so that they can be used for compression or encryption, maximizing reuse opportunities\n+        private byte[] largerBuffer;\n+        private byte[] smallerBuffer;\n+        private boolean closed;\n+\n+        private void checkNotClosed()\n+        {\n+            if (closed) {\n+                throw new IllegalStateException(\"PagesSerdeContext is already closed\");\n+            }\n+        }\n \n-            slice = Slices.wrappedBuffer(decrypted, 0, decryptedSize);\n+        private DynamicSliceOutput acquireSliceOutput(int estimatedSize)\n+        {\n+            checkNotClosed();\n+            if (sliceOutput != null && sliceOutput.writableBytes() >= estimatedSize) {\n+                DynamicSliceOutput result = this.sliceOutput;\n+                this.sliceOutput = null;\n+                return result;\n+            }\n+            this.sliceOutput = null; // Clear any existing slice output that might be smaller than the request\n+            return new DynamicSliceOutput(estimatedSize);\n         }\n \n-        if (serializedPage.isCompressed()) {\n-            checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n+        private void releaseSliceOutput(DynamicSliceOutput sliceOutput)\n+        {\n+            if (closed) {\n+                return;\n+            }\n+            sliceOutput.reset();\n+            if (sliceOutput.writableBytes() <= MAX_BUFFER_RETAINED_SIZE) {\n+                this.sliceOutput = sliceOutput;\n+            }\n+        }\n \n-            int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n-            byte[] decompressed = new byte[uncompressedSize];\n-            checkState(decompressor.get().decompress(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    decompressed,\n-                    0,\n-                    uncompressedSize) == uncompressedSize);\n+        private byte[] acquireBuffer(int size)\n+        {\n+            checkNotClosed();\n+            byte[] result;\n+            //  Check the smallest buffer first\n+            if (smallerBuffer != null && smallerBuffer.length >= size) {\n+                result = smallerBuffer;\n+                smallerBuffer = null;\n+                return result;\n+            }\n+            if (largerBuffer != null && largerBuffer.length >= size) {\n+                result = largerBuffer;\n+                largerBuffer = smallerBuffer;\n+                smallerBuffer = null;\n+                return result;\n+            }\n+            return new byte[size];\n+        }\n \n-            slice = Slices.wrappedBuffer(decompressed);\n+        private void releaseBuffer(byte[] buffer)\n+        {\n+            if (closed || buffer.length > MAX_BUFFER_RETAINED_SIZE) {\n+                return;\n+            }\n+            if (largerBuffer == null) {\n+                largerBuffer = buffer;\n+            }\n+            else if (smallerBuffer == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 278}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzNDYzNzg5", "url": "https://github.com/trinodb/trino/pull/5545#pullrequestreview-513463789", "createdAt": "2020-10-21T09:07:46Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwOTowNzo0N1rOHlh7yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwOTozMTo1MlrOHli8Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExNTMzNg==", "bodyText": "You can simply return serialized pages. They don't have to be consumed by Blackhole", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509115336", "createdAt": "2020-10-21T09:07:47Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExNTQ5OA==", "bodyText": "please return deserialized pages", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509115498", "createdAt": "2020-10-21T09:08:01Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)\n+    {\n+        Page[] pages = data.dataPages;\n+        PagesSerde serde = data.serde;\n+        for (Page p : pages) {\n+            bh.consume(serde.serialize(p));\n+        }\n+    }\n+\n+    @Benchmark\n+    public void deserialize(BenchmarkData data, Blackhole bh)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExNjY2OA==", "bodyText": "use different types (instead of just VACHAR)", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509116668", "createdAt": "2020-10-21T09:09:48Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)\n+    {\n+        Page[] pages = data.dataPages;\n+        PagesSerde serde = data.serde;\n+        for (Page p : pages) {\n+            bh.consume(serde.serialize(p));\n+        }\n+    }\n+\n+    @Benchmark\n+    public void deserialize(BenchmarkData data, Blackhole bh)\n+    {\n+        SerializedPage[] pages = data.serializedPages;\n+        PagesSerde serde = data.serde;\n+        for (SerializedPage p : pages) {\n+            bh.consume(serde.deserialize(p));\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BenchmarkData\n+    {\n+        private static final int ROW_COUNT = 10000;\n+        private static final RowType rowType = RowType.anonymous(ImmutableList.of(VARCHAR, VARCHAR, VARCHAR, VARCHAR));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExODM1MA==", "bodyText": "Just make it a field as in BenchmarkData, see: io.prestosql.orc.BenchmarkColumnReaders.BenchmarkData#random", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509118350", "createdAt": "2020-10-21T09:12:26Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)\n+    {\n+        Page[] pages = data.dataPages;\n+        PagesSerde serde = data.serde;\n+        for (Page p : pages) {\n+            bh.consume(serde.serialize(p));\n+        }\n+    }\n+\n+    @Benchmark\n+    public void deserialize(BenchmarkData data, Blackhole bh)\n+    {\n+        SerializedPage[] pages = data.serializedPages;\n+        PagesSerde serde = data.serde;\n+        for (SerializedPage p : pages) {\n+            bh.consume(serde.deserialize(p));\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BenchmarkData\n+    {\n+        private static final int ROW_COUNT = 10000;\n+        private static final RowType rowType = RowType.anonymous(ImmutableList.of(VARCHAR, VARCHAR, VARCHAR, VARCHAR));\n+        private static final List<Type> TYPES = ImmutableList.of(BIGINT, rowType, rowType, rowType);\n+        @Param({\"true\", \"false\"})\n+        private boolean encrypted;\n+        @Param({\"true\", \"false\"})\n+        private boolean compressed;\n+        @Param(\"1000\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExOTA5OQ==", "bodyText": "add a test method for benchmarks, see: io.prestosql.orc.BenchmarkOrcDecimalReader#testReadDecimal", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509119099", "createdAt": "2020-10-21T09:13:35Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.RowType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spiller.AesSpillCipher;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Random;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.metadata.MetadataManager.createTestMetadataManager;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.nio.charset.StandardCharsets.ISO_8859_1;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(SECONDS)\n+@Fork(1)\n+@Warmup(iterations = 10, time = 1, timeUnit = SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = SECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+public class BenchmarkPagesSerde\n+{\n+    @Benchmark\n+    public void serialize(BenchmarkData data, Blackhole bh)\n+    {\n+        Page[] pages = data.dataPages;\n+        PagesSerde serde = data.serde;\n+        for (Page p : pages) {\n+            bh.consume(serde.serialize(p));\n+        }\n+    }\n+\n+    @Benchmark\n+    public void deserialize(BenchmarkData data, Blackhole bh)\n+    {\n+        SerializedPage[] pages = data.serializedPages;\n+        PagesSerde serde = data.serde;\n+        for (SerializedPage p : pages) {\n+            bh.consume(serde.deserialize(p));\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BenchmarkData\n+    {\n+        private static final int ROW_COUNT = 10000;\n+        private static final RowType rowType = RowType.anonymous(ImmutableList.of(VARCHAR, VARCHAR, VARCHAR, VARCHAR));\n+        private static final List<Type> TYPES = ImmutableList.of(BIGINT, rowType, rowType, rowType);\n+        @Param({\"true\", \"false\"})\n+        private boolean encrypted;\n+        @Param({\"true\", \"false\"})\n+        private boolean compressed;\n+        @Param(\"1000\")\n+        private int randomSeed = 1000;\n+\n+        private PagesSerde serde;\n+        private Page[] dataPages;\n+        private SerializedPage[] serializedPages;\n+\n+        @Setup\n+        public void initialize()\n+        {\n+            serde = createPagesSerde();\n+            dataPages = createPages();\n+            serializedPages = createSerializedPages();\n+        }\n+\n+        public Page[] getDataPages()\n+        {\n+            return dataPages;\n+        }\n+\n+        private PagesSerde createPagesSerde()\n+        {\n+            PagesSerdeFactory serdeFactory = new PagesSerdeFactory(createTestMetadataManager().getBlockEncodingSerde(), compressed);\n+            return encrypted ? serdeFactory.createPagesSerdeForSpill(Optional.of(new AesSpillCipher())) : serdeFactory.createPagesSerde();\n+        }\n+\n+        private SerializedPage[] createSerializedPages()\n+        {\n+            SerializedPage[] result = new SerializedPage[dataPages.length];\n+            for (int i = 0; i < result.length; i++) {\n+                result[i] = serde.serialize(dataPages[i]);\n+            }\n+            return result;\n+        }\n+\n+        private Page[] createPages()\n+        {\n+            Random random = new Random(randomSeed);\n+            List<Page> pages = new ArrayList<>();\n+            int remainingRows = ROW_COUNT;\n+            PageBuilder pageBuilder = new PageBuilder(TYPES);\n+            while (remainingRows > 0) {\n+                int rows = 50 + random.nextInt(450); // 50 - 500 rows per pass\n+                List<Object>[] testRows = generateTestRows(random, ImmutableList.of(VARCHAR, VARCHAR, VARCHAR, VARCHAR), rows);\n+                remainingRows -= rows;\n+                for (int i = 0; i < testRows.length; i++) {\n+                    BIGINT.writeLong(pageBuilder.getBlockBuilder(0), i);\n+                    writeRow(testRows[i], pageBuilder.getBlockBuilder(1));\n+                    writeRow(testRows[i], pageBuilder.getBlockBuilder(2));\n+                    writeRow(testRows[i], pageBuilder.getBlockBuilder(3));\n+                }\n+                pageBuilder.declarePositions(rows);\n+                pages.add(pageBuilder.build());\n+                pageBuilder.reset();\n+            }\n+            return pages.toArray(Page[]::new);\n+        }\n+\n+        private void writeRow(List<Object> testRow, BlockBuilder rowBlockBuilder)\n+        {\n+            BlockBuilder singleRowBlockWriter = rowBlockBuilder.beginBlockEntry();\n+            for (Object fieldValue : testRow) {\n+                if (fieldValue == null) {\n+                    singleRowBlockWriter.appendNull();\n+                }\n+                else if (fieldValue instanceof String) {\n+                    VARCHAR.writeSlice(singleRowBlockWriter, utf8Slice((String) fieldValue));\n+                }\n+                else {\n+                    throw new UnsupportedOperationException();\n+                }\n+            }\n+            rowBlockBuilder.closeEntry();\n+        }\n+\n+        // copied & modifed from TestRowBlock\n+        private List<Object>[] generateTestRows(Random random, List<Type> fieldTypes, int numRows)\n+        {\n+            @SuppressWarnings(\"unchecked\")\n+            List<Object>[] testRows = new List[numRows];\n+            for (int i = 0; i < numRows; i++) {\n+                List<Object> testRow = new ArrayList<>(fieldTypes.size());\n+                for (int j = 0; j < fieldTypes.size(); j++) {\n+                    if (fieldTypes.get(j) == VARCHAR) {\n+                        byte[] data = new byte[random.nextInt(128)];\n+                        if (data.length == 0) {\n+                            testRow.add(null);\n+                        }\n+                        else if (data.length < 32 && i > 0) {\n+                            // Repeat values to make compression more interesting\n+                            testRow.add(testRows[i - 1].get(j));\n+                        }\n+                        else {\n+                            random.nextBytes(data);\n+                            testRow.add(new String(data, ISO_8859_1));\n+                        }\n+                    }\n+                    else {\n+                        throw new UnsupportedOperationException();\n+                    }\n+                }\n+                testRows[i] = testRow;\n+            }\n+            return testRows;\n+        }\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEyMTc5OQ==", "bodyText": "Please model benchmarks after io/prestosql/orc/BenchmarkColumnReaders.java. This means benchmarking different column serdes (we can start with Long block only). Block serialization/deserialization consumes large chunk of time when serializing pages.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509121799", "createdAt": "2020-10-21T09:17:32Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEyMjM3OQ==", "bodyText": "I actually started working on similar benchmarks, here is my draft:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /*\n          \n          \n            \n            /*\n          \n          \n            \n             * Licensed under the Apache License, Version 2.0 (the \"License\");\n          \n          \n            \n             * you may not use this file except in compliance with the License.\n          \n          \n            \n             * You may obtain a copy of the License at\n          \n          \n            \n             *\n          \n          \n            \n             *     http://www.apache.org/licenses/LICENSE-2.0\n          \n          \n            \n             *\n          \n          \n            \n             * Unless required by applicable law or agreed to in writing, software\n          \n          \n            \n             * distributed under the License is distributed on an \"AS IS\" BASIS,\n          \n          \n            \n             * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n          \n          \n            \n             * See the License for the specific language governing permissions and\n          \n          \n            \n             * limitations under the License.\n          \n          \n            \n             */\n          \n          \n            \n            package io.prestosql.execution.buffer;\n          \n          \n            \n            \n          \n          \n            \n            import com.google.common.collect.ImmutableList;\n          \n          \n            \n            import io.airlift.slice.BasicSliceInput;\n          \n          \n            \n            import io.airlift.slice.OutputStreamSliceOutput;\n          \n          \n            \n            import io.airlift.slice.Slice;\n          \n          \n            \n            import io.airlift.slice.Slices;\n          \n          \n            \n            import io.prestosql.spi.Page;\n          \n          \n            \n            import io.prestosql.spi.block.Block;\n          \n          \n            \n            import io.prestosql.spi.block.BlockBuilder;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Benchmark;\n          \n          \n            \n            import org.openjdk.jmh.annotations.BenchmarkMode;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Fork;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Measurement;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Mode;\n          \n          \n            \n            import org.openjdk.jmh.annotations.OperationsPerInvocation;\n          \n          \n            \n            import org.openjdk.jmh.annotations.OutputTimeUnit;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Scope;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Setup;\n          \n          \n            \n            import org.openjdk.jmh.annotations.State;\n          \n          \n            \n            import org.openjdk.jmh.annotations.Warmup;\n          \n          \n            \n            import org.openjdk.jmh.runner.Runner;\n          \n          \n            \n            import org.openjdk.jmh.runner.options.Options;\n          \n          \n            \n            import org.openjdk.jmh.runner.options.OptionsBuilder;\n          \n          \n            \n            import org.openjdk.jmh.runner.options.VerboseMode;\n          \n          \n            \n            import org.testng.annotations.Test;\n          \n          \n            \n            \n          \n          \n            \n            import java.io.File;\n          \n          \n            \n            import java.io.FileOutputStream;\n          \n          \n            \n            import java.nio.ByteBuffer;\n          \n          \n            \n            import java.nio.channels.FileChannel;\n          \n          \n            \n            import java.util.ArrayList;\n          \n          \n            \n            import java.util.Iterator;\n          \n          \n            \n            import java.util.List;\n          \n          \n            \n            import java.util.Random;\n          \n          \n            \n            import java.util.concurrent.TimeUnit;\n          \n          \n            \n            \n          \n          \n            \n            import static com.google.common.io.Files.createTempDir;\n          \n          \n            \n            import static io.prestosql.execution.buffer.PagesSerdeUtil.readPages;\n          \n          \n            \n            import static io.prestosql.execution.buffer.PagesSerdeUtil.writePages;\n          \n          \n            \n            import static io.prestosql.spi.type.BigintType.BIGINT;\n          \n          \n            \n            import static java.nio.channels.FileChannel.MapMode.READ_ONLY;\n          \n          \n            \n            import static java.nio.file.Files.readAllBytes;\n          \n          \n            \n            import static java.util.UUID.randomUUID;\n          \n          \n            \n            import static java.util.concurrent.TimeUnit.MILLISECONDS;\n          \n          \n            \n            \n          \n          \n            \n            @State(Scope.Thread)\n          \n          \n            \n            @OutputTimeUnit(TimeUnit.NANOSECONDS)\n          \n          \n            \n            @Fork(3)\n          \n          \n            \n            @Warmup(iterations = 30, time = 500, timeUnit = MILLISECONDS)\n          \n          \n            \n            @Measurement(iterations = 20, time = 500, timeUnit = MILLISECONDS)\n          \n          \n            \n            @BenchmarkMode(Mode.AverageTime)\n          \n          \n            \n            @OperationsPerInvocation(BenchmarkPagesSerde.ROWS)\n          \n          \n            \n            public class BenchmarkPagesSerde\n          \n          \n            \n            {\n          \n          \n            \n                public static final int ROWS = 10_000_000;\n          \n          \n            \n                private static final PagesSerde SERDE = new TestingPagesSerdeFactory().createPagesSerde();\n          \n          \n            \n            \n          \n          \n            \n                @Benchmark\n          \n          \n            \n                public Object readLongWithNull(BenchmarkData data)\n          \n          \n            \n                {\n          \n          \n            \n                    return ImmutableList.copyOf(readPages(SERDE, new BasicSliceInput(data.getDataSource())));\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                @State(Scope.Thread)\n          \n          \n            \n                public static class BenchmarkData\n          \n          \n            \n                {\n          \n          \n            \n                    private final Random random = new Random(0);\n          \n          \n            \n                    private File temporaryDirectory;\n          \n          \n            \n                    private File file;\n          \n          \n            \n                    private Slice dataSource;\n          \n          \n            \n            \n          \n          \n            \n                    @Setup\n          \n          \n            \n                    public void setup()\n          \n          \n            \n                            throws Exception\n          \n          \n            \n                    {\n          \n          \n            \n                        temporaryDirectory = createTempDir();\n          \n          \n            \n                        file = new File(temporaryDirectory, randomUUID().toString());\n          \n          \n            \n                        BlockBuilder blockBuilder = BIGINT.createBlockBuilder(null, 1024);\n          \n          \n            \n                        Iterator<?> values = createValues();\n          \n          \n            \n                        while (values.hasNext()) {\n          \n          \n            \n                            Object value = values.next();\n          \n          \n            \n                            if (value == null) {\n          \n          \n            \n                                blockBuilder.appendNull();\n          \n          \n            \n                            }\n          \n          \n            \n                            else {\n          \n          \n            \n                                BIGINT.writeLong(blockBuilder, ((Number) value).longValue());\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n                        Page page = new Page(blockBuilder.build());\n          \n          \n            \n                        writePages(SERDE, new OutputStreamSliceOutput(new FileOutputStream(file)), page);\n          \n          \n            \n                        dataSource = Slices.wrappedBuffer(readAllBytes(file.toPath()));\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    public Slice getDataSource()\n          \n          \n            \n                    {\n          \n          \n            \n                        return dataSource;\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    protected Iterator<?> createValues()\n          \n          \n            \n                    {\n          \n          \n            \n                        List<Long> values = new ArrayList<>();\n          \n          \n            \n                        for (int i = 0; i < ROWS; ++i) {\n          \n          \n            \n                            if (random.nextBoolean()) {\n          \n          \n            \n                                values.add(random.nextLong());\n          \n          \n            \n                            }\n          \n          \n            \n                            else {\n          \n          \n            \n                                values.add(null);\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n                        return values.iterator();\n          \n          \n            \n                    }\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                @Test\n          \n          \n            \n                public void testReadLongWithNull()\n          \n          \n            \n                        throws Exception\n          \n          \n            \n                {\n          \n          \n            \n                    BenchmarkPagesSerde benchmark = new BenchmarkPagesSerde();\n          \n          \n            \n                    BenchmarkData data = new BenchmarkData();\n          \n          \n            \n                    data.setup();\n          \n          \n            \n                    benchmark.readLongWithNull(data);\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public static void main(String[] args)\n          \n          \n            \n                        throws Exception\n          \n          \n            \n                {\n          \n          \n            \n                    Options options = new OptionsBuilder()\n          \n          \n            \n                            .verbosity(VerboseMode.NORMAL)\n          \n          \n            \n                            .include(\".*\" + BenchmarkPagesSerde.class.getSimpleName() + \".*\")\n          \n          \n            \n                            .build();\n          \n          \n            \n            \n          \n          \n            \n                    new Runner(options).run();\n          \n          \n            \n                }\n          \n          \n            \n            }", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509122379", "createdAt": "2020-10-21T09:18:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkPagesSerde.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEyMTc5OQ=="}, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEyNzExNg==", "bodyText": "why do we need to close it? Java will automatically GC unused objects", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509127116", "createdAt": "2020-10-21T09:25:01Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,225 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()\n+    {\n+        return new PagesSerdeContext();\n+    }\n+\n     public SerializedPage serialize(Page page)\n     {\n-        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n-        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n-        Slice slice = serializationBuffer.slice();\n-        int uncompressedSize = serializationBuffer.size();\n-        MarkerSet markers = MarkerSet.empty();\n-\n-        if (compressor.isPresent()) {\n-            byte[] compressed = new byte[compressor.get().maxCompressedLength(uncompressedSize)];\n-            int compressedSize = compressor.get().compress(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    uncompressedSize,\n-                    compressed,\n-                    0,\n-                    compressed.length);\n-\n-            if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n-                slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n-                markers.add(COMPRESSED);\n-            }\n+        try (PagesSerdeContext context = newContext()) {\n+            return serialize(context, page);\n         }\n+    }\n \n-        if (spillCipher.isPresent()) {\n-            byte[] encrypted = new byte[spillCipher.get().encryptedMaxLength(slice.length())];\n-            int encryptedSize = spillCipher.get().encrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    encrypted,\n-                    0);\n-\n-            slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n-            markers.add(ENCRYPTED);\n-        }\n+    public SerializedPage serialize(PagesSerdeContext context, Page page)\n+    {\n+        DynamicSliceOutput serializationBuffer = context.acquireSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            writeRawPage(page, serializationBuffer, blockEncodingSerde);\n+            Slice slice = serializationBuffer.slice();\n+            int uncompressedSize = serializationBuffer.size();\n+            MarkerSet markers = MarkerSet.empty();\n \n-        if (!slice.isCompact()) {\n-            slice = Slices.copyOf(slice);\n-        }\n+            if (compressor.isPresent()) {\n+                byte[] compressed = context.acquireBuffer(compressor.get().maxCompressedLength(uncompressedSize));\n+                int compressedSize = compressor.get().compress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        uncompressedSize,\n+                        compressed,\n+                        0,\n+                        compressed.length);\n+\n+                if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n+                    slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n+                    markers.add(COMPRESSED);\n+                    inUseTempBuffer = compressed; // Track the compression buffer as in use\n+                }\n+                else {\n+                    // Eager release of the compression buffer to enable reusing it for encryption without an extra allocation\n+                    context.releaseBuffer(compressed);\n+                }\n+            }\n+\n+            if (spillCipher.isPresent()) {\n+                byte[] encrypted = context.acquireBuffer(spillCipher.get().encryptedMaxLength(slice.length()));\n+                int encryptedSize = spillCipher.get().encrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        encrypted,\n+                        0);\n \n-        return new SerializedPage(slice, markers, page.getPositionCount(), uncompressedSize);\n+                slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n+                markers.add(ENCRYPTED);\n+                //  Previous buffer is no longer in use and can be released\n+                if (inUseTempBuffer != null) {\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = encrypted;\n+            }\n+            //  Resulting slice *must* be copied to ensure the shared buffers aren't referenced after method exit\n+            return new SerializedPage(Slices.copyOf(slice), markers, page.getPositionCount(), uncompressedSize);\n+        }\n+        finally {\n+            context.releaseSliceOutput(serializationBuffer);\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n     }\n \n     public Page deserialize(SerializedPage serializedPage)\n+    {\n+        try (PagesSerdeContext context = newContext()) {\n+            return deserialize(context, serializedPage);\n+        }\n+    }\n+\n+    public Page deserialize(PagesSerdeContext context, SerializedPage serializedPage)\n     {\n         checkArgument(serializedPage != null, \"serializedPage is null\");\n \n         Slice slice = serializedPage.getSlice();\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            if (serializedPage.isEncrypted()) {\n+                checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+\n+                byte[] decrypted = context.acquireBuffer(spillCipher.get().decryptedMaxLength(slice.length()));\n+                int decryptedSize = spillCipher.get().decrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decrypted,\n+                        0);\n+\n+                slice = Slices.wrappedBuffer(decrypted, 0, decryptedSize);\n+                inUseTempBuffer = decrypted;\n+            }\n+\n+            if (serializedPage.isCompressed()) {\n+                checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n+\n+                int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n+                byte[] decompressed = context.acquireBuffer(uncompressedSize);\n+                checkState(decompressor.get().decompress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decompressed,\n+                        0,\n+                        uncompressedSize) == uncompressedSize);\n \n-        if (serializedPage.isEncrypted()) {\n-            checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+                slice = Slices.wrappedBuffer(decompressed, 0, uncompressedSize);\n+                if (inUseTempBuffer != null) {\n+                    //  Previous buffer is no longer in use\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = decompressed;\n+            }\n+\n+            return readRawPage(serializedPage.getPositionCount(), slice.getInput(), blockEncodingSerde);\n+        }\n+        finally {\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n+    }\n \n-            byte[] decrypted = new byte[spillCipher.get().decryptedMaxLength(slice.length())];\n-            int decryptedSize = spillCipher.get().decrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    decrypted,\n-                    0);\n+    public static final class PagesSerdeContext\n+            implements AutoCloseable\n+    {\n+        //  Limit retained buffers to 4x the default max page size\n+        private static final int MAX_BUFFER_RETAINED_SIZE = DEFAULT_MAX_PAGE_SIZE_IN_BYTES * 4;\n+\n+        private DynamicSliceOutput sliceOutput;\n+        //  Wraps two buffers since encryption + decryption will use at most 2 buffers at once. Buffers are kept in relative order\n+        //  based on length so that they can be used for compression or encryption, maximizing reuse opportunities\n+        private byte[] largerBuffer;\n+        private byte[] smallerBuffer;\n+        private boolean closed;\n+\n+        private void checkNotClosed()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEyODM1MA==", "bodyText": "can slice output be aquired twice?", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509128350", "createdAt": "2020-10-21T09:26:47Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,225 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()\n+    {\n+        return new PagesSerdeContext();\n+    }\n+\n     public SerializedPage serialize(Page page)\n     {\n-        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n-        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n-        Slice slice = serializationBuffer.slice();\n-        int uncompressedSize = serializationBuffer.size();\n-        MarkerSet markers = MarkerSet.empty();\n-\n-        if (compressor.isPresent()) {\n-            byte[] compressed = new byte[compressor.get().maxCompressedLength(uncompressedSize)];\n-            int compressedSize = compressor.get().compress(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    uncompressedSize,\n-                    compressed,\n-                    0,\n-                    compressed.length);\n-\n-            if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n-                slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n-                markers.add(COMPRESSED);\n-            }\n+        try (PagesSerdeContext context = newContext()) {\n+            return serialize(context, page);\n         }\n+    }\n \n-        if (spillCipher.isPresent()) {\n-            byte[] encrypted = new byte[spillCipher.get().encryptedMaxLength(slice.length())];\n-            int encryptedSize = spillCipher.get().encrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    encrypted,\n-                    0);\n-\n-            slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n-            markers.add(ENCRYPTED);\n-        }\n+    public SerializedPage serialize(PagesSerdeContext context, Page page)\n+    {\n+        DynamicSliceOutput serializationBuffer = context.acquireSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            writeRawPage(page, serializationBuffer, blockEncodingSerde);\n+            Slice slice = serializationBuffer.slice();\n+            int uncompressedSize = serializationBuffer.size();\n+            MarkerSet markers = MarkerSet.empty();\n \n-        if (!slice.isCompact()) {\n-            slice = Slices.copyOf(slice);\n-        }\n+            if (compressor.isPresent()) {\n+                byte[] compressed = context.acquireBuffer(compressor.get().maxCompressedLength(uncompressedSize));\n+                int compressedSize = compressor.get().compress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        uncompressedSize,\n+                        compressed,\n+                        0,\n+                        compressed.length);\n+\n+                if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n+                    slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n+                    markers.add(COMPRESSED);\n+                    inUseTempBuffer = compressed; // Track the compression buffer as in use\n+                }\n+                else {\n+                    // Eager release of the compression buffer to enable reusing it for encryption without an extra allocation\n+                    context.releaseBuffer(compressed);\n+                }\n+            }\n+\n+            if (spillCipher.isPresent()) {\n+                byte[] encrypted = context.acquireBuffer(spillCipher.get().encryptedMaxLength(slice.length()));\n+                int encryptedSize = spillCipher.get().encrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        encrypted,\n+                        0);\n \n-        return new SerializedPage(slice, markers, page.getPositionCount(), uncompressedSize);\n+                slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n+                markers.add(ENCRYPTED);\n+                //  Previous buffer is no longer in use and can be released\n+                if (inUseTempBuffer != null) {\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = encrypted;\n+            }\n+            //  Resulting slice *must* be copied to ensure the shared buffers aren't referenced after method exit\n+            return new SerializedPage(Slices.copyOf(slice), markers, page.getPositionCount(), uncompressedSize);\n+        }\n+        finally {\n+            context.releaseSliceOutput(serializationBuffer);\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n     }\n \n     public Page deserialize(SerializedPage serializedPage)\n+    {\n+        try (PagesSerdeContext context = newContext()) {\n+            return deserialize(context, serializedPage);\n+        }\n+    }\n+\n+    public Page deserialize(PagesSerdeContext context, SerializedPage serializedPage)\n     {\n         checkArgument(serializedPage != null, \"serializedPage is null\");\n \n         Slice slice = serializedPage.getSlice();\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            if (serializedPage.isEncrypted()) {\n+                checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+\n+                byte[] decrypted = context.acquireBuffer(spillCipher.get().decryptedMaxLength(slice.length()));\n+                int decryptedSize = spillCipher.get().decrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decrypted,\n+                        0);\n+\n+                slice = Slices.wrappedBuffer(decrypted, 0, decryptedSize);\n+                inUseTempBuffer = decrypted;\n+            }\n+\n+            if (serializedPage.isCompressed()) {\n+                checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n+\n+                int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n+                byte[] decompressed = context.acquireBuffer(uncompressedSize);\n+                checkState(decompressor.get().decompress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        decompressed,\n+                        0,\n+                        uncompressedSize) == uncompressedSize);\n \n-        if (serializedPage.isEncrypted()) {\n-            checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n+                slice = Slices.wrappedBuffer(decompressed, 0, uncompressedSize);\n+                if (inUseTempBuffer != null) {\n+                    //  Previous buffer is no longer in use\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = decompressed;\n+            }\n+\n+            return readRawPage(serializedPage.getPositionCount(), slice.getInput(), blockEncodingSerde);\n+        }\n+        finally {\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n+        }\n+    }\n \n-            byte[] decrypted = new byte[spillCipher.get().decryptedMaxLength(slice.length())];\n-            int decryptedSize = spillCipher.get().decrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    decrypted,\n-                    0);\n+    public static final class PagesSerdeContext\n+            implements AutoCloseable\n+    {\n+        //  Limit retained buffers to 4x the default max page size\n+        private static final int MAX_BUFFER_RETAINED_SIZE = DEFAULT_MAX_PAGE_SIZE_IN_BYTES * 4;\n+\n+        private DynamicSliceOutput sliceOutput;\n+        //  Wraps two buffers since encryption + decryption will use at most 2 buffers at once. Buffers are kept in relative order\n+        //  based on length so that they can be used for compression or encryption, maximizing reuse opportunities\n+        private byte[] largerBuffer;\n+        private byte[] smallerBuffer;\n+        private boolean closed;\n+\n+        private void checkNotClosed()\n+        {\n+            if (closed) {\n+                throw new IllegalStateException(\"PagesSerdeContext is already closed\");\n+            }\n+        }\n \n-            slice = Slices.wrappedBuffer(decrypted, 0, decryptedSize);\n+        private DynamicSliceOutput acquireSliceOutput(int estimatedSize)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEzMTg0Mw==", "bodyText": "PagesSerde is not thread-safe. It's mean to be used from single-thread. Therefore, we don't need extra PagesSerdeContext. We can keep temporary buffers within PagesSerde itself.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r509131843", "createdAt": "2020-10-21T09:31:52Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,225 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NTc5NDMz", "url": "https://github.com/trinodb/trino/pull/5545#pullrequestreview-516579433", "createdAt": "2020-10-26T09:06:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwOTowNjo0NlrOHoGS7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwOToxNjozMlrOHoGp3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgwODIzOQ==", "bodyText": "ExchangeOperator might benefit from having buffers long-lived.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r511808239", "createdAt": "2020-10-26T09:06:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,216 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n-    public SerializedPage serialize(Page page)\n+    public PagesSerdeContext newContext()\n     {\n-        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n-        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n-        Slice slice = serializationBuffer.slice();\n-        int uncompressedSize = serializationBuffer.size();\n-        MarkerSet markers = MarkerSet.empty();\n-\n-        if (compressor.isPresent()) {\n-            byte[] compressed = new byte[compressor.get().maxCompressedLength(uncompressedSize)];\n-            int compressedSize = compressor.get().compress(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    uncompressedSize,\n-                    compressed,\n-                    0,\n-                    compressed.length);\n-\n-            if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n-                slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n-                markers.add(COMPRESSED);\n+        return new PagesSerdeContext();\n+    }\n+\n+    public SerializedPage serialize(PagesSerdeContext context, Page page)\n+    {\n+        DynamicSliceOutput serializationBuffer = context.acquireSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n+        byte[] inUseTempBuffer = null;\n+        try {\n+            writeRawPage(page, serializationBuffer, blockEncodingSerde);\n+            Slice slice = serializationBuffer.slice();\n+            int uncompressedSize = serializationBuffer.size();\n+            MarkerSet markers = MarkerSet.empty();\n+\n+            if (compressor.isPresent()) {\n+                byte[] compressed = context.acquireBuffer(compressor.get().maxCompressedLength(uncompressedSize));\n+                int compressedSize = compressor.get().compress(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        uncompressedSize,\n+                        compressed,\n+                        0,\n+                        compressed.length);\n+\n+                if ((((double) compressedSize) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n+                    slice = Slices.wrappedBuffer(compressed, 0, compressedSize);\n+                    markers.add(COMPRESSED);\n+                    inUseTempBuffer = compressed; // Track the compression buffer as in use\n+                }\n+                else {\n+                    // Eager release of the compression buffer to enable reusing it for encryption without an extra allocation\n+                    context.releaseBuffer(compressed);\n+                }\n             }\n-        }\n \n-        if (spillCipher.isPresent()) {\n-            byte[] encrypted = new byte[spillCipher.get().encryptedMaxLength(slice.length())];\n-            int encryptedSize = spillCipher.get().encrypt(\n-                    slice.byteArray(),\n-                    slice.byteArrayOffset(),\n-                    slice.length(),\n-                    encrypted,\n-                    0);\n-\n-            slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n-            markers.add(ENCRYPTED);\n-        }\n+            if (spillCipher.isPresent()) {\n+                byte[] encrypted = context.acquireBuffer(spillCipher.get().encryptedMaxLength(slice.length()));\n+                int encryptedSize = spillCipher.get().encrypt(\n+                        slice.byteArray(),\n+                        slice.byteArrayOffset(),\n+                        slice.length(),\n+                        encrypted,\n+                        0);\n \n-        if (!slice.isCompact()) {\n-            slice = Slices.copyOf(slice);\n+                slice = Slices.wrappedBuffer(encrypted, 0, encryptedSize);\n+                markers.add(ENCRYPTED);\n+                //  Previous buffer is no longer in use and can be released\n+                if (inUseTempBuffer != null) {\n+                    context.releaseBuffer(inUseTempBuffer);\n+                }\n+                inUseTempBuffer = encrypted;\n+            }\n+            //  Resulting slice *must* be copied to ensure the shared buffers aren't referenced after method exit\n+            return new SerializedPage(Slices.copyOf(slice), markers, page.getPositionCount(), uncompressedSize);\n+        }\n+        finally {\n+            context.releaseSliceOutput(serializationBuffer);\n+            if (inUseTempBuffer != null) {\n+                context.releaseBuffer(inUseTempBuffer);\n+            }\n         }\n-\n-        return new SerializedPage(slice, markers, page.getPositionCount(), uncompressedSize);\n     }\n \n     public Page deserialize(SerializedPage serializedPage)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgxMjA0NA==", "bodyText": "we are creating temp buffers for a single page, we most likely want them to be long-lived.", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r511812044", "createdAt": "2020-10-26T09:13:13Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TaskOutputOperator.java", "diffHunk": "@@ -142,14 +142,22 @@ public void addInput(Page page)\n \n         page = pagePreprocessor.apply(page);\n \n-        List<SerializedPage> serializedPages = splitPage(page, DEFAULT_MAX_PAGE_SIZE_IN_BYTES).stream()\n-                .map(serde::serialize)\n-                .collect(toImmutableList());\n-\n-        outputBuffer.enqueue(serializedPages);\n+        outputBuffer.enqueue(splitAndSerializePage(page));\n         operatorContext.recordOutput(page.getSizeInBytes(), page.getPositionCount());\n     }\n \n+    private List<SerializedPage> splitAndSerializePage(Page page)\n+    {\n+        List<Page> split = splitPage(page, DEFAULT_MAX_PAGE_SIZE_IN_BYTES);\n+        ImmutableList.Builder<SerializedPage> builder = ImmutableList.builderWithExpectedSize(split.size());\n+        try (PagesSerde.PagesSerdeContext context = serde.newContext()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgxNDEwOQ==", "bodyText": "if you let some PagesSerde instances be longer-lived, how large do you let those buffers get? Do you need to reduce the max buffer size in those scenarios to avoid consuming too much memory? Do you need to track that memory somewhere?\n\nWhen we have long-lived objects of larger size, ideally we should account for their memory using LocalMemoryContext or AggregatedMemoryContext.\n\nwhich would not be particularly efficient since Lz4Compressor has that internal 16KiB \"table\"\n\nThat could be a concern (albeit a small one), but serialized page/compression/decompression buffers would be much larger than that. Generally, that would be a problem only when a single page is serialized/deserialized (which is the case of ExchangeOperator or TaskOutputOperator), but we should avoid that anyway.\nAdditional notes:\n\nPagesSerde is contextual object. No need to have another one.\nPagesSerdeContext contains aquire/release logic which won't be needed if PagesSerde stored buffers itself.\nPagesSerdeContext is PagesSerde specific. We would rather have generic BufferPool that could be also used in BlockSerde", "url": "https://github.com/trinodb/trino/pull/5545#discussion_r511814109", "createdAt": "2020-10-26T09:16:32Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/PagesSerde.java", "diffHunk": "@@ -56,86 +56,225 @@ public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> co\n         this.spillCipher = requireNonNull(spillCipher, \"spillCipher is null\");\n     }\n \n+    public PagesSerdeContext newContext()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEzMTg0Mw=="}, "originalCommit": null, "originalPosition": 20}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b82e00eb9a2796614c2cf3dad40e5691b39e4a0", "author": {"user": {"login": "pettyjamesm", "name": "James Petty"}}, "url": "https://github.com/trinodb/trino/commit/3b82e00eb9a2796614c2cf3dad40e5691b39e4a0", "committedDate": "2020-11-05T11:52:15Z", "message": "Add BenchmarkPagesSerde\n\nAlso makes AesSpillCipher visible for the purposes of testing and\nbenchmarking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51cff0b7102e03d3c413da114362a7199decd345", "author": {"user": {"login": "pettyjamesm", "name": "James Petty"}}, "url": "https://github.com/trinodb/trino/commit/51cff0b7102e03d3c413da114362a7199decd345", "committedDate": "2020-11-05T11:52:15Z", "message": "Add PagesSerdeContext abstraction to enable temporary buffer reuse\n\nReduces the allocation rate of PagesSerde when multiple pages are\nserialized or deserialized in a batch by reusing byte array buffers\nand DynamicSliceOutput instances through the new PagesSerdeContext."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "51cff0b7102e03d3c413da114362a7199decd345", "author": {"user": {"login": "pettyjamesm", "name": "James Petty"}}, "url": "https://github.com/trinodb/trino/commit/51cff0b7102e03d3c413da114362a7199decd345", "committedDate": "2020-11-05T11:52:15Z", "message": "Add PagesSerdeContext abstraction to enable temporary buffer reuse\n\nReduces the allocation rate of PagesSerde when multiple pages are\nserialized or deserialized in a batch by reusing byte array buffers\nand DynamicSliceOutput instances through the new PagesSerdeContext."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI0NzcxNjAw", "url": "https://github.com/trinodb/trino/pull/5545#pullrequestreview-524771600", "createdAt": "2020-11-06T00:19:09Z", "commit": {"oid": "51cff0b7102e03d3c413da114362a7199decd345"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3449, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}