{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxMTY4NzQz", "number": 6178, "reviewThreads": {"totalCount": 93, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo0NzoyOFrOFP2_cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMTowN1rOFXzWEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTczOTM5OnYy", "diffSide": "RIGHT", "path": "pom.xml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo0NzoyOFrOIVavsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQxOTozMzoxNFrOIV1QBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTIwMw==", "bodyText": "@electrum What do we feel about updating to latest vs the first version that added the support for Glue statistics API? (Which would be 1.11.811).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559329203", "createdAt": "2021-01-18T05:47:28Z", "author": {"login": "hashhar"}, "path": "pom.xml", "diffHunk": "@@ -48,7 +48,7 @@\n         <dep.antlr.version>4.8</dep.antlr.version>\n         <dep.airlift.version>201</dep.airlift.version>\n         <dep.packaging.version>${dep.airlift.version}</dep.packaging.version>\n-        <dep.aws-sdk.version>1.11.749</dep.aws-sdk.version>\n+        <dep.aws-sdk.version>1.11.901</dep.aws-sdk.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MDk5MA==", "bodyText": "Nevermind, seems like we are already updated to an even newer version on master.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559360990", "createdAt": "2021-01-18T07:29:05Z", "author": {"login": "hashhar"}, "path": "pom.xml", "diffHunk": "@@ -48,7 +48,7 @@\n         <dep.antlr.version>4.8</dep.antlr.version>\n         <dep.airlift.version>201</dep.airlift.version>\n         <dep.packaging.version>${dep.airlift.version}</dep.packaging.version>\n-        <dep.aws-sdk.version>1.11.749</dep.aws-sdk.version>\n+        <dep.aws-sdk.version>1.11.901</dep.aws-sdk.version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTIwMw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc2MzQ2Mw==", "bodyText": "yes after rebase we are running on 1.11.921", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559763463", "createdAt": "2021-01-18T19:33:14Z", "author": {"login": "GaruGaru"}, "path": "pom.xml", "diffHunk": "@@ -48,7 +48,7 @@\n         <dep.antlr.version>4.8</dep.antlr.version>\n         <dep.airlift.version>201</dep.airlift.version>\n         <dep.packaging.version>${dep.airlift.version}</dep.packaging.version>\n-        <dep.aws-sdk.version>1.11.749</dep.aws-sdk.version>\n+        <dep.aws-sdk.version>1.11.901</dep.aws-sdk.version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTIwMw=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc0MjAyOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo0ODo0MVrOIVaxEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQxOTozMzo0OVrOIV1Q1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTU1NQ==", "bodyText": "How are these values decided? If there's a limit to the maximum/minimum value then please document it as a code comment or as a runtime check via something like verify().", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559329555", "createdAt": "2021-01-18T05:48:41Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc2MzY3MA==", "bodyText": "Right, I've added the explanation with the aws api reference link", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559763670", "createdAt": "2021-01-18T19:33:49Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTU1NQ=="}, "originalCommit": null, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc1MzQ5OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo1NToyMVrOIVa3nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQxOTozNDoxNlrOIV1Rcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMTIyOQ==", "bodyText": "Is it possible to build this directly without iterating over columnStatsBuilder first? ie. populate this while collecting the futures in the loop above?\nSame applicable in getPartitionColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559331229", "createdAt": "2021-01-18T05:55:21Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc2MzgyNg==", "bodyText": "Nice catch, I've changed the implementation as you suggested", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559763826", "createdAt": "2021-01-18T19:34:16Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMTIyOQ=="}, "originalCommit": null, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc1NjYyOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo1Njo0OVrOIVa5RA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo1Njo0OVrOIVa5RA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMTY1Mg==", "bodyText": "We prefer Guava immutable collections over JDK unmodifiable collections where possible. Since this list won't have nulls use toImmutableList (static import from Guava).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559331652", "createdAt": "2021-01-18T05:56:49Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc2MzU4OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjowMDoxNFrOIVa9Bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNjoyNzoyMFrOIWWjgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ==", "bodyText": "Can we add this feature behind a config toggle for now? Since the planner will invoke stats calls and it's easy for people to run into Glue API rate limits so I can see people wanting to have the ability to disable this if needed.\nIt can/should default to true though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559332615", "createdAt": "2021-01-18T06:00:14Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MTM4NA==", "bodyText": "Nevermind, I saw that you are picking the impl. based on the config toggle so that impls. don't need to be aware if things are enabled or disabled. Nice.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559361384", "createdAt": "2021-01-18T07:30:06Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc2NDUxMg==", "bodyText": "Yes, I'm not sure if having a No op implementation is a common pattern in the codebase, we may also change the default implementation to use a toggle flag if you think it's more appropriate", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559764512", "createdAt": "2021-01-18T19:36:12Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTkyOTM2MA==", "bodyText": "We do have some no-op implementations in other places in the code. It looks fine to me.\nBut I'll let the maintainers take the call on this one.\ncc: @findepi @electrum", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559929360", "createdAt": "2021-01-19T05:54:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk3NTMwMw==", "bodyText": "We did have a no-op implementation because stats for glue was extensions point. It was needed until Glue provided first-class stats support.\nWe should maintain the extension point for a while, before we can remove it.\nSo the DefaultGCSP can change its' behavior, but should not be used uncondintionally. cc @sopel39\nAlso, we need a safety toggle to be able to ignore stats, should users run into any problems.\n@GaruGaru can you please confirm hive.table-statistics-enabled can be used to skip getting stats from Glue?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559975303", "createdAt": "2021-01-19T07:57:20Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0OTA4MQ==", "bodyText": "In order to enable/disable the statistics get/update I've introduced the hive.metastore.glue.statistics-enabled flag, do you think we can use hive.table-statistics-enabled directly or we should check them both ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560049081", "createdAt": "2021-01-19T09:53:23Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5MjY0OA==", "bodyText": "One flag should be enough. You cannot use 2 metastores at the same time anyway.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560092648", "createdAt": "2021-01-19T11:00:53Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDMwOTEyMQ==", "bodyText": "I've removed hive.metastore.glue.statistics-enabled in favour of hive.table-statistics-enabled", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560309121", "createdAt": "2021-01-19T16:27:20Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc2NDk4OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjowMDo1N1rOIVa90g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjowMDo1N1rOIVa90g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjgxOA==", "bodyText": "Rename var to partitionColumnStats.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559332818", "createdAt": "2021-01-18T06:00:57Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc2ODAyOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjowMzoxMVrOIVa_sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNjozMDoyMVrOIWWtDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMzI5Ng==", "bodyText": "Are we swallowing exceptions here? I think this method should throw a PrestoException with HIVE_METASTORE_ERROR.\nOr am I reading this incorrectly?\nSame applicable to other places where Glue responses are collected.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559333296", "createdAt": "2021-01-18T06:03:11Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDMxMTU2Nw==", "bodyText": "I solved this but at the moment I'm catching AWSGlueException, should the catch clause also check for more generic exceptions ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560311567", "createdAt": "2021-01-19T16:30:21Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMzI5Ng=="}, "originalCommit": null, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTc5NzcwOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoxODoyMlrOIVbQUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo1MDoyMFrOIV22hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzNzU1NQ==", "bodyText": "This condition works today because we are always fetching table statistics.\nIf we make the feature toggleable then the stats object being empty doesn't mean stats have to be dropped.\nInstead, what if we:\n\nGet current stats from Glue.\nCalculate the ones that have changed (i.e. current - updated) and the ones that are now missing.\nMake an API call to update only the ones that have changed.\nMake an API call to delete the ones that are missing.\n\nSame is applicable to updatePartitionStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559337555", "createdAt": "2021-01-18T06:18:22Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build().forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+        if (columnStatistics.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MjAxMw==", "bodyText": "I now see that this class is used only when stats are enabled so the condition to switch on makes sense.\nStill, this method behaves differently compared to the one for ThriftHiveMetastore. The impl I'm suggesting would preserve semantics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559362013", "createdAt": "2021-01-18T07:31:39Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build().forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+        if (columnStatistics.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzNzU1NQ=="}, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4OTcwMg==", "bodyText": "Agree, the code with the boolean flag / check was written that way to preserve the ThriftHiveMetastore behaviour but keeping the same semantic is the right thing to do here in both updatePartitionStatisticsand  updateTableColumnStatistics.\nThis change is likely to impact the performance of the implementation (glue api call) but from my understanding the update statistics process is not that latency sensitive", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559789702", "createdAt": "2021-01-18T20:50:20Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build().forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+        if (columnStatistics.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzNzU1NQ=="}, "originalCommit": null, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgwNTM5OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyMjoyN1rOIVbUzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjo0NDozNVrOIWvNgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA==", "bodyText": "Is this Table object coming from Hive metastore API?\nI think it's unclean to depend on the Thrift models for Glue. If TableInput has something missing we can add a wrapper over it maybe?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559338700", "createdAt": "2021-01-18T06:22:27Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODc0Mw==", "bodyText": "Same for Partition below.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559338743", "createdAt": "2021-01-18T06:22:42Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA=="}, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc3MzYwNw==", "bodyText": "I agree, We may have a more defined separation between the packages but we need models defined by Table, Column ,Partition` classes.\nWe can either duplicates the attributes to some Glue specific wrappers or create some shared definitions but that may be risky in case of hive/glue api changes", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559773607", "createdAt": "2021-01-18T20:01:52Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA=="}, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcxMzA4OQ==", "bodyText": "This is fine to keep as is. If there is some breakage in future (unlikely) then we can take a look at extracting a wrapper.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560713089", "createdAt": "2021-01-20T06:44:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgwNzQ3OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyMzo1NFrOIVbWGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyMzo1NFrOIVbWGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzOTAzMw==", "bodyText": "Rename to something more descriptive.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559339033", "createdAt": "2021-01-18T06:23:54Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -163,18 +163,20 @@\n     private final Optional<String> defaultDir;\n     private final String catalogId;\n     private final int partitionSegments;\n-    private final Executor executor;\n+    private final Executor partitionsExecutor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgxMzU2OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyNjo1MVrOIVbZrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyNjo1MVrOIVbZrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzOTk0OQ==", "bodyText": "nit:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Enabled statistics for glue tables\")\n          \n          \n            \n                @ConfigDescription(\"Enable statistics for glue tables\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559339949", "createdAt": "2021-01-18T06:26:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgxNDI4OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyNzoxMFrOIVbaFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyNzoxMFrOIVbaFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDA1Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Config(\"hive.metastore.glue.enable-column-stat\")\n          \n          \n            \n                @Config(\"hive.metastore.glue.statistics-enabled\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340053", "createdAt": "2021-01-18T06:27:10Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgxNzcwOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyODozNFrOIVbb0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyODozNFrOIVbb0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDQ5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")\n          \n          \n            \n                @ConfigDescription(\"Number of threads for parallel statistics reads from Glue\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340498", "createdAt": "2021-01-18T06:28:34Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")\n+    public GlueHiveMetastoreConfig setEnableColumnStatistics(boolean enableColumnStatistics)\n+    {\n+        this.enableColumnStatistics = enableColumnStatistics;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getReadStatisticsThreads()\n+    {\n+        return readStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.read-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgxODUyOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyODo1NVrOIVbcOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyODo1NVrOIVbcOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDYwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Number of threads for parallel column writing statistics fetches from Glue\")\n          \n          \n            \n                @ConfigDescription(\"Number of threads for parallel statistics writes to Glue\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340602", "createdAt": "2021-01-18T06:28:55Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")\n+    public GlueHiveMetastoreConfig setEnableColumnStatistics(boolean enableColumnStatistics)\n+    {\n+        this.enableColumnStatistics = enableColumnStatistics;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getReadStatisticsThreads()\n+    {\n+        return readStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.read-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")\n+    public GlueHiveMetastoreConfig setReadStatisticsThreads(int getReadStatisticsThreads)\n+    {\n+        this.readStatisticsThreads = getReadStatisticsThreads;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getWriteStatisticsThreads()\n+    {\n+        return writeStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.write-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel column writing statistics fetches from Glue\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgxOTU1OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueMetastoreModule.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyOTozMlrOIVbc2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjoyOTozMlrOIVbc2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDc2MA==", "bodyText": "Please revert. This is just a syntax change.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340760", "createdAt": "2021-01-18T06:29:32Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,19 +46,28 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n         newOptionalBinder(binder, Key.get(RequestHandler2.class, ForGlueHiveMetastore.class));\n \n-        newOptionalBinder(binder, Key.get(new TypeLiteral<Predicate<Table>>() {}, ForGlueHiveMetastore.class))\n+        newOptionalBinder(binder, Key.get(new TypeLiteral<Predicate<Table>>()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgyMjc4OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjozMTowMlrOIVbeog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjozMTowMlrOIVbeog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MTIxOA==", "bodyText": "MILLIS_PER_DAY?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559341218", "createdAt": "2021-01-18T06:31:02Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTgyMzYxOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjozMToyOVrOIVbfHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNjozMToyOVrOIVbfHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MTM0MQ==", "bodyText": "Rename to trinoColumnStats.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559341341", "createdAt": "2021-01-18T06:31:29Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTkwMDMwOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzowNjozNVrOIVcK6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjo0NToxOVrOIWvOcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ==", "bodyText": "Are the various allowed column types documented somewhere? Can there be a case where a HiveType isn't supported by Glue?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559352555", "createdAt": "2021-01-18T07:06:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjYzMg==", "bodyText": "Same in toGlueColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559352632", "createdAt": "2021-01-18T07:06:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ=="}, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc3Nzc1MQ==", "bodyText": "The switch case follow the aws glue api reference, if the type is not supported a TrinoException with HIVE_INVALID_METADATA is thrown in both toGlueColumnStatisticsData and fromGlueColumnStatistics,\nDo you think we can handle this better ? Should I also add the docs link as reference to the to/from methods ?\napi reference: https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-common.html#aws-glue-api-common-ColumnStatistics", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559777751", "createdAt": "2021-01-18T20:14:43Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ=="}, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcxMzMyOQ==", "bodyText": "This makes sense. Consider this resolved.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560713329", "createdAt": "2021-01-20T06:45:19Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ=="}, "originalCommit": null, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTkwODIzOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzowOTozNVrOIVcPNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzowOTozNVrOIVcPNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MzY1Mg==", "bodyText": "We can instead loop on partition.getColumns to avoid the lookup in columnByName.\nI don't think there can be cases where partition.getColumns doesn't match columns in prestoColumnStats. Please correct me if I'm wrong.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559353652", "createdAt": "2021-01-18T07:09:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTkyMDkzOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzoxNTowN1rOIVcWvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzoxNTowN1rOIVcWvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1NTU4Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n          \n          \n            \n                private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n          \n      \n    \n    \n  \n\nnit: Rename the method to follow the fromXXX and toXXX pattern.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559355583", "createdAt": "2021-01-18T07:15:07Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 195}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTkyODkxOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzoxNzo1MVrOIVcbMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDozMDoyNlrOIV2cIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1NjcyMw==", "bodyText": "Someone more familiar with datetime gotchas should take a look at this.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559356723", "createdAt": "2021-01-18T07:17:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / DAY_TO_MILLISECOND_FACTOR;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4Mjk0Nw==", "bodyText": "We may use  LocalDate.ofInstant but I'm not sure how to handle the ZoneId parameter", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559782947", "createdAt": "2021-01-18T20:30:26Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / DAY_TO_MILLISECOND_FACTOR;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1NjcyMw=="}, "originalCommit": null, "originalPosition": 307}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTk1NTA3OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzoyODoxMVrOIVcqWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo0MDo1MlrOIV2p5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MDYwMw==", "bodyText": "Can we then change this to an assertThat(super.testUpdateTableColumnStatisticsEmptyOptionalFields()).throws(xxx)?\nThat way if Glue's behaviour changes in future we'll know that we can/need to change our impl.\nSame for other commented out tests.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559360603", "createdAt": "2021-01-18T07:28:11Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NjQ2OQ==", "bodyText": "Agree, but we should also be careful with this since glue is returning http status code 500 so this case is not handled by their api yet, I've added some specific check on the error message to address this", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559786469", "createdAt": "2021-01-18T20:40:52Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MDYwMw=="}, "originalCommit": null, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyMTk2OTI4OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzozMzoyNlrOIVcyfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo0NDozN1rOIV2uXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MjY4NA==", "bodyText": "Does the change suggested in updateTableColumnStatistics allow us to remove this boolean control variable?\nI'm not in favour of using boolean arguments to decide method behaviour.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559362684", "createdAt": "2021-01-18T07:33:26Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueColumnStatisticsProvider.java", "diffHunk": "@@ -32,7 +30,7 @@\n \n     Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition);\n \n-    void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics);\n \n-    void updatePartitionStatistics(PartitionInput partition, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> columnStatistics, boolean forPartitionCreation);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzYxNQ==", "bodyText": "Totally agree with removing the boolean flag, the proposed change should address this", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559787615", "createdAt": "2021-01-18T20:44:37Z", "author": {"login": "GaruGaru"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueColumnStatisticsProvider.java", "diffHunk": "@@ -32,7 +30,7 @@\n \n     Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition);\n \n-    void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics);\n \n-    void updatePartitionStatistics(PartitionInput partition, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> columnStatistics, boolean forPartitionCreation);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MjY4NA=="}, "originalCommit": null, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNDc2MzI3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo0NDowN1rOIV2tsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMDoxM1rOIhdxZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzQ0Mw==", "bodyText": "throw new SkipException would be more appropriate, but i'd still want to understand better what is supposed to be tested here and cannot be", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559787443", "createdAt": "2021-01-18T20:44:07Z", "author": {"login": "findepi"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDM3MDIyNA==", "bodyText": "This is kinda strange, from my understanding here the test try to perform a statistics update for all the columns but without min/max values.\nMin / Max values are actually optional according to the docs .\nBut the Glue api answer with an Status Code: 500; Error Code: InternalServiceException Without giving much context.\nRequests were all the statistics (min, max, nulls ...) are specified are completing correctly", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560370224", "createdAt": "2021-01-19T17:51:11Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzQ0Mw=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU4MjQyOQ==", "bodyText": "@GaruGaru knowing the deficiency of Glue can we make the code write minimal/maximal value for a type if actual min/max is not present in HiveColumnStatistics?\nSo for BIGINT we would write -2^63/2^63 - 1 for INTEGER -2^31``/2^31 - 1` ... and so on.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569582429", "createdAt": "2021-02-03T17:00:24Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzQ0Mw=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk2MTcwMg==", "bodyText": "@GaruGaru has this one been addressed?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571961702", "createdAt": "2021-02-08T11:10:13Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzQ0Mw=="}, "originalCommit": null, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDc3MTQzOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoxODoyNFrOIWuqDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoxODoyNFrOIWuqDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNDAxNA==", "bodyText": "Add static import for fromGlueColumnStatistics.\nAlso in getPartitionColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560704014", "createdAt": "2021-01-20T06:18:24Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -92,17 +98,14 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             return glueClient.getColumnStatisticsForTable(request);\n         }, readExecutor)));\n \n-        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n         for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n-            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n-            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+            tableColumnsStats.getColumnStatisticsList()\n+                    .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDc3NjQ0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoyMDozMVrOIWutGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoyMDozMVrOIWutGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNDc5Mw==", "bodyText": "How does the statistics object look when logged?\nWould it be more useful to just log ((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560704793", "createdAt": "2021-01-20T06:20:31Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -279,7 +279,7 @@ private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatis\n                 catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n                 break;\n             default:\n-                throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDc5NTc3OnYy", "diffSide": "LEFT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoyOToxM1rOIWu4ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoyOToxM1rOIWu4ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNzc0Mg==", "bodyText": "I'd keep the comment about why this fails. Glue requires min/max to be set or more accurately Glue doesn't have any optional fields in statistics.\nBut this doesn't match the documentation from AWS somehow. They mention min/max as Required: No.\nIf it's possible can you take a look at the response returned from AWS by enabling their debug logging as decribed at https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/java-dg-logging.html#sdk-net-logging-request-response.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560707742", "createdAt": "2021-01-20T06:29:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -179,16 +179,18 @@ public void testUpdateTableColumnStatistics()\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n             throws Exception\n     {\n-        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n-        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n     public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n             throws Exception\n     {\n-        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n-        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTUzNzYxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODoxNzozMVrOIYDvQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODoyNTowMlrOIYEChw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA5Nzk4Ng==", "bodyText": "please setup that in the module:\n        installModuleIf(\n                HiveConfig.class,\n                HiveConfig::isTableStatisticsEnabled,\n                innerBinder -> innerBinder.bind(GlueColumnStatisticsProvider.class).to(DefaultGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON),\n                innerBinder -> innerBinder.bind(GlueColumnStatisticsProvider.class).to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON));\n\nshould do", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562097986", "createdAt": "2021-01-21T18:17:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -185,10 +189,16 @@ public GlueHiveMetastore(\n         this.defaultDir = glueConfig.getDefaultWarehouseDir();\n         this.catalogId = glueConfig.getCatalogId().orElse(null);\n         this.partitionSegments = glueConfig.getPartitionSegments();\n-        this.executor = requireNonNull(executor, \"executor is null\");\n-        this.columnStatisticsProvider = requireNonNull(columnStatisticsProvider, \"columnStatisticsProvider is null\");\n+        this.partitionsReadExecutor = requireNonNull(partitionsReadExecutor, \"executor is null\");\n         this.assumeCanonicalPartitionKeys = glueConfig.isAssumeCanonicalPartitionKeys();\n         this.tableFilter = requireNonNull(tableFilter, \"tableFilter is null\");\n+        this.enableColumnStatistics = hiveConfig.isTableStatisticsEnabled();\n+        if (this.enableColumnStatistics) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwMjkxOQ==", "bodyText": "Oh I see that it would require some more refactor regarding stats so those are guice bound too. I guess it can be done as a followup.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562102919", "createdAt": "2021-01-21T18:25:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -185,10 +189,16 @@ public GlueHiveMetastore(\n         this.defaultDir = glueConfig.getDefaultWarehouseDir();\n         this.catalogId = glueConfig.getCatalogId().orElse(null);\n         this.partitionSegments = glueConfig.getPartitionSegments();\n-        this.executor = requireNonNull(executor, \"executor is null\");\n-        this.columnStatisticsProvider = requireNonNull(columnStatisticsProvider, \"columnStatisticsProvider is null\");\n+        this.partitionsReadExecutor = requireNonNull(partitionsReadExecutor, \"executor is null\");\n         this.assumeCanonicalPartitionKeys = glueConfig.isAssumeCanonicalPartitionKeys();\n         this.tableFilter = requireNonNull(tableFilter, \"tableFilter is null\");\n+        this.enableColumnStatistics = hiveConfig.isTableStatisticsEnabled();\n+        if (this.enableColumnStatistics) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA5Nzk4Ng=="}, "originalCommit": null, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTU4ODkxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMDowMlrOIYEPBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMlQwOToxMDowNFrOIYbhVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwNjExNg==", "bodyText": "Do we need those configuration parameters? Do we expect that we would need to bump it? If not I would rather not have those. The less config params the better.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562106116", "createdAt": "2021-01-21T18:30:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -40,6 +40,8 @@\n     private Optional<String> catalogId = Optional.empty();\n     private int partitionSegments = 5;\n     private int getPartitionThreads = 20;\n+    private int readStatisticsThreads = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjQ4NzYzOA==", "bodyText": "I agree with having as few params as possible but this parameters are useful for performance tuning when working with tables with an high amount of columns, also making the concurrency configurable should help users to deal with the AWS Glue rate limits.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562487638", "createdAt": "2021-01-22T09:10:04Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -40,6 +40,8 @@\n     private Optional<String> catalogId = Optional.empty();\n     private int partitionSegments = 5;\n     private int getPartitionThreads = 20;\n+    private int readStatisticsThreads = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwNjExNg=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTYwMTgxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMzoyMVrOIYEXDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMzowODo1OFrOIZmH2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwODE3Mg==", "bodyText": "It feels to me that you should not need this one as it is bind in HIveModule which should be always present.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562108172", "createdAt": "2021-01-21T18:33:21Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,10 +47,7 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n+        configBinder(binder).bindConfig(HiveConfig.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjY2OTk0OQ==", "bodyText": "Do we have a test that verify this ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562669949", "createdAt": "2021-01-22T14:32:03Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,10 +47,7 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n+        configBinder(binder).bindConfig(HiveConfig.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwODE3Mg=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzU1NTcyMg==", "bodyText": "I do not believe we have. AFAIK (and I could not find any) we have no proper product-tests coverage for Trino run agains AWS.\ncc: @findepi", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r563555722", "createdAt": "2021-01-25T09:00:21Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,10 +47,7 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n+        configBinder(binder).bindConfig(HiveConfig.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwODE3Mg=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzcwOTkxNQ==", "bodyText": "Correct, we have only non-product tests, like TestHiveGlueMetastore\nthis is tracked by #5426", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r563709915", "createdAt": "2021-01-25T13:08:58Z", "author": {"login": "findepi"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,10 +47,7 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n+        configBinder(binder).bindConfig(HiveConfig.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwODE3Mg=="}, "originalCommit": null, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTY1MTU5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo0NjoyM1rOIYE2DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwODo0NzowN1rOIZcMfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExNjEwOQ==", "bodyText": "those are not used anywhere.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562116109", "createdAt": "2021-01-21T18:46:23Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -59,6 +57,17 @@ protected void setup(Binder binder)\n                 .annotatedWith(ForRecordingHiveMetastore.class)\n                 .to(GlueHiveMetastore.class)\n                 .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsRead.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsWrite.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjY2OTYwMQ==", "bodyText": "Used in GlueHiveMetastore's constructor", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562669601", "createdAt": "2021-01-22T14:31:34Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -59,6 +57,17 @@ protected void setup(Binder binder)\n                 .annotatedWith(ForRecordingHiveMetastore.class)\n                 .to(GlueHiveMetastore.class)\n                 .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsRead.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsWrite.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExNjEwOQ=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzU0NzI2Mw==", "bodyText": "The Executors (which are bound below) are used in GlueHiveMetastore. This one is adding binging for HiveMetastore (annotated with ForGlueColumnStatisticsRead and ForGlueColumnStatisticsWrite).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r563547263", "createdAt": "2021-01-25T08:47:07Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -59,6 +57,17 @@ protected void setup(Binder binder)\n                 .annotatedWith(ForRecordingHiveMetastore.class)\n                 .to(GlueHiveMetastore.class)\n                 .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsRead.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsWrite.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExNjEwOQ=="}, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTY3MzQ0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MTo0NVrOIYFDlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MTo0NVrOIYFDlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExOTU3NQ==", "bodyText": "drop final modifiers on non-fields. We do not have a convention in Trino to use them.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562119575", "createdAt": "2021-01-21T18:51:45Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTY3ODk2OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MzoxM1rOIYFG_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MzoxM1rOIYFG_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyMDQ0Ng==", "bodyText": "extract helper method to create executor given number of threads and name. All three look exactly the same.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562120446", "createdAt": "2021-01-21T18:53:13Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -75,7 +84,33 @@ public Executor createExecutor(CatalogName catalogName, GlueHiveMetastoreConfig\n             return directExecutor();\n         }\n         return new BoundedExecutor(\n-                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-%s\")),\n+                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-partitions-%s\")),\n                 hiveConfig.getGetPartitionThreads());\n     }\n+\n+    @Provides\n+    @Singleton\n+    @ForGlueColumnStatisticsRead\n+    public Executor createStatisticsReadExecutor(CatalogName catalogName, GlueHiveMetastoreConfig hiveConfig)\n+    {\n+        if (hiveConfig.getReadStatisticsThreads() == 1) {\n+            return directExecutor();\n+        }\n+        return new BoundedExecutor(\n+                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-statistics-read-%s\")),\n+                hiveConfig.getReadStatisticsThreads());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTY5MjczOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1NjozMVrOIYFPHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1NjozMVrOIYFPHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyMjUyNw==", "bodyText": "static import MoreFutures.getFutureValue", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562122527", "createdAt": "2021-01-21T18:56:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTcxNDgzOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMTo1OFrOIYFcwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMTo1OFrOIYFcwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNjAxNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n          \n          \n            \n                        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n          \n          \n            \n                        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n          \n          \n            \n                            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n          \n          \n            \n                            tableColumnsStats.getColumnStatisticsList()\n          \n          \n            \n                                    .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        return columnStatsMapBuilder.build();\n          \n          \n            \n                        HiveBasicStatistics tableBasicStatistics = getHiveBasicStatistics(table.getParameters());\n          \n          \n            \n                        ImmutableMap.Builder<String, HiveColumnStatistics> tableColumnStatistics = ImmutableMap.builder();\n          \n          \n            \n                        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n          \n          \n            \n                            GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n          \n          \n            \n                            for (ColumnStatistics singleColumnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n          \n          \n            \n                                tableColumnStatistics.put(\n          \n          \n            \n                                        singleColumnStatistics.getColumnName(),\n          \n          \n            \n                                        fromGlueColumnStatistics(singleColumnStatistics.getStatisticsData(), tableBasicStatistics.getRowCount()));\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        return tableColumnStatistics.build();", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562126016", "createdAt": "2021-01-21T19:01:58Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTcxOTU5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMzoyMFrOIYFf0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMzoyMFrOIYFf0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNjgwMA==", "bodyText": "Please restructure in similar way as above. I think it make the code more readable.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562126800", "createdAt": "2021-01-21T19:03:20Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTcyNTQxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowNTowNFrOIYFjjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowNTowNFrOIYFjjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNzc1Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // Write limit for AWS Glue API GetColumnStatisticsForPartition\n          \n          \n            \n                // Read limit for AWS Glue API GetColumnStatisticsForPartition", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562127757", "createdAt": "2021-01-21T19:05:04Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTczNzU4OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowODoxNVrOIYFq9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowODoxNVrOIYFq9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyOTY1NA==", "bodyText": "can you please check if stream.map.collect would not look nicer?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562129654", "createdAt": "2021-01-21T19:08:15Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTc3Mzk0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxNzo1N1rOIYGBcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxNzo1N1rOIYGBcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNTQwOQ==", "bodyText": "maybe\n                getFutureValue(allOf(writeFutures.toArray(CompletableFuture[]::new)));\n\nI am not super convinced. I would be more if there was allOf which takes a list ....", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562135409", "createdAt": "2021-01-21T19:17:57Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTc3NjczOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxODo0M1rOIYGDKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxODo0M1rOIYGDKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNTg1MA==", "bodyText": "static import runAsync", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562135850", "createdAt": "2021-01-21T19:18:43Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTc3ODM1OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOTowMlrOIYGEGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOTowMlrOIYGEGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNjA5MA==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562136090", "createdAt": "2021-01-21T19:19:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTc3OTIxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOToyMVrOIYGEvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOToyMVrOIYGEvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNjI1Mw==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562136253", "createdAt": "2021-01-21T19:19:21Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTc4NzgwOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyMTozMFrOIYGJ9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyMTozMFrOIYGJ9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNzU5MQ==", "bodyText": "missing return?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562137591", "createdAt": "2021-01-21T19:21:30Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTgwMzA3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo0N1rOIYGUlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo0N1rOIYGUlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0MDMwOA==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562140308", "createdAt": "2021-01-21T19:24:47Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTgwMzQ5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo1NVrOIYGU4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo1NVrOIYGU4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0MDM4NA==", "bodyText": "static import runAsync", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562140384", "createdAt": "2021-01-21T19:24:55Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTgzMDg5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjoxNlrOIYGmAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjoxNlrOIYGmAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NDc2OA==", "bodyText": "name the variables columnChunk", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562144768", "createdAt": "2021-01-21T19:32:16Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 214}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTgzMjc1OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjo0N1rOIYGnEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjo0N1rOIYGnEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NTA0Mg==", "bodyText": "Why don't we need analogous code in updateTableColumnStatistics?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562145042", "createdAt": "2021-01-21T19:32:47Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->\n+                            CompletableFuture.runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                MoreFutures.getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            final boolean partitionExists = partitionExists(partition);\n+            final Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            final Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+\n+            final List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTgzNzg4OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozNDoyM1rOIYGqMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozNDoyM1rOIYGqMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NTg0Mw==", "bodyText": "Use ImmutableListBuilder like everywhere", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562145843", "createdAt": "2021-01-21T19:34:23Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->\n+                            CompletableFuture.runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                MoreFutures.getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            final boolean partitionExists = partitionExists(partition);\n+            final Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            final Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+\n+            final List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> CompletableFuture.runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                MoreFutures.getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    private boolean partitionExists(Partition partition)\n+    {\n+        final BatchGetPartitionResult results = glueClient.batchGetPartition(new BatchGetPartitionRequest()\n+                .withCatalogId(catalogId)\n+                .withDatabaseName(partition.getDatabaseName())\n+                .withTableName(partition.getTableName())\n+                .withPartitionsToGet(\n+                        new PartitionValueList().withValues(partition.getValues())\n+                )\n+        );\n+        return !results.getPartitions().isEmpty() || !results.getUnprocessedKeys().isEmpty();\n+    }\n+\n+    private List<String> getAllColumns(Table table)\n+    {\n+        final List<String> allColumns = new ArrayList<>(table.getDataColumns().size() + table.getPartitionColumns().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 265}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg1MTgwOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozODoxOFrOIYGy6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMlQxNDoyOTozMVrOIYmi5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0ODA3NA==", "bodyText": "this is O(N^2) which with 1000 columns will start to be substantial cost. Pre-build String->Column map", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562148074", "createdAt": "2021-01-21T19:38:18Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0OTY3OQ==", "bodyText": "Naa - it is only partition columns. So I guess we will not have 1000 of those :)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562149679", "createdAt": "2021-01-21T19:41:17Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0ODA3NA=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjQyMDcxMQ==", "bodyText": "Still should be easy to remedy and there's no reason to avoid this unless it's more difficult than expected - #6178 (comment)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562420711", "createdAt": "2021-01-22T06:48:24Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0ODA3NA=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjY2ODI2Mw==", "bodyText": "fixed", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562668263", "createdAt": "2021-01-22T14:29:31Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0ODA3NA=="}, "originalCommit": null, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg2NDM3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MjowMlrOIYG6og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MjowMlrOIYG6og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MDA1MA==", "bodyText": "can you extract common part for column and partition stats to helper method?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562150050", "createdAt": "2021-01-21T19:42:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg2NzkyOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MzowMVrOIYG82Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MzowMVrOIYG82Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MDYxNw==", "bodyText": "put this one below columnByName", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562150617", "createdAt": "2021-01-21T19:43:01Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 195}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg3NjEyOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueToTrinoConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0NToyNlrOIYHB5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0NToyNlrOIYHB5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MTkwOQ==", "bodyText": "seems not needed. revert", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562151909", "createdAt": "2021-01-21T19:45:26Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueToTrinoConverter.java", "diffHunk": "@@ -93,7 +93,7 @@ public static Table convertTable(com.amazonaws.services.glue.model.Table glueTab\n         return tableBuilder.build();\n     }\n \n-    private static Column convertColumn(com.amazonaws.services.glue.model.Column glueColumn)\n+    public static Column convertColumn(com.amazonaws.services.glue.model.Column glueColumn)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg4ODI5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODoyNlrOIYHJEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODoyNlrOIYHJEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1Mzc0Nw==", "bodyText": "this does not seem right? Is that a flow we can get into in real life?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562153747", "createdAt": "2021-01-21T19:48:26Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,61 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzOTg4ODYxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODozMVrOIYHJTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODozMVrOIYHJTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MzgwNA==", "bodyText": "same here", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562153804", "createdAt": "2021-01-21T19:48:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,61 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdatePartitionColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MDg0MjkxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxMzo1MzoxM1rOIbIpnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxOTo1NDoyMlrOIeiKCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTMyNDE4OA==", "bodyText": "What happens if getPartitionStatistics is called for a non-existent partition?\nThere will be 1 API call on the not exists path but 2 on the exists path. Can we avoid this by using the exception thrown when a partition doesn't exist as a control variable instead of the boolean?\nLots of people run into Glue rate-limits so we should strive to reduce API calls to Glue.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r565324188", "createdAt": "2021-01-27T13:53:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,272 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(\n+                    writeChunkFutures.toArray(CompletableFuture[]::new)\n+            ));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg4NzgxNw==", "bodyText": "When called on a non existing partition glue client throw an exception, we may use the exception to check if the partition is present as it will reduce the number of api calls.\nIn getPartitionColumnStatistics we should check for EntityNotFoundException raised by glue client and in that case return an empty partition statistics object, do you think if may be a good compromise between readability and api calls count ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r568887817", "createdAt": "2021-02-02T19:54:22Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,272 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(\n+                    writeChunkFutures.toArray(CompletableFuture[]::new)\n+            ));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTMyNDE4OA=="}, "originalCommit": null, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzEwMzk2OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QwOTo1MjoxM1rOIe5wLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QwOTo1MjoxM1rOIe5wLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTI3NDQxNQ==", "bodyText": "nit: Reformat to place each argument on separate line.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n          \n          \n            \n                        Partition partition,\n          \n          \n            \n                        Map<String, HiveColumnStatistics> trinoColumnStats,\n          \n          \n            \n                        OptionalLong rowCount)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569274415", "createdAt": "2021-02-03T09:52:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzExNDYyOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QwOTo1NDozOFrOIe53IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QwOTo1NDozOFrOIe53IQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTI3NjE5Mw==", "bodyText": "nit: Reformat\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n          \n          \n            \n                        Table table,\n          \n          \n            \n                        Map<String, HiveColumnStatistics> trinoColumnStats,\n          \n          \n            \n                        OptionalLong rowCount)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569276193", "createdAt": "2021-02-03T09:54:38Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4Nzk5NjE5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozMDo0MlrOIfCO8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxNzoyMTo1M1rOIgq0ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxMzM2Mw==", "bodyText": "Is fromMetastoreNullsCount(nullsCountOfBinary) intentionally missing here (it's used in other branches).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569413363", "createdAt": "2021-02-03T13:30:42Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTEyNjkwNw==", "bodyText": "the nullsCountOfBinary variable is the result of fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls()); in this method is assigned to a variable because the value is used twice", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571126907", "createdAt": "2021-02-05T17:21:53Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxMzM2Mw=="}, "originalCommit": null, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODAxMDU3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozNDowNVrOIfCXwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxODowNjowNFrOIgsczA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNTYxNw==", "bodyText": "Possible NPE here. Take a look at ThriftMetastoreUtil#fromMetastoreDate.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569415617", "createdAt": "2021-02-03T13:34:05Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 282}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTEyNjg0OQ==", "bodyText": "Do you think that we can use ThriftMetastoreUtil here or is better to  keep the implementations as separated as possibile ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571126849", "createdAt": "2021-02-05T17:21:48Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNTYxNw=="}, "originalCommit": null, "originalPosition": 282}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTE1MzYxMg==", "bodyText": "I think it's safe to do so. We already use ThriftMetastoreUtil in GlueHiveMetastore for other things.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571153612", "createdAt": "2021-02-05T18:06:04Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNTYxNw=="}, "originalCommit": null, "originalPosition": 282}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODAxODY5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozNTo1M1rOIfCcvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxODowNTowMVrOIgsagQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNjg5Mg==", "bodyText": "Possible NPE here. Take a look at ThriftMetastoreUtil#toMetastoreDate.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569416892", "createdAt": "2021-02-03T13:35:53Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));\n+    }\n+\n+    private static Date localDateToDate(LocalDate date)\n+    {\n+        long millisecondsSinceEpoch = date.toEpochDay() * MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 288}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTEyNjYzMQ==", "bodyText": "the ThriftMetastoreUtil#toMetastoreDate doesn't look like it can handle null references for its argument since it calls arg.toEpochDay().\nHow do you think we should handle this particular case ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571126631", "createdAt": "2021-02-05T17:21:28Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));\n+    }\n+\n+    private static Date localDateToDate(LocalDate date)\n+    {\n+        long millisecondsSinceEpoch = date.toEpochDay() * MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNjg5Mg=="}, "originalCommit": null, "originalPosition": 288}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTE1MzAyNQ==", "bodyText": "That method doesn't need to check since the caller only calls it if the Optional has a value.\nI think you are safe too since this method isn't ever called with a possible null value. Consider this resolved.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571153025", "createdAt": "2021-02-05T18:05:01Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));\n+    }\n+\n+    private static Date localDateToDate(LocalDate date)\n+    {\n+        long millisecondsSinceEpoch = date.toEpochDay() * MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNjg5Mg=="}, "originalCommit": null, "originalPosition": 288}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODAyNTkzOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozNzozNFrOIfChRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozNzozNFrOIfChRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODA1NQ==", "bodyText": "Possible NPE. Let's be defensive here because even though AWS Glue documents these fields to be required but we already know the docs are not 100% correct.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569418055", "createdAt": "2021-02-03T13:37:34Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODAyNzY2OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzozNzo1NVrOIfCiRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxODowODowNFrOIgshMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODMwOA==", "bodyText": "Possible NPE. Let's be defensive here because even though AWS Glue documents these fields to be required but we already know the docs are not 100% correct.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569418308", "createdAt": "2021-02-03T13:37:55Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTEyOTI3OQ==", "bodyText": "Agree but in this cases the method is called inside an Optional#isPresent lambda, NPEs should not happen.\nIn order to be as defensive as possible do you think we can return an Optional here and set min/max when present ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571129279", "createdAt": "2021-02-05T17:25:28Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODMwOA=="}, "originalCommit": null, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTE1NDczNw==", "bodyText": "I missed the call-site when reviewing. This should be fine. Please mark other such instances as resolved. Sorry for the false alarms.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571154737", "createdAt": "2021-02-05T18:08:04Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODMwOA=="}, "originalCommit": null, "originalPosition": 265}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODAzODY0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo0MDoxNVrOIfCo0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDoyMjo0OVrOIhNB_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxOTk4NA==", "bodyText": "We can make the error message more explicit like Unsupported statistics type: %s so that users don't need to look at stack-trace.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569419984", "createdAt": "2021-02-03T13:40:15Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTYzMDc1MQ==", "bodyText": "Should we also add some context to the error ? eg Unsupported statistics type: %s, Only primitive types are supported", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571630751", "createdAt": "2021-02-07T15:07:01Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxOTk4NA=="}, "originalCommit": null, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4NzQyMg==", "bodyText": "I don't think users would know what a PrimitiveType is as defined by the metastore. I'll defer on this to @trinodb/maintainers .", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571687422", "createdAt": "2021-02-07T20:22:49Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxOTk4NA=="}, "originalCommit": null, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODA2NTQxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo0NjozMVrOIfC5rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QxNToxOTowOFrOIhJs9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyNDMwMQ==", "bodyText": "Some of these branches look impossible to hit because we don't/can't write stats for such types into Glue. e.g. TIMESTAMP.\nAm I correct? Or misunderstanding something?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569424301", "createdAt": "2021-02-03T13:46:31Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTYzMjg4NQ==", "bodyText": "The intent here is to handle all the types (SHORT,INT,LONG,TIMESTAMP) Using the same logic by leveraging java switch multiple cases, so in this case all the defined types are written with the LongColumnStatisticsData object to glue, Glue doesn't support short, int and timestamp values.\nShould we make this more explicit ?\nAnother possible change is to handle timestamp type as Date instead of long but I'm not sure if this can help", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571632885", "createdAt": "2021-02-07T15:19:08Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyNDMwMQ=="}, "originalCommit": null, "originalPosition": 235}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODA5NTc0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MzowMVrOIfDMEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MzowMVrOIfDMEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyOTAwOA==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569429008", "createdAt": "2021-02-03T13:53:01Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODA5NzUwOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MzoyM1rOIfDNKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MzoyM1rOIfDNKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyOTI4OA==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569429288", "createdAt": "2021-02-03T13:53:23Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODEyMjE1OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1ODoyN1rOIfDb_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo0Mzo1N1rOIfOqqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzA4Ng==", "bodyText": "In a follow-up we may want to make this execute in the order that futures complete to avoid being blocked on a single slow API call - maybe by adding a callback to the future. Just thinking out loud.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433086", "createdAt": "2021-02-03T13:58:27Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYxNzA2Ng==", "bodyText": "getFutureValue(allOf should work here. But +1 to keep it as a followup.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569617066", "createdAt": "2021-02-03T17:43:57Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzA4Ng=="}, "originalCommit": null, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODEyNDA2OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1ODo1MVrOIfDdQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1ODo1MVrOIfDdQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzQwOQ==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433409", "createdAt": "2021-02-03T13:58:51Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODEyNDYyOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1ODo1OFrOIfDdnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1ODo1OFrOIfDdnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzUwMw==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433503", "createdAt": "2021-02-03T13:58:58Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODg3MTU5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyMjoxN1rOIfKtEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyMjoxN1rOIfKtEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1MjE0Ng==", "bodyText": "nit: move closing brackets to previous line. I wonder why checkstyle didn't complain though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569552146", "createdAt": "2021-02-03T16:22:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODg4MDQ3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyNDowOVrOIfKyqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzozNzowMFrOIfOMfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1MzU3Nw==", "bodyText": "Let's change all occurrences of loops over future where returned values are not checked into something like getFutureValue(allOf(...))? Or is that not equivalent?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569553577", "createdAt": "2021-02-03T16:24:09Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYwOTM0Mw==", "bodyText": "Yeah - please do that. So we acutally wait for all the futures to complete. And we are not leaving work still being processed in executors.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569609343", "createdAt": "2021-02-03T17:37:00Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1MzU3Nw=="}, "originalCommit": null, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODg4MzA3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyNDo0OFrOIfK0Zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyNDo0OFrOIfK0Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1NDAyMw==", "bodyText": "nit: move closing brackets to previous line. I wonder why checkstyle didn't complain though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569554023", "createdAt": "2021-02-03T16:24:48Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODg4NTM1OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjoyNToxN1rOIfK1vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjo0NzoyMFrOIfL6Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1NDM2Nw==", "bodyText": "Let's test for an exception to be thrown instead to avoid an API call. WDYT @losipiuk.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569554367", "createdAt": "2021-02-03T16:25:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU3MTkzNQ==", "bodyText": "If there is clear error code in exception with \"partition not found\" meaning I think we should use exception to avoid extra API call on success path.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569571935", "createdAt": "2021-02-03T16:47:20Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1NDM2Nw=="}, "originalCommit": null, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODkxODc3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjozMTozMlrOIfLKPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xNlQxNzoxMzoxOVrOImQ3gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTYxMw==", "bodyText": "Let's add some comment about why this is failing? AFAIR you said that even though Glue API docs say that some fields are \"not required\" not setting them when making the API call causes an error. Correct?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569559613", "createdAt": "2021-02-03T16:31:32Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3Njk5MzE1NQ==", "bodyText": "I added a comment in the discussion about this issue", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r576993155", "createdAt": "2021-02-16T17:13:19Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTYxMw=="}, "originalCommit": null, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODkxOTY5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjozMTo0NFrOIfLKzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xNlQxNzoxMzoyOFrOImQ33Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTc1OQ==", "bodyText": "Let's add some comment about why this is failing? AFAIR you said that even though Glue API docs say that some fields are \"not required\" not setting them when making the API call causes an error. Correct?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569559759", "createdAt": "2021-02-03T16:31:44Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n     public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdatePartitionColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3Njk5MzI0NQ==", "bodyText": "I added a comment in the discussion about this issue", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r576993245", "createdAt": "2021-02-16T17:13:28Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n     public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdatePartitionColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTc1OQ=="}, "originalCommit": null, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODkzMjg0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjozNDo0OVrOIfLTgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMTowMDo0NFrOIhdamg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MTk4Nw==", "bodyText": "Why this change? This indicates to me that are we somehow calculating data size differently for Thrift vs Glue?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569561987", "createdAt": "2021-02-03T16:34:49Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -513,23 +513,23 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_float\", createDoubleColumnStatistics(OptionalDouble.of(123.25), OptionalDouble.of(567.58), OptionalLong.of(9), OptionalLong.of(10)))\n                             .put(\"t_string\", createStringColumnStatistics(OptionalLong.of(10), OptionalLong.of(50), OptionalLong.of(3), OptionalLong.of(7)))\n                             .put(\"t_varchar\", createStringColumnStatistics(OptionalLong.of(100), OptionalLong.of(230), OptionalLong.of(5), OptionalLong.of(3)))\n-                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(500), OptionalLong.of(1), OptionalLong.of(4)))\n-                            .put(\"t_varbinary\", createBinaryColumnStatistics(OptionalLong.of(4), OptionalLong.of(300), OptionalLong.of(1)))\n+                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(50), OptionalLong.of(1), OptionalLong.of(4)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY0NDU0Ng==", "bodyText": "Here I'm using the ThriftMetastoreUtil#getAverageColumnLength function I had to change the values because Glue  reject logically inconsistent statistics.\nIn particular:\nt_varbinary\ntest data: \n rows:  15\n nulls: 1\n max_size:   4\n total_size: 300\n\navg size: 300/(15rows - 1null) = 20...  > 4 (max)  # ERROR \n\nt_char\n rows: 15\n nulls: 1 \n max_size: 5\n total_size: 500\n\navg size: 500/(15rows - 1null) = 35... > 5 (max) # ERROR", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571644546", "createdAt": "2021-02-07T16:44:06Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -513,23 +513,23 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_float\", createDoubleColumnStatistics(OptionalDouble.of(123.25), OptionalDouble.of(567.58), OptionalLong.of(9), OptionalLong.of(10)))\n                             .put(\"t_string\", createStringColumnStatistics(OptionalLong.of(10), OptionalLong.of(50), OptionalLong.of(3), OptionalLong.of(7)))\n                             .put(\"t_varchar\", createStringColumnStatistics(OptionalLong.of(100), OptionalLong.of(230), OptionalLong.of(5), OptionalLong.of(3)))\n-                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(500), OptionalLong.of(1), OptionalLong.of(4)))\n-                            .put(\"t_varbinary\", createBinaryColumnStatistics(OptionalLong.of(4), OptionalLong.of(300), OptionalLong.of(1)))\n+                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(50), OptionalLong.of(1), OptionalLong.of(4)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MTk4Nw=="}, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk1NTg2Ng==", "bodyText": "because Glue reject logically inconsistent statistics\n\nAre we sure that statistics computation mechanism used by Tino will not trigger this safety valve?\ncc: @findepi", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571955866", "createdAt": "2021-02-08T11:00:44Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -513,23 +513,23 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_float\", createDoubleColumnStatistics(OptionalDouble.of(123.25), OptionalDouble.of(567.58), OptionalLong.of(9), OptionalLong.of(10)))\n                             .put(\"t_string\", createStringColumnStatistics(OptionalLong.of(10), OptionalLong.of(50), OptionalLong.of(3), OptionalLong.of(7)))\n                             .put(\"t_varchar\", createStringColumnStatistics(OptionalLong.of(100), OptionalLong.of(230), OptionalLong.of(5), OptionalLong.of(3)))\n-                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(500), OptionalLong.of(1), OptionalLong.of(4)))\n-                            .put(\"t_varbinary\", createBinaryColumnStatistics(OptionalLong.of(4), OptionalLong.of(300), OptionalLong.of(1)))\n+                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(50), OptionalLong.of(1), OptionalLong.of(4)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MTk4Nw=="}, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODkzODYzOnYy", "diffSide": "LEFT", "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjozNjowMlrOIfLXMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QxNTo0MTo1NlrOIhJ5ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MjkyOA==", "bodyText": "@losipiuk does it make sense for a follow-up task in future to normalize such incorrect stats? Or does the engine already ignore/correct for such stats.\ncc: @sopel", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569562928", "createdAt": "2021-02-03T16:36:02Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -545,10 +545,10 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_bigint\", createIntegerColumnStatistics(OptionalLong.of(2345L), OptionalLong.of(6789L), OptionalLong.of(4), OptionalLong.of(7)))\n                             .put(\"t_integer\", createIntegerColumnStatistics(OptionalLong.of(234L), OptionalLong.of(678L), OptionalLong.of(5), OptionalLong.of(6)))\n                             .put(\"t_smallint\", createIntegerColumnStatistics(OptionalLong.of(23L), OptionalLong.of(65L), OptionalLong.of(7), OptionalLong.of(5)))\n-                            .put(\"t_tinyint\", createIntegerColumnStatistics(OptionalLong.of(12), OptionalLong.of(3L), OptionalLong.of(2), OptionalLong.of(3)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU4NDg3NQ==", "bodyText": "Hmmmm, @GaruGaru I think logically incorrect stats value SHOULD NOT be a problem. i.e. will Glue reject such statistics when writing?\nIf you changed these values just because they were logically inconsistent, let's revert the change.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569584875", "createdAt": "2021-02-03T17:03:42Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -545,10 +545,10 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_bigint\", createIntegerColumnStatistics(OptionalLong.of(2345L), OptionalLong.of(6789L), OptionalLong.of(4), OptionalLong.of(7)))\n                             .put(\"t_integer\", createIntegerColumnStatistics(OptionalLong.of(234L), OptionalLong.of(678L), OptionalLong.of(5), OptionalLong.of(6)))\n                             .put(\"t_smallint\", createIntegerColumnStatistics(OptionalLong.of(23L), OptionalLong.of(65L), OptionalLong.of(7), OptionalLong.of(5)))\n-                            .put(\"t_tinyint\", createIntegerColumnStatistics(OptionalLong.of(12), OptionalLong.of(3L), OptionalLong.of(2), OptionalLong.of(3)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MjkyOA=="}, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTYzNjEyNg==", "bodyText": "I had to change those values because Glue api reject values that are logically inconsistent ( eg avg > max)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571636126", "createdAt": "2021-02-07T15:41:56Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -545,10 +545,10 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_bigint\", createIntegerColumnStatistics(OptionalLong.of(2345L), OptionalLong.of(6789L), OptionalLong.of(4), OptionalLong.of(7)))\n                             .put(\"t_integer\", createIntegerColumnStatistics(OptionalLong.of(234L), OptionalLong.of(678L), OptionalLong.of(5), OptionalLong.of(6)))\n                             .put(\"t_smallint\", createIntegerColumnStatistics(OptionalLong.of(23L), OptionalLong.of(65L), OptionalLong.of(7), OptionalLong.of(5)))\n-                            .put(\"t_tinyint\", createIntegerColumnStatistics(OptionalLong.of(12), OptionalLong.of(3L), OptionalLong.of(2), OptionalLong.of(3)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MjkyOA=="}, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTMyNDUyOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1MzoyOFrOIfPHhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xNlQxMjowNTowNFrOImDahw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNDQ1NA==", "bodyText": "nit:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n          \n          \n            \n            \n          \n          \n            \n                        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n          \n          \n            \n                            List<String> columnsNames = partialColumns.stream()\n          \n          \n            \n                                    .map(Column::getName)\n          \n          \n            \n                                    .collect(toImmutableList());\n          \n          \n            \n            \n          \n          \n            \n                            GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n          \n          \n            \n                                    .withCatalogId(catalogId)\n          \n          \n            \n                                    .withDatabaseName(partition.getDatabaseName())\n          \n          \n            \n                                    .withTableName(partition.getTableName())\n          \n          \n            \n                                    .withColumnNames(columnsNames)\n          \n          \n            \n                                    .withPartitionValues(partition.getValues());\n          \n          \n            \n            \n          \n          \n            \n                            return glueClient.getColumnStatisticsForPartition(request);\n          \n          \n            \n                        }, readExecutor)));\n          \n          \n            \n                        List<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = columnChunks.stream()\n          \n          \n            \n                                .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n          \n          \n            \n                                    List<String> columnsNames = partialColumns.stream()\n          \n          \n            \n                                            .map(Column::getName)\n          \n          \n            \n                                            .collect(toImmutableList());\n          \n          \n            \n            \n          \n          \n            \n                                    GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n          \n          \n            \n                                            .withCatalogId(catalogId)\n          \n          \n            \n                                            .withDatabaseName(partition.getDatabaseName())\n          \n          \n            \n                                            .withTableName(partition.getTableName())\n          \n          \n            \n                                            .withColumnNames(columnsNames)\n          \n          \n            \n                                            .withPartitionValues(partition.getValues());\n          \n          \n            \n                                    return glueClient.getColumnStatisticsForPartition(request);\n          \n          \n            \n                                }, readExecutor))\n          \n          \n            \n                                .collect(toImmutableList());\n          \n      \n    \n    \n  \n\n@hashhar which one looks nicer to you?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569624454", "createdAt": "2021-02-03T17:53:28Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNjg1MA==", "bodyText": "Oh I see that you go this appraach in getTableColumnStatistics. Please be consistent.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569626850", "createdAt": "2021-02-03T17:56:53Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNDQ1NA=="}, "originalCommit": null, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk1ODI2Nw==", "bodyText": "Still not consistent. getPartitionColumnStatistics uses forEach ... getStatsFutures.add(. And getTableColumnStatistics uses .collect(toImmutableList());. Please migrate to .collect(toImmutableList()); with both.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571958267", "createdAt": "2021-02-08T11:04:47Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNDQ1NA=="}, "originalCommit": null, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3Njc3Mjc0Mw==", "bodyText": "Sorry you're right !", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r576772743", "createdAt": "2021-02-16T12:05:04Z", "author": {"login": "GaruGaru"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNDQ1NA=="}, "originalCommit": null, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTM0Mjk4OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1NzozOVrOIfPTDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1NzozOVrOIfPTDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNzQwNQ==", "bodyText": "drop final", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569627405", "createdAt": "2021-02-03T17:57:39Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTM1NzMxOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMDo1N1rOIfPcTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMDo1N1rOIfPcTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyOTc3NA==", "bodyText": "is there a reason to do updates first and removals later? It feels to me it would be better to gather the futures on single list and call getFutureValue(allOf just once.\nSo even in case of an error for some of the calls we have as many changes applied as possible.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569629774", "createdAt": "2021-02-03T18:00:57Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTM2NDgzOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMzowNVrOIfPhOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMzowNVrOIfPhOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzMTAzMg==", "bodyText": "same here. Wouldn't it be better to collect futures on single list?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569631032", "createdAt": "2021-02-03T18:03:05Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTM5NjI3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTowN1rOIfP1bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTowN1rOIfP1bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzNjIwNQ==", "bodyText": "please move call to columnStatisticsProvider.updatePartitionStatistics below glueClient.updatePartition we update the basic stats first.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569636205", "createdAt": "2021-02-03T18:11:07Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -385,8 +397,10 @@ public void updatePartitionStatistics(HiveIdentity identity, Table table, String\n \n         try {\n             PartitionInput partitionInput = GlueInputConverter.convertPartition(partition);\n-            partitionInput.setParameters(updateStatisticsParameters(partition.getParameters(), updatedStatistics.getBasicStatistics()));\n-            columnStatisticsProvider.updatePartitionStatistics(partitionInput, updatedStatistics.getColumnStatistics());\n+            final Map<String, String> updateStatisticsParameters = updateStatisticsParameters(partition.getParameters(), updatedStatistics.getBasicStatistics());\n+            partitionInput.setParameters(updateStatisticsParameters);\n+            partition = Partition.builder(partition).setParameters(updateStatisticsParameters).build();\n+            columnStatisticsProvider.updatePartitionStatistics(partition, updatedStatistics.getColumnStatistics());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTM5Nzc5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTozNFrOIfP2dQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTozNFrOIfP2dQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzNjQ2OQ==", "bodyText": "plase move the call to columnStatisticsProvider.updateTableColumnStatistics(table, updatedStatistics.getColumnStatistics());  below glueClient.updateTable so we update basic stats first.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569636469", "createdAt": "2021-02-03T18:11:34Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -358,8 +368,10 @@ public void updateTableStatistics(HiveIdentity identity, String databaseName, St\n \n         try {\n             TableInput tableInput = GlueInputConverter.convertTable(table);\n-            tableInput.setParameters(updateStatisticsParameters(table.getParameters(), updatedStatistics.getBasicStatistics()));\n-            columnStatisticsProvider.updateTableColumnStatistics(tableInput, updatedStatistics.getColumnStatistics());\n+            final Map<String, String> statisticsParameters = updateStatisticsParameters(table.getParameters(), updatedStatistics.getBasicStatistics());\n+            tableInput.setParameters(statisticsParameters);\n+            table = Table.builder(table).setParameters(statisticsParameters).build();\n+            columnStatisticsProvider.updateTableColumnStatistics(table, updatedStatistics.getColumnStatistics());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTUwMTYzOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozNzo1MFrOIfQ25w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozNzo1MFrOIfQ25w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTY1Mjk2Nw==", "bodyText": "Use braces. This will allow you to use shorter variable names. Like this:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        case DATE:\n          \n          \n            \n                            DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n          \n          \n            \n                            Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n          \n          \n            \n                            Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n          \n          \n            \n                            OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n          \n          \n            \n                            OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n          \n          \n            \n                            return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n          \n          \n            \n            \n          \n          \n            \n                        case DECIMAL:\n          \n          \n            \n                            DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n          \n          \n            \n                            Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n          \n          \n            \n                            Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n          \n          \n            \n                            OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n          \n          \n            \n                            OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n          \n          \n            \n                            return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n          \n          \n            \n                        case DATE: {\n          \n          \n            \n                            DateColumnStatisticsData data = catalogColumnStatisticsData.getDateColumnStatisticsData();\n          \n          \n            \n                            Optional<LocalDate> min = dateToLocalDate(data.getMinimumValue());\n          \n          \n            \n                            Optional<LocalDate> max = dateToLocalDate(data.getMaximumValue());\n          \n          \n            \n                            OptionalLong nullsCount = fromMetastoreNullsCount(data.getNumberOfNulls());\n          \n          \n            \n                            OptionalLong numberOfDistinctValues = OptionalLong.of(data.getNumberOfDistinctValues());\n          \n          \n            \n                            return createDateColumnStatistics(min, max, nullsCount, fromMetastoreDistinctValuesCount(numberOfDistinctValues, nullsCount, rowCount));\n          \n          \n            \n                        }\n          \n          \n            \n                        case DECIMAL: {\n          \n          \n            \n                            DecimalColumnStatisticsData data = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n          \n          \n            \n                            Optional<BigDecimal> min = glueDecimalToBigDecimal(data.getMinimumValue());\n          \n          \n            \n                            Optional<BigDecimal> max = glueDecimalToBigDecimal(data.getMaximumValue());\n          \n          \n            \n                            OptionalLong numberOfDistinctValues = OptionalLong.of(data.getNumberOfDistinctValues());\n          \n          \n            \n                            OptionalLong nullsCount = fromMetastoreNullsCount(data.getNumberOfNulls());\n          \n          \n            \n                            return createDecimalColumnStatistics(min, max, nullsCount, fromMetastoreDistinctValuesCount(numberOfDistinctValues, nullsCount, rowCount));\n          \n          \n            \n                        }", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569652967", "createdAt": "2021-02-03T18:37:50Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4OTUwNDg5OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozODozNFrOIfQ43w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozODozNFrOIfQ43w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTY1MzQ3MQ==", "bodyText": "use braces here to to have separate namespace for each type considered.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569653471", "createdAt": "2021-02-03T18:38:34Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzExODI3OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDoyODozOFrOIhNEwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMDo1OToxMlrOIhdWow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA==", "bodyText": "@losipiuk should we fail if Trino tries to fetch statistics for a partition which doesn't exist? Or return empty stats?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688130", "createdAt": "2021-02-07T20:28:38Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4OTAxOA==", "bodyText": "Btw, this was changed to avoid catching the TrinoException(HIVE_METASTORE_ERROR, EntityNotFoundException) in the caller to detect that a partition doesn't exist.\nI'd prefer if this responsibility of handling EntityNotFoundException would be given to the caller since this is a public method and part of the API.\nWDYT @losipiuk ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571689018", "createdAt": "2021-02-07T20:36:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk1NDg1MQ==", "bodyText": "I think we should throw here and catch in updatePartitionStatistics. Please add a PARTITION_NOT_FOUND error code to HiveErrorCode class so you can determine if you shiould just skip deleting for this partition in updatePartitionStatistics, or should you rather rethrow exception to the caller.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571954851", "createdAt": "2021-02-08T10:59:12Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA=="}, "originalCommit": null, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzEyMTM2OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMToxN1rOIhNGHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMToxN1rOIhNGHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODQ3OQ==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688479", "createdAt": "2021-02-07T20:31:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzEyMTU0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMTozNlrOIhNGOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMTozNlrOIhNGOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODUwNA==", "bodyText": "drop final.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688504", "createdAt": "2021-02-07T20:31:36Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzEyMTg4OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMjowN1rOIhNGXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMjowN1rOIhNGXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODU0Mg==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688542", "createdAt": "2021-02-07T20:32:07Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzEyMjM1OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMjozNVrOIhNGmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMjozNVrOIhNGmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwMQ==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688601", "createdAt": "2021-02-07T20:32:35Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwMzEyMjQwOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozMjo0MVrOIhNGnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMDo0NTozNlrOIhczDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwNw==", "bodyText": "drop final.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688607", "createdAt": "2021-02-07T20:32:41Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk0NTc0MA==", "bodyText": "simplify as above", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571945740", "createdAt": "2021-02-08T10:45:36Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwNw=="}, "originalCommit": null, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNDkxMTM0OnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMDo0NDoyNVrOIhcv6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMDo0NDoyNVrOIhcv6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk0NDkzNw==", "bodyText": "this is not performance critical so let's just use builder() and make ti fluent:\n            List<CompletableFuture<Void>> allFutures = ImmutableList.<CompletableFuture<Void>>builder()\n                    .addAll(updateFutures)\n                    .addAll(deleteFutures)\n                    .build();\n            getFutureValue(allOf(allFutures.toArray(CompletableFuture[]::new)));", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571944937", "createdAt": "2021-02-08T10:44:25Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());\n+            updateOperationsFutures.addAll(updateFutures);\n+            updateOperationsFutures.addAll(deleteFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTAyODAwOnYy", "diffSide": "RIGHT", "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMTowN1rOIhdzhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMTowN1rOIhdzhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk2MjI0NQ==", "bodyText": "drop final", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571962245", "createdAt": "2021-02-08T11:11:07Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.EntityNotFoundException;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (EntityNotFoundException ex) {\n+            return ImmutableMap.of();\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n+                    .collect(toUnmodifiableList());\n+\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n+\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());\n+            updateOperationsFutures.addAll(updateFutures);\n+            updateOperationsFutures.addAll(deleteFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n+\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n+            Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n+\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());\n+            updateOperationsFutures.addAll(writePartitionStatsFutures);\n+            updateOperationsFutures.addAll(deleteStatsFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    private List<String> getAllColumns(Table table)\n+    {\n+        final ImmutableList.Builder<String> allColumns = ImmutableList.builderWithExpectedSize(table.getDataColumns().size() + table.getPartitionColumns().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 240}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4468, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}