{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA3NzQ5MTkz", "number": 3522, "reviewThreads": {"totalCount": 61, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwODoxNDoyNFrOD1J8yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMDo1ODo0OFrOEG6SVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MDY0MTM5OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwODoxNDoyNFrOGKcmxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwODoxNDoyNFrOGKcmxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYwNzYyMw==", "bodyText": "Can we move this below getSqlTimeZone , similarly for other setter method also", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r413607623", "createdAt": "2020-04-23T08:14:24Z", "author": {"login": "Praveen2112"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    public boolean getUseApproxCountDistinct()\n+    {\n+        return useApproximateCountDistinct;\n+    }\n+\n+    public boolean getUseApproxTopN()\n+    {\n+        return useApproximateTopN;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")\n+    public DruidConfig setSqlTimeZone(String sqlTimeZone)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MDY1ODEyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwODoxODoxOFrOGKcw_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMTowMDowOFrOGQXWEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMDIzOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                static final String DRUID_SCHEM = \"druid\";\n          \n          \n            \n                static final String DRUID_SCHEMA = \"druid\";", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r413610238", "createdAt": "2020-04-23T08:18:18Z", "author": {"login": "Praveen2112"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEM = \"druid\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgxMjg4MQ==", "bodyText": "I think the intent was to follow the column name TABLE_SCHEM. I don't feel strongly about either way. Will change to DRUID_SCHEMA.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r419812881", "createdAt": "2020-05-05T01:00:08Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEM = \"druid\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMDIzOA=="}, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MDY2NjI1OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwODoyMDoxM1rOGKc2AA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDo1ODoyNVrOGQXUXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMTUyMA==", "bodyText": "If the schema name is restricted to druid we might have to implement them in getSchemaNames", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r413611520", "createdAt": "2020-04-23T08:20:13Z", "author": {"login": "Praveen2112"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEM = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEM,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgxMjIwNQ==", "bodyText": "With 0.18, Druid supports the following schemas: druid, information_schema, sys, lookup", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r419812205", "createdAt": "2020-05-05T00:57:28Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEM = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEM,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMTUyMA=="}, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgxMjQ0Nw==", "bodyText": "See DruidIntegrationSmokeTest#testShowSchemas", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r419812447", "createdAt": "2020-05-05T00:58:25Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEM = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEM,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMTUyMA=="}, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzgzMDUzOnYy", "diffSide": "RIGHT", "path": ".github/workflows/ci.yml", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoxOTo1M1rOGa66Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMzoxMDo1N1rOGb0WGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTM1NQ==", "bodyText": "how much time does this group take now, and how much time druid adds?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430881355", "createdAt": "2020-05-27T06:19:53Z", "author": {"login": "findepi"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -160,7 +161,7 @@ jobs:\n           - \"presto-sqlserver,presto-postgresql,presto-mysql\"\n           - \"presto-oracle\"\n           - \"presto-kudu\"\n-          - \"presto-phoenix,presto-iceberg\"\n+          - \"presto-phoenix,presto-iceberg,presto-druid\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM3MzIyMg==", "bodyText": "I am actually not sure about what rationale to use when deciding where should I add the presto-druid module? Is it duration a group takes that should determine this?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431373222", "createdAt": "2020-05-27T19:00:16Z", "author": {"login": "samarthjain"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -160,7 +161,7 @@ jobs:\n           - \"presto-sqlserver,presto-postgresql,presto-mysql\"\n           - \"presto-oracle\"\n           - \"presto-kudu\"\n-          - \"presto-phoenix,presto-iceberg\"\n+          - \"presto-phoenix,presto-iceberg,presto-druid\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTM1NQ=="}, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUyNDc4MQ==", "bodyText": "Also, in this run https://github.com/prestosql/presto/pull/3522/checks?check_run_id=711960215, I don't think Druid integration tests ran.\n[INFO] presto-phoenix ..................................... SUCCESS [08:42 min]\n[INFO] presto-iceberg ..................................... SUCCESS [06:35 min]\n[INFO] presto-druid ....................................... SUCCESS [  5.386 s]\n\nMy guess is only the unit tests were executed.\nWhat needs to be done to run the integration test?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431524781", "createdAt": "2020-05-28T00:58:14Z", "author": {"login": "samarthjain"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -160,7 +161,7 @@ jobs:\n           - \"presto-sqlserver,presto-postgresql,presto-mysql\"\n           - \"presto-oracle\"\n           - \"presto-kudu\"\n-          - \"presto-phoenix,presto-iceberg\"\n+          - \"presto-phoenix,presto-iceberg,presto-druid\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTM1NQ=="}, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyMjM2MA==", "bodyText": "I added 85fa532\nlet me know if it helps.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431822360", "createdAt": "2020-05-28T13:10:57Z", "author": {"login": "findepi"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -160,7 +161,7 @@ jobs:\n           - \"presto-sqlserver,presto-postgresql,presto-mysql\"\n           - \"presto-oracle\"\n           - \"presto-kudu\"\n-          - \"presto-phoenix,presto-iceberg\"\n+          - \"presto-phoenix,presto-iceberg,presto-druid\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTM1NQ=="}, "originalCommit": null, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzgzMTE0OnYy", "diffSide": "RIGHT", "path": ".github/workflows/ci.yml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyMDowNVrOGa66ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMTo1OToxNlrOGlCdXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTQ0Mw==", "bodyText": "move to !presto-phoenix,!presto-iceberg, line", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430881443", "createdAt": "2020-05-27T06:20:05Z", "author": {"login": "findepi"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -139,7 +139,8 @@ jobs:\n             !presto-oracle,\n             !presto-kudu,\n             !presto-phoenix,!presto-iceberg,\n-            !presto-docs,!presto-server,!presto-server-rpm'\n+            !presto-docs,!presto-server,!presto-server-rpm,\n+            !presto-druid'", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5MDc4MA==", "bodyText": "the modules here should be in the same order as in the test job definition, to allow eyeballing the differences quickly (linearly \ud83d\ude09 )\nalso, i don't think druid needs a separate job run today, so\n\nadd this to !presto-phoenix,!presto-iceberg,!presto-druid here\n\"presto-phoenix,presto-iceberg,presto-druid\" below", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441490780", "createdAt": "2020-06-17T11:59:16Z", "author": {"login": "findepi"}, "path": ".github/workflows/ci.yml", "diffHunk": "@@ -139,7 +139,8 @@ jobs:\n             !presto-oracle,\n             !presto-kudu,\n             !presto-phoenix,!presto-iceberg,\n-            !presto-docs,!presto-server,!presto-server-rpm'\n+            !presto-docs,!presto-server,!presto-server-rpm,\n+            !presto-druid'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTQ0Mw=="}, "originalCommit": null, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzgzMzU3OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyMDo1MlrOGa68Bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMTowNTo0NFrOGktJrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA==", "bodyText": "What are semantics of this setting? Why do we need it?\n(we don't\u00a0need this in other JDBC-based connectors)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430881798", "createdAt": "2020-05-27T06:20:52Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5MzE1Mw==", "bodyText": "Druid allows setting this a connection property https://druid.apache.org/docs/latest/querying/sql#connection-context.\nSo exposed the setting the connector as well.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431393153", "createdAt": "2020-05-27T19:30:09Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyMzk1Ng==", "bodyText": "Is this similar to session zone in Presto?\nIf so, exposing this as configuration is not correct, as changing the setting would affect correctness of Druid queries Presto generates.\nPlease explain semantics of this thing on druid side.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431823956", "createdAt": "2020-05-28T13:13:22Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjczMDcwMg==", "bodyText": "It sets the time zone for the connection, which affects how time functions and timestamp literals behave.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432730702", "createdAt": "2020-05-29T20:55:27Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjkyNTE5MQ==", "bodyText": "Let me know if you would still like me to remove the config.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432925191", "createdAt": "2020-05-31T08:55:47Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzIxNDY2Ng==", "bodyText": "The config changes the plugin behavior, but is independent from the session zone. So i guess there is actually one config value yielding correct results -- UTC? same as JVM zone? same as session zone? i don't know... I would suggest that you add tests similar to io.prestosql.plugin.postgresql.TestPostgreSqlTypeMapping#testTimestamp", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r433214666", "createdAt": "2020-06-01T12:50:38Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE0MTY3Ng==", "bodyText": "Removed the druid.sql-time-zone config for now.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441141676", "createdAt": "2020-06-16T21:05:44Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private String sqlTimeZone = \"UTC\";\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public String getSqlTimeZone()\n+    {\n+        return this.sqlTimeZone;\n+    }\n+\n+    @Config(\"druid.sql-time-zone\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MTc5OA=="}, "originalCommit": null, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzgzNTI0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyMTozNVrOGa69BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMzoxNzo1NFrOGb0oog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MjA1Mw==", "bodyText": "private", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430882053", "createdAt": "2020-05-27T06:21:35Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM3MzU5Ng==", "bodyText": "Both of these constants are used in DruidQueryRunner", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431373596", "createdAt": "2020-05-27T19:00:55Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MjA1Mw=="}, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyNzEwNg==", "bodyText": "DRUID_CATALOG must be private (explanation there)\nif Druid does not support schemas (always one schema), the DRUID_SCHEMA can stay visible", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431827106", "createdAt": "2020-05-28T13:17:54Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MjA1Mw=="}, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg0MDM0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyMzo1M1rOGa7AQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMTowMjoxNlrOGcr9rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4Mjg4Mg==", "bodyText": "does it mean druid does not support multiple catalogs, schemas?\nwhat would happen if you passed null for catalog and schema (correct from API perspective)?\n\nalso, if if only druid schema is allowed, then add this:\ncheckArgument(schemaName.isEmpty() || schemaName.get().equals(\"druid\")\", ....)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430882882", "createdAt": "2020-05-27T06:23:53Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM4NTMyNg==", "bodyText": "Druid only supports Druid as catalog. Druid datasources always have druid schema. Metadata and other operational information is exposed through the various tables hosted under information_schema, sys and lookup schemas. Should we expose these additional tables through the connector as well?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431385326", "createdAt": "2020-05-27T19:17:21Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4Mjg4Mg=="}, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyNzQ3NA==", "bodyText": "hosted under information_schema, sys and lookup schemas. Should we expose these additional tables through the connector as well?\n\nno", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431827474", "createdAt": "2020-05-28T13:18:31Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4Mjg4Mg=="}, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjczMzYxNA==", "bodyText": "I think overriding the BaseJdbcClient#listSchemas(Connection connection) to return the lone druid schema makes more sense here.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432733614", "createdAt": "2020-05-29T21:02:16Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4Mjg4Mg=="}, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg0MTI4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyNDoyMVrOGa7A5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMTowNDowM1rOGcsAmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MzA0NA==", "bodyText": "Needs to be escaped. see io.prestosql.plugin.jdbc.BaseJdbcClient#escapeNamePattern", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430883044", "createdAt": "2020-05-27T06:24:21Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjczNDM2Mg==", "bodyText": "BaseJdbcClient#escapeNamePattern doesn't work for Druid, unfortunately. See this comment", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432734362", "createdAt": "2020-05-29T21:04:03Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MzA0NA=="}, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg0NTkxOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyNjoyNlrOGa7EEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyNjoyNlrOGa7EEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4Mzg1Ng==", "bodyText": "inine", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430883856", "createdAt": "2020-05-27T06:26:26Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg0NzE4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyNjo1NlrOGa7E4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMTowMzozMVrOGcr_ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NDA2Ng==", "bodyText": "?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430884066", "createdAt": "2020-05-27T06:26:56Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjczNDA5MA==", "bodyText": "Will remove. Missed cleaning it up.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432734090", "createdAt": "2020-05-29T21:03:31Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NDA2Ng=="}, "originalCommit": null, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg0ODczOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjoyNzozNlrOGa7Fzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMjo1ODoxOVrOGcud_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NDMwMw==", "bodyText": "Why is this method overridden?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430884303", "createdAt": "2020-05-27T06:27:36Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc3NDY1Mg==", "bodyText": "This method was overriden since it was calling the getDruidColumns() method.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432774652", "createdAt": "2020-05-29T22:58:19Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NDMwMw=="}, "originalCommit": null, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg1NDc4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozMDoyOFrOGa7Jyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQxMjo1Nzo1M1rOGdJhjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTMyMw==", "bodyText": "Then it might be not correct -- when asking for some_table, you should also get columns from somertable, (unless Druid JDBC not only does not support escaping, but also does not support patterns).\nIf I am right, and there really is no way to escape, we need to filter on our side as well.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430885323", "createdAt": "2020-05-27T06:30:28Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE4NzE0Ng==", "bodyText": "One of the problems I found with BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData) is how it handles _.\npassing orders_1 to escapeNamePattern(\"orders_1\", \"\\\") changes the string to\norders\\_1. And so when the call is made to Druid to get the metadata using:\nprotected ResultSet getColumns(JdbcTableHandle tableHandle, DatabaseMetaData metadata)\n            throws SQLException\n    {\n        return metadata.getColumns(\n                tableHandle.getCatalogName(),\n                escapeNamePattern(Optional.ofNullable(tableHandle.getSchemaName()), metadata.getSearchStringEscape()).orElse(null),\n                escapeNamePattern(Optional.ofNullable(tableHandle.getTableName()), metadata.getSearchStringEscape()).orElse(null),\n                null);\n    }\n\nthe call fails since Druid doesn't remove the escape character \\. So I am not sure if escaping is going to work here.\nDruid though, by itself, does support patterns.\nSee:\nhttps://github.com/apache/druid/blob/master/sql/src/main/java/org/apache/druid/sql/avatica/DruidMeta.java#L457", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432187146", "createdAt": "2020-05-28T23:59:58Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTMyMw=="}, "originalCommit": null, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzIxNzkzNA==", "bodyText": "That's strange, because it reports \\ in java.sql.DatabaseMetaData#getSearchStringEscape...\nIf we cannot use search escapes, this would mean we need to add filtering on our side.\nYou can test this with:\n\ncreate some_table in druid, with a column\ncreate somertable in druid, with b column\nrun DESCRIBE some_table\n\ni expect that, with current code, it will report both a and b columns.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r433217934", "createdAt": "2020-06-01T12:57:53Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTMyMw=="}, "originalCommit": null, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg1Njc5OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozMToxOVrOGa7K_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMzoxOToyMFrOGb0sJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTYyOQ==", "bodyText": "We can modify the QueryBuilder to eg SELECT 1. Would that help?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430885629", "createdAt": "2020-05-27T06:31:19Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.\n+     */\n+    private static ResultSet getDruidColumns(JdbcTableHandle tableHandle, DatabaseMetaData metadata)\n+            throws SQLException\n+    {\n+        return metadata.getColumns(\n+                tableHandle.getCatalogName(),\n+                tableHandle.getSchemaName(),\n+                tableHandle.getTableName(),\n+                null);\n+    }\n+\n+    /**\n+     * Overriding this method to handle following weirdness/issues in Druid:\n+     * 1) Druid doesn't like table names to be qualified with catalog names in the SQL query. So setting it to an empty string.\n+     * 2) Need to use DruidQueryBuilder since Druid doesn't like SELECT NULL queries when there are no columns projected.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM4ODg0Mw==", "bodyText": "This is exactly what we are doing right now in DruidQueryBuilder\n@Override\nprotected String getProjection(List<JdbcColumnHandle> columns)\n{\n        // Druid doesn't support SELECT NULL queries\n        if (columns.isEmpty()) {\n            return \"1\";\n        }\n        return super.getProjection(columns);\n}", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431388843", "createdAt": "2020-05-27T19:21:57Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.\n+     */\n+    private static ResultSet getDruidColumns(JdbcTableHandle tableHandle, DatabaseMetaData metadata)\n+            throws SQLException\n+    {\n+        return metadata.getColumns(\n+                tableHandle.getCatalogName(),\n+                tableHandle.getSchemaName(),\n+                tableHandle.getTableName(),\n+                null);\n+    }\n+\n+    /**\n+     * Overriding this method to handle following weirdness/issues in Druid:\n+     * 1) Druid doesn't like table names to be qualified with catalog names in the SQL query. So setting it to an empty string.\n+     * 2) Need to use DruidQueryBuilder since Druid doesn't like SELECT NULL queries when there are no columns projected.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTYyOQ=="}, "originalCommit": null, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyODAwNQ==", "bodyText": "perfect; then let's change the original class to avoid making a copy/subclass", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431828005", "createdAt": "2020-05-28T13:19:20Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    static final String DRUID_CATALOG = \"druid\";\n+    static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Multiple tables matched: \" + schemaTableName);\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                return jdbcTypeToPrestoType(typeHandle);\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    private Optional<ColumnMapping> jdbcTypeToPrestoType(JdbcTypeHandle type)\n+    {\n+        int columnSize = type.getColumnSize();\n+        if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+            return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+        }\n+        return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+    }\n+\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session))) {\n+            try (ResultSet resultSet = getDruidColumns(tableHandle, connection.getMetaData())) {\n+                List<JdbcColumnHandle> columns = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                            resultSet.getInt(\"DATA_TYPE\"),\n+                            // type_name isn't supported in Druid\n+                            Optional.of(resultSet.getString(\"TYPE_NAME\")),\n+                            resultSet.getInt(\"COLUMN_SIZE\"),\n+                            resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                            // array_dimensions isn't supported in Druid\n+                            Optional.ofNullable(null));\n+                    Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                    // skip unsupported column types\n+                    if (columnMapping.isPresent()) {\n+                        String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                        boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                        columns.add(new JdbcColumnHandle(columnName, typeHandle, columnMapping.get().getType(), nullable));\n+                    }\n+                }\n+                if (columns.isEmpty()) {\n+                    // In rare cases (e.g. PostgreSQL) a table might have no columns.\n+                    throw new TableNotFoundException(tableHandle.getSchemaTableName());\n+                }\n+                return ImmutableList.copyOf(columns);\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Custom way of retrieving column names since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     * method uses character escaping that doesn't jive well with Druid SQL.\n+     */\n+    private static ResultSet getDruidColumns(JdbcTableHandle tableHandle, DatabaseMetaData metadata)\n+            throws SQLException\n+    {\n+        return metadata.getColumns(\n+                tableHandle.getCatalogName(),\n+                tableHandle.getSchemaName(),\n+                tableHandle.getTableName(),\n+                null);\n+    }\n+\n+    /**\n+     * Overriding this method to handle following weirdness/issues in Druid:\n+     * 1) Druid doesn't like table names to be qualified with catalog names in the SQL query. So setting it to an empty string.\n+     * 2) Need to use DruidQueryBuilder since Druid doesn't like SELECT NULL queries when there are no columns projected.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NTYyOQ=="}, "originalCommit": null, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg2MDM0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozMzowMFrOGa7NSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMjo1ODo0MlrOGcueUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NjIxOA==", "bodyText": "target/storage?\n/tmp/$USER-druid-test-storage?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430886218", "createdAt": "2020-05-27T06:33:00Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    public DruidIntegrationSmokeTest()\n+    {\n+        try {\n+            Path storage = Paths.get(\"storage\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc3NDczOQ==", "bodyText": "Will change to target/storage", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432774739", "createdAt": "2020-05-29T22:58:42Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    public DruidIntegrationSmokeTest()\n+    {\n+        try {\n+            Path storage = Paths.get(\"storage\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NjIxOA=="}, "originalCommit": null, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg2Mjk4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozNDowMFrOGa7PAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozNDowMFrOGa7PAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NjY1Ng==", "bodyText": "move IO and instnatiation of the server to createQueryRunner method.\nTest constructors should be as simple as possible, because they are run eagerly at the very start of all tests.\nAlso, the error reporting for ctor failures is suboptimal.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430886656", "createdAt": "2020-05-27T06:34:00Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    public DruidIntegrationSmokeTest()\n+    {\n+        try {\n+            Path storage = Paths.get(\"storage\");\n+            if (Files.exists(storage)) {\n+                druidServer = new TestingDruidServer(storage.toAbsolutePath().toString());\n+            }\n+            else {\n+                druidServer = new TestingDruidServer(Files.createDirectory(storage).toAbsolutePath().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg2NTY5OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozNToxMlrOGa7QzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozNToxMlrOGa7QzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NzExNg==", "bodyText": "Document why.\nSee also https://prestosql.slack.com/archives/CP1MUNEUX/p1588690413495700 how we would like to suppress tests now. This also solves the documentation needs.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430887116", "createdAt": "2020-05-27T06:35:12Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    public DruidIntegrationSmokeTest()\n+    {\n+        try {\n+            Path storage = Paths.get(\"storage\");\n+            if (Files.exists(storage)) {\n+                druidServer = new TestingDruidServer(storage.toAbsolutePath().toString());\n+            }\n+            else {\n+                druidServer = new TestingDruidServer(Files.createDirectory(storage).toAbsolutePath().toString());\n+            }\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        return DruidQueryRunner.createDruidQueryRunnerTpch(druidServer, ORDERS);\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        druidServer.close();\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowSchemas()\n+    {\n+        assertQuery(\"SHOW SCHEMAS FROM druid\", \"VALUES 'druid', 'information_schema', 'sys', 'lookup'\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mzg2Nzc5OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNjozNjowM1rOGa7SNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMjo1OTo0MlrOGcufKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NzQ3OQ==", "bodyText": "Since the connector supports inserts too, add AbstractTestDistributedQueries", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r430887479", "createdAt": "2020-05-27T06:36:03Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUwMzEwMA==", "bodyText": "You mean inserts into non-druid datasources? There is no write path to directly create and insert into a Druid datasource available in the connector.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431503100", "createdAt": "2020-05-27T23:40:48Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NzQ3OQ=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyODQ4Ng==", "bodyText": "As the connector extends base-jdbc, it inherits support for writes", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431828486", "createdAt": "2020-05-28T13:19:59Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NzQ3OQ=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc3NDk1NQ==", "bodyText": "I will override all the write related methods to throw an unsupported operation exception.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r432774955", "createdAt": "2020-05-29T22:59:42Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.QueryRunner;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+\n+@Test\n+public class DruidIntegrationSmokeTest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NzQ3OQ=="}, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4OTYyMzI0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMzoxNjoxMFrOGb0kSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMzoxNjoxMFrOGb0kSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyNTk5Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        queryRunner.createCatalog(DRUID_CATALOG, DRUID_SCHEMA, connectorProperties);\n          \n          \n            \n                        queryRunner.createCatalog(\"druid\", \"druid\", connectorProperties);\n          \n      \n    \n    \n  \n\n\nDruidJdbcClient. DRUID_CATALOG describes fixed catalog on Druid side; on Presto side we could choose any catalog name we want (like \"sales_data\"), and we just chose to name the catalog \"druid\" by convention\nDruidJdbcClient. DRUID_SCHEMA describes fixed schema on Druid side; here this is connector name (which incidentally is also \"druid\")", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r431825993", "createdAt": "2020-05-28T13:16:10Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.Session;\n+import io.prestosql.metadata.QualifiedObjectName;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.MaterializedRow;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.tpch.TpchTable;\n+import org.intellij.lang.annotations.Language;\n+\n+import java.io.BufferedWriter;\n+import java.io.File;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static io.airlift.testing.Closeables.closeAllSuppress;\n+import static io.prestosql.plugin.druid.DruidJdbcClient.DRUID_CATALOG;\n+import static io.prestosql.plugin.druid.DruidJdbcClient.DRUID_SCHEMA;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.TestingSession.testSessionBuilder;\n+import static java.lang.String.format;\n+\n+public class DruidQueryRunner\n+{\n+    private DruidQueryRunner() {}\n+\n+    public static QueryRunner createDruidQueryRunnerTpch(TestingDruidServer testingDruidServer, TpchTable table)\n+            throws Exception\n+    {\n+        DistributedQueryRunner queryRunner = null;\n+        try {\n+            queryRunner = DistributedQueryRunner.builder(createSession()).setNodeCount(3).build();\n+            queryRunner.installPlugin(new TpchPlugin());\n+            queryRunner.createCatalog(\"tpch\", \"tpch\");\n+\n+            Map<String, String> connectorProperties = new HashMap<>();\n+            connectorProperties.putIfAbsent(\"connection-url\", testingDruidServer.getJdbcUrl());\n+            queryRunner.installPlugin(new DruidJdbcPlugin());\n+            queryRunner.createCatalog(DRUID_CATALOG, DRUID_SCHEMA, connectorProperties);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDYxOTI1OnYy", "diffSide": "RIGHT", "path": "presto-main/etc/catalog/druid.properties", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjowMzo0MlrOGlCmPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjowMzo0MlrOGlCmPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5MzA1NA==", "bodyText": "move to presto-server-main/etc/catalog", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441493054", "createdAt": "2020-06-17T12:03:42Z", "author": {"login": "findepi"}, "path": "presto-main/etc/catalog/druid.properties", "diffHunk": "@@ -0,0 +1,7 @@\n+connector.name=druid", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDY1NTUxOnYy", "diffSide": "RIGHT", "path": "presto-druid/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoxNDo0NFrOGlC8Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoxNDo0NFrOGlC8Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5ODY5OQ==", "bodyText": "move this out of SPI section.\nremove <version>", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441498699", "createdAt": "2020-06-17T12:14:44Z", "author": {"login": "findepi"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDY4MzgyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/resources/middleManager.config", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoyMjo1MVrOGlDN7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoyMjo1MVrOGlDN7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwMzIxNA==", "bodyText": "why Xms? remove?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441503214", "createdAt": "2020-06-17T12:22:51Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/resources/middleManager.config", "diffHunk": "@@ -0,0 +1,30 @@\n+druid.service=druid/middleManager\n+druid.plaintextPort=8091\n+\n+# Number of tasks per middleManager\n+druid.worker.capacity=1\n+\n+# Task launch parameters\n+druid.indexer.runner.javaOpts=-server -Xms256m -Xmx384m -XX:MaxDirectMemorySize=200m -Duser.timezone=UTC -Dfile.encoding=UTF-8 -XX:+ExitOnOutOfMemoryError -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDY4ODAwOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/resources/coordinator-jvm.config", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoyNDoxMFrOGlDQyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoyNDoxMFrOGlDQyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwMzk0NA==", "bodyText": "is coordinator-jvm.config for druid's coordinator?\nmaybe rename to druid-.. to avoid confusion w/ presto coordinator", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441503944", "createdAt": "2020-06-17T12:24:10Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/resources/coordinator-jvm.config", "diffHunk": "@@ -0,0 +1,10 @@\n+-server", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDY5MTY0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjoyNToxN1rOGlDTJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QyMjoxNzo1M1rOGlZSPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwNDU1MQ==", "bodyText": "can we check when the condition is satisfied?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441504551", "createdAt": "2020-06-17T12:25:17Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTczNzc0Ng==", "bodyText": "We do the check here:\ndatasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n                if (datasourceNotLoaded) {\n                    attempts--;\n                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n                    Thread.sleep(15000);\n                }", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441737746", "createdAt": "2020-06-17T18:15:42Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwNDU1MQ=="}, "originalCommit": null, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTgwMzg5OA==", "bodyText": "Cool, if we can verify the condition is satisfied, this can benefit in robustness. Then you can also more frequently for faster test startup.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441803898", "createdAt": "2020-06-17T20:08:55Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwNDU1MQ=="}, "originalCommit": null, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg2NDc2NA==", "bodyText": "Not sure I understand the concern here. We check whether datasource is available by using the druid coordinator api. If it isn't available, we sleep for 15 seconds before checking again. In total, we wait for up to 150 seconds before bailing out.\nint attempts = 10;\nwhile (datasourceNotLoaded && attempts > 0) {\n....\n        ObjectMapper mapper = new ObjectMapper();\n        datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n         \n        datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || \n             Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n        if (datasourceNotLoaded) {\n              attempts--;\n              // Wait for some time since it can take a while for coordinator to load the ingested segments\n               Thread.sleep(15000);\n        }\n}\n\nI can probably change the Druid coordinator frequency to run every 1 second to make the loading slightly faster. Right now, it is configured to run every 5 seconds.\ndruid.coordinator.period=PT1S", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441864764", "createdAt": "2020-06-17T22:17:53Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwNDU1MQ=="}, "originalCommit": null, "originalPosition": 243}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgxNDA5OnYy", "diffSide": "RIGHT", "path": "presto-druid/pom.xml", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1ODoyMVrOGlEgRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMDo0MDo0N1rOGlpuWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNDI5Mw==", "bodyText": "Why depend on presto-product-tests-launcher?\n(in any case, the version should be defined in top level pom.xml)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441524293", "createdAt": "2020-06-17T12:58:21Z", "author": {"login": "findepi"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <!-- for testing -->\n+        <dependency>\n+            <groupId>org.testng</groupId>\n+            <artifactId>testng</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-main</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tpch</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tests</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.testcontainers</groupId>\n+            <artifactId>testcontainers</artifactId>\n+            <scope>test</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>jcl-over-slf4j</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.ws.rs</groupId>\n+            <artifactId>javax.ws.rs-api</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-product-tests-launcher</artifactId>\n+            <version>336-SNAPSHOT</version>\n+            <scope>test</scope>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTczNzM3MQ==", "bodyText": "The dependency analyzer complains about adding the explicit dependency.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441737371", "createdAt": "2020-06-17T18:15:06Z", "author": {"login": "samarthjain"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <!-- for testing -->\n+        <dependency>\n+            <groupId>org.testng</groupId>\n+            <artifactId>testng</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-main</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tpch</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tests</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.testcontainers</groupId>\n+            <artifactId>testcontainers</artifactId>\n+            <scope>test</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>jcl-over-slf4j</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.ws.rs</groupId>\n+            <artifactId>javax.ws.rs-api</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-product-tests-launcher</artifactId>\n+            <version>336-SNAPSHOT</version>\n+            <scope>test</scope>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNDI5Mw=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc5MzE0Mw==", "bodyText": "The question is actually why do you need the dependency?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441793143", "createdAt": "2020-06-17T19:48:02Z", "author": {"login": "findepi"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <!-- for testing -->\n+        <dependency>\n+            <groupId>org.testng</groupId>\n+            <artifactId>testng</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-main</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tpch</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tests</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.testcontainers</groupId>\n+            <artifactId>testcontainers</artifactId>\n+            <scope>test</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>jcl-over-slf4j</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.ws.rs</groupId>\n+            <artifactId>javax.ws.rs-api</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-product-tests-launcher</artifactId>\n+            <version>336-SNAPSHOT</version>\n+            <scope>test</scope>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNDI5Mw=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg3ODIxNQ==", "bodyText": "The dependency is needed to use SelectedPortWaitStrategy here:\nthis.zookeeper = new GenericContainer(\"zookeeper\")\n           ...\n                    .waitingFor(new SelectedPortWaitStrategy(2181));\nzookeeper.start();", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441878215", "createdAt": "2020-06-17T22:58:52Z", "author": {"login": "samarthjain"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <!-- for testing -->\n+        <dependency>\n+            <groupId>org.testng</groupId>\n+            <artifactId>testng</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-main</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tpch</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tests</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.testcontainers</groupId>\n+            <artifactId>testcontainers</artifactId>\n+            <scope>test</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>jcl-over-slf4j</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.ws.rs</groupId>\n+            <artifactId>javax.ws.rs-api</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-product-tests-launcher</artifactId>\n+            <version>336-SNAPSHOT</version>\n+            <scope>test</scope>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNDI5Mw=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjEzNDEwNQ==", "bodyText": "You can use  .waitingFor(Wait.forListeningPort()); instead.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442134105", "createdAt": "2020-06-18T10:40:47Z", "author": {"login": "findepi"}, "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,166 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>io.prestosql</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>336-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Jdbc Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-base-jdbc</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <!-- Druid JDBC Connector -->\n+        <dependency>\n+            <groupId>org.apache.calcite.avatica</groupId>\n+            <artifactId>avatica-core</artifactId>\n+            <version>1.16.0</version>\n+            <!-- Excluded as they bring in duplicate classes -->\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>commons-logging</groupId>\n+                    <artifactId>commons-logging</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <!-- SPI -->\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+            <version>2.10.3</version>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <!-- for testing -->\n+        <dependency>\n+            <groupId>org.testng</groupId>\n+            <artifactId>testng</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-main</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tpch</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-tests</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.testcontainers</groupId>\n+            <artifactId>testcontainers</artifactId>\n+            <scope>test</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>jcl-over-slf4j</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>testing</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.ws.rs</groupId>\n+            <artifactId>javax.ws.rs-api</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.prestosql</groupId>\n+            <artifactId>presto-product-tests-launcher</artifactId>\n+            <version>336-SNAPSHOT</version>\n+            <scope>test</scope>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNDI5Mw=="}, "originalCommit": null, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgxODYwOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1OTozNVrOGlEjIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QyMjo0ODozN1rOGlZ6Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTAyNA==", "bodyText": "Shouldn't this be false by default, as this affects query results?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441525024", "createdAt": "2020-06-17T12:59:35Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTczNzk5OQ==", "bodyText": "Druid SQL has this on by default.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441737999", "createdAt": "2020-06-17T18:16:09Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTAyNA=="}, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTgwNTMyNQ==", "bodyText": "We expose Druid data, but we query it with ANSI SQL. If we want to slightly deviate from semantics, for significant performance benefits, this should be an opt in.\nBTW isn't this dead code today? we won't send count distinct or top n queries to Druid yet.\nIf i am right, we should remove this now, and add this later, when we implement agg pushdown, top n pushdown.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441805325", "createdAt": "2020-06-17T20:11:37Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTAyNA=="}, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg3NDk5MA==", "bodyText": "Sounds good. I will get rid of DruidConfig for now.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441874990", "createdAt": "2020-06-17T22:48:37Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTAyNA=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgxOTA0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1OTo0MlrOGlEjZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1OTo0MlrOGlEjZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTA5Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public boolean getUseApproxCountDistinct()\n          \n          \n            \n                public boolean isUseApproxCountDistinct()", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441525092", "createdAt": "2020-06-17T12:59:42Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public boolean getUseApproxCountDistinct()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgxOTQ3OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1OTo0OVrOGlEjqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMjo1OTo0OVrOGlEjqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTE2Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public boolean getUseApproxTopN()\n          \n          \n            \n                public boolean isUseApproxTopN()", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441525162", "createdAt": "2020-06-17T12:59:49Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public boolean getUseApproxCountDistinct()\n+    {\n+        return useApproximateCountDistinct;\n+    }\n+\n+    @Config(\"druid.use-approx-count-distinct\")\n+    public DruidConfig setUseApproxCountDistinct(boolean useApproxCountDistinct)\n+    {\n+        this.useApproximateCountDistinct = useApproxCountDistinct;\n+        return this;\n+    }\n+\n+    public boolean getUseApproxTopN()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgyMDE4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMDowM1rOGlEkKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMDowM1rOGlEkKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTI5MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Config(\"druid.use-approx-topn\")\n          \n          \n            \n                @Config(\"druid.use-approximate-top-n\")", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441525290", "createdAt": "2020-06-17T13:00:03Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public boolean getUseApproxCountDistinct()\n+    {\n+        return useApproximateCountDistinct;\n+    }\n+\n+    @Config(\"druid.use-approx-count-distinct\")\n+    public DruidConfig setUseApproxCountDistinct(boolean useApproxCountDistinct)\n+    {\n+        this.useApproximateCountDistinct = useApproxCountDistinct;\n+        return this;\n+    }\n+\n+    public boolean getUseApproxTopN()\n+    {\n+        return useApproximateTopN;\n+    }\n+\n+    @Config(\"druid.use-approx-topn\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgyMzUzOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMDo1MFrOGlEmNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMDo1MFrOGlEmNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNTgxNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Config(\"druid.use-approx-count-distinct\")\n          \n          \n            \n                @Config(\"druid.use-approximate-count-distinct\")\n          \n      \n    \n    \n  \n\nspell out approximate (especially that druid jdbc config also does not use abbrev)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441525814", "createdAt": "2020-06-17T13:00:50Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidConfig.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.airlift.configuration.Config;\n+\n+public class DruidConfig\n+{\n+    private boolean useApproximateCountDistinct = true;\n+    private boolean useApproximateTopN = true;\n+\n+    public boolean getUseApproxCountDistinct()\n+    {\n+        return useApproximateCountDistinct;\n+    }\n+\n+    @Config(\"druid.use-approx-count-distinct\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgyODUxOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMjowMlrOGlEpSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowMjowMlrOGlEpSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNjYwMA==", "bodyText": "Thanks, these are helpful comments!", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441526600", "createdAt": "2020-06-17T13:02:02Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDgzNjExOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNDowOFrOGlEuUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNDowOFrOGlEuUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyNzg4OA==", "bodyText": "It looks like this doesn't have to be overridden.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441527888", "createdAt": "2020-06-17T13:04:08Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg0NDcyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNjoxMFrOGlEzog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNjoxMFrOGlEzog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyOTI1MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Overriden to filter out tables that don't match @param schemaTableName\n          \n          \n            \n                 */\n          \n          \n            \n                // Overridden to filter out tables that don't match schemaTableName\n          \n      \n    \n    \n  \n\n(typoe, plus it's not a javadoc)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441529250", "createdAt": "2020-06-17T13:06:10Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg1MDY3OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNzo0N1rOGlE3tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowNzo0N1rOGlE3tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMDI5Mg==", "bodyText": "the filtering should be applied regardless whether we have 1 candidate or many\n(if we have 1, it may be a wrong one)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441530292", "createdAt": "2020-06-17T13:07:47Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg1MTYyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowODowM1rOGlE4YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowODowM1rOGlE4YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMDQ2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441530464", "createdAt": "2020-06-17T13:08:03Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg1ODU4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowOTo1NlrOGlE89Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzowOTo1NlrOGlE89Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMTYzNw==", "bodyText": "Javadoc defines method behavior, here you explain technical choice. While this could go as @implNote, it is better to just turn this into /* comment\nalso, Overriden -> Overridden", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441531637", "createdAt": "2020-06-17T13:09:56Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg2MjM0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMDo1MVrOGlE_bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMDo1MVrOGlE_bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMjI3MA==", "bodyText": "move the default out of switch, as last line of the method", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441532270", "createdAt": "2020-06-17T13:10:51Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg2Njg4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMjowMFrOGlFCWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMjowMFrOGlFCWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMzAxNw==", "bodyText": "why is \"\" schema OK here?\nMaybe just:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n          \n          \n            \n                    checkArgument(\"druid\".equals(schemaName), \"Only \\\"druid\\\" schema is supported\");", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441533017", "createdAt": "2020-06-17T13:12:00Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg2ODU2OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMjoyN1rOGlFDeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMjoyN1rOGlFDeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMzMwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n          \n          \n            \n                 * Hence, overriding this method to pass catalog as an empty string.\n          \n          \n            \n                 */\n          \n          \n            \n                // Druid doesn't like table names to be qualified with catalog names in the SQL query.\n          \n          \n            \n                // Hence, overriding this method to pass catalog as an empty string.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441533305", "createdAt": "2020-06-17T13:12:27Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg3Mjc2OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMzozMVrOGlFGKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMzozMVrOGlFGKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzMzk5NQ==", "bodyText": "i think null would be more appriopriate\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"\",\n          \n          \n            \n                                    null,\n          \n      \n    \n    \n  \n\n(please also update method comment)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441533995", "createdAt": "2020-06-17T13:13:31Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg3Mzk1OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMzo0OFrOGlFG6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxMzo0OFrOGlFG6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNDE4Nw==", "bodyText": "same here", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441534187", "createdAt": "2020-06-17T13:13:48Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",\n+                        schemaName,\n+                        table.getTableName(),\n+                        columns,\n+                        table.getConstraint(),\n+                        split.getAdditionalPredicate(),\n+                        tryApplyLimit(table.getLimit()));\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match the @param tableHandle", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg3ODA2OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNDo0N1rOGlFJdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QyMjoyMDo0MVrOGlZWJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNDgzNg==", "bodyText": "Is this the only thing being added here?\nIf we added this in BaseJdbcClient, would it allow us not to override this (lengthy) method?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441534836", "createdAt": "2020-06-17T13:14:47Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",\n+                        schemaName,\n+                        table.getTableName(),\n+                        columns,\n+                        table.getConstraint(),\n+                        split.getAdditionalPredicate(),\n+                        tryApplyLimit(table.getLimit()));\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match the @param tableHandle\n+     * <p>\n+     * See {@link #getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     */\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session));\n+                ResultSet resultSet = getColumns(tableHandle, connection.getMetaData())) {\n+            int allColumns = 0;\n+            List<JdbcColumnHandle> columns = new ArrayList<>();\n+            while (resultSet.next()) {\n+                // skip if table doesn't match expected\n+                if (!(Objects.equals(tableHandle.getCatalogName(), resultSet.getString(\"TABLE_CAT\"))\n+                        && Objects.equals(tableHandle.getSchemaName(), resultSet.getString(\"TABLE_SCHEM\"))\n+                        && Objects.equals(tableHandle.getTableName(), resultSet.getString(\"TABLE_NAME\")))) {\n+                    continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg2NTc2Nw==", "bodyText": "Yes, I wouldn't need to override the method then. Wasn't too sure if it would be ok to move the check in the base class's method. Will move the check in the base class and hopefully tests for other connectors will still pass (they do pass for the Druid connector).", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441865767", "createdAt": "2020-06-17T22:20:41Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",\n+                        schemaName,\n+                        table.getTableName(),\n+                        columns,\n+                        table.getConstraint(),\n+                        split.getAdditionalPredicate(),\n+                        tryApplyLimit(table.getLimit()));\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match the @param tableHandle\n+     * <p>\n+     * See {@link #getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     */\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session));\n+                ResultSet resultSet = getColumns(tableHandle, connection.getMetaData())) {\n+            int allColumns = 0;\n+            List<JdbcColumnHandle> columns = new ArrayList<>();\n+            while (resultSet.next()) {\n+                // skip if table doesn't match expected\n+                if (!(Objects.equals(tableHandle.getCatalogName(), resultSet.getString(\"TABLE_CAT\"))\n+                        && Objects.equals(tableHandle.getSchemaName(), resultSet.getString(\"TABLE_SCHEM\"))\n+                        && Objects.equals(tableHandle.getTableName(), resultSet.getString(\"TABLE_NAME\")))) {\n+                    continue;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNDgzNg=="}, "originalCommit": null, "originalPosition": 225}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg4MTU1OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNTozOVrOGlFLvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNTozOVrOGlFLvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNTQyMQ==", "bodyText": "PostgreSQL -> ...\ni think this my also happen when table is removed concurrently, so just remove the comment and leave the check & throw as is", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441535421", "createdAt": "2020-06-17T13:15:39Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",\n+                        schemaName,\n+                        table.getTableName(),\n+                        columns,\n+                        table.getConstraint(),\n+                        split.getAdditionalPredicate(),\n+                        tryApplyLimit(table.getLimit()));\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match the @param tableHandle\n+     * <p>\n+     * See {@link #getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     */\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session));\n+                ResultSet resultSet = getColumns(tableHandle, connection.getMetaData())) {\n+            int allColumns = 0;\n+            List<JdbcColumnHandle> columns = new ArrayList<>();\n+            while (resultSet.next()) {\n+                // skip if table doesn't match expected\n+                if (!(Objects.equals(tableHandle.getCatalogName(), resultSet.getString(\"TABLE_CAT\"))\n+                        && Objects.equals(tableHandle.getSchemaName(), resultSet.getString(\"TABLE_SCHEM\"))\n+                        && Objects.equals(tableHandle.getTableName(), resultSet.getString(\"TABLE_NAME\")))) {\n+                    continue;\n+                }\n+                allColumns++;\n+                String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                        resultSet.getInt(\"DATA_TYPE\"),\n+                        Optional.ofNullable(resultSet.getString(\"TYPE_NAME\")),\n+                        resultSet.getInt(\"COLUMN_SIZE\"),\n+                        resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                        Optional.empty());\n+                Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                // skip unsupported column types\n+                boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                // Note: some databases (e.g. SQL Server) do not return column remarks/comment here.\n+                Optional<String> comment = Optional.ofNullable(emptyToNull(resultSet.getString(\"REMARKS\")));\n+                if (columnMapping.isPresent()) {\n+                    columns.add(JdbcColumnHandle.builder()\n+                            .setColumnName(columnName)\n+                            .setJdbcTypeHandle(typeHandle)\n+                            .setColumnType(columnMapping.get().getType())\n+                            .setNullable(nullable)\n+                            .setComment(comment)\n+                            .build());\n+                }\n+                if (columnMapping.isEmpty()) {\n+                    UnsupportedTypeHandling unsupportedTypeHandling = getUnsupportedTypeHandling(session);\n+                    verify(unsupportedTypeHandling == IGNORE, \"Unsupported type handling is set to %s, but toPrestoType() returned empty\", unsupportedTypeHandling);\n+                }\n+            }\n+            if (columns.isEmpty()) {\n+                // A table may have no supported columns. In rare cases (e.g. PostgreSQL) a table might have no columns at all.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 255}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg4MjYwOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNTo1MFrOGlFMWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNTo1MFrOGlFMWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNTU3Ng==", "bodyText": "same", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441535576", "createdAt": "2020-06-17T13:15:50Z", "author": {"login": "findepi"}, "path": "presto-druid/src/main/java/io/prestosql/plugin/druid/DruidJdbcClient.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.jdbc.BaseJdbcClient;\n+import io.prestosql.plugin.jdbc.BaseJdbcConfig;\n+import io.prestosql.plugin.jdbc.ColumnMapping;\n+import io.prestosql.plugin.jdbc.ConnectionFactory;\n+import io.prestosql.plugin.jdbc.JdbcColumnHandle;\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcOutputTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcSplit;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.plugin.jdbc.JdbcTypeHandle;\n+import io.prestosql.plugin.jdbc.QueryBuilder;\n+import io.prestosql.plugin.jdbc.UnsupportedTypeHandling;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableMetadata;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.connector.TableNotFoundException;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import javax.inject.Inject;\n+\n+import java.sql.Connection;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Strings.emptyToNull;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n+import static io.prestosql.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n+import static io.prestosql.plugin.jdbc.TypeHandlingJdbcSessionProperties.getUnsupportedTypeHandling;\n+import static io.prestosql.plugin.jdbc.UnsupportedTypeHandling.IGNORE;\n+import static io.prestosql.spi.type.VarcharType.createUnboundedVarcharType;\n+import static io.prestosql.spi.type.VarcharType.createVarcharType;\n+import static java.lang.String.format;\n+import static java.sql.DatabaseMetaData.columnNoNulls;\n+\n+public class DruidJdbcClient\n+        extends BaseJdbcClient\n+{\n+    // Druid maintains its datasources related metadata by setting the catalog name as \"druid\"\n+    // Note that while a user may name the catalog name as something else, metadata queries made\n+    // to druid will always have the TABLE_CATALOG set to DRUID_CATALOG\n+    private static final String DRUID_CATALOG = \"druid\";\n+    // All the datasources in Druid are created under schema \"druid\"\n+    public static final String DRUID_SCHEMA = \"druid\";\n+\n+    @Inject\n+    public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactory)\n+            throws SQLException\n+    {\n+        super(config, \"\\\"\", connectionFactory);\n+    }\n+\n+    @Override\n+    public List<SchemaTableName> getTableNames(JdbcIdentity identity, Optional<String> schema)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            try (ResultSet resultSet = getTables(connection, schema, Optional.empty())) {\n+                ImmutableList.Builder<SchemaTableName> list = ImmutableList.builder();\n+                while (resultSet.next()) {\n+                    list.add(new SchemaTableName(\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                return list.build();\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    protected Collection<String> listSchemas(Connection connection)\n+    {\n+        return ImmutableList.of(DRUID_SCHEMA);\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match @param schemaTableName\n+     */\n+    @Override\n+    public Optional<JdbcTableHandle> getTableHandle(JdbcIdentity identity, SchemaTableName schemaTableName)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(identity)) {\n+            String jdbcSchemaName = schemaTableName.getSchemaName();\n+            String jdbcTableName = schemaTableName.getTableName();\n+            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+                List<JdbcTableHandle> tableHandles = new ArrayList<>();\n+                while (resultSet.next()) {\n+                    tableHandles.add(new JdbcTableHandle(\n+                            schemaTableName,\n+                            DRUID_CATALOG,\n+                            resultSet.getString(\"TABLE_SCHEM\"),\n+                            resultSet.getString(\"TABLE_NAME\")));\n+                }\n+                if (tableHandles.isEmpty()) {\n+                    return Optional.empty();\n+                }\n+                if (tableHandles.size() > 1) {\n+                    return Optional.of(\n+                            getOnlyElement(\n+                                    tableHandles\n+                                            .stream()\n+                                            .filter(\n+                                                    jdbcTableHandle ->\n+                                                            Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n+                                                                    && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                            .collect(Collectors.toList())));\n+                }\n+                return Optional.of(getOnlyElement(tableHandles));\n+            }\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getTables(Connection, Optional, Optional)}\n+     * method uses character escaping that doesn't work well with Druid's Avatica handler.\n+     * Unfortunately, because we can't escape search characters like '_' and '%\", this call\n+     * ends up retrieving metadata for all tables that match the search\n+     * pattern. For ex - LIKE some_table matches somertable, somextable and some_table.\n+     * <p>\n+     * See {@link DruidJdbcClient#getTableHandle(JdbcIdentity, SchemaTableName)} to look at\n+     * how tables are filtered.\n+     */\n+\n+    @Override\n+    protected ResultSet getTables(Connection connection, Optional<String> schemaName, Optional<String> tableName)\n+            throws SQLException\n+    {\n+        DatabaseMetaData metadata = connection.getMetaData();\n+        return metadata.getTables(DRUID_CATALOG,\n+                DRUID_SCHEMA,\n+                tableName.orElse(null),\n+                null);\n+    }\n+\n+    @Override\n+    public Optional<ColumnMapping> toPrestoType(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n+    {\n+        switch (typeHandle.getJdbcType()) {\n+            case Types.VARCHAR:\n+                int columnSize = typeHandle.getColumnSize();\n+                if (columnSize > VarcharType.MAX_LENGTH || columnSize == -1) {\n+                    return Optional.of(varcharColumnMapping(createUnboundedVarcharType()));\n+                }\n+                return Optional.of(varcharColumnMapping(createVarcharType(columnSize)));\n+            default:\n+                return super.toPrestoType(session, connection, typeHandle);\n+        }\n+    }\n+\n+    /**\n+     * Druid doesn't like table names to be qualified with catalog names in the SQL query.\n+     * Hence, overriding this method to pass catalog as an empty string.\n+     */\n+    @Override\n+    public PreparedStatement buildSql(ConnectorSession session, Connection connection, JdbcSplit split, JdbcTableHandle table, List<JdbcColumnHandle> columns)\n+            throws SQLException\n+    {\n+        String schemaName = table.getSchemaName();\n+        checkArgument(schemaName.isEmpty() || schemaName.equals(\"druid\"), \"Only \\\"druid\\\" schema is supported\");\n+        return new QueryBuilder(identifierQuote)\n+                .buildSql(\n+                        this,\n+                        session,\n+                        connection,\n+                        \"\",\n+                        schemaName,\n+                        table.getTableName(),\n+                        columns,\n+                        table.getConstraint(),\n+                        split.getAdditionalPredicate(),\n+                        tryApplyLimit(table.getLimit()));\n+    }\n+\n+    /**\n+     * Overriden to filter out tables that don't match the @param tableHandle\n+     * <p>\n+     * See {@link #getColumns(JdbcTableHandle, DatabaseMetaData)}\n+     */\n+    @Override\n+    public List<JdbcColumnHandle> getColumns(ConnectorSession session, JdbcTableHandle tableHandle)\n+    {\n+        try (Connection connection = connectionFactory.openConnection(JdbcIdentity.from(session));\n+                ResultSet resultSet = getColumns(tableHandle, connection.getMetaData())) {\n+            int allColumns = 0;\n+            List<JdbcColumnHandle> columns = new ArrayList<>();\n+            while (resultSet.next()) {\n+                // skip if table doesn't match expected\n+                if (!(Objects.equals(tableHandle.getCatalogName(), resultSet.getString(\"TABLE_CAT\"))\n+                        && Objects.equals(tableHandle.getSchemaName(), resultSet.getString(\"TABLE_SCHEM\"))\n+                        && Objects.equals(tableHandle.getTableName(), resultSet.getString(\"TABLE_NAME\")))) {\n+                    continue;\n+                }\n+                allColumns++;\n+                String columnName = resultSet.getString(\"COLUMN_NAME\");\n+                JdbcTypeHandle typeHandle = new JdbcTypeHandle(\n+                        resultSet.getInt(\"DATA_TYPE\"),\n+                        Optional.ofNullable(resultSet.getString(\"TYPE_NAME\")),\n+                        resultSet.getInt(\"COLUMN_SIZE\"),\n+                        resultSet.getInt(\"DECIMAL_DIGITS\"),\n+                        Optional.empty());\n+                Optional<ColumnMapping> columnMapping = toPrestoType(session, connection, typeHandle);\n+                // skip unsupported column types\n+                boolean nullable = (resultSet.getInt(\"NULLABLE\") != columnNoNulls);\n+                // Note: some databases (e.g. SQL Server) do not return column remarks/comment here.\n+                Optional<String> comment = Optional.ofNullable(emptyToNull(resultSet.getString(\"REMARKS\")));\n+                if (columnMapping.isPresent()) {\n+                    columns.add(JdbcColumnHandle.builder()\n+                            .setColumnName(columnName)\n+                            .setJdbcTypeHandle(typeHandle)\n+                            .setColumnType(columnMapping.get().getType())\n+                            .setNullable(nullable)\n+                            .setComment(comment)\n+                            .build());\n+                }\n+                if (columnMapping.isEmpty()) {\n+                    UnsupportedTypeHandling unsupportedTypeHandling = getUnsupportedTypeHandling(session);\n+                    verify(unsupportedTypeHandling == IGNORE, \"Unsupported type handling is set to %s, but toPrestoType() returned empty\", unsupportedTypeHandling);\n+                }\n+            }\n+            if (columns.isEmpty()) {\n+                // A table may have no supported columns. In rare cases (e.g. PostgreSQL) a table might have no columns at all.\n+                throw new TableNotFoundException(\n+                        tableHandle.getSchemaTableName(),\n+                        format(\"Table '%s' has no supported columns (all %s columns are not supported)\", tableHandle.getSchemaTableName(), allColumns));\n+            }\n+            return ImmutableList.copyOf(columns);\n+        }\n+        catch (SQLException e) {\n+            throw new PrestoException(JDBC_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Overriden since the {@link BaseJdbcClient#getColumns(JdbcTableHandle, DatabaseMetaData)}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg5MDAwOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNzo0NFrOGlFRTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxNzo0NFrOGlFRTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNjg0NA==", "bodyText": "inline", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441536844", "createdAt": "2020-06-17T13:17:44Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.Session;\n+import io.prestosql.metadata.QualifiedObjectName;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.MaterializedRow;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.tpch.TpchTable;\n+import org.intellij.lang.annotations.Language;\n+\n+import java.io.BufferedWriter;\n+import java.io.File;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static io.airlift.testing.Closeables.closeAllSuppress;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.TestingSession.testSessionBuilder;\n+import static java.lang.String.format;\n+\n+public class DruidQueryRunner\n+{\n+    private DruidQueryRunner() {}\n+\n+    public static QueryRunner createDruidQueryRunnerTpch(TestingDruidServer testingDruidServer)\n+            throws Exception\n+    {\n+        DistributedQueryRunner queryRunner = null;\n+        try {\n+            queryRunner = DistributedQueryRunner.builder(createSession()).setNodeCount(3).build();\n+            queryRunner.installPlugin(new TpchPlugin());\n+            queryRunner.createCatalog(\"tpch\", \"tpch\");\n+\n+            Map<String, String> connectorProperties = new HashMap<>();\n+            connectorProperties.putIfAbsent(\"connection-url\", testingDruidServer.getJdbcUrl());\n+            queryRunner.installPlugin(new DruidJdbcPlugin());\n+            queryRunner.createCatalog(\"druid\", \"druid\", connectorProperties);\n+            return queryRunner;\n+        }\n+        catch (Throwable e) {\n+            closeAllSuppress(e, queryRunner);\n+            throw e;\n+        }\n+    }\n+\n+    public static void copyAndIngestTpchData(TestingDruidServer testingDruidServer, TpchTable table, QueryRunner queryRunner, String druidDatasource, Integer limit)\n+            throws IOException, InterruptedException\n+    {\n+        QualifiedObjectName source = new QualifiedObjectName(\"tpch\", TINY_SCHEMA_NAME, table.getTableName());\n+        String tsvFileLocation = getTSVFileLocation(testingDruidServer.getHostWorkingDirectory(), druidDatasource);\n+        writeDataAsTSV(queryRunner, source, createSession(), tsvFileLocation, limit);\n+        testingDruidServer.ingestData(druidDatasource, getIngestionSpecFileName(druidDatasource), tsvFileLocation);\n+    }\n+\n+    private static String getTSVFileLocation(String directory, String datasource)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg5MTMzOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxODowMVrOGlFSGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxODowMVrOGlFSGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNzA1MQ==", "bodyText": "writeDataAsTsv", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441537051", "createdAt": "2020-06-17T13:18:01Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.Session;\n+import io.prestosql.metadata.QualifiedObjectName;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.MaterializedRow;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.tpch.TpchTable;\n+import org.intellij.lang.annotations.Language;\n+\n+import java.io.BufferedWriter;\n+import java.io.File;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static io.airlift.testing.Closeables.closeAllSuppress;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.TestingSession.testSessionBuilder;\n+import static java.lang.String.format;\n+\n+public class DruidQueryRunner\n+{\n+    private DruidQueryRunner() {}\n+\n+    public static QueryRunner createDruidQueryRunnerTpch(TestingDruidServer testingDruidServer)\n+            throws Exception\n+    {\n+        DistributedQueryRunner queryRunner = null;\n+        try {\n+            queryRunner = DistributedQueryRunner.builder(createSession()).setNodeCount(3).build();\n+            queryRunner.installPlugin(new TpchPlugin());\n+            queryRunner.createCatalog(\"tpch\", \"tpch\");\n+\n+            Map<String, String> connectorProperties = new HashMap<>();\n+            connectorProperties.putIfAbsent(\"connection-url\", testingDruidServer.getJdbcUrl());\n+            queryRunner.installPlugin(new DruidJdbcPlugin());\n+            queryRunner.createCatalog(\"druid\", \"druid\", connectorProperties);\n+            return queryRunner;\n+        }\n+        catch (Throwable e) {\n+            closeAllSuppress(e, queryRunner);\n+            throw e;\n+        }\n+    }\n+\n+    public static void copyAndIngestTpchData(TestingDruidServer testingDruidServer, TpchTable table, QueryRunner queryRunner, String druidDatasource, Integer limit)\n+            throws IOException, InterruptedException\n+    {\n+        QualifiedObjectName source = new QualifiedObjectName(\"tpch\", TINY_SCHEMA_NAME, table.getTableName());\n+        String tsvFileLocation = getTSVFileLocation(testingDruidServer.getHostWorkingDirectory(), druidDatasource);\n+        writeDataAsTSV(queryRunner, source, createSession(), tsvFileLocation, limit);\n+        testingDruidServer.ingestData(druidDatasource, getIngestionSpecFileName(druidDatasource), tsvFileLocation);\n+    }\n+\n+    private static String getTSVFileLocation(String directory, String datasource)\n+    {\n+        String fileName = String.format(\"%s.tsv\", datasource);\n+        return directory + fileName;\n+    }\n+\n+    private static String getIngestionSpecFileName(String datasource)\n+    {\n+        return String.format(\"druid-tpch-ingest-%s.json\", datasource);\n+    }\n+\n+    private static Session createSession()\n+    {\n+        return testSessionBuilder()\n+                .setCatalog(\"druid\")\n+                .setSchema(\"druid\")\n+                .build();\n+    }\n+\n+    private static void writeDataAsTSV(QueryRunner queryRunner, QualifiedObjectName table, Session session, String dataFile, Integer limit)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDg5Mzk3OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxODozOFrOGlFTsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoxODozOFrOGlFTsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzNzQ1OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return data.stream().map(o -> String.valueOf(o))\n          \n          \n            \n                    return data.stream()\n          \n          \n            \n                        .map(String::valueOf)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441537458", "createdAt": "2020-06-17T13:18:38Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/DruidQueryRunner.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.Session;\n+import io.prestosql.metadata.QualifiedObjectName;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.MaterializedRow;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.tpch.TpchTable;\n+import org.intellij.lang.annotations.Language;\n+\n+import java.io.BufferedWriter;\n+import java.io.File;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static io.airlift.testing.Closeables.closeAllSuppress;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.TestingSession.testSessionBuilder;\n+import static java.lang.String.format;\n+\n+public class DruidQueryRunner\n+{\n+    private DruidQueryRunner() {}\n+\n+    public static QueryRunner createDruidQueryRunnerTpch(TestingDruidServer testingDruidServer)\n+            throws Exception\n+    {\n+        DistributedQueryRunner queryRunner = null;\n+        try {\n+            queryRunner = DistributedQueryRunner.builder(createSession()).setNodeCount(3).build();\n+            queryRunner.installPlugin(new TpchPlugin());\n+            queryRunner.createCatalog(\"tpch\", \"tpch\");\n+\n+            Map<String, String> connectorProperties = new HashMap<>();\n+            connectorProperties.putIfAbsent(\"connection-url\", testingDruidServer.getJdbcUrl());\n+            queryRunner.installPlugin(new DruidJdbcPlugin());\n+            queryRunner.createCatalog(\"druid\", \"druid\", connectorProperties);\n+            return queryRunner;\n+        }\n+        catch (Throwable e) {\n+            closeAllSuppress(e, queryRunner);\n+            throw e;\n+        }\n+    }\n+\n+    public static void copyAndIngestTpchData(TestingDruidServer testingDruidServer, TpchTable table, QueryRunner queryRunner, String druidDatasource, Integer limit)\n+            throws IOException, InterruptedException\n+    {\n+        QualifiedObjectName source = new QualifiedObjectName(\"tpch\", TINY_SCHEMA_NAME, table.getTableName());\n+        String tsvFileLocation = getTSVFileLocation(testingDruidServer.getHostWorkingDirectory(), druidDatasource);\n+        writeDataAsTSV(queryRunner, source, createSession(), tsvFileLocation, limit);\n+        testingDruidServer.ingestData(druidDatasource, getIngestionSpecFileName(druidDatasource), tsvFileLocation);\n+    }\n+\n+    private static String getTSVFileLocation(String directory, String datasource)\n+    {\n+        String fileName = String.format(\"%s.tsv\", datasource);\n+        return directory + fileName;\n+    }\n+\n+    private static String getIngestionSpecFileName(String datasource)\n+    {\n+        return String.format(\"druid-tpch-ingest-%s.json\", datasource);\n+    }\n+\n+    private static Session createSession()\n+    {\n+        return testSessionBuilder()\n+                .setCatalog(\"druid\")\n+                .setSchema(\"druid\")\n+                .build();\n+    }\n+\n+    private static void writeDataAsTSV(QueryRunner queryRunner, QualifiedObjectName table, Session session, String dataFile, Integer limit)\n+            throws IOException\n+    {\n+        File file = new File(dataFile);\n+        try (BufferedWriter bw = new BufferedWriter(new FileWriter(file))) {\n+            @Language(\"SQL\") String sql = format(\"SELECT * FROM %s\", table);\n+            if (limit != null) {\n+                sql = sql + \" LIMIT \" + limit;\n+            }\n+            List<MaterializedRow> rows = queryRunner.execute(session, sql).getMaterializedRows();\n+            for (MaterializedRow row : rows) {\n+                bw.write(convertToTSV(row.getFields()));\n+                bw.newLine();\n+            }\n+        }\n+    }\n+\n+    private static String convertToTSV(List<Object> data)\n+    {\n+        return data.stream().map(o -> String.valueOf(o))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDkwMTQyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoyMDoyNVrOGlFYVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QyMjowMjozMVrOGlY77w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzODY0Nw==", "bodyText": "This affects many current & future tests.\nIf druid requires __time column, please copy orderdate column to have both: __time and orderdate.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441538647", "createdAt": "2020-06-17T13:20:25Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner queryRunner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(this.druidServer, ORDERS, queryRunner, ORDERS.getTableName(), null);\n+        return queryRunner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testMultipleRangesPredicate()\n+    {\n+        // Removed orderdate column from projection since druid stores orderdate as __time column", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg1OTA1NQ==", "bodyText": "Good idea. I will change the ingestion spec to ingest orderdate column twice - once as __time Druid timestamp column and the other as a Druid dimension named orderdate.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441859055", "createdAt": "2020-06-17T22:02:31Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner queryRunner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(this.druidServer, ORDERS, queryRunner, ORDERS.getTableName(), null);\n+        return queryRunner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testMultipleRangesPredicate()\n+    {\n+        // Removed orderdate column from projection since druid stores orderdate as __time column", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzODY0Nw=="}, "originalCommit": null, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDkwNjQzOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoyMTozNlrOGlFbhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoyMTozNlrOGlFbhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzOTQ2Mw==", "bodyText": "follow io.prestosql.elasticsearch.BaseElasticsearchSmokeTest#testSelectAll example", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441539463", "createdAt": "2020-06-17T13:21:36Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner queryRunner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(this.druidServer, ORDERS, queryRunner, ORDERS.getTableName(), null);\n+        return queryRunner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testMultipleRangesPredicate()\n+    {\n+        // Removed orderdate column from projection since druid stores orderdate as __time column\n+        assertQuery(\"\" +\n+                \"SELECT orderkey, custkey, orderstatus, totalprice, orderpriority, clerk, shippriority, comment \" +\n+                \"FROM orders \" +\n+                \"WHERE orderkey BETWEEN 10 AND 50\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testRangePredicate()\n+    {\n+        // Removed orderdate column from projection since druid stores orderdate as __time column\n+        assertQuery(\"\" +\n+                \"SELECT orderkey, custkey, orderstatus, totalprice, orderpriority, clerk, shippriority, comment \" +\n+                \"FROM orders \" +\n+                \"WHERE orderkey BETWEEN 10 AND 50\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectInformationSchemaColumns()\n+    {\n+        String catalog = getSession().getCatalog().get();\n+        String schema = getSession().getSchema().get();\n+        String schemaPattern = schema.replaceAll(\".$\", \"_\");\n+\n+        @Language(\"SQL\") String ordersTableWithColumns = \"VALUES \" +\n+                \"('orders', 'orderkey'), \" +\n+                \"('orders', 'custkey'), \" +\n+                \"('orders', 'orderstatus'), \" +\n+                \"('orders', 'totalprice'), \" +\n+                \"('orders', '__time'), \" + // orderdate is mapped to __time column in Druid\n+                \"('orders', 'orderpriority'), \" +\n+                \"('orders', 'clerk'), \" +\n+                \"('orders', 'shippriority'), \" +\n+                \"('orders', 'comment')\";\n+\n+        assertQuery(\"SELECT table_schema FROM information_schema.columns WHERE table_schema = '\" + schema + \"' GROUP BY table_schema\", \"VALUES '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name\", \"VALUES 'orders'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name = 'orders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name LIKE '%rders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '\" + schemaPattern + \"' AND table_name LIKE '_rder_'\", ordersTableWithColumns);\n+        assertQuery(\n+                \"SELECT table_name, column_name FROM information_schema.columns \" +\n+                        \"WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '%orders%'\",\n+                ordersTableWithColumns);\n+\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns\");\n+        assertQuery(\"SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"'\");\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_name LIKE '%'\");\n+        assertQuery(\"SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'\", \"SELECT '' WHERE false\");\n+    }\n+\n+    @Test\n+    @Override\n+    // Ignoring the test for now. For some reason the \"expected\" query is failing\n+    public void testSelectAll()\n+    {\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1MDkyNTQ1OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": false, "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMzoyNTozOFrOGlFnXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQwOTowNzo0M1rOGmNpMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ==", "bodyText": "// Cannot use Files.createTempDirectory() because on Mac by default it uses /var/folders/ which is not visible to Docker for Mac\nPath hostWorkingDirectory = Files.createDirectory(Paths.get(\"/tmp/druid-workdir-\" + randomUUID().toString()));\n\nand remove druid-test-storage from resources", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441542495", "createdAt": "2020-06-17T13:25:38Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg1NDA4Mw==", "bodyText": "Unfortunately, that doesn't work. The GenericContainer library expects the shared directory to be a resource in the class path otherwise we get a directory doesn't exist: access denied error. See https://www.testcontainers.org/features/files/", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r441854083", "createdAt": "2020-06-17T21:50:13Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjA3ODQzMw==", "bodyText": "That's interesting, because we use this pattern elsewhere. Let me look into this.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442078433", "createdAt": "2020-06-18T09:02:43Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NDYzNA==", "bodyText": "I did this:\n// Cannot use Files.createTempDirectory() because on Mac by default it uses /var/folders/ which is not visible to Docker for Mac\nhostWorkingDirectory = Files.createDirectory(Paths.get(\"/tmp/docker-files-\" + randomUUID().toString()));\n\nthen\n.withFileSystemBind(hostWorkingDirectory.toString(), \"/opt/druid/var\", BindMode.READ_WRITE)\n\nit was correctly bound, but something didn't work quite well (the data import).\nPlease try to complete this this way. If you cannot, add a TODO -- using classpath resource as R/W dir is not a good idea.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442144634", "createdAt": "2020-06-18T11:01:50Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjI2Nw==", "bodyText": "Right, I have attempted this as well but unfortunately, the middle manager service running data ingestion runs into issues since it is not able to create directories for storing logs, intermediate segments, etc. I will add a TODO.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442416267", "createdAt": "2020-06-18T18:18:35Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjY4NjkyMg==", "bodyText": "Pushed a commit that attempts to use /tmp/docker-files-UUID as host working directory. The test passed locally on my mac, would be interesting to see if it passes on CI. I have currently removed the assertion to check if file.delete() was successful.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442686922", "createdAt": "2020-06-19T07:47:36Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjcwNzExNg==", "bodyText": "I have currently removed the assertion to check if file.delete() was successful.\n\nSince we know it's not, let's restore the Guava-way, but have it commented out with a TODO.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442707116", "createdAt": "2020-06-19T08:28:55Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjcwODk3MA==", "bodyText": "FYI, it worked for me locally too. @samarthjain thanks for nailing this down.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442708970", "createdAt": "2020-06-19T08:32:20Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjcxMDQzNg==", "bodyText": "Looks like I forgot removing one assertion in the last commit. Either way, looks like the tests did pass on CI as well.\nI think it still makes sense to instead use the deleteRecursively method I had with the assert removed. Since things work fine locally, for anyone running this test, it should clean things up. WDYT?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442710436", "createdAt": "2020-06-19T08:35:28Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjcxOTIzOA==", "bodyText": "The bottom line is -- if we want to provide \"best effort\" delete, we should call MoreFiles.deleteRecursively and suppress exception.\nThere is no point in reimplementing the logic just for that.\ni checked the current code (Attempt using /tmp/docker-files-UUID as host working directory, rebased on master), and replaced deleteRecursively with\ncloser.register(() -> MoreFiles.deleteRecursively(Paths.get(hostWorkingDirectory), RecursiveDeleteOption.ALLOW_INSECURE));\n\nand... did not get the failure back. Very confusing. Can this be in some way non-deterministic?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442719238", "createdAt": "2020-06-19T09:00:11Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjcyMjYwOQ==", "bodyText": "Fair point on suppressing the exception for now.\nLocally, MoreFiles.deleteRecursively() works fine. It is on CI that it fails.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442722609", "createdAt": "2020-06-19T09:07:43Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjQ5NQ=="}, "originalCommit": null, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDYzNjMyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowMTo1OVrOGlqXrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowMTo1OVrOGlqXrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NDY4Ng==", "bodyText": "forClasspathResource", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442144686", "createdAt": "2020-06-18T11:01:59Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDYzOTMwOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowMzowNlrOGlqZfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODo1MTo1NVrOGl8CXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NTE0OA==", "bodyText": "Register this in closer as well:\n closer.register(() -> deleteRecursively(hostWorkingDirectory, ALLOW_INSECURE));\n\n(first, so it's get called last)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442145148", "createdAt": "2020-06-18T11:03:06Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNDE0Mg==", "bodyText": "Thanks for the tip on MoreFiles. I think MoreFiles.deleteDirectoryContents is a better option.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442434142", "createdAt": "2020-06-18T18:51:55Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NTE0OA=="}, "originalCommit": null, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY0MjQzOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNDowNlrOGlqbcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNDowNlrOGlqbcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NTY1MQ==", "bodyText": "[com.google.common.io.MoreFiles.]deleteRecursively(path, ALLOW_INSECURE);", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442145651", "createdAt": "2020-06-18T11:04:06Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);\n+                }\n+            }\n+        }\n+        return !datasourceNotLoaded;\n+    }\n+\n+    private static String getMiddleManagerContainerPathForDataFile(String dataFilePath)\n+    {\n+        return String.format(\"/opt/druid/var/%s\", new File(dataFilePath).getName());\n+    }\n+\n+    // Clean up the contents of the directory\n+    private static void cleanDirectory(File directoryToBeCleaned)\n+    {\n+        File[] allContents = directoryToBeCleaned.listFiles();\n+        if (allContents != null) {\n+            for (File file : allContents) {\n+                if (file.isDirectory()) {\n+                    deleteRecursively(file);\n+                }\n+                else {\n+                    file.delete();\n+                }\n+            }\n+        }\n+    }\n+\n+    private static void deleteRecursively(File directory)\n+    {\n+        File[] allContents = directory.listFiles();\n+        if (allContents != null) {\n+            for (File file : allContents) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY0NDMzOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNDo0NFrOGlqcng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNDo0NFrOGlqcng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NTk1MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return String.format(\"/opt/druid/var/%s\", new File(dataFilePath).getName());\n          \n          \n            \n                    return \"/opt/druid/var/\" + dataFilePath;\n          \n      \n    \n    \n  \n\n?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442145950", "createdAt": "2020-06-18T11:04:44Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.io.Closer;\n+import com.google.common.io.Resources;\n+import io.prestosql.testing.assertions.Assert;\n+import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;\n+import org.testcontainers.containers.BindMode;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy;\n+import org.testcontainers.containers.wait.strategy.Wait;\n+import org.testcontainers.shaded.okhttp3.OkHttpClient;\n+import org.testcontainers.shaded.okhttp3.Request;\n+import org.testcontainers.shaded.okhttp3.RequestBody;\n+import org.testcontainers.shaded.okhttp3.Response;\n+\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+\n+import static com.google.common.io.Resources.getResource;\n+import static java.lang.String.format;\n+import static org.testcontainers.utility.MountableFile.forHostPath;\n+\n+public class TestingDruidServer\n+        implements Closeable\n+{\n+    private final String hostWorkingDirectory;\n+    private final GenericContainer broker;\n+    private final GenericContainer coordinator;\n+    private final GenericContainer historical;\n+    private final GenericContainer middleManager;\n+    private final GenericContainer zookeeper;\n+    private final OkHttpClient httpClient;\n+\n+    private static final int DRUID_COORDINATOR_PORT = 8081;\n+    private static final int DRUID_BROKER_PORT = 8082;\n+    private static final int DRUID_HISTORICAL_PORT = 8083;\n+    private static final int DRUID_MIDDLE_MANAGER_PORT = 8091;\n+\n+    private static final String DRUID_DOCKER_IMAGE = \"apache/druid:0.18.0\";\n+\n+    public TestingDruidServer()\n+    {\n+        try {\n+            this.hostWorkingDirectory = TestingDruidServer.class.getClassLoader().getResource(\"druid-test-storage/\").getPath();\n+            File f = new File(hostWorkingDirectory);\n+            cleanDirectory(f);\n+            // Enable read/write/exec access for the services running in containers\n+            f.setWritable(true, false);\n+            f.setReadable(true, false);\n+            f.setExecutable(true, false);\n+            this.httpClient = new OkHttpClient();\n+            Network network = Network.newNetwork();\n+            this.zookeeper = new GenericContainer(\"zookeeper\")\n+                    .withNetwork(network)\n+                    .withNetworkAliases(\"zookeeper\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .waitingFor(new SelectedPortWaitStrategy(2181));\n+            zookeeper.start();\n+\n+            this.coordinator = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_COORDINATOR_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"coordinator\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .dependsOn(zookeeper)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"druid-coordinator-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/master/coordinator-overlord/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            coordinator.start();\n+\n+            this.broker = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_BROKER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"broker\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"broker-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/query/broker/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            broker.start();\n+\n+            this.historical = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_HISTORICAL_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"historical\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"historical-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/historical/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            historical.start();\n+\n+            this.middleManager = new GenericContainer(DRUID_DOCKER_IMAGE)\n+                    .withExposedPorts(DRUID_MIDDLE_MANAGER_PORT)\n+                    .withNetwork(network)\n+                    .withCommand(\"middleManager\")\n+                    .withWorkingDirectory(\"/opt/druid\")\n+                    .dependsOn(zookeeper, coordinator)\n+                    .withClasspathResourceMapping(\"druid-test-storage/\", \"/opt/druid/var\", BindMode.READ_WRITE)\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"common.runtime.properties\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/_common/common.runtime.properties\")\n+                    .withStartupCheckStrategy(new IsRunningStartupCheckStrategy())\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/runtime.properties\")\n+                    .withCopyFileToContainer(\n+                            forHostPath(getResource(\"middleManager-jvm.config\").getPath()),\n+                            \"/opt/druid/conf/druid/cluster/data/middleManager/jvm.config\")\n+                    .waitingFor(Wait.forHttp(\"/status/selfDiscovered\"));\n+            middleManager.start();\n+        }\n+        catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    public String getHostWorkingDirectory()\n+    {\n+        return hostWorkingDirectory;\n+    }\n+\n+    @Override\n+    public void close()\n+    {\n+        try (Closer closer = Closer.create()) {\n+            closer.register(broker::stop);\n+            closer.register(historical::stop);\n+            closer.register(middleManager::stop);\n+            closer.register(coordinator::stop);\n+            closer.register(zookeeper::stop);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        finally {\n+            cleanDirectory(new File(hostWorkingDirectory));\n+        }\n+    }\n+\n+    public String getJdbcUrl()\n+    {\n+        return getJdbcUrl(broker.getMappedPort(DRUID_BROKER_PORT));\n+    }\n+\n+    public int getCoordinatorOverlordPort()\n+    {\n+        return coordinator.getMappedPort(DRUID_COORDINATOR_PORT);\n+    }\n+\n+    private static String getJdbcUrl(int port)\n+    {\n+        return format(\"jdbc:avatica:remote:url=http://localhost:%s/druid/v2/sql/avatica/\", port);\n+    }\n+\n+    void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n+            throws IOException, InterruptedException\n+    {\n+        middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n+                getMiddleManagerContainerPathForDataFile(dataFilePath));\n+        String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n+\n+        Request.Builder requestBuilder = new Request.Builder();\n+        requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n+                .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n+                .post(RequestBody.create(null, indexTask));\n+        Request ingestionRequest = requestBuilder.build();\n+        Response response = null;\n+        try {\n+            response = httpClient.newCall(ingestionRequest).execute();\n+            Assert.assertTrue(checkDatasourceAvailable(datasource), \"Datasource \" + datasource + \" not loaded\");\n+        }\n+        finally {\n+            if (response != null) {\n+                response.close();\n+            }\n+        }\n+    }\n+\n+    private boolean checkDatasourceAvailable(String datasource)\n+            throws IOException, InterruptedException\n+    {\n+        Map<String, Double> datasourceAvailabilityDetails = null;\n+        boolean datasourceNotLoaded = true;\n+        int attempts = 10;\n+        while (datasourceNotLoaded && attempts > 0) {\n+            Request.Builder requestBuilder = new Request.Builder();\n+            requestBuilder.url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/coordinator/v1/loadstatus\")\n+                    .get();\n+            Request datasourceAvailabilityRequest = requestBuilder.build();\n+            try (Response response = httpClient.newCall(datasourceAvailabilityRequest).execute()) {\n+                ObjectMapper mapper = new ObjectMapper();\n+                datasourceAvailabilityDetails = mapper.readValue(response.body().string(), Map.class);\n+                datasourceNotLoaded = datasourceAvailabilityDetails.get(datasource) == null || Double.compare(datasourceAvailabilityDetails.get(datasource), 100.0) < 0;\n+                if (datasourceNotLoaded) {\n+                    attempts--;\n+                    // Wait for some time since it can take a while for coordinator to load the ingested segments\n+                    Thread.sleep(15000);\n+                }\n+            }\n+        }\n+        return !datasourceNotLoaded;\n+    }\n+\n+    private static String getMiddleManagerContainerPathForDataFile(String dataFilePath)\n+    {\n+        return String.format(\"/opt/druid/var/%s\", new File(dataFilePath).getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY0OTY4OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNjoxNFrOGlqfzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNjoxNFrOGlqfzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0Njc2NQ==", "bodyText": "It's written this way in superclass, as it's generic. In concrete subclass use\nassertThat(computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n        .isEqualTo(\"CREATE TABLE druid.druid.orders (\\n\" +\n              ....", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442146765", "createdAt": "2020-06-18T11:06:14Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+    private static final String SELECT_FROM_ORDERS = \"SELECT \" +\n+            \"orderdate, \" +\n+            \"orderdate AS orderdate_druid_ts, \" + // Druid stores the orderdate_druid_ts column as __time column.\n+            \"orderkey, \" +\n+            \"custkey, \" +\n+            \"orderstatus, \" +\n+            \"totalprice, \" +\n+            \"orderpriority, \" +\n+            \"clerk, \" +\n+            \"shippriority, \" +\n+            \"comment \" +\n+            \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n+        return runner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderdate\", \"varchar\", \"\", \"\")\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY1MDk3OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNjozOVrOGlqgfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMToxNjozMVrOGlqzBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0Njk0MA==", "bodyText": "nit\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThatThrownBy(() -> super.testJoin())\n          \n          \n            \n                    assertThatThrownBy(super::testJoin)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442146940", "createdAt": "2020-06-18T11:06:39Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+    private static final String SELECT_FROM_ORDERS = \"SELECT \" +\n+            \"orderdate, \" +\n+            \"orderdate AS orderdate_druid_ts, \" + // Druid stores the orderdate_druid_ts column as __time column.\n+            \"orderkey, \" +\n+            \"custkey, \" +\n+            \"orderstatus, \" +\n+            \"totalprice, \" +\n+            \"orderpriority, \" +\n+            \"clerk, \" +\n+            \"shippriority, \" +\n+            \"comment \" +\n+            \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n+        return runner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderdate\", \"varchar\", \"\", \"\")\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderdate varchar,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectInformationSchemaColumns()\n+    {\n+        String catalog = getSession().getCatalog().get();\n+        String schema = getSession().getSchema().get();\n+        String schemaPattern = schema.replaceAll(\".$\", \"_\");\n+\n+        @Language(\"SQL\") String ordersTableWithColumns = \"VALUES \" +\n+                \"('orders', 'orderkey'), \" +\n+                \"('orders', 'custkey'), \" +\n+                \"('orders', 'orderstatus'), \" +\n+                \"('orders', 'totalprice'), \" +\n+                \"('orders', 'orderdate'), \" +\n+                \"('orders', '__time'), \" +\n+                \"('orders', 'orderpriority'), \" +\n+                \"('orders', 'clerk'), \" +\n+                \"('orders', 'shippriority'), \" +\n+                \"('orders', 'comment')\";\n+\n+        assertQuery(\"SELECT table_schema FROM information_schema.columns WHERE table_schema = '\" + schema + \"' GROUP BY table_schema\", \"VALUES '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name\", \"VALUES 'orders'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name = 'orders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name LIKE '%rders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '\" + schemaPattern + \"' AND table_name LIKE '_rder_'\", ordersTableWithColumns);\n+        assertQuery(\n+                \"SELECT table_name, column_name FROM information_schema.columns \" +\n+                        \"WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '%orders%'\",\n+                ordersTableWithColumns);\n+\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns\");\n+        assertQuery(\"SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"'\");\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_name LIKE '%'\");\n+        assertQuery(\"SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'\", \"SELECT '' WHERE false\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectAll()\n+    {\n+        // List columns explicitly, as we ingest orderdate column twice in Druid\n+        assertQuery(\"SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment  FROM orders\");\n+    }\n+\n+    @Test\n+    @Override\n+    // nation, region, customer tables don't have any date/time in the rows.\n+    // For a table to be ingested into Druid, a date/time/timestamp column is required.\n+    //TODO: This test needs to be adjusted to possibly join between lineitems and orders datasources\n+    public void testJoin()\n+    {\n+        assertThatThrownBy(() -> super.testJoin())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE1MTY4Nw==", "bodyText": "(the only reason i bother is that the current code gives IDE's warning, and i don't like to have to ignore them, as this makes it harder to notice warnings that actually matter)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442151687", "createdAt": "2020-06-18T11:16:31Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+    private static final String SELECT_FROM_ORDERS = \"SELECT \" +\n+            \"orderdate, \" +\n+            \"orderdate AS orderdate_druid_ts, \" + // Druid stores the orderdate_druid_ts column as __time column.\n+            \"orderkey, \" +\n+            \"custkey, \" +\n+            \"orderstatus, \" +\n+            \"totalprice, \" +\n+            \"orderpriority, \" +\n+            \"clerk, \" +\n+            \"shippriority, \" +\n+            \"comment \" +\n+            \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n+        return runner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderdate\", \"varchar\", \"\", \"\")\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderdate varchar,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectInformationSchemaColumns()\n+    {\n+        String catalog = getSession().getCatalog().get();\n+        String schema = getSession().getSchema().get();\n+        String schemaPattern = schema.replaceAll(\".$\", \"_\");\n+\n+        @Language(\"SQL\") String ordersTableWithColumns = \"VALUES \" +\n+                \"('orders', 'orderkey'), \" +\n+                \"('orders', 'custkey'), \" +\n+                \"('orders', 'orderstatus'), \" +\n+                \"('orders', 'totalprice'), \" +\n+                \"('orders', 'orderdate'), \" +\n+                \"('orders', '__time'), \" +\n+                \"('orders', 'orderpriority'), \" +\n+                \"('orders', 'clerk'), \" +\n+                \"('orders', 'shippriority'), \" +\n+                \"('orders', 'comment')\";\n+\n+        assertQuery(\"SELECT table_schema FROM information_schema.columns WHERE table_schema = '\" + schema + \"' GROUP BY table_schema\", \"VALUES '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name\", \"VALUES 'orders'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name = 'orders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name LIKE '%rders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '\" + schemaPattern + \"' AND table_name LIKE '_rder_'\", ordersTableWithColumns);\n+        assertQuery(\n+                \"SELECT table_name, column_name FROM information_schema.columns \" +\n+                        \"WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '%orders%'\",\n+                ordersTableWithColumns);\n+\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns\");\n+        assertQuery(\"SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"'\");\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_name LIKE '%'\");\n+        assertQuery(\"SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'\", \"SELECT '' WHERE false\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectAll()\n+    {\n+        // List columns explicitly, as we ingest orderdate column twice in Druid\n+        assertQuery(\"SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment  FROM orders\");\n+    }\n+\n+    @Test\n+    @Override\n+    // nation, region, customer tables don't have any date/time in the rows.\n+    // For a table to be ingested into Druid, a date/time/timestamp column is required.\n+    //TODO: This test needs to be adjusted to possibly join between lineitems and orders datasources\n+    public void testJoin()\n+    {\n+        assertThatThrownBy(() -> super.testJoin())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0Njk0MA=="}, "originalCommit": null, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY1MjY0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNzowNVrOGlqhdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNzowNVrOGlqhdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NzE5MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());\n          \n          \n            \n                        \"FROM tpch.tiny.orders\";", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442147191", "createdAt": "2020-06-18T11:07:05Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+    private static final String SELECT_FROM_ORDERS = \"SELECT \" +\n+            \"orderdate, \" +\n+            \"orderdate AS orderdate_druid_ts, \" + // Druid stores the orderdate_druid_ts column as __time column.\n+            \"orderkey, \" +\n+            \"custkey, \" +\n+            \"orderstatus, \" +\n+            \"totalprice, \" +\n+            \"orderpriority, \" +\n+            \"clerk, \" +\n+            \"shippriority, \" +\n+            \"comment \" +\n+            \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY1MzI0OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNzoyMFrOGlqh3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMTowNzoyMFrOGlqh3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE0NzI5NQ==", "bodyText": "move below the constant", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442147295", "createdAt": "2020-06-18T11:07:20Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NDY3NDQyOnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMToxNDozNVrOGlqvNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxMToxNDozNVrOGlqvNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE1MDcwOA==", "bodyText": "We could ingest these tables with some fake time column.\nA follow-up", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442150708", "createdAt": "2020-06-18T11:14:35Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestDruidIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.druid;\n+\n+import io.prestosql.plugin.jdbc.JdbcIdentity;\n+import io.prestosql.plugin.jdbc.JdbcTableHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.testing.AbstractTestIntegrationSmokeTest;\n+import io.prestosql.testing.MaterializedResult;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.assertions.Assert;\n+import org.intellij.lang.annotations.Language;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.tpch.TpchTable.ORDERS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+@Test\n+public class TestDruidIntegrationSmokeTest\n+        extends AbstractTestIntegrationSmokeTest\n+{\n+    private TestingDruidServer druidServer;\n+    private static final String SELECT_FROM_ORDERS = \"SELECT \" +\n+            \"orderdate, \" +\n+            \"orderdate AS orderdate_druid_ts, \" + // Druid stores the orderdate_druid_ts column as __time column.\n+            \"orderkey, \" +\n+            \"custkey, \" +\n+            \"orderstatus, \" +\n+            \"totalprice, \" +\n+            \"orderpriority, \" +\n+            \"clerk, \" +\n+            \"shippriority, \" +\n+            \"comment \" +\n+            \"FROM \" + (\"tpch.tiny.\" + ORDERS.getTableName());\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        this.druidServer = new TestingDruidServer();\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer);\n+        copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n+        return runner;\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void destroy()\n+    {\n+        if (druidServer != null) {\n+            druidServer.close();\n+        }\n+    }\n+\n+    @Test\n+    @Override\n+    public void testDescribeTable()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderdate\", \"varchar\", \"\", \"\")\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE orders\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testShowCreateTable()\n+    {\n+        assertThat((String) computeActual(\"SHOW CREATE TABLE orders\").getOnlyValue())\n+                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass\n+                .matches(\"CREATE TABLE \\\\w+\\\\.\\\\w+\\\\.orders \\\\Q(\\n\" +\n+                        \"   __time timestamp(3) NOT NULL,\\n\" +\n+                        \"   clerk varchar,\\n\" +\n+                        \"   comment varchar,\\n\" +\n+                        \"   custkey bigint NOT NULL,\\n\" +\n+                        \"   orderdate varchar,\\n\" +\n+                        \"   orderkey bigint NOT NULL,\\n\" +\n+                        \"   orderpriority varchar,\\n\" +\n+                        \"   orderstatus varchar,\\n\" +\n+                        \"   shippriority bigint NOT NULL,\\n\" +\n+                        \"   totalprice double NOT NULL\\n\" +\n+                        \")\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectInformationSchemaColumns()\n+    {\n+        String catalog = getSession().getCatalog().get();\n+        String schema = getSession().getSchema().get();\n+        String schemaPattern = schema.replaceAll(\".$\", \"_\");\n+\n+        @Language(\"SQL\") String ordersTableWithColumns = \"VALUES \" +\n+                \"('orders', 'orderkey'), \" +\n+                \"('orders', 'custkey'), \" +\n+                \"('orders', 'orderstatus'), \" +\n+                \"('orders', 'totalprice'), \" +\n+                \"('orders', 'orderdate'), \" +\n+                \"('orders', '__time'), \" +\n+                \"('orders', 'orderpriority'), \" +\n+                \"('orders', 'clerk'), \" +\n+                \"('orders', 'shippriority'), \" +\n+                \"('orders', 'comment')\";\n+\n+        assertQuery(\"SELECT table_schema FROM information_schema.columns WHERE table_schema = '\" + schema + \"' GROUP BY table_schema\", \"VALUES '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name\", \"VALUES 'orders'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name = 'orders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '\" + schema + \"' AND table_name LIKE '%rders'\", ordersTableWithColumns);\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '\" + schemaPattern + \"' AND table_name LIKE '_rder_'\", ordersTableWithColumns);\n+        assertQuery(\n+                \"SELECT table_name, column_name FROM information_schema.columns \" +\n+                        \"WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '%orders%'\",\n+                ordersTableWithColumns);\n+\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns\");\n+        assertQuery(\"SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"'\");\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"'\");\n+        assertQuery(\"SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_schema = '\" + schema + \"' AND table_name LIKE '_rders'\", ordersTableWithColumns);\n+        assertQuerySucceeds(\"SELECT * FROM information_schema.columns WHERE table_catalog = '\" + catalog + \"' AND table_name LIKE '%'\");\n+        assertQuery(\"SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'\", \"SELECT '' WHERE false\");\n+    }\n+\n+    @Test\n+    @Override\n+    public void testSelectAll()\n+    {\n+        // List columns explicitly, as we ingest orderdate column twice in Druid\n+        assertQuery(\"SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment  FROM orders\");\n+    }\n+\n+    @Test\n+    @Override\n+    // nation, region, customer tables don't have any date/time in the rows.\n+    // For a table to be ingested into Druid, a date/time/timestamp column is required.\n+    //TODO: This test needs to be adjusted to possibly join between lineitems and orders datasources", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjgwNDYyOnYy", "diffSide": "LEFT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMDo1Mzo1OVrOGl_2GA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMTowNTo1NlrOGmAM5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NjUzNg==", "bodyText": "you probably need to remove pom.xml dep now", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442496536", "createdAt": "2020-06-18T20:53:59Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -17,7 +17,6 @@\n import com.google.common.io.Closer;\n import com.google.common.io.Resources;\n import io.prestosql.testing.assertions.Assert;\n-import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwMjM3Mg==", "bodyText": "Sorry, missed it.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442502372", "createdAt": "2020-06-18T21:05:56Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -17,7 +17,6 @@\n import com.google.common.io.Closer;\n import com.google.common.io.Resources;\n import io.prestosql.testing.assertions.Assert;\n-import io.prestosql.tests.product.launcher.testcontainers.SelectedPortWaitStrategy;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NjUzNg=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjgxODc5OnYy", "diffSide": "RIGHT", "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMDo1ODo0OFrOGl__ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQwNjo1NDoyNlrOGmKDdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg==", "bodyText": "This fails on CI.\nCould it be that previous code was failing silently too?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442498922", "createdAt": "2020-06-18T20:58:48Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwMTczNA==", "bodyText": "Yeah, just saw that as well :(. In the previous code, we were deleting directory contents in the finally block.\nfinally {\n cleanDirectory(directory)\n}\n\nIf an exception was thrown, I am hoping that the @afterclass method in DruidIntegrationSmokeTest calling druidServer.close() would have failed as well.\n@AfterClass(alwaysRun = true)\n    public void destroy()\n    {\n        if (druidServer != null) {\n            druidServer.close();\n        }\n    }", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442501734", "createdAt": "2020-06-18T21:04:41Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwNDMyOQ==", "bodyText": "Sample successful run with cleanDirectory - https://github.com/prestosql/presto/runs/783346026", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442504329", "createdAt": "2020-06-18T21:10:13Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwODA1Mg==", "bodyText": "i know it was not throwing. But were you actually checking result of file.delete()?", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442508052", "createdAt": "2020-06-18T21:18:08Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUxMzk0Mg==", "bodyText": "Well, locally on my mac, it works fine. I added this assertion:\nAssert.assertTrue(file.delete(), \"Unable to delete: \" + file.getName());\n\nGoing to push by restoring the old code with the assertion added.", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442513942", "createdAt": "2020-06-18T21:30:58Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUyNTg4MA==", "bodyText": "Yep, fails with the old code too.\n[ERROR] destroy(io.prestosql.plugin.druid.TestDruidIntegrationSmokeTest)  Time elapsed: 125.035 s  <<< FAILURE!\njava.lang.AssertionError: Unable to delete: derby.log expected [true] but found [false]\n\tat org.testng.Assert.fail(Assert.java:94)\n\tat org.testng.Assert.failNotEquals(Assert.java:513)\n\tat org.testng.Assert.assertTrue(Assert.java:42)", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442525880", "createdAt": "2020-06-18T22:00:31Z", "author": {"login": "samarthjain"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjY2Mzc5Nw==", "bodyText": "Can you try finish temporary directory approach (#3522 (comment)) ?\nLittering in /tmp is not nice, but much better than in a fixed location (tests are not repetitive). -- This would be a intermediate solution.\nWe could further address cleanup by:\n\ntweaking the user the druid processes are run as, so that files are removable by us\nusing docker volume to contain the fails, instead of  a host directory", "url": "https://github.com/trinodb/trino/pull/3522#discussion_r442663797", "createdAt": "2020-06-19T06:54:26Z", "author": {"login": "findepi"}, "path": "presto-druid/src/test/java/io/prestosql/plugin/druid/TestingDruidServer.java", "diffHunk": "@@ -169,6 +176,8 @@ public String getHostWorkingDirectory()\n     public void close()\n     {\n         try (Closer closer = Closer.create()) {\n+            closer.register(() ->\n+                    deleteDirectoryContents(Path.of(hostWorkingDirectory), ALLOW_INSECURE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5ODkyMg=="}, "originalCommit": null, "originalPosition": 122}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 221, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}