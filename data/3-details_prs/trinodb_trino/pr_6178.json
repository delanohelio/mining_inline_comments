{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxMTY4NzQz", "number": 6178, "title": "Glue metastore statistics integration", "bodyText": "Integrate aws glue statistics api in glue metastore, solves #5072.\nThere are some points that may be worth reviewing:\n\n\nSince the aws sdk has limits for read / write operations in order to improve performance with an high number of columns all write / read operations are executed by a dedicated thread pool, in order to pass multiple Executors i've introduced the ForGlueColumnStatisticsWrite and ForGlueColumnStatisticsRead annotations but I'm not sure if that is a guice's best practice.\n\n\nThe getSupportedColumnStatistics is calling ThriftMetastoreUtil#getSupportedColumnStatistics we may want to duplicate the code to avoid unwanted side effects.\n\n\nThere is some specific code implemented in DefaultGlueColumnStatisticsProvider to match the Hive implementation that clear statistics on update request when the requested columns are empty, I'm not sure if we have have to keep the behaviour in the Glue implementation or is just needed for the test.\n\n\nI modified the GlueColumnStatisticsProvider in order to pass Table and Partition instead of the Glue object TableInput, PartitionInput because these object weren't able to provide all the needed data to create request for the glue api", "createdAt": "2020-12-02T17:19:17Z", "url": "https://github.com/trinodb/trino/pull/6178", "merged": true, "mergeCommit": {"oid": "db91859b87ff51f38c9f82ce44162d2d1a286211"}, "closed": true, "closedAt": "2021-02-24T10:03:48Z", "author": {"login": "GaruGaru"}, "timelineItems": {"totalCount": 47, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdxRuYJAFqTU3MDE4NTIzMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABd9Kz5UgH2gAyNTMxMTY4NzQzOmYxYmNmYTc4NmVlZTA1YmQxZjI2NjdiNjZlZWU1MmQ2ZDA2NzBmMjE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwMTg1MjMw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-570185230", "createdAt": "2021-01-18T05:47:28Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNTo0NzoyOFrOIVavsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwNzozMzoyNlrOIVcyfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTIwMw==", "bodyText": "@electrum What do we feel about updating to latest vs the first version that added the support for Glue statistics API? (Which would be 1.11.811).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559329203", "createdAt": "2021-01-18T05:47:28Z", "author": {"login": "hashhar"}, "path": "pom.xml", "diffHunk": "@@ -48,7 +48,7 @@\n         <dep.antlr.version>4.8</dep.antlr.version>\n         <dep.airlift.version>201</dep.airlift.version>\n         <dep.packaging.version>${dep.airlift.version}</dep.packaging.version>\n-        <dep.aws-sdk.version>1.11.749</dep.aws-sdk.version>\n+        <dep.aws-sdk.version>1.11.901</dep.aws-sdk.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTU1NQ==", "bodyText": "How are these values decided? If there's a limit to the maximum/minimum value then please document it as a code comment or as a runtime check via something like verify().", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559329555", "createdAt": "2021-01-18T05:48:41Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMTIyOQ==", "bodyText": "Is it possible to build this directly without iterating over columnStatsBuilder first? ie. populate this while collecting the futures in the loop above?\nSame applicable in getPartitionColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559331229", "createdAt": "2021-01-18T05:55:21Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMTY1Mg==", "bodyText": "We prefer Guava immutable collections over JDK unmodifiable collections where possible. Since this list won't have nulls use toImmutableList (static import from Guava).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559331652", "createdAt": "2021-01-18T05:56:49Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ==", "bodyText": "Can we add this feature behind a config toggle for now? Since the planner will invoke stats calls and it's easy for people to run into Glue API rate limits so I can see people wanting to have the ability to disable this if needed.\nIt can/should default to true though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559332615", "createdAt": "2021-01-18T06:00:14Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjgxOA==", "bodyText": "Rename var to partitionColumnStats.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559332818", "createdAt": "2021-01-18T06:00:57Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMzI5Ng==", "bodyText": "Are we swallowing exceptions here? I think this method should throw a PrestoException with HIVE_METASTORE_ERROR.\nOr am I reading this incorrectly?\nSame applicable to other places where Glue responses are collected.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559333296", "createdAt": "2021-01-18T06:03:11Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzNzU1NQ==", "bodyText": "This condition works today because we are always fetching table statistics.\nIf we make the feature toggleable then the stats object being empty doesn't mean stats have to be dropped.\nInstead, what if we:\n\nGet current stats from Glue.\nCalculate the ones that have changed (i.e. current - updated) and the ones that are now missing.\nMake an API call to update only the ones that have changed.\nMake an API call to delete the ones that are missing.\n\nSame is applicable to updatePartitionStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559337555", "createdAt": "2021-01-18T06:18:22Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build().forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+        if (columnStatistics.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA==", "bodyText": "Is this Table object coming from Hive metastore API?\nI think it's unclean to depend on the Thrift models for Glue. If TableInput has something missing we can add a wrapper over it maybe?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559338700", "createdAt": "2021-01-18T06:22:27Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODc0Mw==", "bodyText": "Same for Partition below.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559338743", "createdAt": "2021-01-18T06:22:42Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DisabledGlueColumnStatisticsProvider.java", "diffHunk": "@@ -51,15 +49,15 @@\n     }\n \n     @Override\n-    public void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics)\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzODcwMA=="}, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzOTAzMw==", "bodyText": "Rename to something more descriptive.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559339033", "createdAt": "2021-01-18T06:23:54Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -163,18 +163,20 @@\n     private final Optional<String> defaultDir;\n     private final String catalogId;\n     private final int partitionSegments;\n-    private final Executor executor;\n+    private final Executor partitionsExecutor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzOTk0OQ==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Enabled statistics for glue tables\")\n          \n          \n            \n                @ConfigDescription(\"Enable statistics for glue tables\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559339949", "createdAt": "2021-01-18T06:26:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDA1Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Config(\"hive.metastore.glue.enable-column-stat\")\n          \n          \n            \n                @Config(\"hive.metastore.glue.statistics-enabled\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340053", "createdAt": "2021-01-18T06:27:10Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDQ5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")\n          \n          \n            \n                @ConfigDescription(\"Number of threads for parallel statistics reads from Glue\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340498", "createdAt": "2021-01-18T06:28:34Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")\n+    public GlueHiveMetastoreConfig setEnableColumnStatistics(boolean enableColumnStatistics)\n+    {\n+        this.enableColumnStatistics = enableColumnStatistics;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getReadStatisticsThreads()\n+    {\n+        return readStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.read-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDYwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @ConfigDescription(\"Number of threads for parallel column writing statistics fetches from Glue\")\n          \n          \n            \n                @ConfigDescription(\"Number of threads for parallel statistics writes to Glue\")", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340602", "createdAt": "2021-01-18T06:28:55Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -242,4 +245,45 @@ public GlueHiveMetastoreConfig setAssumeCanonicalPartitionKeys(boolean assumeCan\n         this.assumeCanonicalPartitionKeys = assumeCanonicalPartitionKeys;\n         return this;\n     }\n+\n+    public boolean getEnableColumnStatistics()\n+    {\n+        return enableColumnStatistics;\n+    }\n+\n+    @Config(\"hive.metastore.glue.enable-column-stat\")\n+    @ConfigDescription(\"Enabled statistics for glue tables\")\n+    public GlueHiveMetastoreConfig setEnableColumnStatistics(boolean enableColumnStatistics)\n+    {\n+        this.enableColumnStatistics = enableColumnStatistics;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getReadStatisticsThreads()\n+    {\n+        return readStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.read-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel read column statistics fetches from Glue\")\n+    public GlueHiveMetastoreConfig setReadStatisticsThreads(int getReadStatisticsThreads)\n+    {\n+        this.readStatisticsThreads = getReadStatisticsThreads;\n+        return this;\n+    }\n+\n+    @Min(1)\n+    public int getWriteStatisticsThreads()\n+    {\n+        return writeStatisticsThreads;\n+    }\n+\n+    @Config(\"hive.metastore.glue.write-statistics-threads\")\n+    @ConfigDescription(\"Number of threads for parallel column writing statistics fetches from Glue\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MDc2MA==", "bodyText": "Please revert. This is just a syntax change.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559340760", "createdAt": "2021-01-18T06:29:32Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,19 +46,28 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n         newOptionalBinder(binder, Key.get(RequestHandler2.class, ForGlueHiveMetastore.class));\n \n-        newOptionalBinder(binder, Key.get(new TypeLiteral<Predicate<Table>>() {}, ForGlueHiveMetastore.class))\n+        newOptionalBinder(binder, Key.get(new TypeLiteral<Predicate<Table>>()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MTIxOA==", "bodyText": "MILLIS_PER_DAY?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559341218", "createdAt": "2021-01-18T06:31:02Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM0MTM0MQ==", "bodyText": "Rename to trinoColumnStats.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559341341", "createdAt": "2021-01-18T06:31:29Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ==", "bodyText": "Are the various allowed column types documented somewhere? Can there be a case where a HiveType isn't supported by Glue?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559352555", "createdAt": "2021-01-18T07:06:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjYzMg==", "bodyText": "Same in toGlueColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559352632", "createdAt": "2021-01-18T07:06:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MjU1NQ=="}, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1MzY1Mg==", "bodyText": "We can instead loop on partition.getColumns to avoid the lookup in columnByName.\nI don't think there can be cases where partition.getColumns doesn't match columns in prestoColumnStats. Please correct me if I'm wrong.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559353652", "createdAt": "2021-01-18T07:09:35Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1NTU4Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n          \n          \n            \n                private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n          \n      \n    \n    \n  \n\nnit: Rename the method to follow the fromXXX and toXXX pattern.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559355583", "createdAt": "2021-01-18T07:15:07Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM1NjcyMw==", "bodyText": "Someone more familiar with datetime gotchas should take a look at this.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559356723", "createdAt": "2021-01-18T07:17:51Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.prestosql.plugin.hive.HiveType;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long DAY_TO_MILLISECOND_FACTOR = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> prestoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(prestoColumnStats.size());\n+\n+        prestoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = getGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / DAY_TO_MILLISECOND_FACTOR;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MDYwMw==", "bodyText": "Can we then change this to an assertThat(super.testUpdateTableColumnStatisticsEmptyOptionalFields()).throws(xxx)?\nThat way if Glue's behaviour changes in future we'll know that we can/need to change our impl.\nSame for other commented out tests.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559360603", "createdAt": "2021-01-18T07:28:11Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MDk5MA==", "bodyText": "Nevermind, seems like we are already updated to an even newer version on master.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559360990", "createdAt": "2021-01-18T07:29:05Z", "author": {"login": "hashhar"}, "path": "pom.xml", "diffHunk": "@@ -48,7 +48,7 @@\n         <dep.antlr.version>4.8</dep.antlr.version>\n         <dep.airlift.version>201</dep.airlift.version>\n         <dep.packaging.version>${dep.airlift.version}</dep.packaging.version>\n-        <dep.aws-sdk.version>1.11.749</dep.aws-sdk.version>\n+        <dep.aws-sdk.version>1.11.901</dep.aws-sdk.version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMyOTIwMw=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MTM4NA==", "bodyText": "Nevermind, I saw that you are picking the impl. based on the config toggle so that impls. don't need to be aware if things are enabled or disabled. Nice.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559361384", "createdAt": "2021-01-18T07:30:06Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzMjYxNQ=="}, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MjAxMw==", "bodyText": "I now see that this class is used only when stats are enabled so the condition to switch on makes sense.\nStill, this method behaves differently compared to the one for ThriftHiveMetastore. The impl I'm suggesting would preserve semantics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559362013", "createdAt": "2021-01-18T07:31:39Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.prestosql.plugin.hive.HiveBasicStatistics;\n+import io.prestosql.plugin.hive.metastore.Column;\n+import io.prestosql.plugin.hive.metastore.HiveColumnStatistics;\n+import io.prestosql.plugin.hive.metastore.Partition;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.statistics.ColumnStatisticType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        final List<String> columnNames = getAllColumns(table);\n+        final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(table.getDatabaseName())\n+                    .withTableName(table.getTableName())\n+                    .withColumnNames(partialColumns);\n+\n+            return glueClient.getColumnStatisticsForTable(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build()\n+                .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+            final List<String> columnsNames = partialColumns.stream()\n+                    .map(Column::getName)\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                    .withCatalogId(catalogId)\n+                    .withDatabaseName(partition.getDatabaseName())\n+                    .withTableName(partition.getTableName())\n+                    .withColumnNames(columnsNames)\n+                    .withPartitionValues(partition.getValues());\n+\n+            return glueClient.getColumnStatisticsForPartition(request);\n+        }, readExecutor)));\n+\n+        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+            final GetColumnStatisticsForPartitionResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n+            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+        }\n+\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+        columnStatsBuilder.build().forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+        return columnStatsMapBuilder.build();\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+        if (columnStatistics.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTMzNzU1NQ=="}, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTM2MjY4NA==", "bodyText": "Does the change suggested in updateTableColumnStatistics allow us to remove this boolean control variable?\nI'm not in favour of using boolean arguments to decide method behaviour.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559362684", "createdAt": "2021-01-18T07:33:26Z", "author": {"login": "hashhar"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/glue/GlueColumnStatisticsProvider.java", "diffHunk": "@@ -32,7 +30,7 @@\n \n     Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition);\n \n-    void updateTableColumnStatistics(TableInput table, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics);\n \n-    void updatePartitionStatistics(PartitionInput partition, Map<String, HiveColumnStatistics> columnStatistics);\n+    void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> columnStatistics, boolean forPartitionCreation);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwNzY4NTc5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-570768579", "createdAt": "2021-01-18T20:44:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo0NDowN1rOIV2tsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQyMDo0NDowN1rOIV2tsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc4NzQ0Mw==", "bodyText": "throw new SkipException would be more appropriate, but i'd still want to understand better what is supposed to be tested here and cannot be", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r559787443", "createdAt": "2021-01-18T20:44:07Z", "author": {"login": "findepi"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +154,59 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n+        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxOTAwMTgw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-571900180", "createdAt": "2021-01-20T06:18:24Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoxODoyNFrOIWuqDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNjoyOToxM1rOIWu4ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNDAxNA==", "bodyText": "Add static import for fromGlueColumnStatistics.\nAlso in getPartitionColumnStatistics.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560704014", "createdAt": "2021-01-20T06:18:24Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -92,17 +98,14 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             return glueClient.getColumnStatisticsForTable(request);\n         }, readExecutor)));\n \n-        final ImmutableList.Builder<ColumnStatistics> columnStatsBuilder = ImmutableList.builder();\n+        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n         for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n-            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, PrestoException.class);\n-            columnStatsBuilder.addAll(tableColumnsStats.getColumnStatisticsList());\n+            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+            tableColumnsStats.getColumnStatisticsList()\n+                    .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNDc5Mw==", "bodyText": "How does the statistics object look when logged?\nWould it be more useful to just log ((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560704793", "createdAt": "2021-01-20T06:20:31Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -279,7 +279,7 @@ private static ColumnStatisticsData getGlueColumnStatisticsData(HiveColumnStatis\n                 catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n                 break;\n             default:\n-                throw new PrestoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDcwNzc0Mg==", "bodyText": "I'd keep the comment about why this fails. Glue requires min/max to be set or more accurately Glue doesn't have any optional fields in statistics.\nBut this doesn't match the documentation from AWS somehow. They mention min/max as Required: No.\nIf it's possible can you take a look at the response returned from AWS by enabling their debug logging as decribed at https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/java-dg-logging.html#sdk-net-logging-request-response.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r560707742", "createdAt": "2021-01-20T06:29:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -179,16 +179,18 @@ public void testUpdateTableColumnStatistics()\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n             throws Exception\n     {\n-        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n-        // The only exception is when all rows are NULLs. Glue requires min/max to be set.\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n     public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n             throws Exception\n     {\n-        // this test is not really meaningful for Glue, for numeric columns, min/max stat should always be available\n-        // The only exception is when all rows are NULLs. Glue requires min/max to be set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjA5NjA5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573609609", "createdAt": "2021-01-21T18:17:31Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODoxNzozMVrOIYDvQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODoxNzozMVrOIYDvQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA5Nzk4Ng==", "bodyText": "please setup that in the module:\n        installModuleIf(\n                HiveConfig.class,\n                HiveConfig::isTableStatisticsEnabled,\n                innerBinder -> innerBinder.bind(GlueColumnStatisticsProvider.class).to(DefaultGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON),\n                innerBinder -> innerBinder.bind(GlueColumnStatisticsProvider.class).to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON));\n\nshould do", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562097986", "createdAt": "2021-01-21T18:17:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -185,10 +189,16 @@ public GlueHiveMetastore(\n         this.defaultDir = glueConfig.getDefaultWarehouseDir();\n         this.catalogId = glueConfig.getCatalogId().orElse(null);\n         this.partitionSegments = glueConfig.getPartitionSegments();\n-        this.executor = requireNonNull(executor, \"executor is null\");\n-        this.columnStatisticsProvider = requireNonNull(columnStatisticsProvider, \"columnStatisticsProvider is null\");\n+        this.partitionsReadExecutor = requireNonNull(partitionsReadExecutor, \"executor is null\");\n         this.assumeCanonicalPartitionKeys = glueConfig.isAssumeCanonicalPartitionKeys();\n         this.tableFilter = requireNonNull(tableFilter, \"tableFilter is null\");\n+        this.enableColumnStatistics = hiveConfig.isTableStatisticsEnabled();\n+        if (this.enableColumnStatistics) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjE5NjE5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573619619", "createdAt": "2021-01-21T18:30:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMDowMlrOIYEPBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMDowMlrOIYEPBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwNjExNg==", "bodyText": "Do we need those configuration parameters? Do we expect that we would need to bump it? If not I would rather not have those. The less config params the better.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562106116", "createdAt": "2021-01-21T18:30:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastoreConfig.java", "diffHunk": "@@ -40,6 +40,8 @@\n     private Optional<String> catalogId = Optional.empty();\n     private int partitionSegments = 5;\n     private int getPartitionThreads = 20;\n+    private int readStatisticsThreads = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjIyMzEw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573622310", "createdAt": "2021-01-21T18:33:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMzoyMVrOIYEXDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODozMzoyMVrOIYEXDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwODE3Mg==", "bodyText": "It feels to me that you should not need this one as it is bind in HIveModule which should be always present.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562108172", "createdAt": "2021-01-21T18:33:21Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -46,10 +47,7 @@\n     protected void setup(Binder binder)\n     {\n         configBinder(binder).bindConfig(GlueHiveMetastoreConfig.class);\n-\n-        newOptionalBinder(binder, GlueColumnStatisticsProvider.class)\n-                .setDefault().to(DisabledGlueColumnStatisticsProvider.class).in(Scopes.SINGLETON);\n-\n+        configBinder(binder).bindConfig(HiveConfig.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjMyNjQ5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573632649", "createdAt": "2021-01-21T18:46:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo0NjoyM1rOIYE2DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo0NjoyM1rOIYE2DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExNjEwOQ==", "bodyText": "those are not used anywhere.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562116109", "createdAt": "2021-01-21T18:46:23Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -59,6 +57,17 @@ protected void setup(Binder binder)\n                 .annotatedWith(ForRecordingHiveMetastore.class)\n                 .to(GlueHiveMetastore.class)\n                 .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsRead.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);\n+\n+        binder.bind(HiveMetastore.class)\n+                .annotatedWith(ForGlueColumnStatisticsWrite.class)\n+                .to(GlueHiveMetastore.class)\n+                .in(Scopes.SINGLETON);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjM2OTg0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573636984", "createdAt": "2021-01-21T18:51:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MTo0NVrOIYFDlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MTo0NVrOIYFDlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExOTU3NQ==", "bodyText": "drop final modifiers on non-fields. We do not have a convention in Trino to use them.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562119575", "createdAt": "2021-01-21T18:51:45Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjM4MTIy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573638122", "createdAt": "2021-01-21T18:53:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MzoxM1rOIYFG_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1MzoxM1rOIYFG_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyMDQ0Ng==", "bodyText": "extract helper method to create executor given number of threads and name. All three look exactly the same.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562120446", "createdAt": "2021-01-21T18:53:13Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueMetastoreModule.java", "diffHunk": "@@ -75,7 +84,33 @@ public Executor createExecutor(CatalogName catalogName, GlueHiveMetastoreConfig\n             return directExecutor();\n         }\n         return new BoundedExecutor(\n-                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-%s\")),\n+                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-partitions-%s\")),\n                 hiveConfig.getGetPartitionThreads());\n     }\n+\n+    @Provides\n+    @Singleton\n+    @ForGlueColumnStatisticsRead\n+    public Executor createStatisticsReadExecutor(CatalogName catalogName, GlueHiveMetastoreConfig hiveConfig)\n+    {\n+        if (hiveConfig.getReadStatisticsThreads() == 1) {\n+            return directExecutor();\n+        }\n+        return new BoundedExecutor(\n+                newCachedThreadPool(daemonThreadsNamed(\"hive-glue-statistics-read-%s\")),\n+                hiveConfig.getReadStatisticsThreads());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjQwODIw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573640820", "createdAt": "2021-01-21T18:56:31Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1NjozMVrOIYFPHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxODo1NjozMVrOIYFPHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyMjUyNw==", "bodyText": "static import MoreFutures.getFutureValue", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562122527", "createdAt": "2021-01-21T18:56:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 112}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjQ1MjYy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573645262", "createdAt": "2021-01-21T19:01:58Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMTo1OFrOIYFcwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMTo1OFrOIYFcwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNjAxNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n          \n          \n            \n                        final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n          \n          \n            \n                        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n          \n          \n            \n                            final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n          \n          \n            \n                            tableColumnsStats.getColumnStatisticsList()\n          \n          \n            \n                                    .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        return columnStatsMapBuilder.build();\n          \n          \n            \n                        HiveBasicStatistics tableBasicStatistics = getHiveBasicStatistics(table.getParameters());\n          \n          \n            \n                        ImmutableMap.Builder<String, HiveColumnStatistics> tableColumnStatistics = ImmutableMap.builder();\n          \n          \n            \n                        for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n          \n          \n            \n                            GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n          \n          \n            \n                            for (ColumnStatistics singleColumnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n          \n          \n            \n                                tableColumnStatistics.put(\n          \n          \n            \n                                        singleColumnStatistics.getColumnName(),\n          \n          \n            \n                                        fromGlueColumnStatistics(singleColumnStatistics.getStatisticsData(), tableBasicStatistics.getRowCount()));\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        return tableColumnStatistics.build();", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562126016", "createdAt": "2021-01-21T19:01:58Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjQ2MzQ1", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573646345", "createdAt": "2021-01-21T19:03:20Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMzoyMFrOIYFf0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowMzoyMFrOIYFf0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNjgwMA==", "bodyText": "Please restructure in similar way as above. I think it make the code more readable.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562126800", "createdAt": "2021-01-21T19:03:20Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjQ3NjUy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573647652", "createdAt": "2021-01-21T19:05:04Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowNTowNFrOIYFjjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowNTowNFrOIYFjjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyNzc1Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // Write limit for AWS Glue API GetColumnStatisticsForPartition\n          \n          \n            \n                // Read limit for AWS Glue API GetColumnStatisticsForPartition", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562127757", "createdAt": "2021-01-21T19:05:04Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjUwMDE4", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573650018", "createdAt": "2021-01-21T19:08:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowODoxNVrOIYFq9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTowODoxNVrOIYFq9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEyOTY1NA==", "bodyText": "can you please check if stream.map.collect would not look nicer?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562129654", "createdAt": "2021-01-21T19:08:15Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjU3MjM2", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573657236", "createdAt": "2021-01-21T19:17:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxNzo1N1rOIYGBcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxNzo1N1rOIYGBcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNTQwOQ==", "bodyText": "maybe\n                getFutureValue(allOf(writeFutures.toArray(CompletableFuture[]::new)));\n\nI am not super convinced. I would be more if there was allOf which takes a list ....", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562135409", "createdAt": "2021-01-21T19:17:57Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 180}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjU3ODAy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573657802", "createdAt": "2021-01-21T19:18:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxODo0M1rOIYGDKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxODo0M1rOIYGDKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNTg1MA==", "bodyText": "static import runAsync", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562135850", "createdAt": "2021-01-21T19:18:43Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 170}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjU4MDQy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573658042", "createdAt": "2021-01-21T19:19:02Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOTowMlrOIYGEGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOTowMlrOIYGEGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNjA5MA==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562136090", "createdAt": "2021-01-21T19:19:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 176}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjU4Mjc5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573658279", "createdAt": "2021-01-21T19:19:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOToyMVrOIYGEvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToxOToyMVrOIYGEvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNjI1Mw==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562136253", "createdAt": "2021-01-21T19:19:21Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 183}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjU5OTU0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573659954", "createdAt": "2021-01-21T19:21:30Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyMTozMFrOIYGJ9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyMTozMFrOIYGJ9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzNzU5MQ==", "bodyText": "missing return?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562137591", "createdAt": "2021-01-21T19:21:30Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 181}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjYyOTg3", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573662987", "createdAt": "2021-01-21T19:24:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo0N1rOIYGUlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo0N1rOIYGUlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0MDMwOA==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562140308", "createdAt": "2021-01-21T19:24:47Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 193}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjYzMDk1", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573663095", "createdAt": "2021-01-21T19:24:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo1NVrOIYGU4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOToyNDo1NVrOIYGU4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0MDM4NA==", "bodyText": "static import runAsync", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562140384", "createdAt": "2021-01-21T19:24:55Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 186}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjY4NzY4", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573668768", "createdAt": "2021-01-21T19:32:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjoxNlrOIYGmAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjoxNlrOIYGmAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NDc2OA==", "bodyText": "name the variables columnChunk", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562144768", "createdAt": "2021-01-21T19:32:16Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 214}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjY5MTI3", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573669127", "createdAt": "2021-01-21T19:32:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjo0N1rOIYGnEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozMjo0N1rOIYGnEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NTA0Mg==", "bodyText": "Why don't we need analogous code in updateTableColumnStatistics?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562145042", "createdAt": "2021-01-21T19:32:47Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->\n+                            CompletableFuture.runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                MoreFutures.getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            final boolean partitionExists = partitionExists(partition);\n+            final Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            final Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+\n+            final List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 231}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjcwMjc2", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573670276", "createdAt": "2021-01-21T19:34:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozNDoyM1rOIYGqMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozNDoyM1rOIYGqMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0NTg0Mw==", "bodyText": "Use ImmutableListBuilder like everywhere", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562145843", "createdAt": "2021-01-21T19:34:23Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.airlift.concurrent.MoreFutures;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Write limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            final List<String> columnNames = getAllColumns(table);\n+            final List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(table.getDatabaseName())\n+                        .withTableName(table.getTableName())\n+                        .withColumnNames(partialColumns);\n+\n+                return glueClient.getColumnStatisticsForTable(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForTableResult tableColumnsStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                tableColumnsStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(), GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            final List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                final List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                final GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            final HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            final ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                final GetColumnStatisticsForPartitionResult partitionColumnStats = MoreFutures.getFutureValue(future, TrinoException.class);\n+                partitionColumnStats.getColumnStatisticsList()\n+                        .forEach(col -> columnStatsMapBuilder.put(col.getColumnName(),\n+                                GlueStatConverter.fromGlueColumnStatistics(col.getStatisticsData(), tableStatistics.getRowCount())));\n+            }\n+\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> columnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+\n+            if (columnStatistics.isEmpty()) {\n+                final List<CompletableFuture<Void>> writeFutures = Stream.concat(table.getDataColumns().stream(), table.getPartitionColumns().stream())\n+                        .map(column -> CompletableFuture.runAsync(() -> glueClient.deleteColumnStatisticsForTable(\n+                                new DeleteColumnStatisticsForTableRequest()\n+                                        .withCatalogId(catalogId)\n+                                        .withDatabaseName(table.getDatabaseName())\n+                                        .withTableName(table.getTableName())\n+                                        .withColumnName(column.getName())), writeExecutor))\n+                        .collect(Collectors.toUnmodifiableList());\n+\n+                for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                    MoreFutures.getFutureValue(writeFuture);\n+                }\n+            }\n+\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(table, columnStatistics, tableStats.getRowCount());\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> CompletableFuture.runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeChunkFuture : writeChunkFutures) {\n+                MoreFutures.getFutureValue(writeChunkFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            final HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            final List<ColumnStatistics> columnStats = GlueStatConverter.toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            final List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            final List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(column ->\n+                            CompletableFuture.runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                MoreFutures.getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            final boolean partitionExists = partitionExists(partition);\n+            final Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            final Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+\n+            final List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> CompletableFuture.runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)\n+                    ).collect(Collectors.toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                MoreFutures.getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    private boolean partitionExists(Partition partition)\n+    {\n+        final BatchGetPartitionResult results = glueClient.batchGetPartition(new BatchGetPartitionRequest()\n+                .withCatalogId(catalogId)\n+                .withDatabaseName(partition.getDatabaseName())\n+                .withTableName(partition.getTableName())\n+                .withPartitionsToGet(\n+                        new PartitionValueList().withValues(partition.getValues())\n+                )\n+        );\n+        return !results.getPartitions().isEmpty() || !results.getUnprocessedKeys().isEmpty();\n+    }\n+\n+    private List<String> getAllColumns(Table table)\n+    {\n+        final List<String> allColumns = new ArrayList<>(table.getDataColumns().size() + table.getPartitionColumns().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 265}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjczMTc3", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573673177", "createdAt": "2021-01-21T19:38:17Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozODoxOFrOIYGy6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTozODoxOFrOIYGy6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE0ODA3NA==", "bodyText": "this is O(N^2) which with 1000 columns will start to be substantial cost. Pre-build String->Column map", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562148074", "createdAt": "2021-01-21T19:38:18Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjc1OTQ0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573675944", "createdAt": "2021-01-21T19:42:02Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MjowMlrOIYG6og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MjowMlrOIYG6og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MDA1MA==", "bodyText": "can you extract common part for column and partition stats to helper method?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562150050", "createdAt": "2021-01-21T19:42:02Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjc2Njkw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573676690", "createdAt": "2021-01-21T19:43:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MzowMVrOIYG82Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0MzowMVrOIYG82Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MDYxNw==", "bodyText": "put this one below columnByName", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562150617", "createdAt": "2021-01-21T19:43:01Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            final Optional<Column> column = columnByName(partition, columnName);\n+            HiveType columnType = column.get().getType();\n+\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        List<ColumnStatistics> catalogColumnStatisticsList = new ArrayList<>(trinoColumnStats.size());\n+\n+        trinoColumnStats.forEach((columnName, statistics) -> {\n+            HiveType columnType = table.getColumn(columnName).get().getType();\n+            ColumnStatistics catalogColumnStatistics = new ColumnStatistics();\n+\n+            catalogColumnStatistics.setColumnName(columnName);\n+            catalogColumnStatistics.setColumnType(columnType.toString());\n+            ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+            catalogColumnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+            catalogColumnStatistics.setAnalyzedTime(new Date());\n+\n+            catalogColumnStatisticsList.add(catalogColumnStatistics);\n+        });\n+\n+        return catalogColumnStatisticsList;\n+    }\n+\n+    private static Optional<Column> columnByName(Partition partition, String columnName)\n+    {\n+        for (Column column : partition.getColumns()) {\n+            if (column.getName().equals(columnName)) {\n+                return Optional.of(column);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 195}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjc4NDUx", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573678451", "createdAt": "2021-01-21T19:45:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0NToyNlrOIYHB5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0NToyNlrOIYHB5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MTkwOQ==", "bodyText": "seems not needed. revert", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562151909", "createdAt": "2021-01-21T19:45:26Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueToTrinoConverter.java", "diffHunk": "@@ -93,7 +93,7 @@ public static Table convertTable(com.amazonaws.services.glue.model.Table glueTab\n         return tableBuilder.build();\n     }\n \n-    private static Column convertColumn(com.amazonaws.services.glue.model.Column glueColumn)\n+    public static Column convertColumn(com.amazonaws.services.glue.model.Column glueColumn)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjgwNjgx", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573680681", "createdAt": "2021-01-21T19:48:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODoyNlrOIYHJEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODoyNlrOIYHJEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1Mzc0Nw==", "bodyText": "this does not seem right? Is that a flow we can get into in real life?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562153747", "createdAt": "2021-01-21T19:48:26Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,61 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjgwNzU3", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573680757", "createdAt": "2021-01-21T19:48:31Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODozMVrOIYHJTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQxOTo0ODozMVrOIYHJTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjE1MzgwNA==", "bodyText": "same here", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r562153804", "createdAt": "2021-01-21T19:48:31Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,61 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatistics()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        // The original implementation AbstractTestHiveClient#testUpdateTableColumnStatistics assumes each update call to metastore would override\n+        // the previous update call but this is not entirely true for Glue.\n+        // For example, there are 5 columns of a table. if you update 2 columns and then update the remaining 3 columns in two separate calls.\n+        // The second update call would not override the first update call (assume the first 2 and remaining 3 columns are exclusive).\n+        // Following this rationale, provide an empty column stat does not clear all the existing column stats.\n+        // (Glue actually does not accept the empty column stat).\n+        SchemaTableName tableName = temporaryTable(\"update_table_column_statistics\");\n+        try {\n+            doCreateEmptyTable(tableName, ORC, STATISTICS_TABLE_COLUMNS);\n+            // STATISTICS_1_1 must be subset of STATISTICS_1\n+            testUpdateTableStatistics(tableName, EMPTY_TABLE_STATISTICS, STATISTICS_1_1, STATISTICS_1);\n+        }\n+        finally {\n+            dropTable(tableName);\n+        }\n     }\n \n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n-    public void testUpdatePartitionColumnStatistics()\n+    public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdatePartitionColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNjgxMDIy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-573681022", "createdAt": "2021-01-21T19:48:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc3MzU2MDU0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-577356054", "createdAt": "2021-01-27T13:53:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxMzo1MzoxM1rOIbIpnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxMzo1MzoxM1rOIbIpnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTMyNDE4OA==", "bodyText": "What happens if getPartitionStatistics is called for a non-existent partition?\nThere will be 1 API call on the not exists path but 2 on the exists path. Can we avoid this by using the exception thrown when a partition doesn't exist as a control variable instead of the boolean?\nLots of people run into Glue rate-limits so we should strive to reduce API calls to Glue.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r565324188", "createdAt": "2021-01-27T13:53:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,272 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount())\n+                    );\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(\n+                    writeChunkFutures.toArray(CompletableFuture[]::new)\n+            ));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 232}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyMTgyOTA0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582182904", "createdAt": "2021-02-03T09:52:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QwOTo1MjoxM1rOIe5wLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNjozNjowMlrOIfLXMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTI3NDQxNQ==", "bodyText": "nit: Reformat to place each argument on separate line.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n          \n          \n            \n                        Partition partition,\n          \n          \n            \n                        Map<String, HiveColumnStatistics> trinoColumnStats,\n          \n          \n            \n                        OptionalLong rowCount)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569274415", "createdAt": "2021-02-03T09:52:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTI3NjE5Mw==", "bodyText": "nit: Reformat\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n          \n          \n            \n                        Table table,\n          \n          \n            \n                        Map<String, HiveColumnStatistics> trinoColumnStats,\n          \n          \n            \n                        OptionalLong rowCount)", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569276193", "createdAt": "2021-02-03T09:54:38Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxMzM2Mw==", "bodyText": "Is fromMetastoreNullsCount(nullsCountOfBinary) intentionally missing here (it's used in other branches).", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569413363", "createdAt": "2021-02-03T13:30:42Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNTYxNw==", "bodyText": "Possible NPE here. Take a look at ThriftMetastoreUtil#fromMetastoreDate.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569415617", "createdAt": "2021-02-03T13:34:05Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 282}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxNjg5Mg==", "bodyText": "Possible NPE here. Take a look at ThriftMetastoreUtil#toMetastoreDate.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569416892", "createdAt": "2021-02-03T13:35:53Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());\n+        decimal.setScale(catalogDecimal.getScale().shortValue());\n+        return Optional.of(new BigDecimal(new BigInteger(decimal.getUnscaled()), decimal.getScale()));\n+    }\n+\n+    private static Optional<LocalDate> dateToLocalDate(Date date)\n+    {\n+        long daysSinceEpoch = date.getTime() / MILLIS_PER_DAY;\n+        return Optional.of(LocalDate.ofEpochDay(daysSinceEpoch));\n+    }\n+\n+    private static Date localDateToDate(LocalDate date)\n+    {\n+        long millisecondsSinceEpoch = date.toEpochDay() * MILLIS_PER_DAY;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 288}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODA1NQ==", "bodyText": "Possible NPE. Let's be defensive here because even though AWS Glue documents these fields to be required but we already know the docs are not 100% correct.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569418055", "createdAt": "2021-02-03T13:37:34Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));\n+        DecimalNumber catalogDecimal = new DecimalNumber();\n+        catalogDecimal.setUnscaledValue(ByteBuffer.wrap(hiveDecimal.getUnscaled()));\n+        catalogDecimal.setScale((int) hiveDecimal.getScale());\n+        return catalogDecimal;\n+    }\n+\n+    private static Optional<BigDecimal> glueDecimalToBigDecimal(DecimalNumber catalogDecimal)\n+    {\n+        Decimal decimal = new Decimal();\n+        decimal.setUnscaled(catalogDecimal.getUnscaledValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxODMwOA==", "bodyText": "Possible NPE. Let's be defensive here because even though AWS Glue documents these fields to be required but we already know the docs are not 100% correct.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569418308", "createdAt": "2021-02-03T13:37:55Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:\n+                LongColumnStatisticsData catalogLongData = new LongColumnStatisticsData();\n+                statistics.getIntegerStatistics().ifPresent(integerStatistics -> {\n+                    integerStatistics.getMin().ifPresent(catalogLongData::setMinimumValue);\n+                    integerStatistics.getMax().ifPresent(catalogLongData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogLongData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogLongData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.LONG.toString());\n+                catalogColumnStatisticsData.setLongColumnStatisticsData(catalogLongData);\n+                break;\n+            case VARCHAR:\n+            case CHAR:\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = new StringColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogStringData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogStringData::setNumberOfDistinctValues);\n+                catalogStringData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogStringData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.STRING.toString());\n+                catalogColumnStatisticsData.setStringColumnStatisticsData(catalogStringData);\n+                break;\n+            default:\n+                throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics type: \" + statistics);\n+        }\n+        return catalogColumnStatisticsData;\n+    }\n+\n+    private static DecimalNumber bigDecimalToGlueDecimal(BigDecimal decimal)\n+    {\n+        Decimal hiveDecimal = new Decimal((short) decimal.scale(), ByteBuffer.wrap(decimal.unscaledValue().toByteArray()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQxOTk4NA==", "bodyText": "We can make the error message more explicit like Unsupported statistics type: %s so that users don't need to look at stack-trace.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569419984", "createdAt": "2021-02-03T13:40:15Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyNDMwMQ==", "bodyText": "Some of these branches look impossible to hit because we don't/can't write stats for such types into Glue. e.g. TIMESTAMP.\nAm I correct? Or misunderstanding something?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569424301", "createdAt": "2021-02-03T13:46:31Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = new BooleanColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBooleanData::setNumberOfNulls);\n+                statistics.getBooleanStatistics().ifPresent(booleanStatistics -> {\n+                    booleanStatistics.getFalseCount().ifPresent(catalogBooleanData::setNumberOfFalses);\n+                    booleanStatistics.getTrueCount().ifPresent(catalogBooleanData::setNumberOfTrues);\n+                });\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BOOLEAN.toString());\n+                catalogColumnStatisticsData.setBooleanColumnStatisticsData(catalogBooleanData);\n+                break;\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = new BinaryColumnStatisticsData();\n+                statistics.getNullsCount().ifPresent(catalogBinaryData::setNumberOfNulls);\n+                catalogBinaryData.setMaximumLength(statistics.getMaxValueSizeInBytes().orElse(0));\n+                catalogBinaryData.setAverageLength(getAverageColumnLength(statistics.getTotalSizeInBytes(), rowCount, statistics.getNullsCount()).orElse(0));\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.BINARY.toString());\n+                catalogColumnStatisticsData.setBinaryColumnStatisticsData(catalogBinaryData);\n+                break;\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = new DateColumnStatisticsData();\n+                statistics.getDateStatistics().ifPresent(dateStatistics -> {\n+                    dateStatistics.getMin().ifPresent(value -> catalogDateData.setMinimumValue(localDateToDate(value)));\n+                    dateStatistics.getMax().ifPresent(value -> catalogDateData.setMaximumValue(localDateToDate(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDateData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDateData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DATE.toString());\n+                catalogColumnStatisticsData.setDateColumnStatisticsData(catalogDateData);\n+                break;\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = new DecimalColumnStatisticsData();\n+                statistics.getDecimalStatistics().ifPresent(decimalStatistics -> {\n+                    decimalStatistics.getMin().ifPresent(value -> catalogDecimalData.setMinimumValue(bigDecimalToGlueDecimal(value)));\n+                    decimalStatistics.getMax().ifPresent(value -> catalogDecimalData.setMaximumValue(bigDecimalToGlueDecimal(value)));\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDecimalData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDecimalData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DECIMAL.toString());\n+                catalogColumnStatisticsData.setDecimalColumnStatisticsData(catalogDecimalData);\n+                break;\n+            case FLOAT:\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = new DoubleColumnStatisticsData();\n+                statistics.getDoubleStatistics().ifPresent(doubleStatistics -> {\n+                    doubleStatistics.getMin().ifPresent(catalogDoubleData::setMinimumValue);\n+                    doubleStatistics.getMax().ifPresent(catalogDoubleData::setMaximumValue);\n+                });\n+                statistics.getNullsCount().ifPresent(catalogDoubleData::setNumberOfNulls);\n+                toMetastoreDistinctValuesCount(statistics.getDistinctValuesCount(), statistics.getNullsCount()).ifPresent(catalogDoubleData::setNumberOfDistinctValues);\n+                catalogColumnStatisticsData.setType(ColumnStatisticsType.DOUBLE.toString());\n+                catalogColumnStatisticsData.setDoubleColumnStatisticsData(catalogDoubleData);\n+                break;\n+            case BYTE:\n+            case SHORT:\n+            case INT:\n+            case LONG:\n+            case TIMESTAMP:", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyOTAwOA==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569429008", "createdAt": "2021-02-03T13:53:01Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyOTI4OA==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569429288", "createdAt": "2021-02-03T13:53:23Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzA4Ng==", "bodyText": "In a follow-up we may want to make this execute in the order that futures complete to avoid being blocked on a single slow API call - maybe by adding a callback to the future. Just thinking out loud.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433086", "createdAt": "2021-02-03T13:58:27Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzQwOQ==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433409", "createdAt": "2021-02-03T13:58:51Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQzMzUwMw==", "bodyText": "Let's catch any RuntimeException here and wrap in TrinoException here.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569433503", "createdAt": "2021-02-03T13:58:58Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1MjE0Ng==", "bodyText": "nit: move closing brackets to previous line. I wonder why checkstyle didn't complain though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569552146", "createdAt": "2021-02-03T16:22:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1MzU3Nw==", "bodyText": "Let's change all occurrences of loops over future where returned values are not checked into something like getFutureValue(allOf(...))? Or is that not equivalent?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569553577", "createdAt": "2021-02-03T16:24:09Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1NDAyMw==", "bodyText": "nit: move closing brackets to previous line. I wonder why checkstyle didn't complain though.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569554023", "createdAt": "2021-02-03T16:24:48Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1NDM2Nw==", "bodyText": "Let's test for an exception to be thrown instead to avoid an API call. WDYT @losipiuk.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569554367", "createdAt": "2021-02-03T16:25:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n+                getFutureValue(writePartitionStatsFuture);\n+            }\n+\n+            boolean partitionExists = partitionExists(partition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTYxMw==", "bodyText": "Let's add some comment about why this is failing? AFAIR you said that even though Glue API docs say that some fields are \"not required\" not setting them when making the API call causes an error. Correct?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569559613", "createdAt": "2021-02-03T16:31:32Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU1OTc1OQ==", "bodyText": "Let's add some comment about why this is failing? AFAIR you said that even though Glue API docs say that some fields are \"not required\" not setting them when making the API call causes an error. Correct?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569559759", "createdAt": "2021-02-03T16:31:44Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java", "diffHunk": "@@ -152,34 +158,22 @@ public void testRenameTable()\n         // rename table is not yet supported by Glue\n     }\n \n-    @Override\n-    public void testPartitionStatisticsSampling()\n-    {\n-        // Glue metastore does not support column level statistics\n-    }\n-\n-    @Override\n-    public void testUpdateTableColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n-    }\n-\n     @Override\n     public void testUpdateTableColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n-    }\n-\n-    @Override\n-    public void testUpdatePartitionColumnStatistics()\n-    {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdateTableColumnStatisticsEmptyOptionalFields)\n+                .hasMessageContaining(\"Service: AWSGlue; Status Code: 500; Error Code: InternalServiceException;\")\n+                .isInstanceOf(TrinoException.class);\n     }\n \n     @Override\n     public void testUpdatePartitionColumnStatisticsEmptyOptionalFields()\n+            throws Exception\n     {\n-        // column statistics are not supported by Glue\n+        assertThatThrownBy(super::testUpdatePartitionColumnStatisticsEmptyOptionalFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MTk4Nw==", "bodyText": "Why this change? This indicates to me that are we somehow calculating data size differently for Thrift vs Glue?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569561987", "createdAt": "2021-02-03T16:34:49Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -513,23 +513,23 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_float\", createDoubleColumnStatistics(OptionalDouble.of(123.25), OptionalDouble.of(567.58), OptionalLong.of(9), OptionalLong.of(10)))\n                             .put(\"t_string\", createStringColumnStatistics(OptionalLong.of(10), OptionalLong.of(50), OptionalLong.of(3), OptionalLong.of(7)))\n                             .put(\"t_varchar\", createStringColumnStatistics(OptionalLong.of(100), OptionalLong.of(230), OptionalLong.of(5), OptionalLong.of(3)))\n-                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(500), OptionalLong.of(1), OptionalLong.of(4)))\n-                            .put(\"t_varbinary\", createBinaryColumnStatistics(OptionalLong.of(4), OptionalLong.of(300), OptionalLong.of(1)))\n+                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(50), OptionalLong.of(1), OptionalLong.of(4)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MjkyOA==", "bodyText": "@losipiuk does it make sense for a follow-up task in future to normalize such incorrect stats? Or does the engine already ignore/correct for such stats.\ncc: @sopel", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569562928", "createdAt": "2021-02-03T16:36:02Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -545,10 +545,10 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_bigint\", createIntegerColumnStatistics(OptionalLong.of(2345L), OptionalLong.of(6789L), OptionalLong.of(4), OptionalLong.of(7)))\n                             .put(\"t_integer\", createIntegerColumnStatistics(OptionalLong.of(234L), OptionalLong.of(678L), OptionalLong.of(5), OptionalLong.of(6)))\n                             .put(\"t_smallint\", createIntegerColumnStatistics(OptionalLong.of(23L), OptionalLong.of(65L), OptionalLong.of(7), OptionalLong.of(5)))\n-                            .put(\"t_tinyint\", createIntegerColumnStatistics(OptionalLong.of(12), OptionalLong.of(3L), OptionalLong.of(2), OptionalLong.of(3)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjQyNDY0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582642464", "createdAt": "2021-02-03T17:53:28Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1MzoyOFrOIfPHhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1MzoyOFrOIfPHhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNDQ1NA==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n          \n          \n            \n            \n          \n          \n            \n                        columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n          \n          \n            \n                            List<String> columnsNames = partialColumns.stream()\n          \n          \n            \n                                    .map(Column::getName)\n          \n          \n            \n                                    .collect(toImmutableList());\n          \n          \n            \n            \n          \n          \n            \n                            GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n          \n          \n            \n                                    .withCatalogId(catalogId)\n          \n          \n            \n                                    .withDatabaseName(partition.getDatabaseName())\n          \n          \n            \n                                    .withTableName(partition.getTableName())\n          \n          \n            \n                                    .withColumnNames(columnsNames)\n          \n          \n            \n                                    .withPartitionValues(partition.getValues());\n          \n          \n            \n            \n          \n          \n            \n                            return glueClient.getColumnStatisticsForPartition(request);\n          \n          \n            \n                        }, readExecutor)));\n          \n          \n            \n                        List<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = columnChunks.stream()\n          \n          \n            \n                                .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n          \n          \n            \n                                    List<String> columnsNames = partialColumns.stream()\n          \n          \n            \n                                            .map(Column::getName)\n          \n          \n            \n                                            .collect(toImmutableList());\n          \n          \n            \n            \n          \n          \n            \n                                    GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n          \n          \n            \n                                            .withCatalogId(catalogId)\n          \n          \n            \n                                            .withDatabaseName(partition.getDatabaseName())\n          \n          \n            \n                                            .withTableName(partition.getTableName())\n          \n          \n            \n                                            .withColumnNames(columnsNames)\n          \n          \n            \n                                            .withPartitionValues(partition.getValues());\n          \n          \n            \n                                    return glueClient.getColumnStatisticsForPartition(request);\n          \n          \n            \n                                }, readExecutor))\n          \n          \n            \n                                .collect(toImmutableList());\n          \n      \n    \n    \n  \n\n@hashhar which one looks nicer to you?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569624454", "createdAt": "2021-02-03T17:53:28Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 145}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjQ2MTQ1", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582646145", "createdAt": "2021-02-03T17:57:39Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1NzozOVrOIfPTDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNzo1NzozOVrOIfPTDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyNzQwNQ==", "bodyText": "drop final", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569627405", "createdAt": "2021-02-03T17:57:39Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 183}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjQ5MDUx", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582649051", "createdAt": "2021-02-03T18:00:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMDo1N1rOIfPcTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMDo1N1rOIfPcTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYyOTc3NA==", "bodyText": "is there a reason to do updates first and removals later? It feels to me it would be better to gather the futures on single list and call getFutureValue(allOf just once.\nSo even in case of an error for some of the calls we have as many changes applied as possible.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569629774", "createdAt": "2021-02-03T18:00:57Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 172}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjUwNzgz", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582650783", "createdAt": "2021-02-03T18:03:05Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMzowNVrOIfPhOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODowMzowNVrOIfPhOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzMTAzMg==", "bodyText": "same here. Wouldn't it be better to collect futures on single list?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569631032", "createdAt": "2021-02-03T18:03:05Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.AmazonServiceException;\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.BatchGetPartitionRequest;\n+import com.amazonaws.services.glue.model.BatchGetPartitionResult;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.PartitionValueList;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk))))\n+                    .collect(toUnmodifiableList());\n+\n+            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n+\n+            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)))\n+                    ).collect(toUnmodifiableList());\n+\n+            for (CompletableFuture<Void> writeFuture : writeFutures) {\n+                getFutureValue(writeFuture);\n+            }\n+        }\n+        catch (AmazonServiceException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 213}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjU3NDgy", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582657482", "createdAt": "2021-02-03T18:11:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTowN1rOIfP1bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTowN1rOIfP1bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzNjIwNQ==", "bodyText": "please move call to columnStatisticsProvider.updatePartitionStatistics below glueClient.updatePartition we update the basic stats first.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569636205", "createdAt": "2021-02-03T18:11:07Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -385,8 +397,10 @@ public void updatePartitionStatistics(HiveIdentity identity, Table table, String\n \n         try {\n             PartitionInput partitionInput = GlueInputConverter.convertPartition(partition);\n-            partitionInput.setParameters(updateStatisticsParameters(partition.getParameters(), updatedStatistics.getBasicStatistics()));\n-            columnStatisticsProvider.updatePartitionStatistics(partitionInput, updatedStatistics.getColumnStatistics());\n+            final Map<String, String> updateStatisticsParameters = updateStatisticsParameters(partition.getParameters(), updatedStatistics.getBasicStatistics());\n+            partitionInput.setParameters(updateStatisticsParameters);\n+            partition = Partition.builder(partition).setParameters(updateStatisticsParameters).build();\n+            columnStatisticsProvider.updatePartitionStatistics(partition, updatedStatistics.getColumnStatistics());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjU3ODQ5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582657849", "createdAt": "2021-02-03T18:11:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTozNFrOIfP2dQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODoxMTozNFrOIfP2dQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTYzNjQ2OQ==", "bodyText": "plase move the call to columnStatisticsProvider.updateTableColumnStatistics(table, updatedStatistics.getColumnStatistics());  below glueClient.updateTable so we update basic stats first.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569636469", "createdAt": "2021-02-03T18:11:34Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java", "diffHunk": "@@ -358,8 +368,10 @@ public void updateTableStatistics(HiveIdentity identity, String databaseName, St\n \n         try {\n             TableInput tableInput = GlueInputConverter.convertTable(table);\n-            tableInput.setParameters(updateStatisticsParameters(table.getParameters(), updatedStatistics.getBasicStatistics()));\n-            columnStatisticsProvider.updateTableColumnStatistics(tableInput, updatedStatistics.getColumnStatistics());\n+            final Map<String, String> statisticsParameters = updateStatisticsParameters(table.getParameters(), updatedStatistics.getBasicStatistics());\n+            tableInput.setParameters(statisticsParameters);\n+            table = Table.builder(table).setParameters(statisticsParameters).build();\n+            columnStatisticsProvider.updateTableColumnStatistics(table, updatedStatistics.getColumnStatistics());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjc4ODM5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582678839", "createdAt": "2021-02-03T18:37:50Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozNzo1MFrOIfQ25w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozNzo1MFrOIfQ25w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTY1Mjk2Nw==", "bodyText": "Use braces. This will allow you to use shorter variable names. Like this:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        case DATE:\n          \n          \n            \n                            DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n          \n          \n            \n                            Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n          \n          \n            \n                            Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n          \n          \n            \n                            OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n          \n          \n            \n                            OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n          \n          \n            \n                            return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n          \n          \n            \n            \n          \n          \n            \n                        case DECIMAL:\n          \n          \n            \n                            DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n          \n          \n            \n                            Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n          \n          \n            \n                            Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n          \n          \n            \n                            OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n          \n          \n            \n                            OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n          \n          \n            \n                            return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n          \n          \n            \n                        case DATE: {\n          \n          \n            \n                            DateColumnStatisticsData data = catalogColumnStatisticsData.getDateColumnStatisticsData();\n          \n          \n            \n                            Optional<LocalDate> min = dateToLocalDate(data.getMinimumValue());\n          \n          \n            \n                            Optional<LocalDate> max = dateToLocalDate(data.getMaximumValue());\n          \n          \n            \n                            OptionalLong nullsCount = fromMetastoreNullsCount(data.getNumberOfNulls());\n          \n          \n            \n                            OptionalLong numberOfDistinctValues = OptionalLong.of(data.getNumberOfDistinctValues());\n          \n          \n            \n                            return createDateColumnStatistics(min, max, nullsCount, fromMetastoreDistinctValuesCount(numberOfDistinctValues, nullsCount, rowCount));\n          \n          \n            \n                        }\n          \n          \n            \n                        case DECIMAL: {\n          \n          \n            \n                            DecimalColumnStatisticsData data = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n          \n          \n            \n                            Optional<BigDecimal> min = glueDecimalToBigDecimal(data.getMinimumValue());\n          \n          \n            \n                            Optional<BigDecimal> max = glueDecimalToBigDecimal(data.getMaximumValue());\n          \n          \n            \n                            OptionalLong numberOfDistinctValues = OptionalLong.of(data.getNumberOfDistinctValues());\n          \n          \n            \n                            OptionalLong nullsCount = fromMetastoreNullsCount(data.getNumberOfNulls());\n          \n          \n            \n                            return createDecimalColumnStatistics(min, max, nullsCount, fromMetastoreDistinctValuesCount(numberOfDistinctValues, nullsCount, rowCount));\n          \n          \n            \n                        }", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569652967", "createdAt": "2021-02-03T18:37:50Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 136}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjc5NDU0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582679454", "createdAt": "2021-02-03T18:38:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozODozNFrOIfQ43w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxODozODozNFrOIfQ43w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTY1MzQ3MQ==", "bodyText": "use braces here to to have separate namespace for each type considered.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r569653471", "createdAt": "2021-02-03T18:38:34Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/converter/GlueStatConverter.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue.converter;\n+\n+import com.amazonaws.services.glue.model.BinaryColumnStatisticsData;\n+import com.amazonaws.services.glue.model.BooleanColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.ColumnStatisticsData;\n+import com.amazonaws.services.glue.model.ColumnStatisticsType;\n+import com.amazonaws.services.glue.model.DateColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalColumnStatisticsData;\n+import com.amazonaws.services.glue.model.DecimalNumber;\n+import com.amazonaws.services.glue.model.DoubleColumnStatisticsData;\n+import com.amazonaws.services.glue.model.LongColumnStatisticsData;\n+import com.amazonaws.services.glue.model.StringColumnStatisticsData;\n+import io.trino.plugin.hive.HiveType;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.spi.TrinoException;\n+import org.apache.hadoop.hive.metastore.api.Decimal;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.nio.ByteBuffer;\n+import java.time.LocalDate;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBinaryColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createBooleanColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDateColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDecimalColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createDoubleColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createIntegerColumnStatistics;\n+import static io.trino.plugin.hive.metastore.HiveColumnStatistics.createStringColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreDistinctValuesCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.fromMetastoreNullsCount;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getAverageColumnLength;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getTotalSizeInBytes;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.toMetastoreDistinctValuesCount;\n+import static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category.PRIMITIVE;\n+\n+public class GlueStatConverter\n+{\n+    private GlueStatConverter() {}\n+\n+    private static final long MILLIS_PER_DAY = TimeUnit.DAYS.toMillis(1);\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Partition partition, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return partition.getColumns().stream()\n+                .filter(column -> trinoColumnStats.containsKey(column.getName()))\n+                .map(c -> toColumnStatistics(c, trinoColumnStats.get(c.getName()), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    public static List<ColumnStatistics> toGlueColumnStatistics(\n+            Table table, Map<String, HiveColumnStatistics> trinoColumnStats, OptionalLong rowCount)\n+    {\n+        return trinoColumnStats.entrySet().stream()\n+                .map(e -> toColumnStatistics(table.getColumn(e.getKey()).get(), e.getValue(), rowCount))\n+                .collect(toImmutableList());\n+    }\n+\n+    private static ColumnStatistics toColumnStatistics(Column column, HiveColumnStatistics statistics, OptionalLong rowCount)\n+    {\n+        ColumnStatistics columnStatistics = new ColumnStatistics();\n+        HiveType columnType = column.getType();\n+        columnStatistics.setColumnName(column.getName());\n+        columnStatistics.setColumnType(columnType.toString());\n+        ColumnStatisticsData catalogColumnStatisticsData = toGlueColumnStatisticsData(statistics, columnType, rowCount);\n+        columnStatistics.setStatisticsData(catalogColumnStatisticsData);\n+        columnStatistics.setAnalyzedTime(new Date());\n+        return columnStatistics;\n+    }\n+\n+    public static HiveColumnStatistics fromGlueColumnStatistics(ColumnStatisticsData catalogColumnStatisticsData, OptionalLong rowCount)\n+    {\n+        ColumnStatisticsType type = ColumnStatisticsType.fromValue(catalogColumnStatisticsData.getType());\n+        switch (type) {\n+            case BINARY:\n+                BinaryColumnStatisticsData catalogBinaryData = catalogColumnStatisticsData.getBinaryColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfBinary = OptionalLong.of(catalogBinaryData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfBinary = OptionalDouble.of(catalogBinaryData.getAverageLength());\n+                OptionalLong nullsCountOfBinary = fromMetastoreNullsCount(catalogBinaryData.getNumberOfNulls());\n+                return createBinaryColumnStatistics(\n+                        maxColumnLengthOfBinary,\n+                        getTotalSizeInBytes(averageColumnLengthOfBinary, rowCount, nullsCountOfBinary),\n+                        nullsCountOfBinary);\n+\n+            case BOOLEAN:\n+                BooleanColumnStatisticsData catalogBooleanData = catalogColumnStatisticsData.getBooleanColumnStatisticsData();\n+                return createBooleanColumnStatistics(\n+                        OptionalLong.of(catalogBooleanData.getNumberOfTrues()),\n+                        OptionalLong.of(catalogBooleanData.getNumberOfFalses()),\n+                        fromMetastoreNullsCount(catalogBooleanData.getNumberOfNulls()));\n+\n+            case DATE:\n+                DateColumnStatisticsData catalogDateData = catalogColumnStatisticsData.getDateColumnStatisticsData();\n+                Optional<LocalDate> minOfDate = dateToLocalDate(catalogDateData.getMinimumValue());\n+                Optional<LocalDate> maxOfDate = dateToLocalDate(catalogDateData.getMaximumValue());\n+                OptionalLong nullsCountOfDate = fromMetastoreNullsCount(catalogDateData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDate = OptionalLong.of(catalogDateData.getNumberOfDistinctValues());\n+                return createDateColumnStatistics(minOfDate, maxOfDate, nullsCountOfDate, fromMetastoreDistinctValuesCount(distinctValuesCountOfDate, nullsCountOfDate, rowCount));\n+\n+            case DECIMAL:\n+                DecimalColumnStatisticsData catalogDecimalData = catalogColumnStatisticsData.getDecimalColumnStatisticsData();\n+                Optional<BigDecimal> minOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMinimumValue());\n+                Optional<BigDecimal> maxOfDecimal = glueDecimalToBigDecimal(catalogDecimalData.getMaximumValue());\n+                OptionalLong distinctValuesCountOfDecimal = OptionalLong.of(catalogDecimalData.getNumberOfDistinctValues());\n+                OptionalLong nullsCountOfDecimal = fromMetastoreNullsCount(catalogDecimalData.getNumberOfNulls());\n+                return createDecimalColumnStatistics(minOfDecimal, maxOfDecimal, nullsCountOfDecimal, fromMetastoreDistinctValuesCount(distinctValuesCountOfDecimal, nullsCountOfDecimal, rowCount));\n+\n+            case DOUBLE:\n+                DoubleColumnStatisticsData catalogDoubleData = catalogColumnStatisticsData.getDoubleColumnStatisticsData();\n+                OptionalDouble minOfDouble = OptionalDouble.of(catalogDoubleData.getMinimumValue());\n+                OptionalDouble maxOfDouble = OptionalDouble.of(catalogDoubleData.getMaximumValue());\n+                OptionalLong nullsCountOfDouble = fromMetastoreNullsCount(catalogDoubleData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfDouble = OptionalLong.of(catalogDoubleData.getNumberOfDistinctValues());\n+                return createDoubleColumnStatistics(minOfDouble, maxOfDouble, nullsCountOfDouble, fromMetastoreDistinctValuesCount(distinctValuesCountOfDouble, nullsCountOfDouble, rowCount));\n+\n+            case LONG:\n+                LongColumnStatisticsData catalogLongData = catalogColumnStatisticsData.getLongColumnStatisticsData();\n+                OptionalLong minOfLong = OptionalLong.of(catalogLongData.getMinimumValue());\n+                OptionalLong maxOfLong = OptionalLong.of(catalogLongData.getMaximumValue());\n+                OptionalLong nullsCountOfLong = fromMetastoreNullsCount(catalogLongData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfLong = OptionalLong.of(catalogLongData.getNumberOfDistinctValues());\n+                return createIntegerColumnStatistics(minOfLong, maxOfLong, nullsCountOfLong, fromMetastoreDistinctValuesCount(distinctValuesCountOfLong, nullsCountOfLong, rowCount));\n+\n+            case STRING:\n+                StringColumnStatisticsData catalogStringData = catalogColumnStatisticsData.getStringColumnStatisticsData();\n+                OptionalLong maxColumnLengthOfString = OptionalLong.of(catalogStringData.getMaximumLength());\n+                OptionalDouble averageColumnLengthOfString = OptionalDouble.of(catalogStringData.getAverageLength());\n+                OptionalLong nullsCountOfString = fromMetastoreNullsCount(catalogStringData.getNumberOfNulls());\n+                OptionalLong distinctValuesCountOfString = OptionalLong.of(catalogStringData.getNumberOfDistinctValues());\n+\n+                return createStringColumnStatistics(\n+                        maxColumnLengthOfString,\n+                        getTotalSizeInBytes(averageColumnLengthOfString, rowCount, nullsCountOfString),\n+                        nullsCountOfString,\n+                        fromMetastoreDistinctValuesCount(distinctValuesCountOfString, nullsCountOfString, rowCount));\n+        }\n+\n+        throw new TrinoException(HIVE_INVALID_METADATA, \"Invalid column statistics data: \" + catalogColumnStatisticsData);\n+    }\n+\n+    private static ColumnStatisticsData toGlueColumnStatisticsData(HiveColumnStatistics statistics, HiveType columnType, OptionalLong rowCount)\n+    {\n+        TypeInfo typeInfo = columnType.getTypeInfo();\n+        checkArgument(typeInfo.getCategory() == PRIMITIVE, \"unsupported type: %s\", columnType);\n+\n+        ColumnStatisticsData catalogColumnStatisticsData = new ColumnStatisticsData();\n+\n+        switch (((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory()) {\n+            case BOOLEAN:", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 179}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgyNjg1MDI5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-582685029", "createdAt": "2021-02-03T18:45:14Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg1MDcwMDUw", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-585070050", "createdAt": "2021-02-07T20:28:38Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDoyODozOFrOIhNEwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wN1QyMDozNjoxM1rOIhNIOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA==", "bodyText": "@losipiuk should we fail if Trino tries to fetch statistics for a partition which doesn't exist? Or return empty stats?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688130", "createdAt": "2021-02-07T20:28:38Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODQ3OQ==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688479", "createdAt": "2021-02-07T20:31:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODUwNA==", "bodyText": "drop final.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688504", "createdAt": "2021-02-07T20:31:36Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODU0Mg==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688542", "createdAt": "2021-02-07T20:32:07Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwMQ==", "bodyText": "nit: move collect to new line.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688601", "createdAt": "2021-02-07T20:32:35Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwNw==", "bodyText": "drop final.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571688607", "createdAt": "2021-02-07T20:32:41Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4OTAxOA==", "bodyText": "Btw, this was changed to avoid catching the TrinoException(HIVE_METASTORE_ERROR, EntityNotFoundException) in the caller to detect that a partition doesn't exist.\nI'd prefer if this responsibility of handling EntityNotFoundException would be given to the caller since this is a public method and part of the API.\nWDYT @losipiuk ?", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571689018", "createdAt": "2021-02-07T20:36:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA=="}, "originalCommit": null, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg1MzY4ODI0", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-585368824", "createdAt": "2021-02-08T10:44:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMDo0NDoyNVrOIhcv6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMTowMDo0NFrOIhdamg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk0NDkzNw==", "bodyText": "this is not performance critical so let's just use builder() and make ti fluent:\n            List<CompletableFuture<Void>> allFutures = ImmutableList.<CompletableFuture<Void>>builder()\n                    .addAll(updateFutures)\n                    .addAll(deleteFutures)\n                    .build();\n            getFutureValue(allOf(allFutures.toArray(CompletableFuture[]::new)));", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571944937", "createdAt": "2021-02-08T10:44:25Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -169,34 +166,32 @@ public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStati\n             List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n             List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n \n-            List<CompletableFuture<Void>> writeChunkFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n                     () -> glueClient.updateColumnStatisticsForTable(\n                             new UpdateColumnStatisticsForTableRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(table.getDatabaseName())\n                                     .withTableName(table.getTableName())\n-                                    .withColumnStatisticsList(columnChunk))))\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n                     .collect(toUnmodifiableList());\n \n-            getFutureValue(allOf(writeChunkFutures.toArray(CompletableFuture[]::new)));\n-\n-            final Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n             Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForTable(\n                                     new DeleteColumnStatisticsForTableRequest()\n                                             .withCatalogId(catalogId)\n                                             .withDatabaseName(table.getDatabaseName())\n                                             .withTableName(table.getTableName())\n-                                            .withColumnName(column)))\n-                    ).collect(toUnmodifiableList());\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());\n+            updateOperationsFutures.addAll(updateFutures);\n+            updateOperationsFutures.addAll(deleteFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk0NTc0MA==", "bodyText": "simplify as above", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571945740", "createdAt": "2021-02-08T10:45:36Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -217,45 +212,29 @@ public void updatePartitionStatistics(Partition partition, Map<String, HiveColum\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnStatisticsList(columnChunk)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writePartitionStatsFuture : writePartitionStatsFutures) {\n-                getFutureValue(writePartitionStatsFuture);\n-            }\n-\n-            boolean partitionExists = partitionExists(partition);\n-            Map<String, HiveColumnStatistics> currentColumnStatistics = partitionExists ? this.getPartitionColumnStatistics(partition) : Collections.emptyMap();\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n             Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n-            List<CompletableFuture<Void>> writeFutures = removedStatistics.stream()\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n                     .map(column -> runAsync(() ->\n                             glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n                                     .withCatalogId(catalogId)\n                                     .withDatabaseName(partition.getDatabaseName())\n                                     .withTableName(partition.getTableName())\n                                     .withPartitionValues(partition.getValues())\n-                                    .withColumnName(column)), writeExecutor)\n-                    ).collect(toUnmodifiableList());\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n \n-            for (CompletableFuture<Void> writeFuture : writeFutures) {\n-                getFutureValue(writeFuture);\n-            }\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODYwNw=="}, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk1NDg1MQ==", "bodyText": "I think we should throw here and catch in updatePartitionStatistics. Please add a PARTITION_NOT_FOUND error code to HiveErrorCode class so you can determine if you shiould just skip deleting for this partition in updatePartitionStatistics, or should you rather rethrow exception to the caller.", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571954851", "createdAt": "2021-02-08T10:59:12Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -156,7 +150,10 @@ public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catal\n             }\n             return columnStatsMapBuilder.build();\n         }\n-        catch (AmazonServiceException ex) {\n+        catch (EntityNotFoundException ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTY4ODEzMA=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk1NTg2Ng==", "bodyText": "because Glue reject logically inconsistent statistics\n\nAre we sure that statistics computation mechanism used by Tino will not trigger this safety valve?\ncc: @findepi", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571955866", "createdAt": "2021-02-08T11:00:44Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -513,23 +513,23 @@ private static RowType toRowType(List<ColumnMetadata> columns)\n                             .put(\"t_float\", createDoubleColumnStatistics(OptionalDouble.of(123.25), OptionalDouble.of(567.58), OptionalLong.of(9), OptionalLong.of(10)))\n                             .put(\"t_string\", createStringColumnStatistics(OptionalLong.of(10), OptionalLong.of(50), OptionalLong.of(3), OptionalLong.of(7)))\n                             .put(\"t_varchar\", createStringColumnStatistics(OptionalLong.of(100), OptionalLong.of(230), OptionalLong.of(5), OptionalLong.of(3)))\n-                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(500), OptionalLong.of(1), OptionalLong.of(4)))\n-                            .put(\"t_varbinary\", createBinaryColumnStatistics(OptionalLong.of(4), OptionalLong.of(300), OptionalLong.of(1)))\n+                            .put(\"t_char\", createStringColumnStatistics(OptionalLong.of(5), OptionalLong.of(50), OptionalLong.of(1), OptionalLong.of(4)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTU2MTk4Nw=="}, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg1MzkwMjQ4", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-585390248", "createdAt": "2021-02-08T11:11:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMTowN1rOIhdzhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMToxMTowN1rOIhdzhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTk2MjI0NQ==", "bodyText": "drop final", "url": "https://github.com/trinodb/trino/pull/6178#discussion_r571962245", "createdAt": "2021-02-08T11:11:07Z", "author": {"login": "losipiuk"}, "path": "plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/DefaultGlueColumnStatisticsProvider.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.hive.metastore.glue;\n+\n+import com.amazonaws.services.glue.AWSGlueAsync;\n+import com.amazonaws.services.glue.model.ColumnStatistics;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.DeleteColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.EntityNotFoundException;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForPartitionResult;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableRequest;\n+import com.amazonaws.services.glue.model.GetColumnStatisticsForTableResult;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForPartitionRequest;\n+import com.amazonaws.services.glue.model.UpdateColumnStatisticsForTableRequest;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Lists;\n+import io.trino.plugin.hive.HiveBasicStatistics;\n+import io.trino.plugin.hive.metastore.Column;\n+import io.trino.plugin.hive.metastore.HiveColumnStatistics;\n+import io.trino.plugin.hive.metastore.Partition;\n+import io.trino.plugin.hive.metastore.Table;\n+import io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import io.trino.spi.TrinoException;\n+import io.trino.spi.statistics.ColumnStatisticType;\n+import io.trino.spi.type.Type;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Sets.difference;\n+import static io.airlift.concurrent.MoreFutures.getFutureValue;\n+import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.fromGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.glue.converter.GlueStatConverter.toGlueColumnStatistics;\n+import static io.trino.plugin.hive.metastore.thrift.ThriftMetastoreUtil.getHiveBasicStatistics;\n+import static java.util.concurrent.CompletableFuture.allOf;\n+import static java.util.concurrent.CompletableFuture.runAsync;\n+import static java.util.stream.Collectors.toUnmodifiableList;\n+\n+public class DefaultGlueColumnStatisticsProvider\n+        implements GlueColumnStatisticsProvider\n+{\n+    // Read limit for AWS Glue API GetColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_READ_STAT_PAGE_SIZE = 100;\n+\n+    // Write limit for AWS Glue API UpdateColumnStatisticsForPartition\n+    // https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-UpdateColumnStatisticsForPartition\n+    private static final int GLUE_COLUMN_WRITE_STAT_PAGE_SIZE = 25;\n+\n+    private final AWSGlueAsync glueClient;\n+    private final String catalogId;\n+    private final Executor readExecutor;\n+    private final Executor writeExecutor;\n+\n+    public DefaultGlueColumnStatisticsProvider(AWSGlueAsync glueClient, String catalogId, Executor readExecutor, Executor writeExecutor)\n+    {\n+        this.glueClient = glueClient;\n+        this.catalogId = catalogId;\n+        this.readExecutor = readExecutor;\n+        this.writeExecutor = writeExecutor;\n+    }\n+\n+    @Override\n+    public Set<ColumnStatisticType> getSupportedColumnStatistics(Type type)\n+    {\n+        return ThriftMetastoreUtil.getSupportedColumnStatistics(type);\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getTableColumnStatistics(Table table)\n+    {\n+        try {\n+            List<String> columnNames = getAllColumns(table);\n+            List<List<String>> columnChunks = Lists.partition(columnNames, GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+            List<CompletableFuture<GetColumnStatisticsForTableResult>> getStatsFutures = columnChunks.stream()\n+                    .map(partialColumns -> CompletableFuture.supplyAsync(() -> {\n+                        GetColumnStatisticsForTableRequest request = new GetColumnStatisticsForTableRequest()\n+                                .withCatalogId(catalogId)\n+                                .withDatabaseName(table.getDatabaseName())\n+                                .withTableName(table.getTableName())\n+                                .withColumnNames(partialColumns);\n+                        return glueClient.getColumnStatisticsForTable(request);\n+                    }, readExecutor))\n+                    .collect(toImmutableList());\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(table.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForTableResult> future : getStatsFutures) {\n+                GetColumnStatisticsForTableResult tableColumnsStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : tableColumnsStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, HiveColumnStatistics> getPartitionColumnStatistics(Partition partition)\n+    {\n+        try {\n+            List<List<Column>> columnChunks = Lists.partition(partition.getColumns(), GLUE_COLUMN_READ_STAT_PAGE_SIZE);\n+\n+            ImmutableList.Builder<CompletableFuture<GetColumnStatisticsForPartitionResult>> getStatsFutures = ImmutableList.builder();\n+            columnChunks.forEach(partialColumns -> getStatsFutures.add(CompletableFuture.supplyAsync(() -> {\n+                List<String> columnsNames = partialColumns.stream()\n+                        .map(Column::getName)\n+                        .collect(toImmutableList());\n+                GetColumnStatisticsForPartitionRequest request = new GetColumnStatisticsForPartitionRequest()\n+                        .withCatalogId(catalogId)\n+                        .withDatabaseName(partition.getDatabaseName())\n+                        .withTableName(partition.getTableName())\n+                        .withColumnNames(columnsNames)\n+                        .withPartitionValues(partition.getValues());\n+                return glueClient.getColumnStatisticsForPartition(request);\n+            }, readExecutor)));\n+\n+            HiveBasicStatistics tableStatistics = getHiveBasicStatistics(partition.getParameters());\n+            ImmutableMap.Builder<String, HiveColumnStatistics> columnStatsMapBuilder = ImmutableMap.builder();\n+            for (CompletableFuture<GetColumnStatisticsForPartitionResult> future : getStatsFutures.build()) {\n+                GetColumnStatisticsForPartitionResult partitionColumnStats = getFutureValue(future, TrinoException.class);\n+                for (ColumnStatistics columnStatistics : partitionColumnStats.getColumnStatisticsList()) {\n+                    columnStatsMapBuilder.put(\n+                            columnStatistics.getColumnName(),\n+                            fromGlueColumnStatistics(columnStatistics.getStatisticsData(), tableStatistics.getRowCount()));\n+                }\n+            }\n+            return columnStatsMapBuilder.build();\n+        }\n+        catch (EntityNotFoundException ex) {\n+            return ImmutableMap.of();\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updateTableColumnStatistics(Table table, Map<String, HiveColumnStatistics> updatedTableColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics tableStats = getHiveBasicStatistics(table.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(table, updatedTableColumnStatistics, tableStats.getRowCount());\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> updateFutures = columnChunks.stream().map(columnChunk -> runAsync(\n+                    () -> glueClient.updateColumnStatisticsForTable(\n+                            new UpdateColumnStatisticsForTableRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(table.getDatabaseName())\n+                                    .withTableName(table.getTableName())\n+                                    .withColumnStatisticsList(columnChunk)), this.writeExecutor))\n+                    .collect(toUnmodifiableList());\n+\n+            Map<String, HiveColumnStatistics> currentTableColumnStatistics = this.getTableColumnStatistics(table);\n+            Set<String> removedStatistics = difference(currentTableColumnStatistics.keySet(), updatedTableColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> deleteFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForTable(\n+                                    new DeleteColumnStatisticsForTableRequest()\n+                                            .withCatalogId(catalogId)\n+                                            .withDatabaseName(table.getDatabaseName())\n+                                            .withTableName(table.getTableName())\n+                                            .withColumnName(column)), this.writeExecutor)).collect(toUnmodifiableList());\n+\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(updateFutures.size() + deleteFutures.size());\n+            updateOperationsFutures.addAll(updateFutures);\n+            updateOperationsFutures.addAll(deleteFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    @Override\n+    public void updatePartitionStatistics(Partition partition, Map<String, HiveColumnStatistics> updatedColumnStatistics)\n+    {\n+        try {\n+            HiveBasicStatistics partitionStats = getHiveBasicStatistics(partition.getParameters());\n+            List<ColumnStatistics> columnStats = toGlueColumnStatistics(partition, updatedColumnStatistics, partitionStats.getRowCount());\n+\n+            List<List<ColumnStatistics>> columnChunks = Lists.partition(columnStats, GLUE_COLUMN_WRITE_STAT_PAGE_SIZE);\n+\n+            List<CompletableFuture<Void>> writePartitionStatsFutures = columnChunks.stream()\n+                    .map(columnChunk ->\n+                            runAsync(() -> glueClient.updateColumnStatisticsForPartition(new UpdateColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnStatisticsList(columnChunk)), writeExecutor)).collect(toUnmodifiableList());\n+\n+            Map<String, HiveColumnStatistics> currentColumnStatistics = this.getPartitionColumnStatistics(partition);\n+            Set<String> removedStatistics = difference(currentColumnStatistics.keySet(), updatedColumnStatistics.keySet());\n+            List<CompletableFuture<Void>> deleteStatsFutures = removedStatistics.stream()\n+                    .map(column -> runAsync(() ->\n+                            glueClient.deleteColumnStatisticsForPartition(new DeleteColumnStatisticsForPartitionRequest()\n+                                    .withCatalogId(catalogId)\n+                                    .withDatabaseName(partition.getDatabaseName())\n+                                    .withTableName(partition.getTableName())\n+                                    .withPartitionValues(partition.getValues())\n+                                    .withColumnName(column)), writeExecutor)).collect(toUnmodifiableList());\n+\n+            final ImmutableList.Builder<CompletableFuture<Void>> updateOperationsFutures = ImmutableList.builderWithExpectedSize(writePartitionStatsFutures.size() + deleteStatsFutures.size());\n+            updateOperationsFutures.addAll(writePartitionStatsFutures);\n+            updateOperationsFutures.addAll(deleteStatsFutures);\n+            getFutureValue(allOf(updateOperationsFutures.build().toArray(CompletableFuture[]::new)));\n+        }\n+        catch (RuntimeException ex) {\n+            throw new TrinoException(HIVE_METASTORE_ERROR, ex);\n+        }\n+    }\n+\n+    private List<String> getAllColumns(Table table)\n+    {\n+        final ImmutableList.Builder<String> allColumns = ImmutableList.builderWithExpectedSize(table.getDataColumns().size() + table.getPartitionColumns().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 240}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1ODcwMTQ5", "url": "https://github.com/trinodb/trino/pull/6178#pullrequestreview-595870149", "createdAt": "2021-02-22T23:11:41Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1bcfa786eee05bd1f2667b66eee52d6d0670f21", "author": {"user": {"login": "GaruGaru", "name": "Tommaso Garuglieri"}}, "url": "https://github.com/trinodb/trino/commit/f1bcfa786eee05bd1f2667b66eee52d6d0670f21", "committedDate": "2021-02-24T06:22:21Z", "message": "Glue metastore statistics integration"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1998, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}