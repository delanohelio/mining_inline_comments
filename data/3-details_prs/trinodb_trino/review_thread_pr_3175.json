{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxNTQ3NDg5", "number": 3175, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0MToxNVrODp6wsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0MToxNVrODp6wsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjgwOTQ1OnYy", "diffSide": "RIGHT", "path": "presto-parquet/src/main/java/io/prestosql/parquet/ParquetCompressionUtils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0MToxNVrOF5Y-Bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0NDo1MVrOF5ZHSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyMjI0Nw==", "bodyText": "I'd rename this variable to read, and maybe the other one to totalBytesRead to have a clear separation.", "url": "https://github.com/trinodb/trino/pull/3175#discussion_r395722247", "createdAt": "2020-03-20T15:41:15Z", "author": {"login": "martint"}, "path": "presto-parquet/src/main/java/io/prestosql/parquet/ParquetCompressionUtils.java", "diffHunk": "@@ -89,15 +89,26 @@ private static Slice decompressGzip(Slice input, int uncompressedSize)\n             return EMPTY_SLICE;\n         }\n \n-        DynamicSliceOutput sliceOutput = new DynamicSliceOutput(uncompressedSize);\n         byte[] buffer = new byte[uncompressedSize];\n-        try (InputStream gzipInputStream = new GZIPInputStream(input.getInput(), GZIP_BUFFER_SIZE)) {\n-            int bytesRead;\n-            while ((bytesRead = gzipInputStream.read(buffer)) != -1) {\n-                sliceOutput.write(buffer, 0, bytesRead);\n+        int bytesRead = 0;\n+        boolean eos = false;\n+        try (GZIPInputStream gzipInputStream = new GZIPInputStream(input.getInput(), min(GZIP_BUFFER_SIZE, input.length()))) {\n+            int n;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyNDYxOA==", "bodyText": "Have you considered using Guava's ByteStreams.read() instead of rolling you own? (it may be tricky due to the error handling below, but worth considering)", "url": "https://github.com/trinodb/trino/pull/3175#discussion_r395724618", "createdAt": "2020-03-20T15:44:51Z", "author": {"login": "martint"}, "path": "presto-parquet/src/main/java/io/prestosql/parquet/ParquetCompressionUtils.java", "diffHunk": "@@ -89,15 +89,26 @@ private static Slice decompressGzip(Slice input, int uncompressedSize)\n             return EMPTY_SLICE;\n         }\n \n-        DynamicSliceOutput sliceOutput = new DynamicSliceOutput(uncompressedSize);\n         byte[] buffer = new byte[uncompressedSize];\n-        try (InputStream gzipInputStream = new GZIPInputStream(input.getInput(), GZIP_BUFFER_SIZE)) {\n-            int bytesRead;\n-            while ((bytesRead = gzipInputStream.read(buffer)) != -1) {\n-                sliceOutput.write(buffer, 0, bytesRead);\n+        int bytesRead = 0;\n+        boolean eos = false;\n+        try (GZIPInputStream gzipInputStream = new GZIPInputStream(input.getInput(), min(GZIP_BUFFER_SIZE, input.length()))) {\n+            int n;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyMjI0Nw=="}, "originalCommit": null, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 431, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}