{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxNTQ3NDg5", "number": 3175, "title": "Optimize parquet gzip decompression", "bodyText": "Avoids creating an intermediate buffer (with the full uncompressedSize capacity) and copy from buffer to DynamicSliceOutput in parquet gzip decompression. Also avoids allocating the full 8k gzip input buffer size when the slice input is smaller. Finally, a validation check is added to verify the uncompressedSize was correct whereas previously the resulting slice would contain garbage data at the end (likely zeroed memory).", "createdAt": "2020-03-20T13:59:43Z", "url": "https://github.com/trinodb/trino/pull/3175", "merged": true, "mergeCommit": {"oid": "31b2ed6257cf2c6651c4b0626cc36434339a3893"}, "closed": true, "closedAt": "2020-03-20T18:09:11Z", "author": {"login": "pettyjamesm"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPigJhAFqTM3ODU5NDI4OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPjVOAABqjMxNTAwOTI3NjE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NTk0Mjg5", "url": "https://github.com/trinodb/trino/pull/3175#pullrequestreview-378594289", "createdAt": "2020-03-20T15:41:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0MToxNVrOF5Y-Bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTo0NDo1MVrOF5ZHSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyMjI0Nw==", "bodyText": "I'd rename this variable to read, and maybe the other one to totalBytesRead to have a clear separation.", "url": "https://github.com/trinodb/trino/pull/3175#discussion_r395722247", "createdAt": "2020-03-20T15:41:15Z", "author": {"login": "martint"}, "path": "presto-parquet/src/main/java/io/prestosql/parquet/ParquetCompressionUtils.java", "diffHunk": "@@ -89,15 +89,26 @@ private static Slice decompressGzip(Slice input, int uncompressedSize)\n             return EMPTY_SLICE;\n         }\n \n-        DynamicSliceOutput sliceOutput = new DynamicSliceOutput(uncompressedSize);\n         byte[] buffer = new byte[uncompressedSize];\n-        try (InputStream gzipInputStream = new GZIPInputStream(input.getInput(), GZIP_BUFFER_SIZE)) {\n-            int bytesRead;\n-            while ((bytesRead = gzipInputStream.read(buffer)) != -1) {\n-                sliceOutput.write(buffer, 0, bytesRead);\n+        int bytesRead = 0;\n+        boolean eos = false;\n+        try (GZIPInputStream gzipInputStream = new GZIPInputStream(input.getInput(), min(GZIP_BUFFER_SIZE, input.length()))) {\n+            int n;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyNDYxOA==", "bodyText": "Have you considered using Guava's ByteStreams.read() instead of rolling you own? (it may be tricky due to the error handling below, but worth considering)", "url": "https://github.com/trinodb/trino/pull/3175#discussion_r395724618", "createdAt": "2020-03-20T15:44:51Z", "author": {"login": "martint"}, "path": "presto-parquet/src/main/java/io/prestosql/parquet/ParquetCompressionUtils.java", "diffHunk": "@@ -89,15 +89,26 @@ private static Slice decompressGzip(Slice input, int uncompressedSize)\n             return EMPTY_SLICE;\n         }\n \n-        DynamicSliceOutput sliceOutput = new DynamicSliceOutput(uncompressedSize);\n         byte[] buffer = new byte[uncompressedSize];\n-        try (InputStream gzipInputStream = new GZIPInputStream(input.getInput(), GZIP_BUFFER_SIZE)) {\n-            int bytesRead;\n-            while ((bytesRead = gzipInputStream.read(buffer)) != -1) {\n-                sliceOutput.write(buffer, 0, bytesRead);\n+        int bytesRead = 0;\n+        boolean eos = false;\n+        try (GZIPInputStream gzipInputStream = new GZIPInputStream(input.getInput(), min(GZIP_BUFFER_SIZE, input.length()))) {\n+            int n;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyMjI0Nw=="}, "originalCommit": null, "originalPosition": 36}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NjIxNjI0", "url": "https://github.com/trinodb/trino/pull/3175#pullrequestreview-378621624", "createdAt": "2020-03-20T16:12:54Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8b431e8308dce0f19c62b3876b3fb26601cc8dc", "author": {"user": {"login": "pettyjamesm", "name": "James Petty"}}, "url": "https://github.com/trinodb/trino/commit/d8b431e8308dce0f19c62b3876b3fb26601cc8dc", "committedDate": "2020-03-20T16:44:42Z", "message": "Optimize parquet gzip decompression\n\nAvoids creating an intermediate buffer and copy from buffer to\nDynamicSliceOutput in parquet gzip decompression. Also avoids\nallocating the full 8k gzip input buffer size when the slice input\nis smaller. Finally, a validation check is added to verify the\nuncompressedSize is correct whereas previously the resulting slice\nwould contain garbage data at the end (likely zeroed memory)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d8b431e8308dce0f19c62b3876b3fb26601cc8dc", "author": {"user": {"login": "pettyjamesm", "name": "James Petty"}}, "url": "https://github.com/trinodb/trino/commit/d8b431e8308dce0f19c62b3876b3fb26601cc8dc", "committedDate": "2020-03-20T16:44:42Z", "message": "Optimize parquet gzip decompression\n\nAvoids creating an intermediate buffer and copy from buffer to\nDynamicSliceOutput in parquet gzip decompression. Also avoids\nallocating the full 8k gzip input buffer size when the slice input\nis smaller. Finally, a validation check is added to verify the\nuncompressedSize is correct whereas previously the resulting slice\nwould contain garbage data at the end (likely zeroed memory)."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1932, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}