{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM5MzU2NzE0", "number": 6333, "title": "Add streaming TopN rank() implementation", "bodyText": "", "createdAt": "2020-12-14T10:55:02Z", "url": "https://github.com/trinodb/trino/pull/6333", "merged": true, "mergeCommit": {"oid": "ade8af11027ce287df976a95137349ff49240365"}, "closed": true, "closedAt": "2021-01-05T12:39:50Z", "author": {"login": "erichwang"}, "timelineItems": {"totalCount": 38, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdmFEn8AFqTU1MTMyNzY2NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABds80aFgBqjQxNjY3MTU5NTA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUxMzI3NjY0", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-551327664", "createdAt": "2020-12-14T12:40:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMjo0MDo1NVrOIFOlVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMjo0MDo1NVrOIFOlVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM1MjcyNw==", "bodyText": "We should have equivalent of @LegacyConfig for session toggles.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r542352727", "createdAt": "2020-12-14T12:40:55Z", "author": {"login": "findepi"}, "path": "presto-main/src/main/java/io/prestosql/SystemSessionProperties.java", "diffHunk": "@@ -103,7 +103,7 @@\n     public static final String MAX_RECURSION_DEPTH = \"max_recursion_depth\";\n     public static final String USE_MARK_DISTINCT = \"use_mark_distinct\";\n     public static final String PREFER_PARTIAL_AGGREGATION = \"prefer_partial_aggregation\";\n-    public static final String OPTIMIZE_TOP_N_ROW_NUMBER = \"optimize_top_n_row_number\";\n+    public static final String OPTIMIZE_TOP_N_RANKING = \"optimize_top_n_ranking\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzODMyMjA2", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-553832206", "createdAt": "2020-12-16T15:57:52Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNTo1Nzo1MlrOIHMgEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNjowMTo0M1rOIHMsMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA==", "bodyText": "could that have negative performance impact? Currently on CPU cache miss just sequential data row needs to be loaded. With two arrays, that might mean one more RAM read and worse data locality", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544415760", "createdAt": "2020-12-16T15:57:52Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxODg2NQ==", "bodyText": "Can we just assume that (0, 0) are special keys? Why do we have to make it selective?\nIn what way HashStrategy can be more clever regarding to special keys? Does that introduce additional branching for CPU?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544418865", "createdAt": "2020-12-16T16:01:43Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -108,6 +109,13 @@\n      */\n     protected long defRetValue;\n \n+    /**\n+     * The two-part value denoting unmapped keys (or null keys). These values may be passed back via the HashStrategy callback\n+     * during equality checks, even though no keys with these values have been added.\n+     */\n+    protected final long nullKey1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzODk3MzQ5", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-553897349", "createdAt": "2020-12-16T17:02:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowMjo1N1rOIHPpvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzowNDo1MVrOIHPvMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzM5MQ==", "bodyText": "it's fine to use RankingType from TopNRankingNode. That should simplify imports", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467391", "createdAt": "2020-12-16T17:02:57Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "diffHunk": "@@ -42,9 +43,17 @@\n     public static class TopNRankingOperatorFactory\n             implements OperatorFactory\n     {\n+        public enum RankingType", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzUyOA==", "bodyText": "nit: separate commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467528", "createdAt": "2020-12-16T17:03:09Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRankingOperator.java", "diffHunk": "@@ -201,20 +215,29 @@ public TopNRankingOperator(\n                     expectedPositions,\n                     isDictionaryAggregationEnabled(operatorContext.getSession()),\n                     joinCompiler,\n-                     blockTypeOperators,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2NzgzMA==", "bodyText": "If there is just one RankingType, you could static import all of these", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544467830", "createdAt": "2020-12-16T17:03:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/LocalExecutionPlanner.java", "diffHunk": "@@ -924,6 +925,20 @@ public PhysicalOperation visitTopNRanking(TopNRankingNode node, LocalExecutionPl\n             return new PhysicalOperation(operatorFactory, makeLayout(node), context, source);\n         }\n \n+        private TopNRankingOperator.TopNRankingOperatorFactory.RankingType toOperatorRankingType(TopNRankingNode.RankingType rankingType)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODQ3OA==", "bodyText": "static import ROW_NUMBER", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468478", "createdAt": "2020-12-16T17:04:27Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/PlanNodeDecorrelator.java", "diffHunk": "@@ -322,6 +323,7 @@ public PlanNodeDecorrelator(Metadata metadata, SymbolAllocator symbolAllocator,\n                                 new Specification(\n                                         ImmutableList.copyOf(childDecorrelationResult.symbolsToPropagate),\n                                         Optional.of(orderingScheme)),\n+                                RankingType.ROW_NUMBER,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODU3Nw==", "bodyText": "static import ROW_NUMBER", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468577", "createdAt": "2020-12-16T17:04:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "diffHunk": "@@ -143,6 +144,7 @@ public Result apply(FilterNode filter, Captures captures, Context context)\n                 window.getId(),\n                 window.getSource(),\n                 window.getSpecification(),\n+                RankingType.ROW_NUMBER,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ2ODc4Ng==", "bodyText": "static import (here and other places)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r544468786", "createdAt": "2020-12-16T17:04:51Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -157,7 +158,7 @@ else if (source instanceof WindowNode && canOptimizeWindowFunction((WindowNode)\n                 WindowNode windowNode = (WindowNode) source;\n                 // verify that unordered row_number window functions are replaced by RowNumberNode\n                 verify(windowNode.getOrderingScheme().isPresent());\n-                TopNRankingNode topNRankingNode = convertToTopNRanking(windowNode, limit);\n+                TopNRankingNode topNRankingNode = convertToTopNRanking(windowNode, RankingType.ROW_NUMBER, limit);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NTU2MzQ1", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-555556345", "createdAt": "2020-12-18T14:50:14Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDo1MDoxNVrOIIl6Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToxOTo0M1rOIInTEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg4MDYxOA==", "bodyText": "Could you describe what does key1 and key2 store?\nIt seems that when guard value collide with actual values it might lead to some odd issues. How did it work when when (0, 0) was both guard and real value?\nIn join (io.prestosql.operator.PagesHash) we use double level addressing (with compact hash io.prestosql.operator.PagesHash#positionToHashes for performance). IIRC flattening join hash did not help performance. Maybe we should have something similar here?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545880618", "createdAt": "2020-12-18T14:50:15Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -64,7 +64,8 @@\n     /**\n      * The array of keys.\n      */\n-    protected LongBigArray key;\n+    protected LongBigArray key1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQxNTc2MA=="}, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5MzU5OA==", "bodyText": "Is this a hash map? Do we need to initialize every position to -1. Do we expect positions to be \"freed\"?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545893598", "createdAt": "2020-12-18T15:03:24Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 624}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NDg1Nw==", "bodyText": "We could consider int here. Do we expect queries to actually limit rank/row number above 2^32? This could save a lot of mem.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545894857", "createdAt": "2020-12-18T15:05:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 628}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5NTkwNw==", "bodyText": "Could we observe N and then N+10 and then N+5?\nnit: static import max", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545895907", "createdAt": "2020-12-18T15:07:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 640}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg5OTE2MQ==", "bodyText": "Should heapIndexBuffer and metricsBuffer be merged together? Do we expect these to be used independently? If they are part of same array, then we could save on memory access from CPU", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545899161", "createdAt": "2020-12-18T15:12:35Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 623}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwMjYzOA==", "bodyText": "Could you extract constants like 4 as a static final variables, e.g:\nPOSITIONS_PER_ENTRY", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545902638", "createdAt": "2020-12-18T15:18:21Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 739}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwMzM3OA==", "bodyText": "ditto. You could also extract PEER_GROUP_COUNT_OFFSET, LEFT_CHILD_HEAP_INDEX_OFFSET", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545903378", "createdAt": "2020-12-18T15:19:43Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);\n+            }\n+\n+            setPeerGroupIndex(newHeapIndex, peerGroupIndex);\n+            setPeerGroupCount(newHeapIndex, peerGroupCount);\n+            setLeftChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+            setRightChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+\n+            return newHeapIndex;\n+        }\n+\n+        public void deallocate(long index)\n+        {\n+            emptySlots.enqueue(index);\n+        }\n+\n+        public long getActiveNodeCount()\n+        {\n+            return capacity - emptySlots.longSize();\n+        }\n+\n+        public long getPeerGroupIndex(long index)\n+        {\n+            return buffer.get(index * 4);\n+        }\n+\n+        public void setPeerGroupIndex(long index, long peerGroupIndex)\n+        {\n+            buffer.set(index * 4, peerGroupIndex);\n+        }\n+\n+        public long getPeerGroupCount(long index)\n+        {\n+            return buffer.get(index * 4 + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 772}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NTg1NjY1", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-555585665", "createdAt": "2020-12-18T15:26:18Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToyNjoxOFrOIInkmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNToyNjoxOFrOIInkmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTkwNzg2Nw==", "bodyText": "Extract:\nprivate static final int POSITIONS_PER_ENTRY=2\n\n?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r545907867", "createdAt": "2020-12-18T15:26:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,\n+                leftIntegrityStats.getPeerGroupCount() + rightIntegrityStats.getPeerGroupCount() + 1,\n+                leftIntegrityStats.getValueCount() + rightIntegrityStats.getValueCount() + peerGroupCount);\n+    }\n+\n+    private static class IntegrityStats\n+    {\n+        private final long maxDepth;\n+        private final long peerGroupCount;\n+        private final long valueCount;\n+\n+        public IntegrityStats(long maxDepth, long peerGroupCount, long valueCount)\n+        {\n+            this.maxDepth = maxDepth;\n+            this.peerGroupCount = peerGroupCount;\n+            this.valueCount = valueCount;\n+        }\n+\n+        public long getMaxDepth()\n+        {\n+            return maxDepth;\n+        }\n+\n+        public long getPeerGroupCount()\n+        {\n+            return peerGroupCount;\n+        }\n+\n+        public long getValueCount()\n+        {\n+            return valueCount;\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex1,\n+         *  [LONG] heapNodeIndex2,\n+         *  ...\n+         */\n+        // Since we have a single element per group, this array is effectively indexed on group ID\n+        private final LongBigArray heapIndexBuffer = new LongBigArray(UNKNOWN_INDEX);\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] valueCount1, [LONG] heapSize1,\n+         *  [LONG] valueCount2, [LONG] heapSize2,\n+         *  ...\n+         */\n+        private final LongBigArray metricsBuffer = new LongBigArray(0);\n+\n+        private long totalGroups;\n+\n+        public void allocateGroupIfNeeded(long groupId)\n+        {\n+            // Group IDs generated by GroupByHash are always generated consecutively starting from 0, so observing a\n+            // group ID N means groups [0, N] inclusive must exist.\n+            totalGroups = Math.max(groupId + 1, totalGroups);\n+            heapIndexBuffer.ensureCapacity(totalGroups);\n+            metricsBuffer.ensureCapacity(totalGroups * 2);\n+        }\n+\n+        public long getTotalGroups()\n+        {\n+            return totalGroups;\n+        }\n+\n+        public long getHeapRootNodeIndex(long groupId)\n+        {\n+            return heapIndexBuffer.get(groupId);\n+        }\n+\n+        public void setHeapRootNodeIndex(long groupId, long heapNodeIndex)\n+        {\n+            heapIndexBuffer.set(groupId, heapNodeIndex);\n+        }\n+\n+        public long getHeapValueCount(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2);\n+        }\n+\n+        public void setHeapValueCount(long groupId, long count)\n+        {\n+            metricsBuffer.set(groupId * 2, count);\n+        }\n+\n+        public void addHeapValueCount(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2, delta);\n+        }\n+\n+        public void incrementHeapValueCount(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2);\n+        }\n+\n+        public long getHeapSize(long groupId)\n+        {\n+            return metricsBuffer.get(groupId * 2 + 1);\n+        }\n+\n+        public void setHeapSize(long groupId, long size)\n+        {\n+            metricsBuffer.set(groupId * 2 + 1, size);\n+        }\n+\n+        public void addHeapSize(long groupId, long delta)\n+        {\n+            metricsBuffer.add(groupId * 2 + 1, delta);\n+        }\n+\n+        public void incrementHeapSize(long groupId)\n+        {\n+            metricsBuffer.increment(groupId * 2 + 1);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + heapIndexBuffer.sizeOf() + metricsBuffer.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of nodes in the heap. Nodes are referenced by their node index for operations.\n+     */\n+    private static class HeapNodeBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(HeapNodeBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] peerGroupIndex1, [LONG] peerGroupCount1, [LONG] leftChildNodeIndex1, [LONG] rightChildNodeIndex1,\n+         *  [LONG] peerGroupIndex2, [LONG] peerGroupCount2, [LONG] leftChildNodeIndex2, [LONG] rightChildNodeIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new heap node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long peerGroupIndex, long peerGroupCount)\n+        {\n+            long newHeapIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newHeapIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newHeapIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 4);\n+            }\n+\n+            setPeerGroupIndex(newHeapIndex, peerGroupIndex);\n+            setPeerGroupCount(newHeapIndex, peerGroupCount);\n+            setLeftChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+            setRightChildHeapIndex(newHeapIndex, UNKNOWN_INDEX);\n+\n+            return newHeapIndex;\n+        }\n+\n+        public void deallocate(long index)\n+        {\n+            emptySlots.enqueue(index);\n+        }\n+\n+        public long getActiveNodeCount()\n+        {\n+            return capacity - emptySlots.longSize();\n+        }\n+\n+        public long getPeerGroupIndex(long index)\n+        {\n+            return buffer.get(index * 4);\n+        }\n+\n+        public void setPeerGroupIndex(long index, long peerGroupIndex)\n+        {\n+            buffer.set(index * 4, peerGroupIndex);\n+        }\n+\n+        public long getPeerGroupCount(long index)\n+        {\n+            return buffer.get(index * 4 + 1);\n+        }\n+\n+        public void setPeerGroupCount(long index, long peerGroupCount)\n+        {\n+            buffer.set(index * 4 + 1, peerGroupCount);\n+        }\n+\n+        public void incrementPeerGroupCount(long index)\n+        {\n+            buffer.increment(index * 4 + 1);\n+        }\n+\n+        public void addPeerGroupCount(long index, long delta)\n+        {\n+            buffer.add(index * 4 + 1, delta);\n+        }\n+\n+        public long getLeftChildHeapIndex(long index)\n+        {\n+            return buffer.get(index * 4 + 2);\n+        }\n+\n+        public void setLeftChildHeapIndex(long index, long childHeapIndex)\n+        {\n+            buffer.set(index * 4 + 2, childHeapIndex);\n+        }\n+\n+        public long getRightChildHeapIndex(long index)\n+        {\n+            return buffer.get(index * 4 + 3);\n+        }\n+\n+        public void setRightChildHeapIndex(long index, long childHeapIndex)\n+        {\n+            buffer.set(index * 4 + 3, childHeapIndex);\n+        }\n+\n+        public long sizeOf()\n+        {\n+            return INSTANCE_SIZE + buffer.sizeOf() + emptySlots.sizeOf();\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting storage of peer groups as linked chains of matching values. Peer groups are referenced by\n+     * their node index for operations.\n+     */\n+    private static class PeerGroupBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(PeerGroupBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] rowId1, [LONG] nextPeerIndex1,\n+         *  [LONG] rowId2, [LONG] nextPeerIndex2,\n+         *  ...\n+         */\n+        private final LongBigArray buffer = new LongBigArray();\n+\n+        private final LongBigArrayFIFOQueue emptySlots = new LongBigArrayFIFOQueue();\n+\n+        private long capacity;\n+\n+        /**\n+         * Allocates storage for a new peer group node.\n+         *\n+         * @return index referencing the node\n+         */\n+        public long allocateNewNode(long rowId, long nextPeerIndex)\n+        {\n+            long newPeerIndex;\n+            if (!emptySlots.isEmpty()) {\n+                newPeerIndex = emptySlots.dequeueLong();\n+            }\n+            else {\n+                newPeerIndex = capacity;\n+                capacity++;\n+                buffer.ensureCapacity(capacity * 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 850}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1ODMxNDMx", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-555831431", "createdAt": "2020-12-18T21:43:17Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMTo0MzoxN1rOIIzmJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQyMjowNDoyOFrOII0D7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNDg2OA==", "bodyText": "some comment what it represents exactly would be great", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546104868", "createdAt": "2020-12-18T21:43:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNjU4Ng==", "bodyText": "What exactly is rowId? Is it address as in PagesIndex?\nWhy nullRowId needs to be parametrized? Can it be some special constant?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546106586", "createdAt": "2020-12-18T21:48:07Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNjcxMw==", "bodyText": "nit: each arg in newline", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546106713", "createdAt": "2020-12-18T21:48:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNzAyMw==", "bodyText": "nit: 0 also doesn't make sense, but it's detail", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546107023", "createdAt": "2020-12-18T21:49:19Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEwNzMwMw==", "bodyText": "Can that be part of constructor? I see that Long2LongOpenCustomHashMap doesn't have such method", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546107303", "createdAt": "2020-12-18T21:50:09Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExMDYyMA==", "bodyText": "move method below usage", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546110620", "createdAt": "2020-12-18T21:59:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExMjQ5NA==", "bodyText": "move private methods below public", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546112494", "createdAt": "2020-12-18T22:04:28Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 182}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NjgzMzU2", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-556683356", "createdAt": "2020-12-21T21:44:09Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMTo0NDoxMFrOIJm2vA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMTo0NDoxMFrOIJm2vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk0NDcwMA==", "bodyText": "add some comment why it has to be false", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r546944700", "createdAt": "2020-12-21T21:44:10Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 178}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODQ2OTIz", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-557846923", "createdAt": "2020-12-23T12:46:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMjo0Njo0NlrOIKjvdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDo1Mjo1NVrOIKnBTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0MjI2MQ==", "bodyText": "Can we assume nullRowId to be -1 for simplicity? It seems to be inline with RowReferencePageManager", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547942261", "createdAt": "2020-12-23T12:46:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0Mzg4OA==", "bodyText": "you could inline peerGroupBuffer.getRowId(peerGroupIndex)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547943888", "createdAt": "2020-12-23T12:51:13Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk0OTE5Ng==", "bodyText": "this is neat idea!", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547949196", "createdAt": "2020-12-23T13:04:51Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 318}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1MDkzMA==", "bodyText": "I think it would be simpler if you handled that explicitly at the beginning of the method:\nlong heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\nif (heapSize == 1) {\n  // last insertion leaf was the root node\n  ...\n  return heapRootNodeIndex;\n}\n\nthen the code here would simplify:\nsetChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\ngroupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\ngroupIdToHeapBuffer.addHeapSize(groupId, -1);\nreturn currentNodeIndex;", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547950930", "createdAt": "2020-12-23T13:09:25Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1OTk4NA==", "bodyText": "Once this condition is true it will stay being true until end of traversal. You could save some potentially expensive comparisons by setting some:\nrowSwapped = true\n\nand changing this if to:\nif (rowSwapped || rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n ...\n}", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547959984", "createdAt": "2020-12-23T13:31:45Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 389}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk2Mjc1OQ==", "bodyText": "nit: heapInsert is always called with newPeerGroupCount=1", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547962759", "createdAt": "2020-12-23T13:38:13Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4Njk2MQ==", "bodyText": "static import abs", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547986961", "createdAt": "2020-12-23T14:33:05Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 573}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4Nzc3Nw==", "bodyText": "static import max", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547987777", "createdAt": "2020-12-23T14:34:55Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, 0);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapValueCount(groupId, -heapNodeBuffer.getPeerGroupCount(currentNodeIndex));\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     */\n+    private void heapInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount)\n+    {\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+            verify(peerGroupLookup.put(groupId, newCanonicalRowId, heapRootNodeIndex) == UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapValueCount(groupId, newPeerGroupCount);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount);\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId));\n+        while (!heapTraversal.isTarget()) {\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(currentHeapNodeIndex);\n+            long currentCanonicalRowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, currentCanonicalRowId) > 0) {\n+                long peerGroupCount = heapNodeBuffer.getPeerGroupCount(currentHeapNodeIndex);\n+\n+                // Swap the peer groups\n+                heapNodeBuffer.setPeerGroupIndex(currentHeapNodeIndex, newPeerGroupIndex);\n+                heapNodeBuffer.setPeerGroupCount(currentHeapNodeIndex, newPeerGroupCount);\n+                peerGroupLookup.put(groupId, newCanonicalRowId, currentHeapNodeIndex);\n+\n+                newPeerGroupIndex = peerGroupIndex;\n+                newPeerGroupCount = peerGroupCount;\n+                newCanonicalRowId = currentCanonicalRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newPeerGroupIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, newHeapNodeIndex);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Pop the root off the group ID's max heap and insert the new peer group.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newPeerGroupIndex, long newPeerGroupCount, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for the new peer group\n+        groupIdToHeapBuffer.addHeapValueCount(groupId, newPeerGroupCount - heapNodeBuffer.getPeerGroupCount(heapRootNodeIndex));\n+        dropHeapNodePeerGroup(groupId, heapRootNodeIndex, contextEvictionListener);\n+\n+        long newCanonicalRowId = peerGroupBuffer.getRowId(newPeerGroupIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(maxChildNodeIndex);\n+            long maxChildCanonicalRowId = peerGroupBuffer.getRowId(maxChildPeerGroupIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightChildPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(rightChildNodeIndex);\n+                long rightChildCanonicalRowId = peerGroupBuffer.getRowId(rightChildPeerGroupIndex);\n+                if (rowComparisonStrategy.compare(rightChildCanonicalRowId, maxChildCanonicalRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildPeerGroupIndex = rightChildPeerGroupIndex;\n+                    maxChildCanonicalRowId = rightChildCanonicalRowId;\n+                }\n+            }\n+\n+            if (rowComparisonStrategy.compare(newCanonicalRowId, maxChildCanonicalRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, maxChildPeerGroupIndex);\n+            heapNodeBuffer.setPeerGroupCount(currentNodeIndex, heapNodeBuffer.getPeerGroupCount(maxChildNodeIndex));\n+            peerGroupLookup.put(groupId, maxChildCanonicalRowId, currentNodeIndex);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setPeerGroupIndex(currentNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupCount(currentNodeIndex, newPeerGroupCount);\n+        peerGroupLookup.put(groupId, newCanonicalRowId, currentNodeIndex);\n+    }\n+\n+    /**\n+     * Deallocates all peer group associations for this heap node, leaving a structural husk with no contents. Assumes\n+     * that any required group level metric changes are handled externally.\n+     */\n+    private void dropHeapNodePeerGroup(long groupId, long heapNodeIndex, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        checkState(peerGroupIndex != UNKNOWN_INDEX, \"Heap node must have at least one peer group\");\n+\n+        long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+        long nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        peerGroupBuffer.deallocate(peerGroupIndex);\n+        verify(peerGroupLookup.remove(groupId, rowId) == heapNodeIndex);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(rowId);\n+        }\n+\n+        peerGroupIndex = nextPeerIndex;\n+\n+        while (peerGroupIndex != UNKNOWN_INDEX) {\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            nextPeerIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            peerGroupBuffer.deallocate(peerGroupIndex);\n+\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(rowId);\n+            }\n+\n+            peerGroupIndex = nextPeerIndex;\n+        }\n+    }\n+\n+    /**\n+     * Sanity check the invariants of the underlying data structure.\n+     */\n+    @VisibleForTesting\n+    void verifyIntegrity()\n+    {\n+        long totalHeapNodes = 0;\n+        long totalValueCount = 0;\n+        for (long groupId = 0; groupId < groupIdToHeapBuffer.getTotalGroups(); groupId++) {\n+            long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+            long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+            long rootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(rootNodeIndex == UNKNOWN_INDEX || calculateRootRank(rootNodeIndex) <= topN, \"Max heap has more values than needed\");\n+            IntegrityStats integrityStats = verifyHeapIntegrity(groupId, rootNodeIndex);\n+            verify(integrityStats.getPeerGroupCount() == heapSize, \"Recorded heap size does not match actual heap size\");\n+            totalHeapNodes += integrityStats.getPeerGroupCount();\n+            verify(integrityStats.getValueCount() == heapValueCount, \"Recorded value count does not match actual value count\");\n+            totalValueCount += integrityStats.getValueCount();\n+        }\n+        verify(totalHeapNodes == heapNodeBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+        verify(totalHeapNodes == peerGroupLookup.size(), \"Peer group lookup does not have the right number of entries\");\n+        verify(totalValueCount == peerGroupBuffer.getActiveNodeCount(), \"Failed to deallocate some unused nodes\");\n+    }\n+\n+    private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n+    {\n+        if (heapNodeIndex == UNKNOWN_INDEX) {\n+            return new IntegrityStats(0, 0, 0);\n+        }\n+        long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long peerGroupCount = heapNodeBuffer.getPeerGroupCount(heapNodeIndex);\n+        long leftChildHeapIndex = heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex);\n+        long rightChildHeapIndex = heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+\n+        long actualPeerGroupCount = 0;\n+        long previousRowId;\n+        long rowId = -1; // Arbitrary initial value that will be overwritten\n+        do {\n+            previousRowId = rowId;\n+            rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+            actualPeerGroupCount++;\n+            if (actualPeerGroupCount >= 2) {\n+                verify(rowComparisonStrategy.equals(rowId, previousRowId), \"Row value does not belong in peer group\");\n+            }\n+            verify(peerGroupLookup.get(groupId, rowId) == heapNodeIndex, \"Mismatch between peer group and lookup mapping\");\n+\n+            peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+        }\n+        while (peerGroupIndex != UNKNOWN_INDEX);\n+        verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");\n+\n+        if (leftChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(leftChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+        if (rightChildHeapIndex != UNKNOWN_INDEX) {\n+            verify(leftChildHeapIndex != UNKNOWN_INDEX, \"Left should always be inserted before right\");\n+            verify(rowComparisonStrategy.compare(rowId, peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(rightChildHeapIndex))) > 0, \"Max heap invariant violated\");\n+        }\n+\n+        IntegrityStats leftIntegrityStats = verifyHeapIntegrity(groupId, leftChildHeapIndex);\n+        IntegrityStats rightIntegrityStats = verifyHeapIntegrity(groupId, rightChildHeapIndex);\n+\n+        verify(Math.abs(leftIntegrityStats.getMaxDepth() - rightIntegrityStats.getMaxDepth()) <= 1, \"Heap not balanced\");\n+\n+        return new IntegrityStats(\n+                Math.max(leftIntegrityStats.getMaxDepth(), rightIntegrityStats.getMaxDepth()) + 1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 576}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5Mjg3NQ==", "bodyText": "use dataProvider instead, e.g:\n    @DataProvider(name = \"parameters\")\n    public static Object[][] parameters()\n    {\n        List<Integer> topNs = Arrays.asList(1, 2, 3);\n        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n        List<Object[]> parameters = new ArrayList();\n        for (int topN : topNs) {\n            for (int valueCount : valueCounts) {\n                for (int groupCount : groupCounts) {\n                    for (boolean drainWithRanking : drainWithRankings) {\n                         parameters.add(new Object[] {topN, valueCount, groupCount, drainWithRanking});\n                    }\n                }\n            }\n        }\n       return parameters.toArray(new Object[0][]);\n    }\n\nand then in test:\n    @Test(dataProvider = \"parameters\")\n    public void testSinglePeerGroupInsert(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n    {\n      ....\n    }", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547992875", "createdAt": "2020-12-23T14:46:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRankAccumulator.RowComparisonStrategy;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertNotEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankAccumulator\n+{\n+    private static final long NULL_ROW_ID = Long.MIN_VALUE;\n+    private static final RowComparisonStrategy ROW_COMPARISON_STRATEGY = new RowComparisonStrategy()\n+    {\n+        @Override\n+        public int compare(long leftRowId, long rightRowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(leftRowId, NULL_ROW_ID);\n+            assertNotEquals(rightRowId, NULL_ROW_ID);\n+            return Long.compare(leftRowId, rightRowId);\n+        }\n+\n+        @Override\n+        public long hashCode(long rowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(rowId, NULL_ROW_ID);\n+            return rowId;\n+        }\n+    };\n+\n+    @Test\n+    public void testSinglePeerGroupInsert()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5NTk4MQ==", "bodyText": "extract from the loop", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547995981", "createdAt": "2020-12-23T14:52:55Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRankAccumulator.RowComparisonStrategy;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertNotEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankAccumulator\n+{\n+    private static final long NULL_ROW_ID = Long.MIN_VALUE;\n+    private static final RowComparisonStrategy ROW_COMPARISON_STRATEGY = new RowComparisonStrategy()\n+    {\n+        @Override\n+        public int compare(long leftRowId, long rightRowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(leftRowId, NULL_ROW_ID);\n+            assertNotEquals(rightRowId, NULL_ROW_ID);\n+            return Long.compare(leftRowId, rightRowId);\n+        }\n+\n+        @Override\n+        public long hashCode(long rowId)\n+        {\n+            // Null rowIds should never be observed\n+            assertNotEquals(rowId, NULL_ROW_ID);\n+            return rowId;\n+        }\n+    };\n+\n+    @Test\n+    public void testSinglePeerGroupInsert()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);\n+        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n+        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n+        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n+\n+        for (int topN : topNs) {\n+            for (int valueCount : valueCounts) {\n+                for (int groupCount : groupCounts) {\n+                    for (boolean drainWithRanking : drainWithRankings) {\n+                        assertSinglePeerGroupInsert(topN, valueCount, groupCount, drainWithRanking);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void assertSinglePeerGroupInsert(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n+    {\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRankAccumulator accumulator = new GroupedTopNRankAccumulator(ROW_COMPARISON_STRATEGY, NULL_ROW_ID, topN, evicted::add);\n+        accumulator.verifyIntegrity();\n+\n+        // Add the same value repeatedly, so everything should be accepted, and all results will have a rank of 1\n+        int rowId = -1;\n+\n+        for (int i = 0; i < valueCount; i++) {\n+            for (int groupId = 0; groupId < groupCount; groupId++) {\n+                assertTrue(accumulator.add(groupId, rowId));\n+                accumulator.verifyIntegrity();\n+\n+                // No evictions because rank does not change for the same input\n+                assertTrue(evicted.isEmpty());\n+            }\n+        }\n+\n+        for (int groupId = 0; groupId < groupCount; groupId++) {\n+            LongBigArray rowIdOutput = new LongBigArray();\n+            LongBigArray rankingOutput = new LongBigArray();\n+            if (drainWithRanking) {\n+                assertEquals(accumulator.drainTo(groupId, rowIdOutput, rankingOutput), valueCount);\n+            }\n+            else {\n+                assertEquals(accumulator.drainTo(groupId, rowIdOutput), valueCount);\n+            }\n+            accumulator.verifyIntegrity();\n+\n+            for (int i = 0; i < valueCount; i++) {\n+                assertEquals(rowIdOutput.get(i), rowId);\n+                if (drainWithRanking) {\n+                    // Everything should have a rank of 1\n+                    assertEquals(rankingOutput.get(i), 1);\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testIncreasingAllUniqueValues()\n+    {\n+        List<Integer> topNs = Arrays.asList(1, 2, 3);\n+        List<Integer> valueCounts = Arrays.asList(0, 1, 2, 4, 8);\n+        List<Integer> groupCounts = Arrays.asList(1, 2, 3);\n+        List<Boolean> drainWithRankings = Arrays.asList(true, false);\n+\n+        for (int topN : topNs) {\n+            for (int valueCount : valueCounts) {\n+                for (int groupCount : groupCounts) {\n+                    for (boolean drainWithRanking : drainWithRankings) {\n+                        assertIncreasingAllUniqueValues(topN, valueCount, groupCount, drainWithRanking);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void assertIncreasingAllUniqueValues(int topN, long valueCount, long groupCount, boolean drainWithRanking)\n+    {\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRankAccumulator accumulator = new GroupedTopNRankAccumulator(ROW_COMPARISON_STRATEGY, NULL_ROW_ID, topN, evicted::add);\n+        accumulator.verifyIntegrity();\n+\n+        for (int rowId = 0; rowId < valueCount; rowId++) {\n+            for (int groupId = 0; groupId < groupCount; groupId++) {\n+                // Since rowIds are in increasing order, only the first topN will be accepted\n+                assertEquals(accumulator.add(groupId, rowId), rowId < topN);\n+                accumulator.verifyIntegrity();\n+\n+                // No evictions because all results should be rejected at add()\n+                assertTrue(evicted.isEmpty());\n+            }\n+        }\n+\n+        for (int groupId = 0; groupId < groupCount; groupId++) {\n+            LongBigArray rowIdOutput = new LongBigArray();\n+            LongBigArray rankingOutput = new LongBigArray();\n+            long expectedResultCount = Math.min(valueCount, topN);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3OTI4Njc0", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-557928674", "createdAt": "2020-12-23T15:00:16Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTowMDoxNlrOIKnPsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTozNDowMFrOIKoNyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk5OTY2NA==", "bodyText": "Do we need this method at all since we have compare? That would simplify it.\nIs compare consistent with equals regarding nulls? I believe it's consistent regarding NaN, but please double check.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r547999664", "createdAt": "2020-12-23T15:00:16Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDI2Nw==", "bodyText": "Could we limit scope of this interface to just PagesWithPositionHash? PageWithPositionComparator already deals with equality", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548000267", "createdAt": "2020-12-23T15:01:26Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/PageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+\n+/**\n+ * Equals and hash evaluated at the specified page positions. Implementations need to be hash table friendly.\n+ *\n+ * Note: this usage is likely to be megamorphic, so use at your own risk!\n+ */\n+public interface PageWithPositionEqualsAndHash", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMDc1Ng==", "bodyText": "static import, but I would just assume -1 is the special value. I don't expect GroupedTopNRankAccumulator to be used in any other context.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548000756", "createdAt": "2020-12-23T15:02:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public boolean equals(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return equalsAndHash.equals(leftPage, leftPosition, rightPage, rightPosition);\n+                    }\n+\n+                    @Override\n+                    public long hashCode(long rowId)\n+                    {\n+                        Page page = pageManager.getPage(rowId);\n+                        int position = pageManager.getPosition(rowId);\n+                        return equalsAndHash.hashCode(page, position);\n+                    }\n                 },\n+                RowReferencePageManager.RESERVED_UNUSED_ROW_ID,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwMjU2NQ==", "bodyText": "Is it possible to optimize this loop to avoid allocation of row id?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548002565", "createdAt": "2020-12-23T15:06:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -93,56 +120,41 @@ public long getEstimatedSizeInBytes()\n         return INSTANCE_SIZE\n                 + groupByHash.getEstimatedSize()\n                 + pageManager.sizeOf()\n-                + groupedTopNRowNumberAccumulator.sizeOf();\n+                + groupedTopNRankAccumulator.sizeOf();\n     }\n \n     private void processPage(Page newPage, GroupByIdBlock groupIds)\n     {\n         try (LoadCursor loadCursor = pageManager.add(newPage)) {\n-            GroupedTopNRowNumberAccumulator.RowReference rowReferenceView = asRowReferenceView(loadCursor);\n             for (int position = 0; position < newPage.getPositionCount(); position++) {\n                 long groupId = groupIds.getGroupId(position);\n                 loadCursor.advance();\n-                groupedTopNRowNumberAccumulator.add(groupId, rowReferenceView);\n+                long rowId = loadCursor.allocateRowId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDI0MQ==", "bodyText": "Double.NaN are also not distinct from each other. Did you check standard how rank() function should be implemented? Or is it DB implementation detail?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548004241", "createdAt": "2020-12-23T15:09:45Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDc1Mw==", "bodyText": "Make sure you test peer groups with nulls and NaN", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548004753", "createdAt": "2020-12-23T15:10:53Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNjU0NA==", "bodyText": "this can be compiled (io.prestosql.sql.gen.OrderingCompiler#internalCompilePageWithPositionComparator), so maybe equals should default to compare?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548006544", "createdAt": "2020-12-23T15:14:52Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankBuilder.java", "diffHunk": "@@ -32,40 +32,67 @@\n import static java.util.Objects.requireNonNull;\n \n /**\n- * This class finds the top N rows defined by {@param comparator} for each group specified by {@param groupByHash}.\n+ * This class finds the top N rows by rank value defined by {@param comparator} and {@param equalsAndHash} for each\n+ * group specified by {@param groupByHash}.\n  */\n public class GroupedTopNRankBuilder\n         implements GroupedTopNBuilder\n {\n     private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankBuilder.class).instanceSize();\n \n     private final List<Type> sourceTypes;\n-    private final boolean produceRowNumber;\n+    private final boolean produceRanking;\n     private final GroupByHash groupByHash;\n     private final RowReferencePageManager pageManager = new RowReferencePageManager();\n-    private final GroupedTopNRowNumberAccumulator groupedTopNRowNumberAccumulator;\n+    private final GroupedTopNRankAccumulator groupedTopNRankAccumulator;\n \n     public GroupedTopNRankBuilder(\n             List<Type> sourceTypes,\n             PageWithPositionComparator comparator,\n+            PageWithPositionEqualsAndHash equalsAndHash,\n             int topN,\n-            boolean produceRowNumber,\n+            boolean produceRanking,\n             GroupByHash groupByHash)\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.produceRowNumber = produceRowNumber;\n+        this.produceRanking = produceRanking;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n-                (leftRowId, rightRowId) -> {\n-                    Page leftPage = pageManager.getPage(leftRowId);\n-                    int leftPosition = pageManager.getPosition(leftRowId);\n-                    Page rightPage = pageManager.getPage(rightRowId);\n-                    int rightPosition = pageManager.getPosition(rightRowId);\n-                    return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);\n+        requireNonNull(equalsAndHash, \"equalsAndHash is null\");\n+        groupedTopNRankAccumulator = new GroupedTopNRankAccumulator(\n+                new RowComparisonStrategy()\n+                {\n+                    @Override\n+                    public int compare(long leftRowId, long rightRowId)\n+                    {\n+                        Page leftPage = pageManager.getPage(leftRowId);\n+                        int leftPosition = pageManager.getPosition(leftRowId);\n+                        Page rightPage = pageManager.getPage(rightRowId);\n+                        int rightPosition = pageManager.getPosition(rightRowId);\n+                        return comparator.compareTo(leftPage, leftPosition, rightPage, rightPosition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxMTUxNQ==", "bodyText": "Could you extract this into separate method, e.g:\nvoid assertAccumulatorOutput(GroupedTopNBuilder builder, boolean produceRanking, Page result) {\n   ...\n}\n\nThen you could use it:\nassertAccumulatorOutput(\n  groupedTopNBuilder,\n  produceRankings,\n  rowPageBuilder(types)\n   .row(0L, 0.1)\n   .row(1L, 0.2)\n   .row(0L, 0.3)\n   .row(0L, 0.2)\n   .row(1L, 0.5)\n   .row(1L, 0.4)\n   .row(1L, 0.3)\n   .row(1L, 0.3)\n   .build())", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548011515", "createdAt": "2020-12-23T15:25:16Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder\n+{\n+    private TypeOperators typeOperators;\n+    private BlockTypeOperators blockTypeOperators;\n+\n+    @BeforeMethod\n+    public void setUp()\n+    {\n+        typeOperators = new TypeOperators();\n+        blockTypeOperators = new BlockTypeOperators(typeOperators);\n+    }\n+\n+    @DataProvider\n+    public static Object[][] produceRanking()\n+    {\n+        return new Object[][] {{true}, {false}};\n+    }\n+\n+    @Test\n+    public void testEmptyInput()\n+    {\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                ImmutableList.of(BIGINT),\n+                (left, leftPosition, right, rightPosition) -> {\n+                    throw new UnsupportedOperationException();\n+                },\n+                new PageWithPositionEqualsAndHash()\n+                {\n+                    @Override\n+                    public boolean equals(Page left, int leftPosition, Page right, int rightPosition)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+\n+                    @Override\n+                    public long hashCode(Page page, int position)\n+                    {\n+                        throw new UnsupportedOperationException();\n+                    }\n+                },\n+                5,\n+                false,\n+                new NoChannelGroupByHash());\n+        assertFalse(groupedTopNBuilder.buildResult().hasNext());\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testSingleGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(DOUBLE);\n+\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(0), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(0), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                new NoChannelGroupByHash());\n+\n+        // Expected effect: [0.2 x 1 => rank=1, 0.3 x 2 => rank=2]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.3)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because single value 0.4 is too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.4)\n+                        .build()).process());\n+\n+        // Next page should cause 0.3 values to be evicted (first page will be compacted)\n+        // Expected effect: [0.1 x 2 => rank 1, 0.2 x 3 => rank 3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0.1)\n+                        .row(0.2)\n+                        .row(0.3)\n+                        .row(0.2)\n+                        .row(0.1)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {\n+            Page expected = rowPageBuilder(DOUBLE, BIGINT)\n+                    .row(0.1, 1)\n+                    .row(0.1, 1)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .row(0.2, 3)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE, BIGINT), getOnlyElement(output), expected);\n+        }\n+        else {\n+            Page expected = rowPageBuilder(DOUBLE)\n+                    .row(0.1)\n+                    .row(0.1)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .row(0.2)\n+                    .build();\n+            assertPageEquals(ImmutableList.of(DOUBLE), getOnlyElement(output), expected);\n+        }\n+    }\n+\n+    @Test(dataProvider = \"produceRanking\")\n+    public void testMultiGroupTopN(boolean produceRanking)\n+    {\n+        List<Type> types = ImmutableList.of(BIGINT, DOUBLE);\n+\n+        GroupByHash groupByHash = createGroupByHash(ImmutableList.of(types.get(0)), ImmutableList.of(0), NOOP);\n+        GroupedTopNBuilder groupedTopNBuilder = new GroupedTopNRankBuilder(\n+                types,\n+                new SimplePageWithPositionComparator(types, ImmutableList.of(1), ImmutableList.of(ASC_NULLS_LAST), typeOperators),\n+                new SimplePageWithPositionEqualsAndHash(types, ImmutableList.of(1), blockTypeOperators),\n+                3,\n+                produceRanking,\n+                groupByHash);\n+\n+        // Expected effect:\n+        // Group 0 [0.2 x 1 => rank=1, 0.3 x 3 => rank=2]\n+        // Group 1 [0.2 x 1 => rank=1]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.2)\n+                        .build()).process());\n+\n+        // Page should be dropped, because all values too large to be considered\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.4)\n+                        .row(1L, 0.4)\n+                        .build()).process());\n+\n+        // Next page should cause evict 0.3 from group 0, which should cause the first page to be compacted\n+        // Expected effect:\n+        // Group 0 [0.1 x 1 => rank=1, 0.2 x 2 => rank=2]\n+        // Group 1 [0.2 x 2 => rank=1, 0.3 x 2 => rank=3]\n+        assertTrue(groupedTopNBuilder.processPage(\n+                rowPageBuilder(types)\n+                        .row(0L, 0.1)\n+                        .row(1L, 0.2)\n+                        .row(0L, 0.3)\n+                        .row(0L, 0.2)\n+                        .row(1L, 0.5)\n+                        .row(1L, 0.4)\n+                        .row(1L, 0.3)\n+                        .row(1L, 0.3)\n+                        .build()).process());\n+\n+        List<Page> output = ImmutableList.copyOf(groupedTopNBuilder.buildResult());\n+        assertEquals(output.size(), 1);\n+\n+        if (produceRanking) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNDM4Ng==", "bodyText": "You should remove optimizeTopNRowNumber feature config too (and add it to @DefunctConfig list)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548014386", "createdAt": "2020-12-23T15:31:24Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/analyzer/FeaturesConfig.java", "diffHunk": "@@ -444,6 +445,19 @@ public FeaturesConfig setOptimizeTopNRowNumber(boolean optimizeTopNRowNumber)\n         return this;\n     }\n \n+    public boolean isOptimizeTopNRanking()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNTIwMA==", "bodyText": "this rename belongs to previous commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548015200", "createdAt": "2020-12-23T15:33:21Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -215,7 +215,7 @@ private PlanNode rewriteFilterSource(FilterNode filterNode, PlanNode source, Sym\n             ExtractionResult extractionResult = fromPredicate(metadata, typeOperators, session, filterNode.getPredicate(), types);\n             TupleDomain<Symbol> tupleDomain = extractionResult.getTupleDomain();\n \n-            if (!allValuesInDomain(tupleDomain, rankingSymbol, upperBound)) {\n+            if (!allRankingValuesInDomain(tupleDomain, rankingSymbol, upperBound)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxNTU2MQ==", "bodyText": "Is it possible to write a test?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548015561", "createdAt": "2020-12-23T15:34:00Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -241,7 +241,7 @@ private static boolean allValuesInDomain(TupleDomain<Symbol> tupleDomain, Symbol\n             if (domain == null) {\n                 return true;\n             }\n-            return domain.getValues().contains(ValueSet.ofRanges(range(domain.getType(), 0L, true, upperBound, true)));\n+            return domain.getValues().contains(ValueSet.ofRanges(range(domain.getType(), 1L, true, upperBound, true)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3OTg1MjU5", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-557985259", "createdAt": "2020-12-23T15:40:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MDoyN1rOIKoaWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNTo0MTozN1rOIKocNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxODc3Ng==", "bodyText": "static import", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548018776", "createdAt": "2020-12-23T15:40:27Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/iterative/rule/PushPredicateThroughProjectIntoWindow.java", "diffHunk": "@@ -95,19 +98,30 @@ public PushPredicateThroughProjectIntoWindow(Metadata metadata, TypeOperators ty\n                         .matching(ProjectNode::isIdentity)\n                         .capturedAs(PROJECT)\n                         .with(source().matching(window()\n-                                .matching(window -> {\n-                                    if (window.getOrderingScheme().isEmpty()) {\n-                                        return false;\n-                                    }\n-                                    if (window.getWindowFunctions().size() != 1) {\n-                                        return false;\n-                                    }\n-                                    FunctionId functionId = getOnlyElement(window.getWindowFunctions().values()).getResolvedFunction().getFunctionId();\n-                                    return functionId.equals(metadata.resolveFunction(QualifiedName.of(\"row_number\"), ImmutableList.of()).getFunctionId());\n-                                })\n+                                .matching(window -> toRankingType(metadata, window) != null)\n                                 .capturedAs(WINDOW)))));\n     }\n \n+    @Nullable\n+    private static RankingType toRankingType(Metadata metadata, WindowNode window)\n+    {\n+        if (window.getOrderingScheme().isEmpty()) {\n+            return null;\n+        }\n+        if (window.getWindowFunctions().size() != 1) {\n+            return null;\n+        }\n+\n+        FunctionId functionId = getOnlyElement(window.getWindowFunctions().values()).getResolvedFunction().getFunctionId();\n+        if (functionId.equals(metadata.resolveFunction(QualifiedName.of(\"row_number\"), ImmutableList.of()).getFunctionId())) {\n+            return RankingType.ROW_NUMBER;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAxOTI1Mw==", "bodyText": "return Optional here", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548019253", "createdAt": "2020-12-23T15:41:37Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/sql/planner/optimizations/WindowFilterPushDown.java", "diffHunk": "@@ -298,16 +306,29 @@ private TopNRankingNode convertToTopNRanking(WindowNode windowNode, RankingType\n \n         private boolean canReplaceWithRowNumber(WindowNode node)\n         {\n-            return canOptimizeWindowFunction(node) && node.getOrderingScheme().isEmpty();\n+            if (node.getWindowFunctions().size() != 1) {\n+                return false;\n+            }\n+            Symbol rankingSymbol = getOnlyElement(node.getWindowFunctions().entrySet()).getKey();\n+            FunctionId functionId = node.getWindowFunctions().get(rankingSymbol).getResolvedFunction().getFunctionId();\n+            return functionId.equals(rowNumberFunctionId) && node.getOrderingScheme().isEmpty();\n         }\n \n-        private boolean canOptimizeWindowFunction(WindowNode node)\n+        @Nullable\n+        private RankingType toTopNRankingType(WindowNode node)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4MjMyMjU5", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-558232259", "createdAt": "2020-12-23T21:16:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMToxNjozMlrOIK2O6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QyMTo1MDoxNFrOIK3t3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0NTIyNA==", "bodyText": "Up to you. Generally, I prefer to keep special cases isolated (preferably early on) and have main/happy path unconditional. Extra validate(previousNodeIndex != UNKNOWN_INDEX) doesn't seem that bad IMO.", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548245224", "createdAt": "2020-12-23T21:16:32Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -0,0 +1,894 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import io.prestosql.util.LongLong2LongOpenCustomBigHashMap;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Memory Layout:\n+ * <pre>\n+ *          +--------------------+    +---------------+    +---------------+\n+ *          |GroupIdToHeapBuffer |    |HeapNodeBuffer |    |PeerGroupBuffer|\n+ *          +--------------------+    +---------------+    +---------------+\n+ * Group1+->+RootNodeIndex1+--------->+PeerGroupIndex1+--->+RowID1         |\n+ *          |RootNodeIndex2      |    |PeerGroupCount1|    |NextPeerIndex1+--+\n+ *          |...                 |    |LeftChild1   +----+ |RowID2         | |\n+ *          +--------------------+    |RightChild1    |  | |NextPeerIndex2 | |\n+ *          |ValueCount1         |    |PeerGroupIndex2+<-+ |RowID3   <-------+\n+ *          |HeapSize1           |    |PeerGroupCount2|    |NextPeerIndex3 |\n+ *          |ValueCount2         |    |LeftChild2     |    |...            |\n+ *          |HeapSize2           |    |RightChild2    |    +---------------+\n+ *          |...                 |    |...            |\n+ *          +--------------------+    +---------------+\n+ * </pre>\n+ */\n+public class GroupedTopNRankAccumulator\n+{\n+    public interface RowComparisonStrategy\n+    {\n+        int compare(long leftRowId, long rightRowId);\n+\n+        default boolean equals(long leftRowId, long rightRowId)\n+        {\n+            return compare(leftRowId, rightRowId) == 0;\n+        }\n+\n+        long hashCode(long rowId);\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRankAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+    private static final long NULL_GROUP_ID = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final PeerGroupBuffer peerGroupBuffer = new PeerGroupBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongLong2LongOpenCustomBigHashMap peerGroupLookup;\n+\n+    private final RowComparisonStrategy rowComparisonStrategy;\n+    private final long nullRowId;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRankAccumulator(RowComparisonStrategy rowComparisonStrategy, long nullRowId, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparisonStrategy = requireNonNull(rowComparisonStrategy, \"rowComparisonStrategy is null\");\n+        this.peerGroupLookup = new LongLong2LongOpenCustomBigHashMap(10_000, new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+        {\n+            @Override\n+            public long hashCode(long groupId, long rowId)\n+            {\n+                // TODO: benchmarks show the hashCode computation as a major hotspot that should be optimized\n+                return groupId * 31 + rowComparisonStrategy.hashCode(rowId);\n+            }\n+\n+            @Override\n+            public boolean equals(long leftGroupId, long leftRowId, long rightGroupId, long rightRowId)\n+            {\n+                if (leftGroupId != rightGroupId) {\n+                    return false;\n+                }\n+                if (leftRowId == rightRowId) {\n+                    return true;\n+                }\n+                // fastutil custom hash strategy will pass the null keys back for equality checks.\n+                // We add extra handling here so that these are not visible to the rowComparisonStrategy implementation.\n+                if (leftRowId == nullRowId || rightRowId == nullRowId) {\n+                    return false;\n+                }\n+                return rowComparisonStrategy.equals(leftRowId, rightRowId);\n+            }\n+        }, NULL_GROUP_ID, nullRowId);\n+        this.nullRowId = nullRowId;\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+\n+        peerGroupLookup.defaultReturnValue(UNKNOWN_INDEX);\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE\n+                + groupIdToHeapBuffer.sizeOf()\n+                + heapNodeBuffer.sizeOf()\n+                + peerGroupBuffer.sizeOf()\n+                + heapTraversal.sizeOf()\n+                + peerGroupLookup.sizeOf();\n+    }\n+\n+    private long calculateRootRank(long groupId)\n+    {\n+        long heapValueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        long heapRootIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootIndex != UNKNOWN_INDEX, \"Group does not have a root\");\n+        long rootPeerGroupCount = heapNodeBuffer.getPeerGroupCount(heapRootIndex);\n+        return heapValueCount - rootPeerGroupCount + 1;\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, long newRowId)\n+    {\n+        checkArgument(newRowId != nullRowId, \"Cannot add null row ID\");\n+\n+        // Insert to any existing peer groups first (heap nodes contain distinct values)\n+        long peerHeapNodeIndex = peerGroupLookup.get(groupId, newRowId);\n+        if (peerHeapNodeIndex != UNKNOWN_INDEX) {\n+            directPeerGroupInsert(groupId, peerHeapNodeIndex, newRowId);\n+            if (calculateRootRank(groupId) > topN) {\n+                heapPop(groupId, rowIdEvictionListener);\n+            }\n+            // Return true because heapPop is guaranteed not to evict the newly inserted row (by definition of rank)\n+            return true;\n+        }\n+\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+        if (groupIdToHeapBuffer.getHeapValueCount(groupId) < topN) {\n+            // Always safe to insert if total number of values is still less than topN\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            heapInsert(groupId, newPeerGroupIndex, 1);\n+            return true;\n+        }\n+        else if (rowComparisonStrategy.compare(newRowId, peekRootRowId(groupId)) < 0) {\n+            // Given that total number of values >= topN, we can only consider values that are less than the root (otherwise topN would be violated)\n+            long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(newRowId, UNKNOWN_INDEX);\n+            // Rank will increase by +1 after insertion, so only need to pop if root rank is already == topN.\n+            if (calculateRootRank(groupId) < topN) {\n+                heapInsert(groupId, newPeerGroupIndex, 1);\n+            }\n+            else {\n+                heapPopAndInsert(groupId, newPeerGroupIndex, 1, rowIdEvictionListener);\n+            }\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    private void directPeerGroupInsert(long groupId, long heapNodeIndex, long rowId)\n+    {\n+        long existingPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapNodeIndex);\n+        long newPeerGroupIndex = peerGroupBuffer.allocateNewNode(rowId, existingPeerGroupIndex);\n+        heapNodeBuffer.setPeerGroupIndex(heapNodeIndex, newPeerGroupIndex);\n+        heapNodeBuffer.incrementPeerGroupCount(heapNodeIndex);\n+        groupIdToHeapBuffer.incrementHeapValueCount(groupId);\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group has nothing to peek\");\n+        return peerGroupBuffer.getRowId(heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex));\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID and ranking buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffers\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput, LongBigArray rankingOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+        rankingOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            long rank = calculateRootRank(groupId);\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                rankingOutput.set(insertionIndex, rank);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     * After this method completion, the Accumulator will contain zero rows for the specified groupId.\n+     *\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long valueCount = groupIdToHeapBuffer.getHeapValueCount(groupId);\n+        rowIdOutput.ensureCapacity(valueCount);\n+\n+        // Heap is inverted to output order, so insert back to front\n+        long insertionIndex = valueCount - 1;\n+        while (insertionIndex >= 0) {\n+            long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+            verify(heapRootNodeIndex != UNKNOWN_INDEX);\n+\n+            long peerGroupIndex = heapNodeBuffer.getPeerGroupIndex(heapRootNodeIndex);\n+            verify(peerGroupIndex != UNKNOWN_INDEX, \"Peer group should have at least one value\");\n+\n+            do {\n+                long rowId = peerGroupBuffer.getRowId(peerGroupIndex);\n+                rowIdOutput.set(insertionIndex, rowId);\n+                insertionIndex--;\n+                peerGroupIndex = peerGroupBuffer.getNextPeerIndex(peerGroupIndex);\n+            }\n+            while (peerGroupIndex != UNKNOWN_INDEX);\n+\n+            heapPop(groupId, null);\n+        }\n+        return valueCount;\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastHeapNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastPeerGroupIndex = heapNodeBuffer.getPeerGroupIndex(lastHeapNodeIndex);\n+        long lastPeerGroupCount = heapNodeBuffer.getPeerGroupCount(lastHeapNodeIndex);\n+\n+        if (lastHeapNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            dropHeapNodePeerGroup(groupId, lastHeapNodeIndex, contextEvictionListener);\n+        }\n+        else {\n+            // Pop the root and insert the last peer group back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastPeerGroupIndex, lastPeerGroupCount, contextEvictionListener);\n+        }\n+\n+        // peerGroupLookup entry will be updated by definition of inserting the last peer group into a new node\n+        heapNodeBuffer.deallocate(lastHeapNodeIndex);\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @return leaf node index that was detached from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk1MDkzMA=="}, "originalCommit": null, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0OTA0OQ==", "bodyText": "Given that we use:\n        typeOperators = new TypeOperators();\n        blockTypeOperators = new BlockTypeOperators(typeOperators);\n\nI think some basic test here would also work since it would use same comparators, equals as non-test code (just not compiled version)", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548249049", "createdAt": "2020-12-23T21:21:31Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRankBuilder.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.primitives.Ints;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeOperators;\n+import io.prestosql.sql.gen.JoinCompiler;\n+import io.prestosql.type.BlockTypeOperators;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static com.google.common.collect.Iterables.getOnlyElement;\n+import static io.prestosql.RowPageBuilder.rowPageBuilder;\n+import static io.prestosql.RowPagesBuilder.rowPagesBuilder;\n+import static io.prestosql.operator.PageAssertions.assertPageEquals;\n+import static io.prestosql.operator.UpdateMemory.NOOP;\n+import static io.prestosql.spi.connector.SortOrder.ASC_NULLS_LAST;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRankBuilder", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODAwNDc1Mw=="}, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI2OTUzMg==", "bodyText": "static import format", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r548269532", "createdAt": "2020-12-23T21:50:14Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/sql/planner/optimizations/TestWindowFilterPushDown.java", "diffHunk": "@@ -101,74 +158,81 @@ public void testFilterAboveWindow()\n \n         // remove subplan if predicate on row number symbol can't be satisfied\n         assertPlanWithSession(\n-                \"SELECT * FROM (SELECT name, row_number() OVER(ORDER BY name) FROM nation) t(name, row_number) WHERE row_number < 0\",\n+                String.format(\"SELECT * FROM (SELECT name, %s() OVER(ORDER BY name) FROM nation) t(name, ranking) WHERE ranking < 0\", rankingFunction),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5NDgzMTMx", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-559483131", "createdAt": "2020-12-29T11:03:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMTowMzozOFrOIMMyJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQxMTozNzoxMFrOIMNWaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MzI3MQ==", "bodyText": "static import ASC_NULLS_FIRST", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549663271", "createdAt": "2020-12-29T11:03:38Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRankingOperator.java", "diffHunk": "@@ -243,4 +244,57 @@ public void testMemoryReservationYield()\n         }\n         assertEquals(count, 1_000 * 500);\n     }\n+\n+    @Test\n+    public void testRankNullAndNan()\n+    {\n+        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(BIGINT, DOUBLE);\n+        List<Page> input = rowPagesBuilder\n+                .row(1L, null)\n+                .row(2L, 0.2)\n+                .row(2L, Double.NaN)\n+                .row(3L, 0.1)\n+                .row(3L, 0.91)\n+                .pageBreak()\n+                .row(1L, 0.4)\n+                .pageBreak()\n+                .row(1L, 0.5)\n+                .row(1L, null)\n+                .row(1L, 0.6)\n+                .row(2L, 0.7)\n+                .row(2L, Double.NaN)\n+                .build();\n+\n+        TopNRankingOperatorFactory operatorFactory = new TopNRankingOperatorFactory(\n+                0,\n+                new PlanNodeId(\"test\"),\n+                RANK,\n+                ImmutableList.of(BIGINT, DOUBLE),\n+                Ints.asList(1, 0),\n+                Ints.asList(0),\n+                ImmutableList.of(BIGINT),\n+                Ints.asList(1),\n+                ImmutableList.of(SortOrder.ASC_NULLS_FIRST),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY3MjU1Mw==", "bodyText": "window operator behaves differently regarding NaNs (#6462). They are not equal there because window operator uses io.prestosql.operator.PagesHashStrategy#rowEqualsRow (which treats nulls as equal, but not NaNs)\nI think we should use equality here too. It should be fine to have two rows non-equal but compare=0. Essentially, such rows will be placed next to each other in absolute ordering, but they will still form different peer groups", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r549672553", "createdAt": "2020-12-29T11:37:10Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/SimplePageWithPositionEqualsAndHash.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.type.BlockTypeOperators;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionHashCode;\n+import io.prestosql.type.BlockTypeOperators.BlockPositionIsDistinctFrom;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SimplePageWithPositionEqualsAndHash\n+        implements PageWithPositionEqualsAndHash\n+{\n+    private final IntList equalityChannels;\n+    private final List<BlockPositionIsDistinctFrom> distinctFromOperators;\n+    private final List<BlockPositionHashCode> hashOperators;\n+\n+    public SimplePageWithPositionEqualsAndHash(List<Type> channelTypes, List<Integer> equalityChannels, BlockTypeOperators blockTypeOperators)\n+    {\n+        requireNonNull(channelTypes, \"channelTypes is null\");\n+        this.equalityChannels = new IntArrayList(requireNonNull(equalityChannels, \"equalityChannels is null\"));\n+        checkArgument(channelTypes.size() >= equalityChannels.size(), \"channelTypes cannot have fewer columns then equalityChannels\");\n+\n+        // Use IS DISTINCT FROM for equality, because it evaluates NULL values as distinct (unlike SQL EQUALS).", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwMDExNTQ4", "url": "https://github.com/trinodb/trino/pull/6333#pullrequestreview-560011548", "createdAt": "2020-12-30T11:31:36Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMTozNlrOIMrQng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMTozMzo0NlrOIMrS8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjU5MA==", "bodyText": "Let's remove HACK from commit message. It's just maintaining current semantics. In fact, I would just squash it, but if it would make it easier to revert later on, we could keep it as separate commit", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550162590", "createdAt": "2020-12-30T11:31:36Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRankAccumulator.java", "diffHunk": "@@ -577,11 +577,11 @@ private IntegrityStats verifyHeapIntegrity(long groupId, long heapNodeIndex)\n         verify(actualPeerGroupCount == peerGroupCount, \"Recorded peer group count does not match actual\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MjkyMA==", "bodyText": "Please create separate PR. This commit is unrelated to rank improvements", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550162920", "createdAt": "2020-12-30T11:32:54Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/operator/TopNRowNumberOperator.java", "diffHunk": "@@ -33,7 +33,6 @@\n import static com.google.common.base.Preconditions.checkState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MzE4NA==", "bodyText": "Why would that fail with previous TopNRowNumberOperatorCode code? Was it because BIGINT and DOUBLE comparisons were compatible?", "url": "https://github.com/trinodb/trino/pull/6333#discussion_r550163184", "createdAt": "2020-12-30T11:33:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestTopNRowNumberOperator.java", "diffHunk": "@@ -93,30 +94,30 @@ public void tearDown()\n     @Test(dataProvider = \"hashEnabledValues\")\n     public void testPartitioned(boolean hashEnabled)\n     {\n-        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), BIGINT, DOUBLE);\n+        RowPagesBuilder rowPagesBuilder = rowPagesBuilder(hashEnabled, Ints.asList(0), VARCHAR, DOUBLE);\n         List<Page> input = rowPagesBuilder\n-                .row(1L, 0.3)\n-                .row(2L, 0.2)\n-                .row(3L, 0.1)\n-                .row(3L, 0.91)\n+                .row(\"a\", 0.3)\n+                .row(\"b\", 0.2)\n+                .row(\"c\", 0.1)\n+                .row(\"c\", 0.91)\n                 .pageBreak()\n-                .row(1L, 0.4)\n+                .row(\"a\", 0.4)\n                 .pageBreak()\n-                .row(1L, 0.5)\n-                .row(1L, 0.6)\n-                .row(2L, 0.7)\n-                .row(2L, 0.8)\n+                .row(\"a\", 0.5)\n+                .row(\"a\", 0.6)\n+                .row(\"b\", 0.7)\n+                .row(\"b\", 0.8)\n                 .pageBreak()\n-                .row(2L, 0.9)\n+                .row(\"b\", 0.9)\n                 .build();\n \n         TopNRowNumberOperatorFactory operatorFactory = new TopNRowNumberOperatorFactory(\n                 0,\n                 new PlanNodeId(\"test\"),\n-                ImmutableList.of(BIGINT, DOUBLE),\n+                ImmutableList.of(VARCHAR, DOUBLE),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "182fac1c71d14b12deacf562942f478412bfd484", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/182fac1c71d14b12deacf562942f478412bfd484", "committedDate": "2021-01-04T21:01:17Z", "message": "Remove extra space from TopNRowNumberOperator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59f7cfc73433018398344498bab676e93d76be6c", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/59f7cfc73433018398344498bab676e93d76be6c", "committedDate": "2021-01-04T21:01:17Z", "message": "Fix TopNRowNumberOperator incorrectly swapped types\n\nTopNRowNumberOperator was previously incorrectly using the output type\norder for the SimplePageWithPositionComparator strategy, when the\nchannels were all defined in terms of the input types. This issue is not\nvisible in production code because the LocalExecutionPlanner always puts\nthe outputs in the same order as the inputs, but this means that the\ncurrent set of tests were accidentally correct. The tests have been\nupdated to fail if this occurs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e1eecc18bb8801d45add025b0f72e120040fc59", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/4e1eecc18bb8801d45add025b0f72e120040fc59", "committedDate": "2021-01-04T21:01:17Z", "message": "Allow LongLong2LongOpenCustomBigHashMap to explicitly set null keys\n\nLongLong2LongOpenCustomBigHashMap originally uses the value zero to\nrepresent keys that haven't been mapped yet (fastutil calls these null\nkeys in their code). However, this means that the custom HashStrategy\nwill sometimes be asked to check equality on zero valued keys, even\nthough a zero value key may not exist from the strategies perspective.\nTo help callers better disambiguate this situation, we now allow the\ncallers to configure the null keys to be used on instance creation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "015ce17a142b54edeef8358e57465c1792595b1e", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/015ce17a142b54edeef8358e57465c1792595b1e", "committedDate": "2021-01-04T21:01:17Z", "message": "Fix typo in GroupedTopNBuilder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "960b3638b966cace5a1dd1692dc7d35e3613b688", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/960b3638b966cace5a1dd1692dc7d35e3613b688", "committedDate": "2021-01-04T21:01:17Z", "message": "Extract GroupedTopNBuilder as an interface\n\nRenames:\nGroupedTopNBuilder => GroupedTopNRowNumberBuilder\nBenchmarkGroupedTopNBuilder => BenchmarkGroupedTopNRowNumberBuilder\nTestGroupedTopNBuilder => TestGroupedTopNRowNumberBuilder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "309c208ae9f386500516e27ea23ab3eab808722e", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/309c208ae9f386500516e27ea23ab3eab808722e", "committedDate": "2021-01-04T21:01:17Z", "message": "Rename TopNRowNumber* => TopNRanking*\n\nGeneralizing TopNRowNumber components as a more generic top N ranking\nsystem to allow inclusions of rank and dense_rank"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a626f0b2ad812ecf5d34c831314126cab1c1439", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/1a626f0b2ad812ecf5d34c831314126cab1c1439", "committedDate": "2021-01-04T21:01:17Z", "message": "Add planner scaffolding to enable streaming topn RANK and DENSE_RANK\n\nProvides the template to quickly enable streaming topn RANK and\nDENSE_RANK, but does not enable them yet."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b73dd12b3e85a5f457b5146fe5be502a7998fc02", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/b73dd12b3e85a5f457b5146fe5be502a7998fc02", "committedDate": "2021-01-04T21:01:17Z", "message": "Add GroupedTopNRankAccumulator for streaming rank"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5643850bc6643f3740e1f99c614460a04dc24e4d", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/5643850bc6643f3740e1f99c614460a04dc24e4d", "committedDate": "2021-01-04T21:01:17Z", "message": "Copy GroupedTopNRowNumberBuilder as new rank builder template"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7de1cf1591c59515d4ffad6eeeb3a0ee12aa0cc2", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/7de1cf1591c59515d4ffad6eeeb3a0ee12aa0cc2", "committedDate": "2021-01-04T21:01:17Z", "message": "Properly implement GroupedTopNRankBuilder within stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6318b53e4c96f6a82d50e60e9057f90f36526656", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/6318b53e4c96f6a82d50e60e9057f90f36526656", "committedDate": "2021-01-04T21:01:17Z", "message": "Replace optimizer.optimize-top-n-row-number config with general version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c98eb0883496b47844d20227e53e879b6ece7709", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/c98eb0883496b47844d20227e53e879b6ece7709", "committedDate": "2021-01-04T21:01:17Z", "message": "Add optimizer capability to produce streaming topN rank() plans"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ceabdd95930023311b22daa6e4ee9607dc06a04d", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/ceabdd95930023311b22daa6e4ee9607dc06a04d", "committedDate": "2021-01-04T21:01:17Z", "message": "Tighten WindowFilterPushDown predicate domain check\n\nWindowFilterPushDown was previously too loose inchecking for rank bounds\nbetween 0 to N when comparing with a TopN operator. All rank values\nstart at 1."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a8c8afadedc16cfe475ee74d50de7277e1d89f8", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/7a8c8afadedc16cfe475ee74d50de7277e1d89f8", "committedDate": "2021-01-04T21:01:17Z", "message": "Clean up for GroupedTopNRowNumberAccumulator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fee1af842dc66021db9eca61e6d98d785d63722f", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/fee1af842dc66021db9eca61e6d98d785d63722f", "committedDate": "2021-01-04T21:01:17Z", "message": "Force TopNRankingOperator compatibility with current Window behavior\n\nThe default Window implementation uses equalsNullSafe rather than the\nexpected IS NOT DISTINCT FROM semantics to determine peer groups. This\nmeans values such as NaN, positive/negative zero, and nested null\nstructure types  will be incorrectly treated as separate peer groups. We\nare putting in this temporary hack to retain compatibility with the\ncurrent window behavior, but will need to revert this after it gets\nfixed."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "fee1af842dc66021db9eca61e6d98d785d63722f", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/fee1af842dc66021db9eca61e6d98d785d63722f", "committedDate": "2021-01-04T21:01:17Z", "message": "Force TopNRankingOperator compatibility with current Window behavior\n\nThe default Window implementation uses equalsNullSafe rather than the\nexpected IS NOT DISTINCT FROM semantics to determine peer groups. This\nmeans values such as NaN, positive/negative zero, and nested null\nstructure types  will be incorrectly treated as separate peer groups. We\nare putting in this temporary hack to retain compatibility with the\ncurrent window behavior, but will need to revert this after it gets\nfixed."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1822, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}