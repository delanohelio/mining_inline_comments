{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI4NjczNTE1", "number": 3935, "title": "Use hive column indices for parquet tuple domain creation when specified", "bodyText": "Fixes a bug in Parquet predicate pushdown when the column ordering\nof the Hive schema does not match the column ordering in the Parquet\nfile. The use of column indices vs column names was inconsistent.\nfixes: #3574", "createdAt": "2020-06-05T19:07:58Z", "url": "https://github.com/trinodb/trino/pull/3935", "merged": true, "mergeCommit": {"oid": "bc93b02cb3f104aae3c40a1ad56369facf64baac"}, "closed": true, "closedAt": "2020-06-15T21:04:00Z", "author": {"login": "alexjo2144"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoYZ7tAFqTQyNTU4OTgzMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcrhWPRgBqjM0NDQ2MjQ3MDQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NTg5ODMz", "url": "https://github.com/trinodb/trino/pull/3935#pullrequestreview-425589833", "createdAt": "2020-06-05T19:59:06Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOTo1OTowNlrOGf7sxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQyMDowOTowM1rOGf78fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNzE1OQ==", "bodyText": "Why useParquetColumnNames=true in by-index flow?", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436137159", "createdAt": "2020-06-05T19:59:06Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();\n+        Optional<ReaderProjections> readerProjections = projectBaseColumns(hiveColumnHandles);\n+        List<HiveColumnHandle> baseColumns = readerProjections.map(ReaderProjections::getReaderColumns).orElse(hiveColumnHandles);\n+\n+        List<Optional<org.apache.parquet.schema.Type>> parquetFields = baseColumns.stream()\n+                .map(column -> getParquetType(column, fileSchema, true))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNzk3Ng==", "bodyText": "descriptorsByName -> descriptorsByColumnName\nmove this line just before the for loop where it's being populated\nand use ImmutableList.builder", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436137976", "createdAt": "2020-06-05T20:00:57Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzOTgwMw==", "bodyText": "new String[] {parquetField.getName()}\n\nthis seems to be correct for top-level fields; is it also correct for nested?\nif a have a top level col but also nested r.col, will this get confused?", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436139803", "createdAt": "2020-06-05T20:05:34Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();\n+        Optional<ReaderProjections> readerProjections = projectBaseColumns(hiveColumnHandles);\n+        List<HiveColumnHandle> baseColumns = readerProjections.map(ReaderProjections::getReaderColumns).orElse(hiveColumnHandles);\n+\n+        List<Optional<org.apache.parquet.schema.Type>> parquetFields = baseColumns.stream()\n+                .map(column -> getParquetType(column, fileSchema, true))\n+                .map(Optional::ofNullable)\n+                .collect(toImmutableList());\n+\n+        for (int columnIndex = 0; columnIndex < baseColumns.size(); columnIndex++) {\n+            HiveColumnHandle column = baseColumns.get(columnIndex);\n+            if (column.getHiveType().getCategory() != PRIMITIVE) {\n+                continue;\n+            }\n+\n+            parquetFields.get(columnIndex).ifPresent(parquetField -> {\n+                descriptorsByName.put(\n+                        ImmutableList.of(fileSchema.getFields().get(column.getBaseHiveColumnIndex()).getName()),\n+                        new RichColumnDescriptor(fileSchema.getColumnDescription(new String[] {parquetField.getName()}), parquetField.asPrimitiveType()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MDY2NA==", "bodyText": "I think it would be more adequate to place the fix inside the getParquetTupleDomain. Did you try that?", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436140664", "createdAt": "2020-06-05T20:07:40Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -200,7 +201,16 @@ public static ReaderPageSourceWithProjections createPageSource(\n             }\n \n             Map<List<String>, RichColumnDescriptor> descriptorsByPath = getDescriptors(fileSchema, requestedSchema);\n-            TupleDomain<ColumnDescriptor> parquetTupleDomain = getParquetTupleDomain(descriptorsByPath, effectivePredicate);\n+\n+            Map<List<String>, RichColumnDescriptor> descriptorForTupleDomain;\n+            if (useColumnNames) {\n+                descriptorForTupleDomain = descriptorsByPath;\n+            }\n+            else {\n+                descriptorForTupleDomain = getDescriptorsUsingIndex(columns, fileSchema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MTE4Mg==", "bodyText": "Well done!\nWhile at it, we could rename the test to make it a bit broader, and verify the behavior under parquet_use_column_names=true too.", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436141182", "createdAt": "2020-06-05T20:09:03Z", "author": {"login": "findepi"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4292,6 +4292,58 @@ public void testSubfieldReordering()\n         }\n     }\n \n+    @Test\n+    public void testParquetByColumnIndex()\n+    {\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+\n+        String tableName = \"test_parquet_by_column_index\";\n+\n+        assertUpdate(session, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar, \" +\n+                        \"  b varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                tableName));\n+        assertUpdate(session, \"INSERT INTO \" + tableName + \" VALUES ('a', 'b')\", 1);\n+\n+        assertQuery(\n+                session,\n+                \"SELECT a, b FROM \" + tableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                session,\n+                \"SELECT a FROM \" + tableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + tableName).getOnlyValue();\n+\n+        // Reverse the table so that the Hive column ordering does not match the Parquet column ordering\n+        String reversedTableName = \"test_parquet_by_column_index_reversed\";\n+        assertUpdate(session, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                reversedTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                session,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('b', 'a')\");\n+        assertQuery(\n+                session,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('b')\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2MzcwMDIw", "url": "https://github.com/trinodb/trino/pull/3935#pullrequestreview-426370020", "createdAt": "2020-06-08T15:42:04Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNTo0MjowNFrOGgkdqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNTo0MjowNFrOGgkdqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjgwNTAzMg==", "bodyText": "Would this work?\nRichColumnDescriptor descriptor;\nif (useColumnNames) {\n    descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n}\nelse {\n    org.apache.parquet.schema.Type parquetField = fileSchema.getType(columnHandle.getBaseHiveColumnIndex());\n    if (!parquetField.isPrimitive()) {\n        // obvious mismatch\n        continue;\n    }\n    descriptor = descriptorsByPath.get(ImmutableList.of(parquetField.getName()));\n}", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436805032", "createdAt": "2020-06-08T15:42:04Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -323,7 +334,7 @@ public static ReaderPageSourceWithProjections createPageSource(\n                 continue;\n             }\n \n-            RichColumnDescriptor descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            RichColumnDescriptor descriptor = columnDescriptors.get(ImmutableList.of(columnHandle.getName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NTczMzAz", "url": "https://github.com/trinodb/trino/pull/3935#pullrequestreview-427573303", "createdAt": "2020-06-09T21:55:22Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMTo1NToyM1rOGhdz_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMTo1NTozNFrOGhd0UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc0NDYzOQ==", "bodyText": "unwrap ifs:\nif (parquetField == null) {\n  // Parquet file has fewer column than partition\n  continue;\n}\nif(!parquetField.isPrimitive()) {\n  ....", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r437744639", "createdAt": "2020-06-09T21:55:23Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -319,11 +324,27 @@ public static ReaderPageSourceWithProjections createPageSource(\n         for (Entry<HiveColumnHandle, Domain> entry : effectivePredicate.getDomains().get().entrySet()) {\n             HiveColumnHandle columnHandle = entry.getKey();\n             // skip looking up predicates for complex types as Parquet only stores stats for primitives\n-            if (columnHandle.getHiveType().getCategory() != PRIMITIVE) {\n+            if (columnHandle.getHiveType().getCategory() != PRIMITIVE || columnHandle.getColumnType() != REGULAR) {\n                 continue;\n             }\n \n-            RichColumnDescriptor descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            RichColumnDescriptor descriptor;\n+            if (useColumnNames) {\n+                descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            }\n+            else {\n+                org.apache.parquet.schema.Type parquetField = getParquetType(columnHandle, fileSchema, false);\n+                if (parquetField != null) {\n+                    if(!parquetField.isPrimitive()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc0NDcyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n      \n    \n    \n  \n\nnit", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r437744720", "createdAt": "2020-06-09T21:55:34Z", "author": {"login": "findepi"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4294,6 +4294,148 @@ public void testSubfieldReordering()\n         }\n     }\n \n+    @Test\n+    public void testParquetColumnNameMappings()\n+    {\n+        Session sessionUsingColumnIndex = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+        Session sessionUsingColumnName = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"true\")\n+                .build();\n+\n+        String tableName = \"test_parquet_by_column_index\";\n+\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar, \" +\n+                        \"  b varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                tableName));\n+        assertUpdate(sessionUsingColumnIndex, \"INSERT INTO \" + tableName + \" VALUES ('a', 'b')\", 1);\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a, b FROM \" + tableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a FROM \" + tableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + tableName).getOnlyValue();\n+\n+        // Reverse the table so that the Hive column ordering does not match the Parquet column ordering\n+        String reversedTableName = \"test_parquet_by_column_index_reversed\";\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                reversedTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('b', 'a')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('b')\");\n+\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + reversedTableName);\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + tableName);\n+    }\n+\n+    @Test\n+    public void testParquetWithMissingColumns()\n+    {\n+        Session sessionUsingColumnIndex = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+        Session sessionUsingColumnName = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"true\")\n+                .build();\n+\n+        String singleColumnTableName = \"test_parquet_with_missing_columns_one\";\n+\n+        assertUpdate(format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                singleColumnTableName));\n+        assertUpdate(sessionUsingColumnIndex, \"INSERT INTO \" + singleColumnTableName + \" VALUES ('a')\", 1);\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + singleColumnTableName).getOnlyValue();\n+        String multiColumnTableName = \"test_parquet_missing_columns_two\";\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                multiColumnTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + multiColumnTableName + \" WHERE b IS NULL\",\n+                \"VALUES ('a')\");\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + multiColumnTableName + \" WHERE a = 'a'\",\n+                \"VALUES ('a')\");\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT b FROM \" + multiColumnTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('a')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT b FROM \" + multiColumnTableName + \" WHERE a IS NULL\",\n+                \"VALUES ('a')\");\n+\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + singleColumnTableName);\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + multiColumnTableName);\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 117}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI5NjE3MTk3", "url": "https://github.com/trinodb/trino/pull/3935#pullrequestreview-429617197", "createdAt": "2020-06-12T10:02:01Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d81ae6a28c6713187ba0b4e92875e8f614cbca78", "author": {"user": {"login": "alexjo2144", "name": "Alexander Jo"}}, "url": "https://github.com/trinodb/trino/commit/d81ae6a28c6713187ba0b4e92875e8f614cbca78", "committedDate": "2020-06-15T14:15:22Z", "message": "Use hive column indices for parquet tuple domain creation when specified\n\nFixes a bug in Parquet predicate pushdown when the column ordering\nof the Hive schema does not match the column ordering in the Parquet\nfile. The use of column indices vs column names was inconsistent."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d81ae6a28c6713187ba0b4e92875e8f614cbca78", "author": {"user": {"login": "alexjo2144", "name": "Alexander Jo"}}, "url": "https://github.com/trinodb/trino/commit/d81ae6a28c6713187ba0b4e92875e8f614cbca78", "committedDate": "2020-06-15T14:15:22Z", "message": "Use hive column indices for parquet tuple domain creation when specified\n\nFixes a bug in Parquet predicate pushdown when the column ordering\nof the Hive schema does not match the column ordering in the Parquet\nfile. The use of column indices vs column names was inconsistent."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 578, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}