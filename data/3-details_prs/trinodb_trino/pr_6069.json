{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MzIwMTcz", "number": 6069, "title": "Implement aggregation pushdown in Pinot", "bodyText": "Resolves #4140", "createdAt": "2020-11-24T08:59:27Z", "url": "https://github.com/trinodb/trino/pull/6069", "merged": true, "mergeCommit": {"oid": "c2c4f3fe72e00f5e0f6a1e8062a917f9a7f53713"}, "closed": true, "closedAt": "2021-08-24T14:00:23Z", "author": {"login": "elonazoulay"}, "timelineItems": {"totalCount": 73, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfvluhABqjQwMzQ2NDE0NTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABe3h2IcgFqTczNzI2NTkzNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc0NTMxMjgy", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-574531282", "createdAt": "2021-01-22T18:53:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMlQxODo1MzoyN1rOIYxDJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMzowNToxNlrOIaus8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MDM1Ng==", "bodyText": "This should be enabled by default. It should exist as a fallback only until we're confident the feature works as expected, and then we should remove it entirely.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562840356", "createdAt": "2021-01-22T18:53:27Z", "author": {"login": "martint"}, "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotConfig.java", "diffHunk": "@@ -50,6 +50,7 @@\n     private int fetchRetryCount = 2;\n     private int nonAggregateLimitForBrokerQueries = 25_000;\n     private int maxRowsPerSplitForSegmentQueries = 50_000;\n+    private boolean aggregationPushdownEnabled;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MTI5MQ==", "bodyText": "Why?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562841291", "createdAt": "2021-01-22T18:55:12Z", "author": {"login": "martint"}, "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5NTU4OA==", "bodyText": "I'm not sure I understand this comment. What do you mean by \"aggregation expressions\"?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562995588", "createdAt": "2021-01-23T01:23:14Z", "author": {"login": "martint"}, "path": "presto-pinot/src/main/java/io/prestosql/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,32 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171\n+                // Until then this branch will never be executed", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5NTIzMg==", "bodyText": "This is hard to read, especially with the optional and lambda in the middle. I'd break it up into multiple parts and make the check more explicit.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564895232", "createdAt": "2021-01-26T23:01:16Z", "author": {"login": "martint"}, "path": "presto-pinot/src/main/java/io/prestosql/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,32 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171\n+                // Until then this branch will never be executed\n+                return Optional.of(\"distinctcount\");\n+            }\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static String getInputExpresion(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        // Pinot converts count(column_name) to count(*)\n+        if (aggregateFunction.getInputs().isEmpty() || getAggregationFunctionName(aggregateFunction).map(functionName -> functionName.equalsIgnoreCase(\"count\")).orElse(false)) {\n+            return \"*\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5NTkxOQ==", "bodyText": "This seems unrelated to this change, so move to a separate commit", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564895919", "createdAt": "2021-01-26T23:01:54Z", "author": {"login": "martint"}, "path": "presto-pinot/src/test/java/io/prestosql/pinot/PinotQueryRunner.java", "diffHunk": "@@ -36,19 +39,26 @@ public static DistributedQueryRunner createPinotQueryRunner(Map<String, String>\n             throws Exception\n     {\n         DistributedQueryRunner queryRunner = DistributedQueryRunner.builder(createSession(\"default\"))\n-                .setNodeCount(2)\n+                .setNodeCount(3)\n                 .setExtraProperties(extraProperties)\n                 .build();\n         queryRunner.installPlugin(new PinotPlugin(extension));\n-        queryRunner.createCatalog(\"pinot\", \"pinot\", extraPinotProperties);\n+        queryRunner.createCatalog(PINOT_CATALOG, PINOT_CATALOG, extraPinotProperties);\n         return queryRunner;\n     }\n \n     public static Session createSession(String schema)\n+    {\n+        return createSession(schema, new PinotConfig());\n+    }\n+\n+    public static Session createSession(String schema, PinotConfig config)\n     {\n         SessionPropertyManager sessionPropertyManager = new SessionPropertyManager();\n+        PinotSessionProperties pinotSessionProperties = new PinotSessionProperties(config);\n+        sessionPropertyManager.addConnectorSessionProperties(new CatalogName(PINOT_CATALOG), pinotSessionProperties.getSessionProperties());\n         return testSessionBuilder(sessionPropertyManager)\n-                .setCatalog(\"pinot\")\n+                .setCatalog(PINOT_CATALOG)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5OTA1OA==", "bodyText": "What role does this column name have? Will it be an issue if it contains characters like parentheses?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564899058", "createdAt": "2021-01-26T23:05:16Z", "author": {"login": "martint"}, "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();\n+        }\n+        if (tableHandle.getLimit().isPresent()) {\n+            // handle's limit is applied after aggregations, so we cannot apply aggregations if limit is already set\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            String inputExpression = getInputExpresion(aggregate);\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (!aggregateFunctionName.isPresent()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA0NTkyMDk5", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-604592099", "createdAt": "2021-03-04T21:46:59Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMTo0Njo1OVrOIwnfqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMTo0Njo1OVrOIwnfqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg0OTY0MQ==", "bodyText": "nit: here & elsewhere, update the link please", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r587849641", "createdAt": "2021-03-04T21:46:59Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,34 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NzkyNjM2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-605792636", "createdAt": "2021-03-06T22:28:12Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNlQyMjoyODoxMlrOIxp_bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNlQyMjozMjowNFrOIxqA4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ==", "bodyText": "The two are not equivalent. in SQL, count(column_name) counts how many non-null values there are", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939119", "createdAt": "2021-03-06T22:28:12Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,34 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/trinodb/trino/issues/4171\n+                // Until then this branch will never be executed\n+                return Optional.of(\"distinctcount\");\n+            }\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static String getInputExpresion(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        boolean isCountFunction = aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false);\n+        // Pinot converts count(column_name) to count(*)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTMxNQ==", "bodyText": "Can this be modelled with io.trino.plugin.pinot.query.DynamicTable#query as a nested query?\nSee \n  \n    \n      trino/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/JdbcMetadata.java\n    \n    \n         Line 248\n      in\n      6e3bc78\n    \n    \n    \n    \n\n        \n          \n           handle = flushAttributesAsQuery(session, handle); \n        \n    \n  \n\n\nand the test\n\n  \n    \n      trino/plugin/trino-postgresql/src/test/java/io/trino/plugin/postgresql/TestPostgreSqlConnectorTest.java\n    \n    \n         Line 520\n      in\n      f2582d1\n    \n    \n    \n    \n\n        \n          \n           .isFullyPushedDown();", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939315", "createdAt": "2021-03-06T22:30:07Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();\n+        }\n+        if (tableHandle.getLimit().isPresent()) {\n+            // handle's limit is applied after aggregations, so we cannot apply aggregations if limit is already set\n+            return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA==", "bodyText": "Can you update the test cases to use io.trino.sql.query.QueryAssertions.QueryAssert#isFullyPushedDown to verify that pushdown actually takes places?\nThis has the added benefit that it automatically verifies correctness, by comparing results with pushdown and without.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939490", "createdAt": "2021-03-06T22:32:04Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestMinimalFunctionality.java", "diffHunk": "@@ -184,6 +187,31 @@ public void testLimitForSegmentQueries()\n         assertQueryFails(\"SELECT * FROM \" + TOPIC_AND_TABLE, \"Segment query returned.*\");\n     }\n \n+    @Test\n+    public void testAggregationPushdown()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM5Mjc5NzQw", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-639279740", "createdAt": "2021-04-19T20:29:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0xOVQyMDoyOToyNlrOJLnL6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0xOVQyMDozOTozNVrOJLnjNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1NjEzNg==", "bodyText": "pinot.aggregation-pushdown.enabled", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616156136", "createdAt": "2021-04-19T20:29:26Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +258,16 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.enable-aggregation-pushdown\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1NjQ5OQ==", "bodyText": "aggregation_pushdown_enabled", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616156499", "createdAt": "2021-04-19T20:29:59Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotSessionProperties.java", "diffHunk": "@@ -34,6 +34,7 @@\n     private static final String PREFER_BROKER_QUERIES = \"prefer_broker_queries\";\n     private static final String RETRY_COUNT = \"retry_count\";\n     private static final String NON_AGGREGATE_LIMIT_FOR_BROKER_QUERIES = \"non_aggregate_limit_for_broker_queries\";\n+    private static final String ENABLE_AGGREGATION_PUSHDOWN = \"enable_aggregation_pushdown\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1OTMzNQ==", "bodyText": "Maybe call it TestPinotMetadata since this looks like a unit test of that class", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616159335", "createdAt": "2021-04-19T20:35:05Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.trino.plugin.pinot.client.PinotClient;\n+import io.trino.plugin.pinot.query.AggregationExpression;\n+import io.trino.plugin.pinot.query.DynamicTable;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.AggregationApplicationResult;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.predicate.TupleDomain;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalLong;\n+\n+import static io.airlift.concurrent.Threads.threadsNamed;\n+import static io.trino.plugin.pinot.PinotQueryRunner.createSession;\n+import static io.trino.plugin.pinot.TestPinotQueryBase.getTestingMetadata;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static io.trino.spi.type.DoubleType.DOUBLE;\n+import static java.util.concurrent.Executors.newCachedThreadPool;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestAggregationPushdown", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1OTgyNg==", "bodyText": "BTW Maybe  you can  copy TestPostgreSqlConnectorTest.test*AggregationPushdown methods into Pinot tests (of course, the relevant ones?)\nThis would give you isFullyPushedDown usage and many test cases out of the box", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616159826", "createdAt": "2021-04-19T20:35:55Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestMinimalFunctionality.java", "diffHunk": "@@ -184,6 +187,31 @@ public void testLimitForSegmentQueries()\n         assertQueryFails(\"SELECT * FROM \" + TOPIC_AND_TABLE, \"Segment query returned.*\");\n     }\n \n+    @Test\n+    public void testAggregationPushdown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MDMwNg==", "bodyText": "Why this is expected to fail? please add explanation.\n(same below)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616160306", "createdAt": "2021-04-19T20:36:41Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestMinimalFunctionality.java", "diffHunk": "@@ -184,6 +187,31 @@ public void testLimitForSegmentQueries()\n         assertQueryFails(\"SELECT * FROM \" + TOPIC_AND_TABLE, \"Segment query returned.*\");\n     }\n \n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        Session aggregationPushdownEnabledSession = Session.builder(getDistributedQueryRunner().getDefaultSession())\n+                .setCatalogSessionProperty(\"pinot\", \"enable_aggregation_pushdown\", \"true\")\n+                .build();\n+        String noGroupingsQueryTemplate = \"SELECT COUNT(*), SUM(%1$s), AVG(%1$s), MIN(%1$s), MAX(%1$s) FROM \" + TOPIC_AND_TABLE;\n+        assertQueryFails(format(noGroupingsQueryTemplate, \"long_number\"), \"Segment query returned.*\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MTY0MQ==", "bodyText": "seems like there is some overlap between this test and TestMinimalFunctionality.\nMaybe having one would be enough?\nI'd prefer having tests here, and trying to migrate away of \"test minimal functionality\" classes (they are lightweight, but then it's unclear which tests should be added there and which ones here, etc.)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616161641", "createdAt": "2021-04-19T20:38:54Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,357 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.trino.plugin.pinot.client.PinotHostMapper;\n+import io.trino.sql.planner.plan.AggregationNode;\n+import io.trino.sql.planner.plan.ExchangeNode;\n+import io.trino.sql.planner.plan.LimitNode;\n+import io.trino.sql.planner.plan.ProjectNode;\n+import io.trino.testing.AbstractTestQueryFramework;\n+import io.trino.testing.QueryRunner;\n+import io.trino.testing.kafka.TestingKafka;\n+import org.apache.avro.Schema;\n+import org.apache.avro.SchemaBuilder;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.shaded.org.bouncycastle.util.encoders.Hex;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.stream.IntStream;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.inject.multibindings.OptionalBinder.newOptionalBinder;\n+import static io.airlift.testing.Closeables.closeAllRuntimeException;\n+import static io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG;\n+import static java.lang.Math.abs;\n+import static java.lang.String.join;\n+import static java.util.stream.Collectors.toList;\n+import static org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG;\n+import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Test(singleThreaded = true)\n+public class TestPinotIntegrationSmokeTest\n+        extends AbstractTestQueryFramework\n+{\n+    // TODO extend BaseConnectorTest\n+    private static final String ALL_TYPES = \"alltypes\";\n+    private static final int DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES = 10;\n+    private static final int COUNT = 1000;\n+    private static final int NULL_COUNT = 17;\n+    private static final int ARRAY_NULL_COUNT = 13;\n+    private TestingPinotCluster pinot;\n+    private TestingKafka kafka;\n+    private Random random;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        random = new Random(22);\n+        kafka = TestingKafka.createWithSchemaRegistry();\n+        kafka.start();\n+        pinot = new TestingPinotCluster(kafka.getNetwork());\n+        pinot.start();\n+\n+        kafka.createTopic(ALL_TYPES);\n+\n+        int step = 3;\n+        int offset = 1;\n+        checkState(COUNT > NULL_COUNT, \"COUNT must be greater than NULL_COUNT\");\n+        checkState(NULL_COUNT > ARRAY_NULL_COUNT, \"NULL_COUNT must be greater than ARRAY_NULL_COUNT\");\n+        ImmutableList.Builder<ProducerRecord<String, GenericRecord>> builder = ImmutableList.builder();\n+        for (long i = 0; i < COUNT - NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, \"key\" + i * step, createRandomRecord(offset + i * step)));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - NULL_COUNT; i < COUNT - ARRAY_NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - ARRAY_NULL_COUNT; i < COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createArrayNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        pinot.createSchema(getClass().getClassLoader().getResourceAsStream(\"alltypes_schema.json\"), ALL_TYPES);\n+        pinot.addRealTimeTable(getClass().getClassLoader().getResourceAsStream(\"alltypes_realtimeSpec.json\"), ALL_TYPES);\n+\n+        Map<String, String> pinotProperties = ImmutableMap.<String, String>builder()\n+                .put(\"pinot.controller-urls\", pinot.getControllerConnectString())\n+                .build();\n+\n+        return PinotQueryRunner.createPinotQueryRunner(\n+                ImmutableMap.of(),\n+                pinotProperties,\n+                Optional.of(binder -> newOptionalBinder(binder, PinotHostMapper.class).setBinding()\n+                        .toInstance(new TestingPinotHostMapper(pinot.getBrokerHostAndPort(), pinot.getServerHostAndPort()))));\n+    }\n+\n+    private static ImmutableMap.Builder<String, String> schemaRegistryAwareProducer(TestingKafka testingKafka)\n+    {\n+        return ImmutableMap.<String, String>builder()\n+                .put(SCHEMA_REGISTRY_URL_CONFIG, testingKafka.getSchemaRegistryConnectString())\n+                .put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName())\n+                .put(VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void tearDown()\n+    {\n+        closeAllRuntimeException(pinot, kafka);\n+    }\n+\n+    private GenericRecord createRandomRecord(long offset)\n+    {\n+        return createTestRecord(\n+                random.ints(3, 0, 10001).limit(3).mapToObj(val -> \"string_\" + val).collect(toList()),\n+                Arrays.asList(random.nextBoolean(), random.nextBoolean(), random.nextBoolean()),\n+                random.ints().limit(3).boxed().collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().map(Double::floatValue).collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().collect(toList()),\n+                random.longs(3, ((long) Integer.MIN_VALUE) * 2, ((long) Integer.MAX_VALUE) * 2).boxed().collect(toList()),\n+                Instant.now().truncatedTo(ChronoUnit.DAYS).plusMillis(offset).toEpochMilli());\n+    }\n+\n+    private GenericRecord createArrayNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        List<String> stringList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                stringList.add(\"string_\" + abs(random.nextInt(10001)));\n+            }\n+            else {\n+                stringList.add(null);\n+            }\n+        }\n+        List<Boolean> booleanList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                booleanList.add(random.nextBoolean());\n+            }\n+            else {\n+                booleanList.add(null);\n+            }\n+        }\n+\n+        List<Integer> integerList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            integerList.add(null);\n+        }\n+\n+        List<Integer> integerWithDefaultList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                integerWithDefaultList.add(random.nextInt(10000));\n+            }\n+            else {\n+                integerWithDefaultList.add(null);\n+            }\n+        }\n+\n+        List<Float> floatList = new ArrayList<>();\n+        floatList.add(null);\n+\n+        List<Integer> doubleList = new ArrayList<>();\n+        doubleList.add(null);\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_array_col\", stringList)\n+                .set(\"bool_array_col\", booleanList)\n+                .set(\"int_array_col\", integerList)\n+                .set(\"int_array_col_with_pinot_default\", integerWithDefaultList)\n+                .set(\"float_array_col\", floatList)\n+                .set(\"double_array_col\", doubleList)\n+                .set(\"long_array_col\", new ArrayList<>())\n+                .build();\n+    }\n+\n+    private static GenericRecord createTestRecord(\n+            List<String> stringArrayColumn,\n+            List<Boolean> booleanArrayColumn,\n+            List<Integer> intArrayColumn,\n+            List<Float> floatArrayColumn,\n+            List<Double> doubleArrayColumn,\n+            List<Long> longArrayColumn,\n+            long updatedAtMillis)\n+    {\n+        Schema schema = getAvroSchema();\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_CoL\", stringArrayColumn.get(0))\n+                .set(\"bool_COL\", booleanArrayColumn.get(0))\n+                .set(\"bytes_col\", Hex.toHexString(stringArrayColumn.get(0).getBytes(StandardCharsets.UTF_8)))\n+                .set(\"string_array_col\", stringArrayColumn)\n+                .set(\"bool_array_col\", booleanArrayColumn)\n+                .set(\"int_array_col\", intArrayColumn)\n+                .set(\"int_array_col_with_pinot_default\", intArrayColumn)\n+                .set(\"float_array_col\", floatArrayColumn)\n+                .set(\"double_array_col\", doubleArrayColumn)\n+                .set(\"long_array_col\", longArrayColumn)\n+                .set(\"int_CoL\", intArrayColumn.get(0))\n+                .set(\"float_col\", floatArrayColumn.get(0))\n+                .set(\"double_col\", doubleArrayColumn.get(0))\n+                .set(\"long_CoL\", longArrayColumn.get(0))\n+                .set(\"updated_at\", updatedAtMillis)\n+                .build();\n+    }\n+\n+    private static GenericRecord createNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        return new GenericRecordBuilder(schema).build();\n+    }\n+\n+    private static Schema getAvroSchema()\n+    {\n+        // Note:\n+        // The reason optional() is used is because the avro record can omit those fields.\n+        // Fields with nullable type are required to be included or have a default value.\n+        // ex. if \"string_col\" is set to type().nullable().stringType().noDefault()\n+        // the following error is returned: Field string_col type:UNION pos:0 not set and has no default value\n+\n+        return SchemaBuilder.record(\"alltypes\")\n+                .fields()\n+                .name(\"string_CoL\").type().optional().stringType()\n+                .name(\"bool_COL\").type().optional().booleanType()\n+                .name(\"bytes_col\").type().optional().stringType()\n+                .name(\"string_array_col\").type().optional().array().items().nullable().stringType()\n+                .name(\"bool_array_col\").type().optional().array().items().nullable().booleanType()\n+                .name(\"int_array_col\").type().optional().array().items().nullable().intType()\n+                .name(\"int_array_col_with_pinot_default\").type().optional().array().items().nullable().intType()\n+                .name(\"float_array_col\").type().optional().array().items().nullable().floatType()\n+                .name(\"double_array_col\").type().optional().array().items().nullable().doubleType()\n+                .name(\"long_array_col\").type().optional().array().items().nullable().longType()\n+                .name(\"int_CoL\").type().optional().intType()\n+                .name(\"float_col\").type().optional().floatType()\n+                .name(\"double_col\").type().optional().doubleType()\n+                .name(\"long_CoL\").type().optional().longType()\n+                .name(\"updated_at\").type().optional().longType()\n+                .endRecord();\n+    }\n+\n+    @Test\n+    public void testCount()\n+    {\n+        assertQuery(\"SELECT \\\"count(*)\\\" FROM \\\"SELECT COUNT(*) FROM \" + ALL_TYPES + \"\\\"\", \"VALUES(\" + COUNT + \")\");\n+        // If no limit is supplied to a broker query, 10 rows will be returned. Verify this behavior:\n+        assertQuery(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES + \"\\\"\", \"VALUES (\" + DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES + \")\");\n+    }\n+\n+    @Test\n+    public void testNullBehavior()\n+    {\n+        // Verify the null behavior of pinot:\n+        // Default null value for varbinary (BYtES in pinot) is X''\n+        // Arrays of varbinary are not supported in pinot\n+        // Default null value for long single value columns is 0\n+        // Default null value for long array values is Long.MIN_VALUE,\n+        // Default null value for int single value columns is 0\n+        // Default null value for int array values is Integer.MIN_VALUE,\n+        // Default null value for float single value columns is 0.0F\n+        // Default null value for float array values is -INFINITY,\n+        // Default null value for double single value columns is 0.0D\n+        // Default null value for double array values is -INFINITY,\n+\n+        assertQuery(\"SELECT MIN(long_col), MIN(element_at(long_array_col, 1)),\" +\n+                        \"  MIN(int_col), MIN(element_at(int_array_col, 1)), MIN(element_at(int_array_col_with_pinot_default, 1)),\" +\n+                        \"  MIN(float_col), MIN(element_at(float_array_col, 1)),\" +\n+                        \"  MIN(double_col), MIN(element_at(double_array_col, 1))\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X''\",\n+                \"VALUES(0, \" + Long.MIN_VALUE + \", \" +\n+                        \"  0, \" + Integer.MIN_VALUE + \", 7,\" +\n+                        \"  0.0, -POWER(0, -1),\" +\n+                        \"  0.0, -POWER(0, -1)\" +\n+                        \")\");\n+\n+        // Default null value for strings is the string 'null'\n+        // Default null value for booleans is the string 'null', boolean is treated as a string\n+        assertQuery(\"SELECT DISTINCT string_col, element_at(string_array_col, 1), bool_col, element_at(bool_array_col, 1)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES ('null', 'null', 'null', 'null')\");\n+\n+        // Null behavior for arrays:\n+        // Default value for a \"null\" array is 1 element with default null array value,\n+        // ex.\n+        // Null string or boolean arrays will have ['null'] as the default,\n+        // Null integer arrays will have [Integer.MIN_VALUE] as the default\n+        // Null long arrays will have [Long.MIN_VALUE] as the default,\n+        // Null float arrays will have [-INFINITY] as the default\n+        // Null double arrays will have [-INFINITY] as the default\n+        // As mentioned above, arrays of varbinary are not supported\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, NULL_COUNT - ARRAY_NULL_COUNT).mapToObj(i -> \"(1, 1, 1, 1, 1, 1, 1)\").collect(toList())));\n+\n+        // If an array contains both null and non-null values, the null values are omitted:\n+        // There are 5 values in the avro records, but only the 3 non-null values are in pinot\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(bool_array_col, 1) != 'null'\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, ARRAY_NULL_COUNT).mapToObj(i -> \"(3, 3, 1, 3, 1, 1, 1)\").collect(toList())));\n+    }\n+\n+    @Test\n+    public void testAggregationPushdown()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 329}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MjEwMw==", "bodyText": "sum is defined for doubles, but also for bigint, decimal. is it an issue?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616162103", "createdAt": "2021-04-19T20:39:35Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -41,7 +41,7 @@\n     private static final CalciteSqlCompiler REQUEST_COMPILER = new CalciteSqlCompiler();\n     private static final String COLUMN_KEY = \"column\";\n     private static final String WILDCARD = \"*\";\n-    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"distinctcounthll\", \"avg\");\n+    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"sum\", \"distinctcounthll\", \"avg\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc5NDEwOTgw", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-679410980", "createdAt": "2021-06-09T09:16:49Z", "commit": null, "state": "DISMISSED", "comments": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0wOVQwOToxNjo0OVrOJqGN7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0wOVQxMDoxMToyMlrOJqIsUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyMTgzNw==", "bodyText": "Second argument is connectorName, so we should pass \"pinot\" here, not PINOT_CATALOG", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648121837", "createdAt": "2021-06-09T09:16:49Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/PinotQueryRunner.java", "diffHunk": "@@ -40,15 +42,15 @@ public static DistributedQueryRunner createPinotQueryRunner(Map<String, String>\n                 .setExtraProperties(extraProperties)\n                 .build();\n         queryRunner.installPlugin(new PinotPlugin(extension));\n-        queryRunner.createCatalog(\"pinot\", \"pinot\", extraPinotProperties);\n+        queryRunner.createCatalog(PINOT_CATALOG, PINOT_CATALOG, extraPinotProperties);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyNjIzNg==", "bodyText": "This should be either handled by the caller of getColumnIndices method, or reflected in the name.\nOtherwise getColumnIndices([\"Something\"]).get(\"Something\") returns null, instead of 0.\nBTW since getColumnIndices is called in one place only, I would just make it more fluent and inline:\nMap<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n        .boxed()\n        // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n        .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n\nThen toLowerCase use when building the Map, and when querying it will be in the same method, which ensures the map is used correctly.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648126236", "createdAt": "2021-06-09T09:22:40Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -419,9 +420,12 @@ protected BrokerResultRow computeNext()\n \n     private static Map<String, Integer> getColumnIndices(String[] columnNames)\n     {\n+        // Note:\n+        // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n+        // To avoid mismatches, lower case all column names\n         ImmutableMap.Builder<String, Integer> columnIndicesBuilder = ImmutableMap.builder();\n         for (int index = 0; index < columnNames.length; index++) {\n-            columnIndicesBuilder.put(columnNames[index], index);\n+            columnIndicesBuilder.put(columnNames[index].toLowerCase(ENGLISH), index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyNzkyOQ==", "bodyText": "Fix filter pushdown for segment queries\n\ncall it \"Remove enforced filter for Pinot segment queries\"", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648127929", "createdAt": "2021-06-09T09:24:48Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -267,7 +291,7 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n                 newDomain,\n                 handle.getLimit(),\n                 handle.getQuery());\n-        return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary(), false));\n+        return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyODM4OA==", "bodyText": "I don't think it's helpful, especially given that the code below is different than the DefaultJdbcMetadata's.\nRemove comment", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648128388", "createdAt": "2021-06-09T09:25:23Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -254,9 +256,31 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n     {\n         PinotTableHandle handle = (PinotTableHandle) table;\n         TupleDomain<ColumnHandle> oldDomain = handle.getConstraint();\n-        // Pinot does not support array literals\n-        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary())\n-                .filter((columnHandle, domain) -> !(((PinotColumnHandle) columnHandle).getDataType() instanceof ArrayType));\n+\n+        // Extracted from DefaultJdbcMetadata", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMTE0NQ==", "bodyText": "Is every other (non-array) filter enforced strictly, including varchar predicates (potentnial case (in)sensitivity issues)?\nWe apparently do not run io.trino.testing.AbstractTestDistributedQueries#testDataMappingSmokeTest and io.trino.testing.AbstractTestDistributedQueries#testCaseSensitiveDataMapping for Pinot yet. This is important.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648131145", "createdAt": "2021-06-09T09:28:59Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -254,9 +256,31 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n     {\n         PinotTableHandle handle = (PinotTableHandle) table;\n         TupleDomain<ColumnHandle> oldDomain = handle.getConstraint();\n-        // Pinot does not support array literals\n-        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary())\n-                .filter((columnHandle, domain) -> !(((PinotColumnHandle) columnHandle).getDataType() instanceof ArrayType));\n+\n+        // Extracted from DefaultJdbcMetadata\n+        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary());\n+        TupleDomain<ColumnHandle> remainingFilter;\n+        if (newDomain.isNone()) {\n+            remainingFilter = TupleDomain.all();\n+        }\n+        else {\n+            Map<ColumnHandle, Domain> domains = newDomain.getDomains().orElseThrow();\n+\n+            Map<ColumnHandle, Domain> supported = new HashMap<>();\n+            Map<ColumnHandle, Domain> unsupported = new HashMap<>();\n+            for (Map.Entry<ColumnHandle, Domain> entry : domains.entrySet()) {\n+                // Pinot does not support array literals\n+                if (((PinotColumnHandle) entry.getKey()).getDataType() instanceof ArrayType) {\n+                    unsupported.put(entry.getKey(), entry.getValue());\n+                }\n+                else {\n+                    supported.put(entry.getKey(), entry.getValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMTg1OA==", "bodyText": "This looks like a refactor. Let's move it out of \"Fix filter pushdown for segment queries\" commit.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648131858", "createdAt": "2021-06-09T09:29:51Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/PinotQueryBuilder.java", "diffHunk": "@@ -100,11 +101,9 @@ private static void generateFilterPql(StringBuilder pqlBuilder, PinotTableHandle\n         ImmutableList.Builder<String> conjunctsBuilder = ImmutableList.builder();\n         timePredicate.ifPresent(conjunctsBuilder::add);\n         if (!tupleDomain.equals(TupleDomain.all())) {\n-            for (PinotColumnHandle columnHandle : columnHandles) {\n-                Domain domain = tupleDomain.getDomains().get().get(columnHandle);\n-                if (domain != null) {\n-                    conjunctsBuilder.add(toPredicate(columnHandle.getColumnName(), domain));\n-                }\n+            Map<ColumnHandle, Domain> domains = tupleDomain.getDomains().orElseThrow();\n+            for (Map.Entry<ColumnHandle, Domain> entry : domains.entrySet()) {\n+                conjunctsBuilder.add(toPredicate(((PinotColumnHandle) entry.getKey()).getColumnName(), entry.getValue()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMzY2MA==", "bodyText": "The intent of QueryAssert (assertThat(query(...))) is to avoid methods with many overloads, or abstractions that make it harder to add more assertions. I.e. the assertThat(query(...)) should typically be used directly. If there is something preventing us from doing that (e.g. so verbose that it's unreadable) we should think how to improve.\nPlease inline these.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648133660", "createdAt": "2021-06-09T09:32:13Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -417,6 +419,16 @@ public static Object of(\n         }\n     }\n \n+    private void checkResultMatchesAndIsPushedDown(@Language(\"SQL\") String query, @Language(\"SQL\") String expected)\n+    {\n+        assertThat(query(query)).matches(expected).isFullyPushedDown();\n+    }\n+\n+    private void checkResultMatchesAndIsNotPushedDown(@Language(\"SQL\") String query, @Language(\"SQL\") String expected, Class<? extends PlanNode>... retainedNodes)\n+    {\n+        assertThat(query(query)).matches(expected).isNotFullyPushedDown(retainedNodes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNDE5Mg==", "bodyText": "'string_3' and VARCHAR 'string_3' is the same value and same type. Please remove VARCHAR.\nWhy the third value changed its type from varchar to BIGINT?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648134192", "createdAt": "2021-06-09T09:32:55Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -520,16 +530,16 @@ public void testNonLowerCaseColumnNames()\n                         \"  FROM  \\\"SELECT updatedatseconds, longcol, stringcol FROM \" + MIXED_CASE_COLUMN_NAMES_TABLE + \"\\\"\",\n                 mixedCaseColumnNamesTableValues);\n \n-        String singleRowValues = \"VALUES ('string_3', '3', '1620604803')\";\n+        String singleRowValues = \"VALUES (VARCHAR 'string_3', BIGINT '3', BIGINT '1620604803')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNTEyNg==", "bodyText": "VARCHAR is redundant here", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648135126", "createdAt": "2021-06-09T09:34:09Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -732,33 +742,33 @@ public void testBrokerQueriesWithCaseStatementsInFilter()\n     @Test\n     public void testFilterWithRealLiteral()\n     {\n-        String expectedSingleValue = \"VALUES ('3.5', 'vendor1')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price = 3.5\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price <= 3.5\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3 AND 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 3 AND price < 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 3.5 AND price <= 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 3.6\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5)\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5, 4)\", expectedSingleValue);\n+        String expectedSingleValue = \"VALUES (REAL '3.5', VARCHAR 'vendor1')\";\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price = 3.5\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price <= 3.5\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3 AND 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 3 AND price < 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 3.5 AND price <= 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 3.6\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5)\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5, 4)\", expectedSingleValue);\n         // NOT IN is not pushed down\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price NOT IN (4.5, 5.5, 6.5, 7.5, 8.5, 9.5)\")).isNotFullyPushedDown(FilterNode.class);\n \n         String expectedMultipleValues = \"VALUES\" +\n-                \"  ('3.5', 'vendor1'),\" +\n-                \"  ('4.5', 'vendor2')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 4.6\", expectedMultipleValues);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3.5 AND 4.5\", expectedMultipleValues);\n-\n-        String expectedMaxValue = \"VALUES ('9.5', 'vendor7')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 9\", expectedMaxValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 9\", expectedMaxValue);\n+                \"  (REAL '3.5', VARCHAR 'vendor1'),\" +\n+                \"  (REAL '4.5', VARCHAR 'vendor2')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNzYzMw==", "bodyText": "Maybe add sth like\nLimit is guaranteed when dynamicTable is present, because broker query has one split.\n\nor even better:\nboolean singleSplit = dynamicTable.isPresent();\nreturn Optional.of(new LimitApplicationResult<>(handle, singleSplit, false));", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648137633", "createdAt": "2021-06-09T09:37:33Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -248,7 +248,7 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n                 handle.getConstraint(),\n                 OptionalLong.of(limit),\n                 dynamicTable);\n-        return Optional.of(new LimitApplicationResult<>(handle, false, false));\n+        return Optional.of(new LimitApplicationResult<>(handle, dynamicTable.isPresent(), false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTAxNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n          \n          \n            \n            \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\" \" +", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139015", "createdAt": "2021-06-09T09:39:20Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTQ1Mw==", "bodyText": "fmt:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n          \n          \n            \n                            \"  WHERE int_col > 0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n          \n          \n            \n            Write", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139453", "createdAt": "2021-06-09T09:39:54Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n+                \"  WHERE bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE +\n+                \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTg0MA==", "bodyText": "Why false is in quotes?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139840", "createdAt": "2021-06-09T09:40:23Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n+                \"  WHERE bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE +\n+                \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MDAwMg==", "bodyText": "copy naming and test cases from io.trino.plugin.jdbc.BaseJdbcConnectorTest#testLimitPushdown", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648140002", "createdAt": "2021-06-09T09:40:37Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MTY5NQ==", "bodyText": "maybe something \"approximate-count-distinct\"\nbut i am not convinced we want this at all. Instead, we should support pushdown for approx_distinct.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648141695", "createdAt": "2021-06-09T09:42:48Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +260,38 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.aggregation-pushdown.enabled\")\n+    public PinotConfig setAggregationPushdownEnabled(boolean aggregationPushdownEnabled)\n+    {\n+        this.aggregationPushdownEnabled = aggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isDistinctCountHllEnabled()\n+    {\n+        return distinctCountHllEnabled;\n+    }\n+\n+    /**\n+     * Pinot distinctcounthll benefits from the star tree index.\n+     * For performance reasons this may be desirable.\n+     * The default behavior is to group by the grouping columns\n+     * and the distinct count column, and use trino to do the\n+     * final aggregation.\n+     * @param distinctCountHllEnabled\n+     * @return\n+     */\n+    @Config(\"pinot.distinct-count-hll.enabled\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MzE3OA==", "bodyText": ".orElseThrow(() -> ...) since you assume below the expression must be present", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648143178", "createdAt": "2021-06-09T09:44:40Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NTA1NQ==", "bodyText": "Add explanation", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648145055", "createdAt": "2021-06-09T09:47:11Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NTE3Nw==", "bodyText": "Explain why.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648145177", "createdAt": "2021-06-09T09:47:19Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NjYxMw==", "bodyText": "The input validation is not spread across two methods.\nInline.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648146613", "createdAt": "2021-06-09T09:49:14Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1MDU4NA==", "bodyText": "SUPPORTED_AGGREGATIONS should contain names of Trino aggregate functions.\nremove distinctcounthll  from it.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648150584", "createdAt": "2021-06-09T09:54:20Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+        String outputColumnName = format(\"distinctcounthll(%s)\", inputExpression.get());\n+        aggregationExpressions.add(new AggregationExpression(\n+                outputColumnName,\n+                inputExpression.get(),\n+                \"distinctcounthll\"));\n+        PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, DOUBLE);\n+        projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+        resultAssignments.add(new Assignment(outputColumnName, newColumn, DOUBLE));\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (!SUPPORTED_AGGREGATIONS.contains(aggregateFunction.getFunctionName()) ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1NjM3NA==", "bodyText": "sort items don't matter for count function", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648156374", "createdAt": "2021-06-09T10:02:33Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+        String outputColumnName = format(\"distinctcounthll(%s)\", inputExpression.get());\n+        aggregationExpressions.add(new AggregationExpression(\n+                outputColumnName,\n+                inputExpression.get(),\n+                \"distinctcounthll\"));\n+        PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, DOUBLE);\n+        projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+        resultAssignments.add(new Assignment(outputColumnName, newColumn, DOUBLE));\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (!SUPPORTED_AGGREGATIONS.contains(aggregateFunction.getFunctionName()) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent()) {\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static Optional<String> getInputExpression(AggregateFunction aggregateFunction, Map<String, ColumnHandle> columnHandles)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        // Pinot converts count(column_name) to count(*)\n+        if (isCountStarFunction(aggregateFunction)) {\n+            return Optional.of(\"*\");\n+        }\n+        if (aggregateFunction.getInputs().size() != 1) {\n+            return Optional.empty();\n+        }\n+        String inputColumnName = ((Variable) getOnlyElement(aggregateFunction.getInputs())).getName();\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) columnHandles.get(inputColumnName);\n+        if (pinotColumnHandle != null && SUPPORTED_INPUT_TYPES.contains(pinotColumnHandle.getDataType())) {\n+            return Optional.of(pinotColumnHandle.getColumnName());\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static boolean isCountFunction(AggregateFunction aggregateFunction)\n+    {\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        return aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false);\n+    }\n+\n+    private static boolean isCountStarFunction(AggregateFunction aggregateFunction)\n+    {\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        return aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false) &&\n+                aggregateFunction.getInputs().isEmpty() &&\n+                !aggregateFunction.isDistinct() &&\n+                aggregateFunction.getFilter().isEmpty() &&\n+                aggregateFunction.getSortItems().isEmpty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1ODY1NQ==", "bodyText": "This should be handled for individual functions separately. What would it take to use AggregateFunctionRewriter here?\nAlso, checking isDistinct is not enough.\nSee io.trino.plugin.jdbc.expression.AggregateFunctionPatterns#basicAggregation which matches only \"basic\" aggregation functions, without features that are both:  easy to forget about and hard to implement in the remote system.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648158655", "createdAt": "2021-06-09T10:05:52Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE2MjM4NQ==", "bodyText": "in DynamicTable what are the semantics of filters, aggregations, sorting, etc?\nWhich is applied first, which is second, etc.?\nCurrent ordering of fields suggest that aggregation comes before filter, so this line looks incorrect -- you are transposing pre-existing filter with an aggregation.\nIf this is \"just\" a matter of field ordering in DynamicTable, please update it and add commentary like here:\n\n  \n    \n      trino/presto-base-jdbc/src/main/java/io/prestosql/plugin/jdbc/JdbcTableHandle.java\n    \n    \n        Lines 47 to 56\n      in\n      b52bcd7\n    \n    \n    \n    \n\n        \n          \n           private final TupleDomain<ColumnHandle> constraint; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // semantically aggregation is applied after constraint \n        \n\n        \n          \n           private final Optional<List<List<JdbcColumnHandle>>> groupingSets; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // semantically limit is applied after aggregation \n        \n\n        \n          \n           private final OptionalLong limit; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // columns of the relation described by this handle, after projections, aggregations, etc. \n        \n\n        \n          \n           private final Optional<List<JdbcColumnHandle>> columns; \n        \n    \n  \n\n\nWhen doing that, sure the ordering of fields matches that of constructor arguments, they are equally important!", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648162385", "createdAt": "2021-06-09T10:11:22Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk4MzkxNjc2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-698391676", "createdAt": "2021-07-02T17:39:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMlQxNzozOTowN1rOJ4cT5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMlQxODowNzozNFrOJ4dF-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Mzg3OA==", "bodyText": "Where does this number come from? What are the implications of using a smaller or larger number?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663163878", "createdAt": "2021-07-02T17:39:07Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +317,74 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate and grouping columns are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<AggregationFunctionRewriteResult> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            aggregationExpressions.add(rewriteResult.get().getAggregationExpression());\n+            projections.add(rewriteResult.get().getProjection());\n+            resultAssignments.add(rewriteResult.get().getAssignment());\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        // Currently pinot has a max limit of Integer.MAX_VALUE\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(1_000_000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NDYyOQ==", "bodyText": "This might be easier to read as:\n if (tableHandle.getQuery().isPresent() &&\n    (!tableHandle.getQuery().get().getAggregateColumns().isEmpty() || !tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\nBasically, \"if the query is present and either aggregate columns or grouping columns are non-empty...\"", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663164629", "createdAt": "2021-07-02T17:40:52Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +317,74 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate and grouping columns are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzAzMA==", "bodyText": "Is this a reliable way to tell if it's count(*)? Maybe we should encode that in the column handle and tag them when the operation is pushed down.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167030", "createdAt": "2021-07-02T17:45:47Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -479,7 +480,20 @@ public static ResultsIterator fromResultTable(ResultTable resultTable, List<Pino\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from an aggregate with no grouping columns, make sure all non-count columns are null\n+        if (brokerResponse.getNumDocsScanned() == 0 && resultTable.getRows().size() == 1) {\n+            Object[] originalRow = getOnlyElement(resultTable.getRows());\n+            Object[] newRow = new Object[originalRow.length];\n+            for (int i = 0; i < originalRow.length; i++) {\n+                if (resultTable.getDataSchema().getColumnName(i).equals(\"count(*)\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzY2OA==", "bodyText": "Unrelated formatting changes", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167668", "createdAt": "2021-07-02T17:46:48Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,34 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n+\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n+\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzgzNw==", "bodyText": "Why did this change position?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167837", "createdAt": "2021-07-02T17:47:08Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,34 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n+\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n+\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;\n \n     @JsonCreator\n     public DynamicTable(\n             @JsonProperty(\"tableName\") String tableName,\n             @JsonProperty(\"suffix\") Optional<String> suffix,\n             @JsonProperty(\"selections\") List<String> selections,\n-            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n             @JsonProperty(\"filter\") Optional<String> filter,\n+            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Nzk4Mw==", "bodyText": "Why did this change position?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167983", "createdAt": "2021-07-02T17:47:24Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -54,8 +65,8 @@ public DynamicTable(\n         this.tableName = requireNonNull(tableName, \"tableName is null\");\n         this.suffix = requireNonNull(suffix, \"suffix is null\");\n         this.selections = ImmutableList.copyOf(requireNonNull(selections, \"selections is null\"));\n-        this.groupingColumns = ImmutableList.copyOf(requireNonNull(groupingColumns, \"groupingColumns is null\"));\n         this.filter = requireNonNull(filter, \"filter is null\");\n+        this.groupingColumns = ImmutableList.copyOf(requireNonNull(groupingColumns, \"groupingColumns is null\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODQ2OQ==", "bodyText": "Unrelated change (i.e., reordering of methods). If it's warranted, move it to a separate commit.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663168469", "createdAt": "2021-07-02T17:48:27Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -76,9 +87,9 @@ public String getTableName()\n     }\n \n     @JsonProperty\n-    public List<String> getGroupingColumns()\n+    public List<String> getSelections()\n     {\n-        return groupingColumns;\n+        return selections;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw==", "bodyText": "What happened to distinctcounthll?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663168763", "createdAt": "2021-07-02T17:49:05Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -42,8 +47,9 @@\n     private static final CalciteSqlCompiler REQUEST_COMPILER = new CalciteSqlCompiler();\n     private static final String COLUMN_KEY = \"column\";\n     private static final String WILDCARD = \"*\";\n-    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"distinctcounthll\", \"avg\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE3MzE2OA==", "bodyText": "Why is this not part of the pattern?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663173168", "createdAt": "2021-07-02T17:59:02Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementMinMax.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code min(x)}, {@code max(x)}.\n+ */\n+public class ImplementMinMax\n+        implements AggregateFunctionRule\n+{\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().matching(Set.of(\"min\", \"max\")::contains))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<AggregationFunctionRewriteResult> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        if (!isSupportedSingleColumnAggregateFunction(aggregateFunction, context)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE3NjY5Nw==", "bodyText": "Remove commented out code", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663176697", "createdAt": "2021-07-02T18:07:34Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementSum.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code sum(x)}\n+ */\n+public class ImplementSum\n+        implements AggregateFunctionRule\n+{\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    //public ImplementSum(Function<DecimalType, Optional<JdbcTypeHandle>> decimalTypeHandle)\n+    public ImplementSum()\n+    {\n+        //this.decimalTypeHandle = requireNonNull(decimalTypeHandle, \"decimalTypeHandle is null\");\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNDE3NDI5", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-701417429", "createdAt": "2021-07-07T20:25:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QyMDoyNTo0OVrOJ62GKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QyMDozNToyMFrOJ62bng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4MzQ5Nw==", "bodyText": "This should go in the first commit", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665683497", "createdAt": "2021-07-07T20:25:49Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -233,8 +251,8 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n             dynamicTable = Optional.of(new DynamicTable(dynamicTable.get().getTableName(),\n                     dynamicTable.get().getSuffix(),\n                     dynamicTable.get().getSelections(),\n-                    dynamicTable.get().getGroupingColumns(),\n                     dynamicTable.get().getFilter(),\n+                    dynamicTable.get().getGroupingColumns(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NDkwNA==", "bodyText": "This change should go in the first commit.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665684904", "createdAt": "2021-07-07T20:28:16Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,34 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n+\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n+\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;\n \n     @JsonCreator\n     public DynamicTable(\n             @JsonProperty(\"tableName\") String tableName,\n             @JsonProperty(\"suffix\") Optional<String> suffix,\n             @JsonProperty(\"selections\") List<String> selections,\n-            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n             @JsonProperty(\"filter\") Optional<String> filter,\n+            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzgzNw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NTE5OQ==", "bodyText": "This change should go in the first commit", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665685199", "createdAt": "2021-07-07T20:28:49Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,24 +29,33 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n-    private final List<AggregationExpression> aggregateColumns;\n+    private final List<PinotColumnHandle> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;\n \n     @JsonCreator\n     public DynamicTable(\n             @JsonProperty(\"tableName\") String tableName,\n             @JsonProperty(\"suffix\") Optional<String> suffix,\n             @JsonProperty(\"selections\") List<String> selections,\n-            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n             @JsonProperty(\"filter\") Optional<String> filter,\n-            @JsonProperty(\"aggregateColumns\") List<AggregationExpression> aggregateColumns,\n+            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n+            @JsonProperty(\"aggregateColumns\") List<PinotColumnHandle> aggregateColumns,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NTQ2NQ==", "bodyText": "I looks like this is still not resolved. Move the change to the first commit.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665685465", "createdAt": "2021-07-07T20:29:21Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -76,9 +87,9 @@ public String getTableName()\n     }\n \n     @JsonProperty\n-    public List<String> getGroupingColumns()\n+    public List<String> getSelections()\n     {\n-        return groupingColumns;\n+        return selections;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODQ2OQ=="}, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NjIxMA==", "bodyText": "Place one argument per line when splitting arguments across lines. So, format it like this:\naggregateColumnsBuilder.add(new PinotColumnHandle(\n        aggregationFunction.getResultColumnName(),\n        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665686210", "createdAt": "2021-07-07T20:30:42Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,47 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(aggregationFunction.getResultColumnName(),\n+                        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NjU1MA==", "bodyText": "I'd just call this toTrinoType", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665686550", "createdAt": "2021-07-07T20:31:20Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,47 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(aggregationFunction.getResultColumnName(),\n+                        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));\n             }\n         }\n \n-        return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+        return new DynamicTable(pinotTableName, suffix, selectionColumns, filter, groupByColumns, aggregateColumnsBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+    }\n+\n+    private static Type getTrinoTypeFromColumnDataType(DataSchema.ColumnDataType columnDataType)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4ODk5MA==", "bodyText": "It's not very clear what this means. I would call this \"returnNullOnEmptyGroup\" and adjust the code accordingly.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665688990", "createdAt": "2021-07-07T20:35:20Z", "author": {"login": "martint"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -56,6 +64,12 @@ public ColumnMetadata getColumnMetadata()\n         return new ColumnMetadata(getColumnName(), getDataType());\n     }\n \n+    @JsonProperty\n+    public boolean isPreservePinotEmptyAggregateValue()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAwNDI2Njc4", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-700426678", "createdAt": "2021-07-06T22:21:44Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQyMjoyMTo0NFrOJ6HITA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QyMjoxNjoyMlrOJ65lCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkxMzk5Ng==", "bodyText": "so we need to register here whenever we implement a new pushdown? Can we make this to something using  Reflectionor or Annotation?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r664913996", "createdAt": "2021-07-06T22:21:44Z", "author": {"login": "xiangfu0"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -100,6 +114,14 @@ public PinotMetadata(\n                         }, executor));\n \n         executor.execute(() -> this.allTablesCache.refresh(ALL_TABLES_CACHE_KEY));\n+        this.maxRowsPerBrokerQuery = pinotConfig.getMaxRowsForBrokerQueries();\n+        this.aggregateFunctionRewriter = new AggregateFunctionRewriter(identity(), ImmutableSet.<AggregateFunctionRule>builder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkyNTMyNA==", "bodyText": "Do we need this limitForBrokerQueries in PinotBrokerPageSource? I feel we should leverage this in the planning phase, if it's large than this number, then we can fall back to segment-level query without broker pushdown?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r664925324", "createdAt": "2021-07-06T22:50:44Z", "author": {"login": "xiangfu0"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotBrokerPageSource.java", "diffHunk": "@@ -45,20 +49,24 @@\n     private boolean finished;\n     private long readTimeNanos;\n     private long completedBytes;\n+    private final AtomicLong currentRowCount = new AtomicLong();\n+    private final int limitForBrokerQueries;\n \n     private Iterator<BrokerResultRow> resultIterator;\n \n     public PinotBrokerPageSource(\n             ConnectorSession session,\n             PinotQuery query,\n             List<PinotColumnHandle> columnHandles,\n-            PinotClient pinotClient)\n+            PinotClient pinotClient,\n+            int limitForBrokerQueries)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTcxODQyOA==", "bodyText": "Can you add some comments on this, why we need it?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665718428", "createdAt": "2021-07-07T21:29:24Z", "author": {"login": "xiangfu0"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -29,14 +29,22 @@\n {\n     private final String columnName;\n     private final Type dataType;\n+    private final boolean preservePinotEmptyAggregateValue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ==", "bodyText": "Also, do you have any idea how we can push down count(distinct A) to Pinot as distinctCount(A)  or  count(distinct A) ?\nNote, Pinot internal will rewrite count(distinct A)  to distinctCount(A) as well.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665740555", "createdAt": "2021-07-07T22:16:22Z", "author": {"login": "xiangfu0"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -100,6 +114,14 @@ public PinotMetadata(\n                         }, executor));\n \n         executor.execute(() -> this.allTablesCache.refresh(ALL_TABLES_CACHE_KEY));\n+        this.maxRowsPerBrokerQuery = pinotConfig.getMaxRowsForBrokerQueries();\n+        this.aggregateFunctionRewriter = new AggregateFunctionRewriter(identity(), ImmutableSet.<AggregateFunctionRule>builder()\n+                .add(new ImplementCountAll())\n+                .add(new ImplementAvg())\n+                .add(new ImplementMinMax())\n+                .add(new ImplementSum())\n+                .add(new ImplementApproxDistinct())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA4MzA2ODQz", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-708306843", "createdAt": "2021-07-16T11:55:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMTo1NToyN1rOKAF7kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMTo1Nzo1NlrOKAGAlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NTgxMA==", "bodyText": "preservePinotEmptyAggregateValue -> returnNullOnEmptyGroup", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671185810", "createdAt": "2021-07-16T11:55:27Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -83,6 +99,7 @@ public String toString()\n         return toStringHelper(this)\n                 .add(\"columnName\", columnName)\n                 .add(\"dataType\", dataType)\n+                .add(\"preservePinotEmptyAggregateValue\", returnNullOnEmptyGroup)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NjM2MA==", "bodyText": "\"after sorting\"", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671186360", "createdAt": "2021-07-16T11:56:34Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NjUxNg==", "bodyText": "add // semantically sorting is applied after aggregation", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671186516", "createdAt": "2021-07-16T11:56:51Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw==", "bodyText": "should query be moved before filter, aggregations, sorting and limit?\nie are filter, aggregations, sorting and limit applied on top of a query?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671187003", "createdAt": "2021-07-16T11:57:45Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzA5Mg==", "bodyText": "what about selections?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671187092", "createdAt": "2021-07-16T11:57:56Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw=="}, "originalCommit": null, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA4MzIwMTc0", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-708320174", "createdAt": "2021-07-16T12:05:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMjowNTozN1rOKAGQ3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMjowOTowMlrOKAGaDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw==", "bodyText": "I understand limitForBrokerQueries is a temporary workaround until fix for apache/pinot#7110 is widespread. Let's add a TODO comment here so that we can remove this.\nAnyway, i don't quite understand why we want to do this.\nWe apply limit after the fact. We already know Pinot didn't crash and handled our query correctly.\nPlease store the explanation as a code comment.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671191263", "createdAt": "2021-07-16T12:05:37Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotBrokerPageSource.java", "diffHunk": "@@ -113,6 +121,9 @@ public Page getNextPage()\n         int rowCount = 0;\n         while (size < PageBuilderStatus.DEFAULT_MAX_PAGE_SIZE_IN_BYTES && resultIterator.hasNext()) {\n             rowCount++;\n+            if (currentRowCount.incrementAndGet() > limitForBrokerQueries) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTk1Ng==", "bodyText": "Looks like TestBrokerQueries could benefit from a test that shows that the broker queries limit gets applied.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671191956", "createdAt": "2021-07-16T12:06:50Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestBrokerQueries.java", "diffHunk": "@@ -46,6 +46,7 @@\n     private static final DataSchema DATA_SCHEMA;\n     private static final List<Object[]> TEST_DATA;\n     private static final ResultTable RESULT_TABLE;\n+    private static final int LIMIT_FOR_BROKER_QUERIES = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MzYxNA==", "bodyText": "where does -2147483648 come from? it's an integer overflow on the Pinot side, right?\nplease add a link to a Pinot issue here for clarify\n// Note that -2147483648 is due to an integer overflow in Pinot, see https://.....", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671193614", "createdAt": "2021-07-16T12:09:02Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,6 +599,44 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + ((long) Integer.MAX_VALUE + 1) + \"\\\"\",\n+                \"Query select string_col, long_col from alltypes limit -2147483648 encountered exception org.apache.pinot.common.response.broker.QueryProcessingException@\\\\w+ with query \\\"select string_col, long_col from alltypes limit -2147483648\\\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA4MzI5MzIy", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-708329322", "createdAt": "2021-07-16T12:17:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMjoxNzozOFrOKAGxNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xNlQxMjo1MToyMlrOKAIcAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5OTU0Mw==", "bodyText": "// If returning from a global aggregation (no grouping columns) over an empty table, NULL-out all aggregation function results except for `count()`\n\nSome questions\n\nIs brokerResponse.getNumDocsScanned() == 0 equivalent to saying \"table is empty\"? Can a document hold no rows? What if there were documents scanned, but data was filtered out (SELECT max(x) FROM non_empty_table WHERE y = non_existent_value)?\nresultTable.getRows().size() == 1  combined with \"no data\" is a tricky way saying \"global aggregation\". Would checking query.getGroupByClauses()==0 be sufficient? (assuming getGroupByClauses is populated correctly, which i didn't check)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671199543", "createdAt": "2021-07-16T12:17:38Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -462,24 +462,39 @@ private BrokerResponseNative submitBrokerQueryJson(ConnectorSession session, Pin\n     public Iterator<BrokerResultRow> createResultIterator(ConnectorSession session, PinotQuery query, List<PinotColumnHandle> columnHandles)\n     {\n         BrokerResponseNative response = submitBrokerQueryJson(session, query);\n-        return fromResultTable(response.getResultTable(), columnHandles);\n+        return fromResultTable(response, columnHandles);\n     }\n \n     @VisibleForTesting\n-    public static ResultsIterator fromResultTable(ResultTable resultTable, List<PinotColumnHandle> columnHandles)\n+    public static ResultsIterator fromResultTable(BrokerResponseNative brokerResponse, List<PinotColumnHandle> columnHandles)\n     {\n-        requireNonNull(resultTable, \"resultTable is null\");\n+        requireNonNull(brokerResponse, \"brokerResponse is null\");\n         requireNonNull(columnHandles, \"columnHandles is null\");\n+        ResultTable resultTable = brokerResponse.getResultTable();\n         String[] columnNames = resultTable.getDataSchema().getColumnNames();\n         Map<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n                 .boxed()\n                 // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n                 .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n         int[] indices = new int[columnNames.length];\n+        int[] inverseIndices = new int[columnNames.length];\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n+            inverseIndices[indices[i]] = i;\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from an aggregate with no grouping columns, make sure all non-count columns are null\n+        if (brokerResponse.getNumDocsScanned() == 0 && resultTable.getRows().size() == 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMjkyMA==", "bodyText": "looks like unrelated to aggregations, is it?\nSeems like you're fixing reading of array type when the array itself is null?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671202920", "createdAt": "2021-07-16T12:22:16Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/decoders/ArrayDecoder.java", "diffHunk": "@@ -42,11 +42,16 @@ public ArrayDecoder(Type type)\n     public void decode(Supplier<Object> getter, BlockBuilder output)\n     {\n         List<?> value = (List<?>) getter.get();\n-        BlockBuilder elementBlockBuilder = type.getElementType().createBlockBuilder(null, 1);\n-        for (int i = 0; i < value.size(); i++) {\n-            int index = i;\n-            elementDecoder.decode(() -> value.get(index), elementBlockBuilder);\n+        if (value == null) {\n+            output.appendNull();\n+        }\n+        else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMzI1Mw==", "bodyText": "looks like unrelated to aggregations, is it?\n(same for other decoders)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671203253", "createdAt": "2021-07-16T12:22:48Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/decoders/BigintDecoder.java", "diffHunk": "@@ -25,6 +25,12 @@\n     @Override\n     public void decode(Supplier<Object> getter, BlockBuilder output)\n     {\n-        BIGINT.writeLong(output, ((Number) getter.get()).longValue());\n+        Object value = getter.get();\n+        if (value == null) {\n+            output.appendNull();\n+        }\n+        else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA==", "bodyText": "Let's move AggregateFunctionPatterns to plugin-toolkit instead of copying it.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671205418", "createdAt": "2021-07-16T12:25:42Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionPatterns.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Match;\n+import io.trino.matching.Pattern;\n+import io.trino.matching.PatternVisitor;\n+import io.trino.matching.Property;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.ConnectorExpression;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.type.Type;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Predicate;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public final class AggregateFunctionPatterns\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionPatterns", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTE4NA==", "bodyText": "#8578", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219184", "createdAt": "2021-07-16T12:42:58Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionPatterns.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Match;\n+import io.trino.matching.Pattern;\n+import io.trino.matching.PatternVisitor;\n+import io.trino.matching.Property;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.ConnectorExpression;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.type.Type;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Predicate;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public final class AggregateFunctionPatterns\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionPatterns", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA=="}, "originalCommit": null, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTMyNA==", "bodyText": "#8578", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219324", "createdAt": "2021-07-16T12:43:09Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionRewriter.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableSet;\n+import io.trino.matching.Match;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.connector.ConnectorSession;\n+\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public final class AggregateFunctionRewriter\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionRewriter", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTQwNg==", "bodyText": "#8578", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219406", "createdAt": "2021-07-16T12:43:14Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionRule.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.connector.ConnectorSession;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Verify.verifyNotNull;\n+import static java.util.Objects.requireNonNull;\n+\n+public interface AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionRule", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMDY4Mw==", "bodyText": "SUPPORTED_INPUT_TYPES doesn't look like specific to averages, so reuse here looks wrong.\ni suggest defining supported types directly here, in ImplementAvg\n(some for other cases)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671220683", "createdAt": "2021-07-16T12:44:50Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementAvg.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.DynamicTableBuilder.SUPPORTED_INPUT_TYPES;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+public class ImplementAvg\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"avg\"))\n+                .with(singleInput().matching(\n+                        variable()\n+                                .with(expressionType().matching(SUPPORTED_INPUT_TYPES::contains))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMjY1Nw==", "bodyText": "the intention of \n  \n    \n      trino/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/expression/ImplementCountAll.java\n    \n    \n         Line 61\n      in\n      d649dca\n    \n    \n    \n    \n\n        \n          \n           verify(aggregateFunction.getOutputType() == BIGINT); \n        \n    \n  \n\n is \"make sure this code gets updated, should return type of count(*) change to whatever else\"\nremove .with(outputType().equalTo(BIGINT)); from the pattern above, to achieve the same (otherwise this line would be redundant)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671222657", "createdAt": "2021-07-16T12:47:08Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountAll.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.inputs;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * Implements {@code count(*)}.\n+ */\n+public class ImplementCountAll\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementCountAll\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(inputs().equalTo(List.of()))\n+                .with(outputType().equalTo(BIGINT));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        verify(aggregateFunction.getOutputType() == BIGINT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMzQ2MA==", "bodyText": "inline outputColumnHandle\n(same in others)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671223460", "createdAt": "2021-07-16T12:47:58Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountAll.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.inputs;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * Implements {@code count(*)}.\n+ */\n+public class ImplementCountAll\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementCountAll\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(inputs().equalTo(List.of()))\n+                .with(outputType().equalTo(BIGINT));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        verify(aggregateFunction.getOutputType() == BIGINT);\n+        PinotColumnHandle outputColumnHandle = new PinotColumnHandle(\"count(*)\", aggregateFunction.getOutputType(), false);\n+        return Optional.of(outputColumnHandle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyNTA2NQ==", "bodyText": "SUPPORTED_INPUT_TYPES doesn't look specific to min or max (to comparisons).\ni would suggest defining supported data types directly here, in ImplementMinMax", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671225065", "createdAt": "2021-07-16T12:49:39Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementMinMax.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.DynamicTableBuilder.SUPPORTED_INPUT_TYPES;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code min(x)}, {@code max(x)}.\n+ */\n+public class ImplementMinMax\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementMinMax\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().matching(Set.of(\"min\", \"max\")::contains))\n+                .with(singleInput().matching(\n+                        variable()\n+                                .with(expressionType().matching(SUPPORTED_INPUT_TYPES::contains))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyNjg4MQ==", "bodyText": "Could Pinot reuse io.trino.plugin.jdbc.BaseJdbcConnectorTest#testAggregationPushdown?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671226881", "createdAt": "2021-07-16T12:51:22Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,357 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.trino.plugin.pinot.client.PinotHostMapper;\n+import io.trino.sql.planner.plan.AggregationNode;\n+import io.trino.sql.planner.plan.ExchangeNode;\n+import io.trino.sql.planner.plan.LimitNode;\n+import io.trino.sql.planner.plan.ProjectNode;\n+import io.trino.testing.AbstractTestQueryFramework;\n+import io.trino.testing.QueryRunner;\n+import io.trino.testing.kafka.TestingKafka;\n+import org.apache.avro.Schema;\n+import org.apache.avro.SchemaBuilder;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.shaded.org.bouncycastle.util.encoders.Hex;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.stream.IntStream;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.inject.multibindings.OptionalBinder.newOptionalBinder;\n+import static io.airlift.testing.Closeables.closeAllRuntimeException;\n+import static io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG;\n+import static java.lang.Math.abs;\n+import static java.lang.String.join;\n+import static java.util.stream.Collectors.toList;\n+import static org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG;\n+import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Test(singleThreaded = true)\n+public class TestPinotIntegrationSmokeTest\n+        extends AbstractTestQueryFramework\n+{\n+    // TODO extend BaseConnectorTest\n+    private static final String ALL_TYPES = \"alltypes\";\n+    private static final int DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES = 10;\n+    private static final int COUNT = 1000;\n+    private static final int NULL_COUNT = 17;\n+    private static final int ARRAY_NULL_COUNT = 13;\n+    private TestingPinotCluster pinot;\n+    private TestingKafka kafka;\n+    private Random random;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        random = new Random(22);\n+        kafka = TestingKafka.createWithSchemaRegistry();\n+        kafka.start();\n+        pinot = new TestingPinotCluster(kafka.getNetwork());\n+        pinot.start();\n+\n+        kafka.createTopic(ALL_TYPES);\n+\n+        int step = 3;\n+        int offset = 1;\n+        checkState(COUNT > NULL_COUNT, \"COUNT must be greater than NULL_COUNT\");\n+        checkState(NULL_COUNT > ARRAY_NULL_COUNT, \"NULL_COUNT must be greater than ARRAY_NULL_COUNT\");\n+        ImmutableList.Builder<ProducerRecord<String, GenericRecord>> builder = ImmutableList.builder();\n+        for (long i = 0; i < COUNT - NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, \"key\" + i * step, createRandomRecord(offset + i * step)));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - NULL_COUNT; i < COUNT - ARRAY_NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - ARRAY_NULL_COUNT; i < COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createArrayNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        pinot.createSchema(getClass().getClassLoader().getResourceAsStream(\"alltypes_schema.json\"), ALL_TYPES);\n+        pinot.addRealTimeTable(getClass().getClassLoader().getResourceAsStream(\"alltypes_realtimeSpec.json\"), ALL_TYPES);\n+\n+        Map<String, String> pinotProperties = ImmutableMap.<String, String>builder()\n+                .put(\"pinot.controller-urls\", pinot.getControllerConnectString())\n+                .build();\n+\n+        return PinotQueryRunner.createPinotQueryRunner(\n+                ImmutableMap.of(),\n+                pinotProperties,\n+                Optional.of(binder -> newOptionalBinder(binder, PinotHostMapper.class).setBinding()\n+                        .toInstance(new TestingPinotHostMapper(pinot.getBrokerHostAndPort(), pinot.getServerHostAndPort()))));\n+    }\n+\n+    private static ImmutableMap.Builder<String, String> schemaRegistryAwareProducer(TestingKafka testingKafka)\n+    {\n+        return ImmutableMap.<String, String>builder()\n+                .put(SCHEMA_REGISTRY_URL_CONFIG, testingKafka.getSchemaRegistryConnectString())\n+                .put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName())\n+                .put(VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void tearDown()\n+    {\n+        closeAllRuntimeException(pinot, kafka);\n+    }\n+\n+    private GenericRecord createRandomRecord(long offset)\n+    {\n+        return createTestRecord(\n+                random.ints(3, 0, 10001).limit(3).mapToObj(val -> \"string_\" + val).collect(toList()),\n+                Arrays.asList(random.nextBoolean(), random.nextBoolean(), random.nextBoolean()),\n+                random.ints().limit(3).boxed().collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().map(Double::floatValue).collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().collect(toList()),\n+                random.longs(3, ((long) Integer.MIN_VALUE) * 2, ((long) Integer.MAX_VALUE) * 2).boxed().collect(toList()),\n+                Instant.now().truncatedTo(ChronoUnit.DAYS).plusMillis(offset).toEpochMilli());\n+    }\n+\n+    private GenericRecord createArrayNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        List<String> stringList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                stringList.add(\"string_\" + abs(random.nextInt(10001)));\n+            }\n+            else {\n+                stringList.add(null);\n+            }\n+        }\n+        List<Boolean> booleanList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                booleanList.add(random.nextBoolean());\n+            }\n+            else {\n+                booleanList.add(null);\n+            }\n+        }\n+\n+        List<Integer> integerList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            integerList.add(null);\n+        }\n+\n+        List<Integer> integerWithDefaultList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                integerWithDefaultList.add(random.nextInt(10000));\n+            }\n+            else {\n+                integerWithDefaultList.add(null);\n+            }\n+        }\n+\n+        List<Float> floatList = new ArrayList<>();\n+        floatList.add(null);\n+\n+        List<Integer> doubleList = new ArrayList<>();\n+        doubleList.add(null);\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_array_col\", stringList)\n+                .set(\"bool_array_col\", booleanList)\n+                .set(\"int_array_col\", integerList)\n+                .set(\"int_array_col_with_pinot_default\", integerWithDefaultList)\n+                .set(\"float_array_col\", floatList)\n+                .set(\"double_array_col\", doubleList)\n+                .set(\"long_array_col\", new ArrayList<>())\n+                .build();\n+    }\n+\n+    private static GenericRecord createTestRecord(\n+            List<String> stringArrayColumn,\n+            List<Boolean> booleanArrayColumn,\n+            List<Integer> intArrayColumn,\n+            List<Float> floatArrayColumn,\n+            List<Double> doubleArrayColumn,\n+            List<Long> longArrayColumn,\n+            long updatedAtMillis)\n+    {\n+        Schema schema = getAvroSchema();\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_CoL\", stringArrayColumn.get(0))\n+                .set(\"bool_COL\", booleanArrayColumn.get(0))\n+                .set(\"bytes_col\", Hex.toHexString(stringArrayColumn.get(0).getBytes(StandardCharsets.UTF_8)))\n+                .set(\"string_array_col\", stringArrayColumn)\n+                .set(\"bool_array_col\", booleanArrayColumn)\n+                .set(\"int_array_col\", intArrayColumn)\n+                .set(\"int_array_col_with_pinot_default\", intArrayColumn)\n+                .set(\"float_array_col\", floatArrayColumn)\n+                .set(\"double_array_col\", doubleArrayColumn)\n+                .set(\"long_array_col\", longArrayColumn)\n+                .set(\"int_CoL\", intArrayColumn.get(0))\n+                .set(\"float_col\", floatArrayColumn.get(0))\n+                .set(\"double_col\", doubleArrayColumn.get(0))\n+                .set(\"long_CoL\", longArrayColumn.get(0))\n+                .set(\"updated_at\", updatedAtMillis)\n+                .build();\n+    }\n+\n+    private static GenericRecord createNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        return new GenericRecordBuilder(schema).build();\n+    }\n+\n+    private static Schema getAvroSchema()\n+    {\n+        // Note:\n+        // The reason optional() is used is because the avro record can omit those fields.\n+        // Fields with nullable type are required to be included or have a default value.\n+        // ex. if \"string_col\" is set to type().nullable().stringType().noDefault()\n+        // the following error is returned: Field string_col type:UNION pos:0 not set and has no default value\n+\n+        return SchemaBuilder.record(\"alltypes\")\n+                .fields()\n+                .name(\"string_CoL\").type().optional().stringType()\n+                .name(\"bool_COL\").type().optional().booleanType()\n+                .name(\"bytes_col\").type().optional().stringType()\n+                .name(\"string_array_col\").type().optional().array().items().nullable().stringType()\n+                .name(\"bool_array_col\").type().optional().array().items().nullable().booleanType()\n+                .name(\"int_array_col\").type().optional().array().items().nullable().intType()\n+                .name(\"int_array_col_with_pinot_default\").type().optional().array().items().nullable().intType()\n+                .name(\"float_array_col\").type().optional().array().items().nullable().floatType()\n+                .name(\"double_array_col\").type().optional().array().items().nullable().doubleType()\n+                .name(\"long_array_col\").type().optional().array().items().nullable().longType()\n+                .name(\"int_CoL\").type().optional().intType()\n+                .name(\"float_col\").type().optional().floatType()\n+                .name(\"double_col\").type().optional().doubleType()\n+                .name(\"long_CoL\").type().optional().longType()\n+                .name(\"updated_at\").type().optional().longType()\n+                .endRecord();\n+    }\n+\n+    @Test\n+    public void testCount()\n+    {\n+        assertQuery(\"SELECT \\\"count(*)\\\" FROM \\\"SELECT COUNT(*) FROM \" + ALL_TYPES + \"\\\"\", \"VALUES(\" + COUNT + \")\");\n+        // If no limit is supplied to a broker query, 10 rows will be returned. Verify this behavior:\n+        assertQuery(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES + \"\\\"\", \"VALUES (\" + DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES + \")\");\n+    }\n+\n+    @Test\n+    public void testNullBehavior()\n+    {\n+        // Verify the null behavior of pinot:\n+        // Default null value for varbinary (BYtES in pinot) is X''\n+        // Arrays of varbinary are not supported in pinot\n+        // Default null value for long single value columns is 0\n+        // Default null value for long array values is Long.MIN_VALUE,\n+        // Default null value for int single value columns is 0\n+        // Default null value for int array values is Integer.MIN_VALUE,\n+        // Default null value for float single value columns is 0.0F\n+        // Default null value for float array values is -INFINITY,\n+        // Default null value for double single value columns is 0.0D\n+        // Default null value for double array values is -INFINITY,\n+\n+        assertQuery(\"SELECT MIN(long_col), MIN(element_at(long_array_col, 1)),\" +\n+                        \"  MIN(int_col), MIN(element_at(int_array_col, 1)), MIN(element_at(int_array_col_with_pinot_default, 1)),\" +\n+                        \"  MIN(float_col), MIN(element_at(float_array_col, 1)),\" +\n+                        \"  MIN(double_col), MIN(element_at(double_array_col, 1))\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X''\",\n+                \"VALUES(0, \" + Long.MIN_VALUE + \", \" +\n+                        \"  0, \" + Integer.MIN_VALUE + \", 7,\" +\n+                        \"  0.0, -POWER(0, -1),\" +\n+                        \"  0.0, -POWER(0, -1)\" +\n+                        \")\");\n+\n+        // Default null value for strings is the string 'null'\n+        // Default null value for booleans is the string 'null', boolean is treated as a string\n+        assertQuery(\"SELECT DISTINCT string_col, element_at(string_array_col, 1), bool_col, element_at(bool_array_col, 1)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES ('null', 'null', 'null', 'null')\");\n+\n+        // Null behavior for arrays:\n+        // Default value for a \"null\" array is 1 element with default null array value,\n+        // ex.\n+        // Null string or boolean arrays will have ['null'] as the default,\n+        // Null integer arrays will have [Integer.MIN_VALUE] as the default\n+        // Null long arrays will have [Long.MIN_VALUE] as the default,\n+        // Null float arrays will have [-INFINITY] as the default\n+        // Null double arrays will have [-INFINITY] as the default\n+        // As mentioned above, arrays of varbinary are not supported\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, NULL_COUNT - ARRAY_NULL_COUNT).mapToObj(i -> \"(1, 1, 1, 1, 1, 1, 1)\").collect(toList())));\n+\n+        // If an array contains both null and non-null values, the null values are omitted:\n+        // There are 5 values in the avro records, but only the 3 non-null values are in pinot\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(bool_array_col, 1) != 'null'\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, ARRAY_NULL_COUNT).mapToObj(i -> \"(3, 3, 1, 3, 1, 1, 1)\").collect(toList())));\n+    }\n+\n+    @Test\n+    public void testAggregationPushdown()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MTY0MQ=="}, "originalCommit": null, "originalPosition": 329}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE0MzQzNDk0", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-714343494", "createdAt": "2021-07-25T19:07:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yNVQxOTowNzo0N1rOKE3UOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yNVQxOTowNzo0N1rOKE3UOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjE4OTI0Mw==", "bodyText": "What is this about?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676189243", "createdAt": "2021-07-25T19:07:47Z", "author": {"login": "findepi"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountDistinct.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.PinotSessionProperties.isDistinctCountPushdownEnabled;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementCountDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(outputType().equalTo(BIGINT))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        if (!isDistinctCountPushdownEnabled(context.getSession())) {\n+            return Optional.empty();\n+        }\n+        Variable input = captures.get(INPUT);\n+        verify(aggregateFunction.getOutputType() == BIGINT);\n+        if (context.getExistingGroupingColumns().isEmpty() || !context.getExistingGroupingColumns().get().contains(input.getName())) {\n+            return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE0NDcwNzc4", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-714470778", "createdAt": "2021-07-26T06:06:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yNlQwNjowNjozNFrOKE--ZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yNlQwNjoyMzoyNFrOKE_aMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNDcyNA==", "bodyText": "nit: distinctCountPushdownEnabled -> countDistinctPushdownEnabled (since that's what the optimizer calls it)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676314724", "createdAt": "2021-07-26T06:06:34Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -50,6 +51,9 @@\n     private int fetchRetryCount = 2;\n     private int nonAggregateLimitForBrokerQueries = 25_000;\n     private int maxRowsPerSplitForSegmentQueries = 50_000;\n+    private int maxRowsForBrokerQueries = 50_000;\n+    private boolean aggregationPushdownEnabled = true;\n+    private boolean distinctCountPushdownEnabled = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNTY4Mg==", "bodyText": "Add validation to disallow setting this without also setting pinot.aggregation-pushdown.enabled.\nBtw why do we need this? If we don't pushdown COUNT(DISTINCT) then also we might end up with a full-scan? Or is that not true? i.e. why can't we have just pinot.aggregation-pushdown.enabled?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676315682", "createdAt": "2021-07-26T06:08:53Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +261,41 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public int getMaxRowsForBrokerQueries()\n+    {\n+        return maxRowsForBrokerQueries;\n+    }\n+\n+    @Config(\"pinot.max-rows-for-broker-queries\")\n+    public PinotConfig setMaxRowsForBrokerQueries(int maxRowsForBrokerQueries)\n+    {\n+        this.maxRowsForBrokerQueries = maxRowsForBrokerQueries;\n+        return this;\n+    }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.aggregation-pushdown.enabled\")\n+    public PinotConfig setAggregationPushdownEnabled(boolean aggregationPushdownEnabled)\n+    {\n+        this.aggregationPushdownEnabled = aggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isDistinctCountPushdownEnabled()\n+    {\n+        return distinctCountPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.distinct-count-pushdown.enabled\")\n+    @ConfigDescription(\"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNzE0MA==", "bodyText": "Add validation to ensure this cannot be set without setting pinot.aggregation-pushdown.enabled too.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676317140", "createdAt": "2021-07-26T06:12:17Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotSessionProperties.java", "diffHunk": "@@ -108,6 +120,16 @@ public PinotSessionProperties(PinotConfig pinotConfig)\n                         \"Number of segments of the same host per split\",\n                         pinotConfig.getSegmentsPerSplit(),\n                         value -> checkArgument(value > 0, \"Number of segments per split must be more than zero\"),\n+                        false),\n+                booleanProperty(\n+                        AGGREGATION_PUSHDOWN_ENABLED,\n+                        \"Enable aggregation pushdown\",\n+                        pinotConfig.isAggregationPushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        DISTINCT_COUNT_PUSHDOWN_ENABLED,\n+                        \"Enable distinct count pushdown\",\n+                        pinotConfig.isDistinctCountPushdownEnabled(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxODEyOQ==", "bodyText": "Maybe fall-through instead?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676318129", "createdAt": "2021-07-26T06:14:47Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,48 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(\n+                        aggregationFunction.getResultColumnName(),\n+                        toTrinoType(aggregationFunction.getFinalResultColumnType())));\n             }\n         }\n \n-        return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+        return new DynamicTable(pinotTableName, suffix, selectionColumns, filter, groupByColumns, aggregateColumnsBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+    }\n+\n+    private static Type toTrinoType(DataSchema.ColumnDataType columnDataType)\n+    {\n+        switch (columnDataType) {\n+            case INT:\n+                return INTEGER;\n+            case LONG:\n+                return BIGINT;\n+            case FLOAT:\n+                return REAL;\n+            case DOUBLE:\n+                return DOUBLE;\n+            case STRING:\n+                return VARCHAR;\n+            case BYTES:\n+                return VARBINARY;\n+            case INT_ARRAY:\n+                return new ArrayType(INTEGER);\n+            case LONG_ARRAY:\n+                return new ArrayType(BIGINT);\n+            case DOUBLE_ARRAY:\n+                return new ArrayType(DOUBLE);\n+            case STRING_ARRAY:\n+                return new ArrayType(VARCHAR);\n+            default:\n+                break;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxOTgxOA==", "bodyText": "Remove to make the verify in rewrite actually work. This pattern will not match any query shapes that would fail the verify.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676319818", "createdAt": "2021-07-26T06:18:44Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementApproxDistinct.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementApproxDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"approx_distinct\"))\n+                .with(outputType().equalTo(BIGINT))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMyMTg0MQ==", "bodyText": "Take a look at BaseJdbcConnectorTest#testAggregationPushdown (and similarly named methods) for some other useful tests.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676321841", "createdAt": "2021-07-26T06:23:24Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +860,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIzOTk4NDE3", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-723998417", "createdAt": "2021-08-06T05:42:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo0MjoxM1rOKMRvEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo0MjoxM1rOKMRvEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2MjEyOA==", "bodyText": "Why the +1? Deserves a comment in my opinion since it's not obvious (to me at least).", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683962128", "createdAt": "2021-08-06T05:42:13Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +314,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments, tableHandle);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(maxRowsPerBrokerQuery + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 153}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDAxMTQ2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724001146", "createdAt": "2021-08-06T05:48:50Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo0ODo1MFrOKMR4Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo0ODo1MFrOKMR4Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2NDQ5NQ==", "bodyText": "cc: @martint This looks correct to me (I looked at most aggregation functions) but I'd appreciate your view if there are any other functions that behave like count?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683964495", "createdAt": "2021-08-06T05:48:50Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -462,24 +462,39 @@ private BrokerResponseNative submitBrokerQueryJson(ConnectorSession session, Pin\n     public Iterator<BrokerResultRow> createResultIterator(ConnectorSession session, PinotQuery query, List<PinotColumnHandle> columnHandles)\n     {\n         BrokerResponseNative response = submitBrokerQueryJson(session, query);\n-        return fromResultTable(response.getResultTable(), columnHandles);\n+        return fromResultTable(response, columnHandles, query.getGroupByClauses());\n     }\n \n     @VisibleForTesting\n-    public static ResultsIterator fromResultTable(ResultTable resultTable, List<PinotColumnHandle> columnHandles)\n+    public static ResultsIterator fromResultTable(BrokerResponseNative brokerResponse, List<PinotColumnHandle> columnHandles, int groupByClauses)\n     {\n-        requireNonNull(resultTable, \"resultTable is null\");\n+        requireNonNull(brokerResponse, \"brokerResponse is null\");\n         requireNonNull(columnHandles, \"columnHandles is null\");\n+        ResultTable resultTable = brokerResponse.getResultTable();\n         String[] columnNames = resultTable.getDataSchema().getColumnNames();\n         Map<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n                 .boxed()\n                 // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n                 .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n         int[] indices = new int[columnNames.length];\n+        int[] inverseIndices = new int[columnNames.length];\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n+            inverseIndices[indices[i]] = i;\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from a global aggregation (no grouping columns) over an empty table, NULL-out all aggregation function results except for `count()`", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDA1ODQ4", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724005848", "createdAt": "2021-08-06T05:59:41Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo1OTo0MVrOKMSHsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNTo1OTo0MVrOKMSHsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODQzMg==", "bodyText": "I think you forgot to remove this (or maybe push the commit?)", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968432", "createdAt": "2021-08-06T05:59:41Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementApproxDistinct.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementApproxDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"approx_distinct\"))\n+                .with(outputType().equalTo(BIGINT))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        Variable input = captures.get(INPUT);\n+        verify(aggregateFunction.getOutputType() == BIGINT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDA2MjQx", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724006241", "createdAt": "2021-08-06T06:00:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowMDozM1rOKMSJDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowMDozM1rOKMSJDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODc4MA==", "bodyText": "Remove the comment since it's normal for each datasource to have their own aggregation function semantics and hence the rewrite rules need to be different too.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968780", "createdAt": "2021-08-06T06:00:33Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementAvg.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableSet;\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static io.trino.spi.type.DoubleType.DOUBLE;\n+import static io.trino.spi.type.IntegerType.INTEGER;\n+import static io.trino.spi.type.RealType.REAL;\n+import static java.lang.String.format;\n+\n+public class ImplementAvg\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDEwMDM2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724010036", "createdAt": "2021-08-06T06:07:53Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowNzo1M1rOKMSU4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowNzo1M1rOKMSU4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MTgxMA==", "bodyText": "Can we add validation on our end to disallow such queries? Or is this not easy to do due to dynamic tables?\nOverflows can turn into unsigned values again if the value is sufficiently large (which is easy to do with typos).", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683971810", "createdAt": "2021-08-06T06:07:53Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,12 +603,52 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        // Note that -2147483648 is due to an integer overflow in Pinot: https://github.com/apache/pinot/issues/7242", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDEwNjM4", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724010638", "createdAt": "2021-08-06T06:08:56Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowODo1NlrOKMSWzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjowODo1NlrOKMSWzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjMwMQ==", "bodyText": "This behaviour might be very surprising for people looking at this from the Trino side. Not sure if we can do anything about this though?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683972301", "createdAt": "2021-08-06T06:08:56Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,12 +603,52 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        // Note that -2147483648 is due to an integer overflow in Pinot: https://github.com/apache/pinot/issues/7242\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + ((long) Integer.MAX_VALUE + 1) + \"\\\"\",\n+                \"Query select string_col, long_col from alltypes limit -2147483648 encountered exception org.apache.pinot.common.response.broker.QueryProcessingException@\\\\w+ with query \\\"select string_col, long_col from alltypes limit -2147483648\\\"\");\n+\n+        String tooManyBrokerRowsTableValues = \"VALUES ('string_0', '1620604800'),\" +\n+                \"  ('string_1', '1620604801'),\" +\n+                \"  ('string_2', '1620604802'),\" +\n+                \"  ('string_3', '1620604803'),\" +\n+                \"  ('string_4', '1620604804'),\" +\n+                \"  ('string_5', '1620604805'),\" +\n+                \"  ('string_6', '1620604806'),\" +\n+                \"  ('string_7', '1620604807'),\" +\n+                \"  ('string_8', '1620604808'),\" +\n+                \"  ('string_9', '1620604809'),\" +\n+                \"  ('string_10', '1620604810'),\" +\n+                \"  ('string_11', '1620604811')\";\n+\n+        // Explicit limit is necessary otherwise pinot returns 10 rows.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDExMzYy", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724011362", "createdAt": "2021-08-06T06:10:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMDoxOVrOKMSZLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMDoxOVrOKMSZLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjkwOQ==", "bodyText": "Is the filter on long_col pushed down? We should have tests with both cases where the predicate gets pushed down and where the filtering is done by the engine.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683972909", "createdAt": "2021-08-06T06:10:19Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDExNjE0", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724011614", "createdAt": "2021-08-06T06:10:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMDo0N1rOKMSZ-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMDo0N1rOKMSZ-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzExNQ==", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973115", "createdAt": "2021-08-06T06:10:47Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 156}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDExNzU0", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724011754", "createdAt": "2021-08-06T06:11:06Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMTowNlrOKMSaZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMTowNlrOKMSaZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzIyMA==", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973220", "createdAt": "2021-08-06T06:11:06Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 185}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDExNzk2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724011796", "createdAt": "2021-08-06T06:11:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMToxMFrOKMSagg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxMToxMFrOKMSagg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzI1MA==", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973250", "createdAt": "2021-08-06T06:11:10Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column, a filter and a limit", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 194}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDEzNzQx", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724013741", "createdAt": "2021-08-06T06:15:06Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxNTowNlrOKMSgYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0wNlQwNjoxNTowNlrOKMSgYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3NDc1Mg==", "bodyText": "nit: extra space after SELECT", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683974752", "createdAt": "2021-08-06T06:15:06Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column, a filter and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test single row from pinot where filter results in an empty result set.\n+        // A direct pinot query would return 1 row with default values, not null values.\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col > 4147483649\")).isFullyPushedDown();\n+\n+        // Test passthrough queries with no aggregates\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" WHERE long_col > 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"  GROUP BY string_col\"))\n+                .isFullyPushedDown();\n+\n+        // Passthrough queries with aggregates will not push down more aggregations.\n+        assertThat(query(\"SELECT bool_col, \\\"count(*)\\\", COUNT(*) FROM \\\"SELECT bool_col, count(*) FROM \" +\n+                ALL_TYPES_TABLE + \" GROUP BY bool_col\\\" GROUP BY bool_col, \\\"count(*)\\\"\"))\n+                .isNotFullyPushedDown(ExchangeNode.class, ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        assertThat(query(\"SELECT bool_col, \\\"max(long_col)\\\", COUNT(*) FROM \\\"SELECT bool_col, max(long_col) FROM \" +\n+                ALL_TYPES_TABLE + \" GROUP BY bool_col\\\" GROUP BY bool_col, \\\"max(long_col)\\\"\"))\n+                .isNotFullyPushedDown(ExchangeNode.class, ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        assertThat(query(\"SELECT int_col, COUNT(*) FROM \" + ALL_TYPES_TABLE + \" GROUP BY int_col LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // count(<column>) should not be pushed down, as pinot currently only implements count(*)\n+        assertThat(query(\"SELECT bool_col, COUNT(long_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // AVG on INTEGER columns is not pushed down\n+        assertThat(query(\"SELECT string_col, AVG(int_col) FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // SUM on INTEGER columns is not pushed down\n+        assertThat(query(\"SELECT string_col, SUM(int_col) FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // MIN on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, MIN(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // MAX on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, MAX(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // COUNT on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, COUNT(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // Distinct on varchar is pushed down\n+        assertThat(query(\"SELECT DISTINCT string_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on bool is pushed down\n+        assertThat(query(\"SELECT DISTINCT bool_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on double is pushed down\n+        assertThat(query(\"SELECT DISTINCT double_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on float is pushed down\n+        assertThat(query(\"SELECT DISTINCT float_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on long is pushed down\n+        assertThat(query(\"SELECT DISTINCT long_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on int is partially pushed down\n+        assertThat(query(\"SELECT DISTINCT int_col FROM \" + ALL_TYPES_TABLE))\n+                .isNotFullyPushedDown(ExchangeNode.class);\n+\n+        // Distinct on 2 columns for supported types:\n+        assertThat(query(\"SELECT DISTINCT bool_col, string_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, double_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, float_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, long_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, int_col FROM \" + ALL_TYPES_TABLE))\n+                .isNotFullyPushedDown(ExchangeNode.class);\n+\n+        // Approx distinct on varchar is pushed down\n+        assertThat(query(\"SELECT  approx_distinct(string_col) FROM \" + ALL_TYPES_TABLE))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 295}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI0MDE0NTk2", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-724014596", "createdAt": "2021-08-06T06:16:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3ODg0ODI3", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-727884827", "createdAt": "2021-08-11T19:41:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0xMVQxOTo0MTo1NFrOKPSl5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0xMVQxOTo0MTo1NFrOKPSl5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg==", "bodyText": "@elonazoulay IIUC the grouping columns in rewrite context are only needed to verify that the grouping columns are part of the SELECT clause. If so, can we instead do that validation here after the rewrite is done?\nYes, the connector will end up doing work that gets discarded but that seems cleaner because even if we add grouping columns to RewriteContext I don't see an easy way to populate them for other connectors so we won't be able to provide a sane impl. which doesn't return null for that method.\nI think this is possible to do because here we have tableHandle available from which we can get the grouping columns in case of DynamicTable.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r687121892", "createdAt": "2021-08-11T19:41:54Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +314,75 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments, tableHandle);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyNzg3MTYx", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-732787161", "createdAt": "2021-08-18T12:16:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0xOFQxMjoxNjo1MVrOKTKR6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0xOFQxMjoxNjo1MVrOKTKR6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MTE4MDAxMA==", "bodyText": "Should this return empty if the grouping column doesn't contain the column on which aggregation is applied? Or should it throw an error?", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r691180010", "createdAt": "2021-08-18T12:16:51Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -305,6 +328,109 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments);\n+            rewriteResult = applyCountDistinct(session, aggregate, assignments, tableHandle, rewriteResult);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        // By setting the limit to maxRowsPerBrokerQuery + 1 the connector will\n+        // know when the limit was exceeded and throw an error\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(maxRowsPerBrokerQuery + 1);\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                groupingColumns,\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                limitForDynamicTable,\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private Optional<PinotColumnHandle> applyCountDistinct(ConnectorSession session, AggregateFunction aggregate, Map<String, ColumnHandle> assignments, PinotTableHandle tableHandle, Optional<PinotColumnHandle> rewriteResult)\n+    {\n+        AggregateFunctionRule.RewriteContext context = new AggregateFunctionRule.RewriteContext()\n+        {\n+            @Override\n+            public Map<String, ColumnHandle> getAssignments()\n+            {\n+                return assignments;\n+            }\n+\n+            @Override\n+            public Function<String, String> getIdentifierQuote()\n+            {\n+                return identity();\n+            }\n+\n+            @Override\n+            public ConnectorSession getSession()\n+            {\n+                return session;\n+            }\n+        };\n+\n+        if (implementCountDistinct.getPattern().matches(aggregate, context) && aggregate.getInputs().size() == 1) {\n+            Variable input = (Variable) getOnlyElement(aggregate.getInputs());\n+            if (tableHandle.getQuery().isEmpty() ||\n+                    !tableHandle.getQuery().get().getGroupingColumns().contains(input.getName())) {\n+                return Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 207}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "a30d8750e7120739e2118bcc987ca5349ad0c22a", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/a30d8750e7120739e2118bcc987ca5349ad0c22a", "committedDate": "2021-08-22T21:52:54Z", "message": "Reorder DynamicTable members\n\nReorder members and constructor parameters in order\nof pushdown application."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0a92dd574008f4dc6cefc15337ecfff159ee02e", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/a0a92dd574008f4dc6cefc15337ecfff159ee02e", "committedDate": "2021-08-22T21:55:38Z", "message": "Add filter to equals, hashCode and toString in DynamicTable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9e6ad81fdf542080b4368f901f1ccdac527e13f", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/e9e6ad81fdf542080b4368f901f1ccdac527e13f", "committedDate": "2021-08-22T21:56:07Z", "message": "Add limit for broker queries\n\nAdd a config to set broker query limit.\nIf the limit is set too high, pinot can oom:\nhttps://github.com/apache/incubator-pinot/issues/7110"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f58979f68eda059ca3c8ee686ffb08ed98aefab1", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/f58979f68eda059ca3c8ee686ffb08ed98aefab1", "committedDate": "2021-08-22T21:56:14Z", "message": "Add null handling for decoders\n\nThis is a prepatory commit for aggregation pushdown\nwhich sets values to null, otherwise pinot never\nreturns null values."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1feed23cdaa5f60b5eb5a9f7f1d26303a18960f", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/a1feed23cdaa5f60b5eb5a9f7f1d26303a18960f", "committedDate": "2021-08-22T22:01:16Z", "message": "Implement aggregation pushdown in Pinot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8723d41d1d78ce30174fc9b953c969b02616387e", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/8723d41d1d78ce30174fc9b953c969b02616387e", "committedDate": "2021-08-22T22:03:14Z", "message": "Implement Distinct Count Pushdown in Pinot"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "8723d41d1d78ce30174fc9b953c969b02616387e", "author": {"user": {"login": "elonazoulay", "name": "Elon Azoulay"}}, "url": "https://github.com/trinodb/trino/commit/8723d41d1d78ce30174fc9b953c969b02616387e", "committedDate": "2021-08-22T22:03:14Z", "message": "Implement Distinct Count Pushdown in Pinot"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM1ODUzNDU3", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-735853457", "createdAt": "2021-08-23T08:29:21Z", "commit": {"oid": "e9e6ad81fdf542080b4368f901f1ccdac527e13f"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0yM1QwODoyOToyMVrOKVoNww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0yM1QwODoyOToyMVrOKVoNww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5Mzc2NzYxOQ==", "bodyText": "@elonazoulay Bump.", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r693767619", "createdAt": "2021-08-23T08:29:21Z", "author": {"login": "hashhar"}, "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotBrokerPageSource.java", "diffHunk": "@@ -113,6 +121,9 @@ public Page getNextPage()\n         int rowCount = 0;\n         while (size < PageBuilderStatus.DEFAULT_MAX_PAGE_SIZE_IN_BYTES && resultIterator.hasNext()) {\n             rowCount++;\n+            if (currentRowCount.incrementAndGet() > limitForBrokerQueries) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw=="}, "originalCommit": null, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM3MjY1OTM0", "url": "https://github.com/trinodb/trino/pull/6069#pullrequestreview-737265934", "createdAt": "2021-08-24T14:00:13Z", "commit": {"oid": "8723d41d1d78ce30174fc9b953c969b02616387e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2289, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}