{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2NDQwMTkx", "number": 6072, "title": "Rewrite GroupedTopNBuilder with flat data structures", "bodyText": "GroupedTopNBuilder would previously generate tons of objects for each row and group. By rewriting this entirely with flat data structures we can get massive GC improvements, as well as performance and memory benefits.\nCompared to the preexisting solution, this new implementation shows the following characteristics:\n\nVastly improved GC characteristics: negligible object allocations regardless of row count or group count.\nPerformance benchmarks upwards of 4x performance improvements when working with large numbers of groups, and no worse than parity with the existing solution in the worst case.\nRequires up to 20% less memory than the current solution when there are many groups, but does have increased constant memory overhead when dealing with tiny data sets.\n\nAdditionally, this is setup in preparation for #1073, which will share similar structures for rank and dense rank implementations.", "createdAt": "2020-11-24T12:20:05Z", "url": "https://github.com/trinodb/trino/pull/6072", "merged": true, "mergeCommit": {"oid": "ad41446af4c04da72a20a68aa868dee91b644f3b"}, "closed": true, "closedAt": "2020-12-09T23:08:39Z", "author": {"login": "erichwang"}, "timelineItems": {"totalCount": 34, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfzZeIABqjQwMzU0MzMwMDk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdknDPogFqTU0ODY4OTMwMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTgzNDY3", "url": "https://github.com/trinodb/trino/pull/6072#pullrequestreview-542183467", "createdAt": "2020-12-01T18:30:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODozMDo0M1rOH86T1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMDozNDo0NVrOH8-t6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTk1Nw==", "bodyText": "I suggest we make the rest of the fields package protected until we need them to be public.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533631957", "createdAt": "2020-12-01T18:30:43Z", "author": {"login": "dain"}, "path": "presto-array/src/main/java/io/prestosql/array/BigArrays.java", "diffHunk": "@@ -15,7 +15,7 @@\n \n // Note: this code was forked from fastutil (http://fastutil.di.unimi.it/)\n // Copyright (C) 2010-2013 Sebastiano Vigna\n-final class BigArrays\n+public final class BigArrays", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzOTk4NQ==", "bodyText": "Maybe add a comment that the code style is close to the original, so diffs work better... OR maybe clean this up more", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533639985", "createdAt": "2020-12-01T18:43:55Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -0,0 +1,1617 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.Hash;\n+import it.unimi.dsi.fastutil.HashCommon;\n+import it.unimi.dsi.fastutil.longs.AbstractLong2LongMap;\n+import it.unimi.dsi.fastutil.longs.AbstractLongCollection;\n+import it.unimi.dsi.fastutil.longs.AbstractLongSet;\n+import it.unimi.dsi.fastutil.longs.Long2LongMap;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongCollection;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongSet;\n+import it.unimi.dsi.fastutil.objects.AbstractObjectSet;\n+import it.unimi.dsi.fastutil.objects.ObjectIterator;\n+\n+import java.util.Arrays;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.function.Consumer;\n+\n+import static it.unimi.dsi.fastutil.HashCommon.arraySize;\n+import static it.unimi.dsi.fastutil.HashCommon.maxFill;\n+import static java.util.Objects.requireNonNull;\n+\n+// Note: this code was forked from fastutil (http://fastutil.di.unimi.it/) Long2LongOpenCustomHashMap\n+// Copyright (C) 2002-2019 Sebastiano Vigna\n+public class LongLong2LongOpenCustomHashMap", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY2MjAyMQ==", "bodyText": "Maybe write a test with a really bad hash like return 42, so everything ends up clumped together.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533662021", "createdAt": "2020-12-01T19:20:29Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/util/TestLongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.HashCommon;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestLongLong2LongOpenCustomBigHashMap\n+{\n+    private static final LongLong2LongOpenCustomBigHashMap.HashStrategy DEFAULT_STRATEGY = new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+    {\n+        @Override\n+        public long hashCode(long e1, long e2)\n+        {\n+            return HashCommon.mix(e1) * 31 + HashCommon.mix(e2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY2MzkxMA==", "bodyText": "Maybe add a second loop to verify \"replace\"", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533663910", "createdAt": "2020-12-01T19:23:43Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/util/TestLongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.HashCommon;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestLongLong2LongOpenCustomBigHashMap\n+{\n+    private static final LongLong2LongOpenCustomBigHashMap.HashStrategy DEFAULT_STRATEGY = new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+    {\n+        @Override\n+        public long hashCode(long e1, long e2)\n+        {\n+            return HashCommon.mix(e1) * 31 + HashCommon.mix(e2);\n+        }\n+\n+        @Override\n+        public boolean equals(long a1, long a2, long b1, long b2)\n+        {\n+            return a1 == b1 && a2 == b2;\n+        }\n+    };\n+\n+    @Test\n+    public void testBasicOps()\n+    {\n+        int expected = 100_000;\n+        LongLong2LongOpenCustomBigHashMap map = new LongLong2LongOpenCustomBigHashMap(expected, DEFAULT_STRATEGY);\n+        map.defaultReturnValue(-1);\n+\n+        assertTrue(map.isEmpty());\n+        assertEquals(map.size(), 0);\n+        assertEquals(map.get(0, 0), -1);\n+        assertEquals(map.get(1, -1), -1);\n+\n+        List<Long> values = Arrays.asList(Long.MIN_VALUE, -10L, 0L, 10L, Long.MAX_VALUE);\n+\n+        // Put\n+        int count = 0;\n+        for (long key1 : values) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NTIyOA==", "bodyText": "Maybe remove these in the original fork commit", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533675228", "createdAt": "2020-12-01T19:43:14Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -563,68 +517,56 @@ public boolean containsValue(final long v)\n             return true;\n         }\n         for (int i = n; i-- != 0; ) {\n-            if (!((key[i]) == (0)) && ((value[i]) == (v))) {\n+            if (!((key[i * 2]) == (0) && (key[i * 2 + 1]) == (0)) && ((value[i]) == (v))) {\n                 return true;\n             }\n         }\n         return false;\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-\n-    public long getOrDefault(final long k, final long defaultValue)\n+    public long getOrDefault(final long k1, final long k2, final long defaultValue)\n     {\n-        if ((strategy.equals((k), (0)))) {\n+        if ((strategy.equals((k1), (k2), (0), (0)))) {\n             return containsNullKey ? value[n] : defaultValue;\n         }\n         final long[] key = this.key;\n         // The starting point.\n-        int pos = (it.unimi.dsi.fastutil.HashCommon.mix(strategy.hashCode(k))) & mask;\n-        long curr = key[pos];\n-        if (((curr) == (0))) {\n+        int pos = (it.unimi.dsi.fastutil.HashCommon.mix(strategy.hashCode(k1, k2))) & mask;\n+        long curr1 = key[pos * 2];\n+        long curr2 = key[pos * 2 + 1];\n+        if (((curr1) == (0)) && ((curr2) == (0))) {\n             return defaultValue;\n         }\n-        if ((strategy.equals((k), (curr)))) {\n+        if ((strategy.equals((k1), (k2), (curr1), (curr2)))) {\n             return value[pos];\n         }\n         // There's always an unused entry.\n         while (true) {\n             pos = (pos + 1) & mask;\n-            curr = key[pos];\n-            if (((curr) == (0))) {\n+            curr1 = key[pos * 2];\n+            curr2 = key[pos * 2 + 1];\n+            if (((curr1) == (0)) && ((curr2) == (0))) {\n                 return defaultValue;\n             }\n-            if ((strategy.equals((k), (curr)))) {\n+            if ((strategy.equals((k1), (k2), (curr1), (curr2)))) {\n                 return value[pos];\n             }\n         }\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    public long putIfAbsent(final long k, final long v)\n+    public long putIfAbsent(final long k1, final long k2, final long v)\n     {\n-        final int pos = find(k);\n+        final int pos = find(k1, k2);\n         if (pos >= 0) {\n             return value[pos];\n         }\n-        insert(-pos - 1, k, v);\n+        insert(-pos - 1, k1, k2, v);\n         return defRetValue;\n     }\n \n-    /**\n-     * {@inheritDoc}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 665}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NzUzMg==", "bodyText": "Maybe move the removal of all the unused stuff to another commit.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533677532", "createdAt": "2020-12-01T19:47:16Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -822,619 +672,16 @@ public void clear()\n         Arrays.fill(key, (0));\n     }\n \n-    @Override\n     public int size()\n     {\n         return size;\n     }\n \n-    @Override\n     public boolean isEmpty()\n     {\n         return size == 0;\n     }\n \n-    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 888}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4MjA1MA==", "bodyText": "Remove Serializable from this, and drop transient below and make any fields final if possible", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533682050", "createdAt": "2020-12-01T19:55:16Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/util/Long2LongOpenBigHashMap.java", "diffHunk": "@@ -13,68 +13,71 @@\n  */\n package io.prestosql.util;\n \n+import io.prestosql.array.BigArrays;\n+import io.prestosql.array.LongBigArray;\n import it.unimi.dsi.fastutil.Hash;\n-import it.unimi.dsi.fastutil.HashCommon;\n import it.unimi.dsi.fastutil.longs.AbstractLong2LongMap;\n import it.unimi.dsi.fastutil.longs.AbstractLongCollection;\n import it.unimi.dsi.fastutil.longs.AbstractLongSet;\n import it.unimi.dsi.fastutil.longs.Long2LongMap;\n-import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongBigArrayBigList;\n import it.unimi.dsi.fastutil.longs.LongCollection;\n import it.unimi.dsi.fastutil.longs.LongIterator;\n import it.unimi.dsi.fastutil.longs.LongSet;\n import it.unimi.dsi.fastutil.objects.AbstractObjectSet;\n import it.unimi.dsi.fastutil.objects.ObjectIterator;\n+import org.openjdk.jol.info.ClassLayout;\n \n-import java.util.Arrays;\n import java.util.Map;\n import java.util.NoSuchElementException;\n import java.util.function.Consumer;\n \n-import static it.unimi.dsi.fastutil.HashCommon.arraySize;\n+import static it.unimi.dsi.fastutil.HashCommon.bigArraySize;\n import static it.unimi.dsi.fastutil.HashCommon.maxFill;\n+import static java.lang.Math.toIntExact;\n import static java.util.Objects.requireNonNull;\n \n // Note: this code was forked from fastutil (http://fastutil.di.unimi.it/) Long2LongOpenHashMap\n // Copyright (C) 2002-2019 Sebastiano Vigna\n public class Long2LongOpenBigHashMap\n         extends AbstractLong2LongMap\n-        implements java.io.Serializable, Cloneable, Hash\n+        implements java.io.Serializable, Hash", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4MjY0MA==", "bodyText": "remove these", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533682640", "createdAt": "2020-12-01T19:56:12Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/util/Long2LongOpenBigHashMap.java", "diffHunk": "@@ -1457,108 +1436,83 @@ public boolean trim(final int n)\n      *\n      * @param newN the new size\n      */\n-    protected void rehash(final int newN)\n+    protected void rehash(final long newN)\n     {\n-        final long[] key = this.key;\n-        final long[] value = this.value;\n-        final int mask = newN - 1; // Note that this is used by the hashing macro\n-        final long[] newKey = new long[newN + 1];\n-        final long[] newValue = new long[newN + 1];\n-        int i = n;\n-        int pos;\n-        for (int j = realSize(); j-- != 0; ) {\n-            while (((key[--i]) == (0))) {\n+        final LongBigArray key = this.key;\n+        final LongBigArray value = this.value;\n+        final long mask = newN - 1; // Note that this is used by the hashing macro\n+        final LongBigArray newKey = new LongBigArray();\n+        newKey.ensureCapacity(newN + 1);\n+        final LongBigArray newValue = new LongBigArray();\n+        newValue.ensureCapacity(newN + 1);\n+        long i = n;\n+        long pos;\n+        for (long j = realSize(); j-- != 0; ) {\n+            while (((key.get(--i)) == (0))) {\n                 // Skip\n             }\n-            pos = (int) it.unimi.dsi.fastutil.HashCommon.mix((key[i])) & mask;\n-            if (!((newKey[pos]) == (0))) {\n+            pos = it.unimi.dsi.fastutil.HashCommon.mix((key.get(i))) & mask;\n+            if (!((newKey.get(pos)) == (0))) {\n                 pos = (pos + 1) & mask;\n-                while (!((newKey[pos]) == (0))) {\n+                while (!((newKey.get(pos)) == (0))) {\n                     pos = (pos + 1) & mask;\n                 }\n             }\n-            newKey[pos] = key[i];\n-            newValue[pos] = value[i];\n+            newKey.set(pos, key.get(i));\n+            newValue.set(pos, value.get(i));\n         }\n-        newValue[newN] = value[n];\n+        newValue.set(newN, value.get(n));\n         n = newN;\n         this.mask = mask;\n         maxFill = maxFill(n, f);\n         this.key = newKey;\n         this.value = newValue;\n     }\n \n-    /**\n-     * Returns a deep copy of this map.\n-     *\n-     * <p>\n-     * This method performs a deep copy of this hash map; the data stored in the\n-     * map, however, is not cloned. Note that this makes a difference only for\n-     * object keys.\n-     *\n-     * @return a deep copy of this map.\n-     */\n-    @Override\n-    public Long2LongOpenBigHashMap clone()\n-    {\n-        Long2LongOpenBigHashMap c;\n-        try {\n-            c = (Long2LongOpenBigHashMap) super.clone();\n-        }\n-        catch (CloneNotSupportedException cantHappen) {\n-            throw new InternalError();\n-        }\n-        c.keys = null;\n-        c.values = null;\n-        c.entries = null;\n-        c.containsNullKey = containsNullKey;\n-        c.key = key.clone();\n-        c.value = value.clone();\n-        return c;\n-    }\n-\n     private void writeObject(java.io.ObjectOutputStream s)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5ODg3Mw==", "bodyText": "Did you mean to put this in main instead of test?", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533698873", "createdAt": "2020-12-01T20:25:09Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/CyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.Type;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * GroupByHash that provides a round robin group ID assignment.\n+ */\n+public class CyclingGroupByHash", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5OTQ1MA==", "bodyText": "For benchmarking I think you can use a JMH Blackhole for the sink", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533699450", "createdAt": "2020-12-01T20:26:09Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/CyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.Type;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * GroupByHash that provides a round robin group ID assignment.\n+ */\n+public class CyclingGroupByHash\n+        implements GroupByHash\n+{\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(CyclingGroupByHash.class).instanceSize();\n+\n+    private final int totalGroupCount;\n+    private int maxGroupId;\n+    private int currentGroupId;\n+\n+    public CyclingGroupByHash(int totalGroupCount)\n+    {\n+        this.totalGroupCount = totalGroupCount;\n+    }\n+\n+    @Override\n+    public long getEstimatedSize()\n+    {\n+        return INSTANCE_SIZE;\n+    }\n+\n+    @Override\n+    public long getHashCollisions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public double getExpectedHashCollisions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public List<Type> getTypes()\n+    {\n+        return ImmutableList.of();\n+    }\n+\n+    @Override\n+    public int getGroupCount()\n+    {\n+        return maxGroupId;\n+    }\n+\n+    @Override\n+    public void appendValuesTo(int groupId, PageBuilder pageBuilder, int outputChannelOffset)\n+    {\n+        throw new UnsupportedOperationException(\"CyclingGroupByHash does not support appendValuesTo\");\n+    }\n+\n+    @Override\n+    public Work<?> addPage(Page page)\n+    {\n+        // Create a dump work whose result is never used.\n+        return new CompletedWork<>(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwMjkwOA==", "bodyText": "I think there already is a page equals somewhere, but it might be page equals page.  Maybe you could create a page from the longs and then use the existing page equals page... just an idea", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533702908", "createdAt": "2020-12-01T20:32:22Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestCyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static org.testng.Assert.assertEquals;\n+\n+public class TestCyclingGroupByHash\n+{\n+    @Test\n+    public void testSingleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(1);\n+        Page page = createPage(1);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 0L);\n+    }\n+\n+    @Test\n+    public void testMultipleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(2);\n+        Page page = createPage(3);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 1L, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 1L, 0L);\n+    }\n+\n+    private static void assertContentsEqual(GroupByIdBlock groupByIdBlock, long... groupIds)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNDE2OQ==", "bodyText": "verify the group count also... some tests should verify the group cout is accurate when the count is less than the max count", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533704169", "createdAt": "2020-12-01T20:34:45Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestCyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static org.testng.Assert.assertEquals;\n+\n+public class TestCyclingGroupByHash\n+{\n+    @Test\n+    public void testSingleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(1);\n+        Page page = createPage(1);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 0L);\n+    }\n+\n+    @Test\n+    public void testMultipleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(2);\n+        Page page = createPage(3);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 1L, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 1L, 0L);\n+    }\n+\n+    private static void assertContentsEqual(GroupByIdBlock groupByIdBlock, long... groupIds)\n+    {\n+        assertEquals(groupByIdBlock.getPositionCount(), groupIds.length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0MzEyMjc0", "url": "https://github.com/trinodb/trino/pull/6072#pullrequestreview-544312274", "createdAt": "2020-12-03T19:32:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOTozMjoxOVrOH-t15A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMTozOTo0OVrOH-1ljw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNDgzNg==", "bodyText": "drop the empty javadoc", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535524836", "createdAt": "2020-12-03T19:32:19Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjk2Mw==", "bodyText": "Can we combine with the above call to save an extra traversal? I'm thinking something like addIfNotPresent", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535526963", "createdAt": "2020-12-03T19:34:43Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyODk0Ng==", "bodyText": "Maybe mention that after this call, the accumulator will be empty.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535528946", "createdAt": "2020-12-03T19:36:52Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU2NDUzMg==", "bodyText": "Why use checkArgument here and verify  in other checks?", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535564532", "createdAt": "2020-12-03T20:21:47Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3MjEzNw==", "bodyText": "If it doesn't hurt perf, I would use Optional instead of Nullable", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535572137", "createdAt": "2020-12-03T20:28:55Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NDk3Ng==", "bodyText": "Is root the right term here?", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535574976", "createdAt": "2020-12-03T20:31:35Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3ODE4Mg==", "bodyText": "I assume this is used to \"prune\" the heap down to size.  Maybe explicitly mention that", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535578182", "createdAt": "2020-12-03T20:34:29Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastRowId, contextEvictionListener);\n+        }\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYyNzUwMQ==", "bodyText": "I'm not sure what this means", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535627501", "createdAt": "2020-12-03T21:15:07Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastRowId, contextEvictionListener);\n+        }\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @param groupId\n+     * @return leaf node index that was deatched from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     */\n+    private void heapInsert(long groupId, long newRowId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId) + 1);\n+        while (!heapTraversal.isTarget()) {\n+            long currentRowId = heapNodeBuffer.getRowId(currentHeapNodeIndex);\n+            if (rowComparator.compare(newRowId, currentRowId) > 0) {\n+                // Swap the row values\n+                heapNodeBuffer.setRowId(currentHeapNodeIndex, newRowId);\n+\n+                newRowId = currentRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap and insert the newRowId.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newRowId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for another row\n+        long poppedRowId = heapNodeBuffer.getRowId(heapRootNodeIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildRowId = heapNodeBuffer.getRowId(maxChildNodeIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightRowId = heapNodeBuffer.getRowId(rightChildNodeIndex);\n+                if (rowComparator.compare(rightRowId, maxChildRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildRowId = rightRowId;\n+                }\n+            }\n+\n+            if (rowComparator.compare(newRowId, maxChildRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setRowId(currentNodeIndex, maxChildRowId);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setRowId(currentNodeIndex, newRowId);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(poppedRowId);\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex G1,\n+         *  [LONG] heapNodeIndex G2,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 342}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYzMDQyMw==", "bodyText": "I don't think the layout is important.  This is a index of heap buffer for each group.  The array is indexed on the group id.... maybe stated more cleanly", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535630423", "createdAt": "2020-12-03T21:18:01Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastRowId, contextEvictionListener);\n+        }\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @param groupId\n+     * @return leaf node index that was deatched from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     */\n+    private void heapInsert(long groupId, long newRowId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId) + 1);\n+        while (!heapTraversal.isTarget()) {\n+            long currentRowId = heapNodeBuffer.getRowId(currentHeapNodeIndex);\n+            if (rowComparator.compare(newRowId, currentRowId) > 0) {\n+                // Swap the row values\n+                heapNodeBuffer.setRowId(currentHeapNodeIndex, newRowId);\n+\n+                newRowId = currentRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap and insert the newRowId.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newRowId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for another row\n+        long poppedRowId = heapNodeBuffer.getRowId(heapRootNodeIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildRowId = heapNodeBuffer.getRowId(maxChildNodeIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightRowId = heapNodeBuffer.getRowId(rightChildNodeIndex);\n+                if (rowComparator.compare(rightRowId, maxChildRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildRowId = rightRowId;\n+                }\n+            }\n+\n+            if (rowComparator.compare(newRowId, maxChildRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setRowId(currentNodeIndex, maxChildRowId);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setRowId(currentNodeIndex, newRowId);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(poppedRowId);\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex G1,\n+         *  [LONG] heapNodeIndex G2,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYyNzUwMQ=="}, "originalCommit": null, "originalPosition": 342}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0MTI3Nw==", "bodyText": "Do you get full coverage with these tests?", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535641277", "createdAt": "2020-12-03T21:28:42Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0NDAyNQ==", "bodyText": "maybe add a comment like: add with same group id and larger value, which should be ignored because max is 1.  Same for others", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535644025", "createdAt": "2020-12-03T21:31:58Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator\n+{\n+    @Test\n+    public void testSingleGroupTopN1()\n+    {\n+        int topN = 1;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0NTk5NQ==", "bodyText": "I feel like 1 could be a special case... maybe do a top of 4 and fill 2", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535645995", "createdAt": "2020-12-03T21:34:08Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator\n+{\n+    @Test\n+    public void testSingleGroupTopN1()\n+    {\n+        int topN = 1;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);\n+        assertFalse(accumulator.add(0, rowReference));\n+        assertFalse(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(-1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(0L));\n+\n+        LongBigArray rowIdOutput = new LongBigArray();\n+        assertEquals(accumulator.drainTo(0, rowIdOutput), 1);\n+        assertEquals(rowIdOutput.get(0), -1);\n+    }\n+\n+    @Test\n+    public void testSingleGroupTopN2()\n+    {\n+        int topN = 2;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(2);\n+        assertFalse(accumulator.add(0, rowReference));\n+        assertFalse(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(-2);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(1L));\n+\n+        rowReference.setRowId(-1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(1L, 0L));\n+\n+        LongBigArray rowIdOutput = new LongBigArray();\n+        assertEquals(accumulator.drainTo(0, rowIdOutput), 2);\n+        assertEquals(rowIdOutput.get(0), -2);\n+        assertEquals(rowIdOutput.get(1), -1);\n+    }\n+\n+    @Test\n+    public void testSingleGroupTopN2PartialFill()\n+    {\n+        int topN = 2;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        // Only fill to a part of topN before draining", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY1MTcyNw==", "bodyText": "Normally we name stuff like \"leftPage\" and \"righttPage\". The actual left and right just argument order but it doesn't really matter, but it make it easier to see than a single number.  The is especially true when the argument names get longer.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535651727", "createdAt": "2020-12-03T21:39:49Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNBuilder.java", "diffHunk": "@@ -78,17 +53,20 @@ public GroupedTopNBuilder(\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.topN = topN;\n         this.produceRowNumber = produceRowNumber;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is not null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        this.comparator = (left, right) -> comparator.compareTo(\n-                pageReferences.get(left.getPageId()).getPage(),\n-                left.getPosition(),\n-                pageReferences.get(right.getPageId()).getPage(),\n-                right.getPosition());\n-        this.emptyPageReferenceSlots = new IntFIFOQueue();\n+        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n+                (rowId1, rowId2) -> {\n+                    Page page1 = pageManager.getPage(rowId1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0NDkzNTE4", "url": "https://github.com/trinodb/trino/pull/6072#pullrequestreview-544493518", "createdAt": "2020-12-03T22:08:18Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjowODoxOVrOH-3Rpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwNDoxNTowMlrOH_AEhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY3OTM5OA==", "bodyText": "I think the important part is this has a freelist for tracking.  I think that is important to mention and that the IDs of removed items can be reused.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535679398", "createdAt": "2020-12-03T22:08:19Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/IdRegistry.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.airlift.slice.SizeOf;\n+import it.unimi.dsi.fastutil.ints.IntArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.objects.ObjectArrayList;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+/**\n+ * Object registration system that allows looking up objects via stable IDs.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzY3OQ==", "bodyText": "consider adding a method int IdRegistry.add(IntFunction<T>. Then this can be int pageId = pages.add(id -> new PageAccounting(id, page))", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535707679", "createdAt": "2020-12-03T22:57:28Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxMjg1NA==", "bodyText": "Maybe add method isCursorId, then all of the negative stuff will be encapsulated.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535712854", "createdAt": "2020-12-03T23:07:38Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTI1NA==", "bodyText": "I don't think this comment helps", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715254", "createdAt": "2020-12-03T23:13:12Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTQ3MQ==", "bodyText": "I don't think this will be needed if you add an isCursorId method", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715471", "createdAt": "2020-12-03T23:13:47Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTYxNQ==", "bodyText": "I'd just inline this variable.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715615", "createdAt": "2020-12-03T23:14:11Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTgwNA==", "bodyText": "I'd just inline this variable", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715804", "createdAt": "2020-12-03T23:14:32Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczNDAyNQ==", "bodyText": "Oh I see.  I read this wrong.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535734025", "createdAt": "2020-12-03T23:56:57Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NDk3Ng=="}, "originalCommit": null, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczNDQ0OQ==", "bodyText": "I asked because in peekRootRowId you have the same check, but it is verify.  I would assume the two would be the same.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535734449", "createdAt": "2020-12-03T23:58:00Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU2NDUzMg=="}, "originalCommit": null, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc0OTA1Nw==", "bodyText": "Is there a way to test if the there are no pages now?", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535749057", "createdAt": "2020-12-04T00:35:48Z", "author": {"login": "dain"}, "path": "presto-main/src/test/java/io/prestosql/operator/TestRowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static java.lang.Math.toIntExact;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+import static org.testng.Assert.fail;\n+\n+public class TestRowReferencePageManager\n+{\n+    @Test\n+    public void testEmptyPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+        Page page = createBigIntSingleBlockPage(0, 0);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertFalse(cursor.advance());\n+            try {\n+                cursor.allocateRowId();\n+                fail();\n+            }\n+            catch (IllegalStateException e) {\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testSinglePageRowIds()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        LongComparator rowIdComparator = (rowId1, rowId2) -> {\n+            long value1 = extractValue(pageManager, rowId1);\n+            long value2 = extractValue(pageManager, rowId2);\n+            return Long.compare(value1, value2);\n+        };\n+\n+        long id0;\n+        long id1;\n+        long id3;\n+        Page page = createBigIntSingleBlockPage(0, 4);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            id1 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id1), 1L);\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            assertTrue(cursor.compareTo(rowIdComparator, id1) > 0);\n+            // Skip this row by not allocating an ID\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            assertTrue(cursor.compareTo(rowIdComparator, id1) > 0);\n+            id3 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id3), 3L);\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+        assertEquals(extractValue(pageManager, id1), 1L);\n+        assertEquals(extractValue(pageManager, id3), 3L);\n+    }\n+\n+    @Test\n+    public void testMultiplePageRowIds()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        LongComparator rowIdComparator = (rowId1, rowId2) -> {\n+            long value1 = extractValue(pageManager, rowId1);\n+            long value2 = extractValue(pageManager, rowId2);\n+            return Long.compare(value1, value2);\n+        };\n+\n+        long id0;\n+        Page page = createBigIntSingleBlockPage(0, 1);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            assertFalse(cursor.advance());\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+\n+        long id1;\n+        page = createBigIntSingleBlockPage(1, 2);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            id1 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id1), 1L);\n+            assertFalse(cursor.advance());\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scopes\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+        assertEquals(extractValue(pageManager, id1), 1L);\n+    }\n+\n+    @Test\n+    public void testSkipCompaction()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        long id0;\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            // No compaction candidates until after the cursor is closed\n+            assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+            // Ignore the remaining positions, which means they should remain unreferenced\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+\n+        // With a 1% fill, this page will certainly require compaction\n+        assertEquals(pageManager.getCompactionCandidateCount(), 1);\n+        pageManager.loadAndCompactIfNeeded();\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Should still be able to extract same value after compaction\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+    }\n+\n+    @Test\n+    public void testDereferenceCompaction()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        long id0;\n+        List<Long> rowIdsToDereference = new ArrayList<>();\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            // Collect the remaining rowIds\n+            while (cursor.advance()) {\n+                rowIdsToDereference.add(cursor.allocateRowId());\n+            }\n+        }\n+\n+        // No compaction candidates since all rows should be referenced\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Dereference 99% of row IDs\n+        for (long rowId : rowIdsToDereference) {\n+            pageManager.dereference(rowId);\n+        }\n+\n+        // With a 1% fill, this page will certainly require compaction\n+        assertEquals(pageManager.getCompactionCandidateCount(), 1);\n+        pageManager.loadAndCompactIfNeeded();\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Should still be able to extract same value after compaction\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+    }\n+\n+    @Test\n+    public void testSkipFullPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            // Close the cursor without any row ID allocations\n+        }\n+\n+        // No compaction candidates since page is no longer needed\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+    }\n+\n+    @Test\n+    public void testDereferenceFullPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        List<Long> rowIdsToDereference = new ArrayList<>();\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            while (cursor.advance()) {\n+                rowIdsToDereference.add(cursor.allocateRowId());\n+            }\n+        }\n+\n+        // Dereference all row IDs\n+        for (long rowId : rowIdsToDereference) {\n+            pageManager.dereference(rowId);\n+        }\n+\n+        // No compaction candidates since page is no longer needed\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTgyMzQ5NQ==", "bodyText": "Only one cursor can be open at a time due to how lazy blocks work, so I think we can just make this a single field", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535823495", "createdAt": "2020-12-04T04:15:02Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NTk0MjQ0", "url": "https://github.com/trinodb/trino/pull/6072#pullrequestreview-546594244", "createdAt": "2020-12-07T22:32:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QyMjozMjoyMFrOIA9z4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QyMjozMjoyMFrOIA9z4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg4MzYxOQ==", "bodyText": "I think this need a comment on why this is here and not when the LoadCursor is created.  Also, I was expecting that we would track the bytes of the page that is being loaded.", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537883619", "createdAt": "2020-12-07T22:32:20Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+    private static final int RESERVED_ROW_ID_FOR_CURSOR = -1;\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    @Nullable\n+    private LoadCursor currentCursor;\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        checkState(currentCursor == null, \"Cursor still active\");\n+\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        pageAccounting.lockPage();\n+        currentCursor = new LoadCursor(pageAccounting, () -> {\n+            // Defer certain actions until this close callback\n+            checkState(currentCursor != null);\n+            pageAccounting.unlockPage();\n+            pageAccounting.loadPageLoadIfNeeded();\n+            pageBytes += pageAccounting.sizeOf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5d1e1ba2ed4cfbbe653020734bd9ebe71c88a43", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/b5d1e1ba2ed4cfbbe653020734bd9ebe71c88a43", "committedDate": "2020-12-08T03:40:49Z", "message": "Add fill method to BigArray collections\n\nCopying the one that was already implemented for IntBigArray."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2024120a924bf29c8fbd17ad48fb3a66b8eb1e91", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/2024120a924bf29c8fbd17ad48fb3a66b8eb1e91", "committedDate": "2020-12-08T03:40:49Z", "message": "Add copyTo methods to presto BigArray collections"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd8a7ca6a7b4ee61696b558cd3c1550b1422e3e3", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/bd8a7ca6a7b4ee61696b558cd3c1550b1422e3e3", "committedDate": "2020-12-08T03:40:49Z", "message": "Make BigArrays.SEGMENT_SIZE publicly accessible for optimizations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0fddc9539f557609135521cf33ad8bafb8f41c6d", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/0fddc9539f557609135521cf33ad8bafb8f41c6d", "committedDate": "2020-12-08T03:40:49Z", "message": "Fork a local copy of fastutil Long2LongOpenCustomHashMap\n\nFork a copy of fastutil Long2LongOpenCustomHashMap to a new\nLongLong2LongOpenCustomHashMap stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41da3774ab6acea1e8e5ba8a0a6bb0476127c59b", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/41da3774ab6acea1e8e5ba8a0a6bb0476127c59b", "committedDate": "2020-12-08T03:40:49Z", "message": "Properly implement LongLong2LongOpenCustomHashMap within stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83847a0fa3f4262604abfa3f010fcc8c00af9197", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/83847a0fa3f4262604abfa3f010fcc8c00af9197", "committedDate": "2020-12-08T03:40:49Z", "message": "Rename LongLong2LongOpenCustomHashMap into new big variant stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3774ff64075d1f56efea262ce703070e3e13334e", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/3774ff64075d1f56efea262ce703070e3e13334e", "committedDate": "2020-12-08T03:40:50Z", "message": "Properly implement LongLong2LongOpenCustomBigHashMap within stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9829fbb04705e378280b82ea1f916675eabb9acb", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/9829fbb04705e378280b82ea1f916675eabb9acb", "committedDate": "2020-12-08T03:40:50Z", "message": "Fork a local copy of fastutil Long2LongOpenHashMap\n\nFork a copy of fastutil Long2LongOpenHashMap to new\nLong2LongOpenBigHashMap stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7544842c9c9d6fb9a5cc2d6b9aed57ce1efa0be9", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/7544842c9c9d6fb9a5cc2d6b9aed57ce1efa0be9", "committedDate": "2020-12-08T03:40:50Z", "message": "Properly implement Long2LongOpenBigHashMap within stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "734b99dee6b9e2120d1f8a0972a7051967bab97f", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/734b99dee6b9e2120d1f8a0972a7051967bab97f", "committedDate": "2020-12-08T03:40:50Z", "message": "Fork a local copy of fastutil LongArrayFIFOQueue\n\nFork a copy of fastutil LongArrayFIFOQueue to new LongBigArrayFIFOQueue\nstub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc8d8758b14f57d42f1a2afc0daeb7d92a197f30", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/cc8d8758b14f57d42f1a2afc0daeb7d92a197f30", "committedDate": "2020-12-08T03:40:50Z", "message": "Properly implement LongBigArrayFIFOQueue within stub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa865043602f84e330afbb7068cb08554a437c4a", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/aa865043602f84e330afbb7068cb08554a437c4a", "committedDate": "2020-12-08T03:40:50Z", "message": "Update BenchmarkGroupedTopNBuilder with more realistic paramters\n\n- Update benchmark to actually run over multiple groups\n- Reduce TopN to most common sizes\n- Fix benchmark scoping so that it doesn't bleed the same instance\nacross iterations (GroupedTopNBuilder is only supposed to be used for\nadd/drain pass per instance)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "126b156acb23a5d89d76b9b6f4cfb63080906a11", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/126b156acb23a5d89d76b9b6f4cfb63080906a11", "committedDate": "2020-12-08T03:40:50Z", "message": "Add heap data structure utility for locating path from root to a node"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "faed11387f999579f8daa44e3a52038a274c36b5", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/faed11387f999579f8daa44e3a52038a274c36b5", "committedDate": "2020-12-08T03:40:50Z", "message": "Add GroupedTopNRowNumberAccumulator\n\nThis is a flat data structure for managing multiple top N row number\ngroup calculations that doesn't require per-row or per-group object\nallocations.  The main idea is that a heap (while classically\nrepresented as an array), can be also represented as a tree with node\npointers. These nodes (even across groups) can be efficiently compacted\ninto a single data structure."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "621003602879dcf2484eea15cc77df6ad05acf00", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/621003602879dcf2484eea15cc77df6ad05acf00", "committedDate": "2020-12-08T04:07:25Z", "message": "Refactor GroupedTopNBuilder for better performance and memory\n\n- Introduce RowReferencePageManager to handle the generation of stable\nrow IDs across compaction events\n- Refactor GroupedTopNBuilder to use\nRowReferencePageManager as well as new GroupedTopNRowNumberAccumulator\n\nImproved characteristics\n- Vastly improved GC characteristics:\nNegligible object allocations regardless of row count or group count\n- Performance benchmarks upwards of 4x performance improvements when\nworking with large numbers of groups, and parity with the existing\nsolution in the worst case\n- Requires up to 20% less memory than the current solution when there\nare many groups, but does have a increased constant memory overhead when\ndealing with tiny data sets."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "621003602879dcf2484eea15cc77df6ad05acf00", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/621003602879dcf2484eea15cc77df6ad05acf00", "committedDate": "2020-12-08T04:07:25Z", "message": "Refactor GroupedTopNBuilder for better performance and memory\n\n- Introduce RowReferencePageManager to handle the generation of stable\nrow IDs across compaction events\n- Refactor GroupedTopNBuilder to use\nRowReferencePageManager as well as new GroupedTopNRowNumberAccumulator\n\nImproved characteristics\n- Vastly improved GC characteristics:\nNegligible object allocations regardless of row count or group count\n- Performance benchmarks upwards of 4x performance improvements when\nworking with large numbers of groups, and parity with the existing\nsolution in the worst case\n- Requires up to 20% less memory than the current solution when there\nare many groups, but does have a increased constant memory overhead when\ndealing with tiny data sets."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "committedDate": "2020-12-09T03:52:29Z", "message": "Add structural sanity check method to GroupedTopNRowNumberAccumulator\n\nThe structure has a lot of invariants that can be easily verified, and\nit is quite easy for developers to make mistakes when modifying this\ncode."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "author": {"user": {"login": "erichwang", "name": "Eric Hwang"}}, "url": "https://github.com/trinodb/trino/commit/622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "committedDate": "2020-12-09T03:52:29Z", "message": "Add structural sanity check method to GroupedTopNRowNumberAccumulator\n\nThe structure has a lot of invariants that can be easily verified, and\nit is quite easy for developers to make mistakes when modifying this\ncode."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4Njg5MzAw", "url": "https://github.com/trinodb/trino/pull/6072#pullrequestreview-548689300", "createdAt": "2020-12-09T23:08:21Z", "commit": {"oid": "622be17edc76f48d688e9bbf6eb52b44ee50ab4b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2296, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}