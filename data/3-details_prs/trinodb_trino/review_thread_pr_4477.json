{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwNDYzNjY0", "number": 4477, "reviewThreads": {"totalCount": 52, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjowNDo1NlrOEPXocw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDozMDoyN1rOETSB3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTUxMjgzOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjowNDo1NlrOGzC3cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjowNDo1NlrOGzC3cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE3NzUyMQ==", "bodyText": "It's generally preferred not to negate the condition being tested.  Here you have 2 branches, so it's not offering any advantages.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456177521", "createdAt": "2020-07-17T02:04:56Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTUxOTY1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjowOToyM1rOGzC7kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjowOToyM1rOGzC7kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE3ODU3OA==", "bodyText": "You could use isDateTimeType(type).", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456178578", "createdAt": "2020-07-17T02:09:23Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTUyMzUxOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjoxMTo0MlrOGzC98w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjoxMTo0MlrOGzC98w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE3OTE4Nw==", "bodyText": "No need for this.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456179187", "createdAt": "2020-07-17T02:11:42Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTUzODIzOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjoyMDozM1rOGzDGtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjoyMDozM1rOGzDGtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE4MTQyOA==", "bodyText": "Maybe have a method for DAYS.toMillis(value.getDays()?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456181428", "createdAt": "2020-07-17T02:20:33Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 230}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTU5ODkzOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjo1NzowMFrOGzDqwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMjo1NzowMFrOGzDqwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5MDY1OA==", "bodyText": "Can you rename the data provider so it does not start with 'test'?  Also, there is no need to provide a name in the annotation, if it's identical to the method name.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456190658", "createdAt": "2020-07-17T02:57:00Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider(name = \"testJsonDateTimeFormatsDataProvider\")\n+    public final Object[][] testJsonDateTimeFormatsDataProvider()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTYwNTE2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMzowMDo0MVrOGzDuTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo0NToyMFrOGzV1Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5MTU2Nw==", "bodyText": "Since the column list is the same for each test case, you can hard-code it in the test.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456191567", "createdAt": "2020-07-17T03:00:41Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider(name = \"testJsonDateTimeFormatsDataProvider\")\n+    public final Object[][] testJsonDateTimeFormatsDataProvider()\n+    {\n+        return testJsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> testJsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()\n+                .add(new JsonDateTimeTestCase(\n+                        \"custom_date_time\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"iso8601\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"rfc2822\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03'\",\n+                                        \"TIME '01:02:03 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"milliseconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"seconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ4ODI0Ng==", "bodyText": "unfortunately seconds/milliseconds since epoch don't support date", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456488246", "createdAt": "2020-07-17T14:45:20Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider(name = \"testJsonDateTimeFormatsDataProvider\")\n+    public final Object[][] testJsonDateTimeFormatsDataProvider()\n+    {\n+        return testJsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> testJsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()\n+                .add(new JsonDateTimeTestCase(\n+                        \"custom_date_time\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"iso8601\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"rfc2822\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03'\",\n+                                        \"TIME '01:02:03 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"milliseconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"seconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5MTU2Nw=="}, "originalCommit": null, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTYxMTUyOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMzowNDo1NlrOGzDyJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMzowNDo1NlrOGzDyJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5MjU0OQ==", "bodyText": "String::valueOf would be safer than Object::toString here.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456192549", "createdAt": "2020-07-17T03:04:56Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider(name = \"testJsonDateTimeFormatsDataProvider\")\n+    public final Object[][] testJsonDateTimeFormatsDataProvider()\n+    {\n+        return testJsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> testJsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()\n+                .add(new JsonDateTimeTestCase(\n+                        \"custom_date_time\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"iso8601\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"rfc2822\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\", \"f_date\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03'\",\n+                                        \"TIME '01:02:03 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03 UTC'\",\n+                                        \"DATE '2020-07-15'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"milliseconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03.456'\",\n+                                        \"TIME '01:02:03.456 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03.456 UTC'\"))))\n+                .add(new JsonDateTimeTestCase(\n+                        \"seconds_since_epoch\",\n+                        ImmutableList.of(\"f_time\", \"f_time_with_time_zone\", \"f_timestamp\", \"f_timestamp_with_time_zone\"),\n+                        ImmutableList.of(\n+                                ImmutableList.of(\"TIME '01:02:03'\",\n+                                        \"TIME '01:02:03 UTC'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03'\",\n+                                        \"TIMESTAMP '2020-07-15 01:02:03 UTC'\"))))\n+                .build();\n+    }\n+\n+    private static final class JsonDateTimeTestCase\n+    {\n+        private final String tableName;\n+        private final List<String> fieldNames;\n+        private final List<List<Object>> rowValues;\n+        private final int numRows;\n+\n+        public JsonDateTimeTestCase(String tableName, List<String> fieldNames, List<List<Object>> rowValues)\n+        {\n+            this.tableName = requireNonNull(tableName, \"tableName is null\");\n+            this.fieldNames = ImmutableList.copyOf(fieldNames);\n+            this.rowValues = ImmutableList.copyOf(rowValues);\n+            this.numRows = rowValues.size();\n+        }\n+\n+        public String getTableName()\n+        {\n+            return tableName;\n+        }\n+\n+        public String getFieldNames()\n+        {\n+            return String.join(\", \", fieldNames);\n+        }\n+\n+        public int getNumRows()\n+        {\n+            return numRows;\n+        }\n+\n+        public String getRowValues()\n+        {\n+            String[] values = new String[rowValues.size()];\n+            for (int i = 0; i < rowValues.size(); i++) {\n+                values[i] = \"(\" + rowValues.get(i).stream().map(Object::toString).collect(Collectors.joining(\", \")) + \")\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTY0Mzk2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/encoder/json/TestJsonDateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMzoyNToyMFrOGzEEfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo0ODo1OFrOGzV-gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5NzI0Nw==", "bodyText": "TBH, I find this test difficult to read.  I am looking at the setup and I wouldn't be able to predict what the outcome should be (not without writing a small program).  Maybe I'm missing something, but I don't think it adds anything to the tests in TestKafkaIntegrationSmokeTest.  If you wanted to see the full JSON message that is generated, you can get that in the round-trip test too (in _message).", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456197247", "createdAt": "2020-07-17T03:25:20Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/encoder/json/TestJsonDateTime.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import io.prestosql.plugin.kafka.KafkaColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.RowEncoder;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.DateType;\n+import io.prestosql.spi.type.TimeType;\n+import io.prestosql.spi.type.TimeWithTimeZoneType;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.testing.TestingConnectorSession;\n+import org.testcontainers.shaded.com.google.common.collect.ImmutableList;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.Optional;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.testing.assertions.Assert.assertEquals;\n+\n+public class TestJsonDateTime\n+{\n+    private static final JsonRowEncoderFactory ENCODER_FACTORY = new JsonRowEncoderFactory(new ObjectMapper());\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat)\n+    {\n+        return createColumnHandle(name, type, dataFormat, null);\n+    }\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat, String formatHint)\n+    {\n+        return new KafkaColumnHandle(name, type, name, dataFormat, formatHint, false, false, false);\n+    }\n+\n+    private static RowEncoder createRowEncoder(EncoderColumnHandle... columnHandles)\n+    {\n+        return ENCODER_FACTORY.create(TestingConnectorSession.SESSION, Optional.empty(), ImmutableList.copyOf(columnHandles));\n+    }\n+\n+    @Test\n+    public void testCustomFormat()\n+    {\n+        EncoderColumnHandle col1 = createColumnHandle(\"col1\", DateType.DATE, \"custom-date-time\", \"yyyy-dd-MM\");\n+        EncoderColumnHandle col2 = createColumnHandle(\"col2\", TimeType.TIME, \"custom-date-time\", \"kk:mm:ss.SSS\");\n+        EncoderColumnHandle col3 = createColumnHandle(\"col3\", TimeWithTimeZoneType.TIME_WITH_TIME_ZONE, \"custom-date-time\", \"kk:mm:ss.SSS Z\");\n+        EncoderColumnHandle col4 = createColumnHandle(\"col4\", TimestampType.createTimestampType(3), \"custom-date-time\", \"yyyy-dd-MM kk:mm:ss.SSS\");\n+        EncoderColumnHandle col5 = createColumnHandle(\"col5\", TimestampWithTimeZoneType.createTimestampWithTimeZoneType(3), \"custom-date-time\", \"yyyy-dd-MM kk:mm:ss.SSS Z\");\n+\n+        RowEncoder rowEncoder = createRowEncoder(col1, col2, col3, col4, col5);\n+\n+        Block dateBlock = DateType.DATE.createBlockBuilder(null, 1).writeInt(18458);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5MDYyNg==", "bodyText": "I wrote these tests for development because they are a million times faster than the roundtrip test in TestKafkaIntegrationSmokeTest. They both serve the same purpose now, idk if it would be a good idea to keep them around for development or if I should just use the roundtrip tests.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456490626", "createdAt": "2020-07-17T14:48:58Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/encoder/json/TestJsonDateTime.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import io.prestosql.plugin.kafka.KafkaColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.RowEncoder;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.DateType;\n+import io.prestosql.spi.type.TimeType;\n+import io.prestosql.spi.type.TimeWithTimeZoneType;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.testing.TestingConnectorSession;\n+import org.testcontainers.shaded.com.google.common.collect.ImmutableList;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.Optional;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.testing.assertions.Assert.assertEquals;\n+\n+public class TestJsonDateTime\n+{\n+    private static final JsonRowEncoderFactory ENCODER_FACTORY = new JsonRowEncoderFactory(new ObjectMapper());\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat)\n+    {\n+        return createColumnHandle(name, type, dataFormat, null);\n+    }\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat, String formatHint)\n+    {\n+        return new KafkaColumnHandle(name, type, name, dataFormat, formatHint, false, false, false);\n+    }\n+\n+    private static RowEncoder createRowEncoder(EncoderColumnHandle... columnHandles)\n+    {\n+        return ENCODER_FACTORY.create(TestingConnectorSession.SESSION, Optional.empty(), ImmutableList.copyOf(columnHandles));\n+    }\n+\n+    @Test\n+    public void testCustomFormat()\n+    {\n+        EncoderColumnHandle col1 = createColumnHandle(\"col1\", DateType.DATE, \"custom-date-time\", \"yyyy-dd-MM\");\n+        EncoderColumnHandle col2 = createColumnHandle(\"col2\", TimeType.TIME, \"custom-date-time\", \"kk:mm:ss.SSS\");\n+        EncoderColumnHandle col3 = createColumnHandle(\"col3\", TimeWithTimeZoneType.TIME_WITH_TIME_ZONE, \"custom-date-time\", \"kk:mm:ss.SSS Z\");\n+        EncoderColumnHandle col4 = createColumnHandle(\"col4\", TimestampType.createTimestampType(3), \"custom-date-time\", \"yyyy-dd-MM kk:mm:ss.SSS\");\n+        EncoderColumnHandle col5 = createColumnHandle(\"col5\", TimestampWithTimeZoneType.createTimestampWithTimeZoneType(3), \"custom-date-time\", \"yyyy-dd-MM kk:mm:ss.SSS Z\");\n+\n+        RowEncoder rowEncoder = createRowEncoder(col1, col2, col3, col4, col5);\n+\n+        Block dateBlock = DateType.DATE.createBlockBuilder(null, 1).writeInt(18458);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5NzI0Nw=="}, "originalCommit": null, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTY2MDAzOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMzozNDo1N1rOGzENgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo1MDo1MlrOGzWDlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5OTU1Mg==", "bodyText": "I think there was a suggestion in a previous review about testing with more than one record.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456199552", "createdAt": "2020-07-17T03:34:57Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -189,10 +304,14 @@ public void testRoundTripAllFormats(RoundTripTestCase testCase)\n                         \"all_datatypes_csv\",\n                         ImmutableList.of(\"f_bigint\", \"f_int\", \"f_smallint\", \"f_tinyint\", \"f_double\", \"f_boolean\", \"f_varchar\"),\n                         ImmutableList.of(100000, 1000, 100, 10, 1000.001, true, \"'test'\")))\n+                .add(new RoundTripTestCase(\n+                        \"all_datatypes_json\",\n+                        ImmutableList.of(\"f_bigint\", \"f_int\", \"f_smallint\", \"f_tinyint\", \"f_double\", \"f_boolean\", \"f_varchar\"),\n+                        ImmutableList.of(100000, 1000, 100, 10, 1000.001, true, \"'test'\")))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5MTkyNw==", "bodyText": "yes, that commit is in the raw encoder pr #4417. I'll make sure that get's brought in when it merges", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456491927", "createdAt": "2020-07-17T14:50:52Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -189,10 +304,14 @@ public void testRoundTripAllFormats(RoundTripTestCase testCase)\n                         \"all_datatypes_csv\",\n                         ImmutableList.of(\"f_bigint\", \"f_int\", \"f_smallint\", \"f_tinyint\", \"f_double\", \"f_boolean\", \"f_varchar\"),\n                         ImmutableList.of(100000, 1000, 100, 10, 1000.001, true, \"'test'\")))\n+                .add(new RoundTripTestCase(\n+                        \"all_datatypes_json\",\n+                        ImmutableList.of(\"f_bigint\", \"f_int\", \"f_smallint\", \"f_tinyint\", \"f_double\", \"f_boolean\", \"f_varchar\"),\n+                        ImmutableList.of(100000, 1000, 100, 10, 1000.001, true, \"'test'\")))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE5OTU1Mg=="}, "originalCommit": null, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjM1Mzk4OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/resources/write_test/custom_date_time.json", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODo0MDowNFrOGzKmSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODo0MDowNFrOGzKmSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMwNDIwMg==", "bodyText": "suffix the definitions for testing timestamp with _json so it is obvious what format are we talking about.\ncustom_date_time.json -> custom_date_time_json.json\nAlternatively create write_test/json directory for definitions related to json encoder.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456304202", "createdAt": "2020-07-17T08:40:04Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/resources/write_test/custom_date_time.json", "diffHunk": "@@ -0,0 +1,55 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjYyNjI2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMDowMTo1MFrOGzNMsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo1MzoxNlrOGzWJhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0NjgwMQ==", "bodyText": "A thought. Can we have some tests for validation? Maybe for other formats too?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456346801", "createdAt": "2020-07-17T10:01:50Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5MzQ0NQ==", "bodyText": "yes, that would be a good idea", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456493445", "createdAt": "2020-07-17T14:53:16Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0NjgwMQ=="}, "originalCommit": null, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjYzMDg1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMDowMzoxMVrOGzNPcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMDowMzoxMVrOGzNPcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0NzUwNA==", "bodyText": "check if formatHint is parsable pattern?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456347504", "createdAt": "2020-07-17T10:03:11Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjYzNDI3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMDowNDowM1rOGzNRVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMDowNDowM1rOGzNRVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0Nzk5MA==", "bodyText": "move to the top so it is above more specific checks", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456347990", "createdAt": "2020-07-17T10:04:03Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Njg1MjMwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMToyMDo1M1rOGzPT8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMToyMDo1M1rOGzPT8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM4MTQyNA==", "bodyText": "maybe extract columnHandles.get(currentColumnIndex).getName() as currentColumnName() ?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456381424", "createdAt": "2020-07-17T11:20:53Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Njg2Nzg1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMToyNzoxM1rOGzPdTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo1NToyOFrOGzWPTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM4MzgyMw==", "bodyText": "the constants are repeating in multiple switch cases. Extract consts. Or define enum", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456383823", "createdAt": "2020-07-17T11:27:13Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5NDkyNg==", "bodyText": "oh an enum would be good. What do you think of having separate classes for the formatters? We could precompile a list of formatters at encoder initialization.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456494926", "createdAt": "2020-07-17T14:55:28Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM4MzgyMw=="}, "originalCommit": null, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjkyMTYwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo0Nzo0NFrOGzP9Yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo1NjozNFrOGzWR-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5MjAzNQ==", "bodyText": "can we precompute this one. Seems thread safe and stateless.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456392035", "createdAt": "2020-07-17T11:47:44Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))\n+                        .toString(this.getCustomFormatter(columnHandle.getFormatHint()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5NTYwOQ==", "bodyText": "yes", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456495609", "createdAt": "2020-07-17T14:56:34Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))\n+                        .toString(this.getCustomFormatter(columnHandle.getFormatHint()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5MjAzNQ=="}, "originalCommit": null, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjkyNTAyOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo0ODo1OFrOGzP_YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo0ODo1OFrOGzP_YQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5MjU0NQ==", "bodyText": "why go throw milliseconds and not directly DAYS.toSeconds()", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456392545", "createdAt": "2020-07-17T11:48:58Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))\n+                        .toString(this.getCustomFormatter(columnHandle.getFormatHint()));\n+            case \"rfc2822\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .format(RFC_FORMATTER);\n+            case \"iso8601\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .toLocalDate()\n+                        .format(ISO_DATE);\n+            case \"milliseconds-since-epoch\":\n+                return String.valueOf(DAYS.toMillis(value.getDays()));\n+            case \"seconds-since-epoch\":\n+                return String.valueOf(MILLISECONDS.toSeconds(DAYS.toMillis(value.getDays())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjkzNTI5OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo1MjoxM1rOGzQFWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo1MjoxM1rOGzQFWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5NDA3NQ==", "bodyText": "please name the formatDateTime methods similarly to append* so name contains type of formatted object.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456394075", "createdAt": "2020-07-17T11:52:13Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))\n+                        .toString(this.getCustomFormatter(columnHandle.getFormatHint()));\n+            case \"rfc2822\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .format(RFC_FORMATTER);\n+            case \"iso8601\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .toLocalDate()\n+                        .format(ISO_DATE);\n+            case \"milliseconds-since-epoch\":\n+                return String.valueOf(DAYS.toMillis(value.getDays()));\n+            case \"seconds-since-epoch\":\n+                return String.valueOf(MILLISECONDS.toSeconds(DAYS.toMillis(value.getDays())));\n+            default:\n+                throw new PrestoException(GENERIC_USER_ERROR, format(\"invalid data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlTime value)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 250}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Njk0NTUwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo1NjowNVrOGzQLkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMTo1NjowNVrOGzQLkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5NTY2NQ==", "bodyText": "at this point it is internal error as we validate if data format is correct during encoder construction.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456395665", "createdAt": "2020-07-17T11:56:05Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_USER_ERROR;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.time.ZoneOffset.UTC;\n+import static java.time.format.DateTimeFormatter.ISO_DATE;\n+import static java.time.format.DateTimeFormatter.ISO_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_OFFSET_TIME;\n+import static java.time.format.DateTimeFormatter.ISO_TIME;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+    private static final Set<String> DATE_TIME_FORMATS = ImmutableSet.of(\n+            \"custom-date-time\", \"iso8601\", \"rfc2822\", \"milliseconds-since-epoch\", \"seconds-since-epoch\");\n+    private static final String CUSTOM_DATE_TIME_NAME = \"custom-date-time\";\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            if (!isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+            }\n+            else {\n+                checkArgument(DATE_TIME_FORMATS.contains(columnHandle.getDataFormat()), \"Incorrect data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                if (columnHandle.getDataFormat().equals(CUSTOM_DATE_TIME_NAME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+            }\n+\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+        }\n+\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(columnHandles.get(currentColumnIndex).getName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestampWithTimeZone(SqlTimestampWithTimeZone value)\n+    {\n+        node.put(columnHandles.get(currentColumnIndex).getName(), this.formatDateTime(columnHandles.get(currentColumnIndex), value));\n+    }\n+\n+    private org.joda.time.format.DateTimeFormatter getCustomFormatter(String format)\n+    {\n+        try {\n+            return org.joda.time.format.DateTimeFormat.forPattern(format).withLocale(Locale.ENGLISH);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"invalid joda pattern '%s' passed as format hint\", format));\n+        }\n+    }\n+\n+    private String formatDateTime(EncoderColumnHandle columnHandle, SqlDate value)\n+    {\n+        switch (columnHandle.getDataFormat()) {\n+            case \"custom-date-time\":\n+                return (new DateTime(DAYS.toMillis(value.getDays()), DateTimeZone.UTC))\n+                        .toString(this.getCustomFormatter(columnHandle.getFormatHint()));\n+            case \"rfc2822\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .format(RFC_FORMATTER);\n+            case \"iso8601\":\n+                return Instant.ofEpochMilli(DAYS.toMillis(value.getDays()))\n+                        .atZone(UTC)\n+                        .toLocalDate()\n+                        .format(ISO_DATE);\n+            case \"milliseconds-since-epoch\":\n+                return String.valueOf(DAYS.toMillis(value.getDays()));\n+            case \"seconds-since-epoch\":\n+                return String.valueOf(MILLISECONDS.toSeconds(DAYS.toMillis(value.getDays())));\n+            default:\n+                throw new PrestoException(GENERIC_USER_ERROR, format(\"invalid data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Njk2OTg0OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMjowNDo1MlrOGzQabg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNDo1ODoxMlrOGzWV0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5OTQ3MA==", "bodyText": "how is logic here different from testRoundTripAllFormats?\nCan we make testRoundTripAllFormats and testJsonDateTimeFormats share testcase definition.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456399470", "createdAt": "2020-07-17T12:04:52Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ5NjU5NA==", "bodyText": "yes, that's the plan when the raw encoder pr merges #4417", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r456496594", "createdAt": "2020-07-17T14:58:12Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,6 +162,119 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n+    @Test(dataProvider = \"testJsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5OTQ3MA=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTI5NDY2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0Mjo0MVrOG0-L6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0Mjo0MVrOG0-L6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE5Nzk5Mg==", "bodyText": "extract helper method", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458197992", "createdAt": "2020-07-21T15:42:41Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTMwMzI4OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NDozOVrOG0-RdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NDozOVrOG0-RdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE5OTQxMw==", "bodyText": "static import FormatType", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458199413", "createdAt": "2020-07-21T15:44:39Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTMwNzAxOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NToyNFrOG0-Tqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NToyNFrOG0-Tqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE5OTk3OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n          \n          \n            \n                            if (dataFormat == FormatType.CUSTOM_DATE_TIME) {", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458199978", "createdAt": "2020-07-21T15:45:24Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTMxMjQ0OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0Njo0MFrOG0-XLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0Njo0MFrOG0-XLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIwMDg3OA==", "bodyText": "inline", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458200878", "createdAt": "2020-07-21T15:46:40Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTMxNTgyOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NzoyMFrOG0-ZRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0NzoyMFrOG0-ZRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIwMTQxNA==", "bodyText": "name it formatFunctions", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458201414", "createdAt": "2020-07-21T15:47:20Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTM3Mzc0OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/DefaultFormatFunction.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjowMDowMlrOG0-9VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMTozOToxMFrOG1elAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMDY0NQ==", "bodyText": "this one is never used in practice, as whenever you take something out of formatFunctions you cast it to JsonDateTimeFormatFunction. Is that a bug?\nAlso I do not huge fan of idea of having format functions which do not satisfy common interface in single list.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458210645", "createdAt": "2020-07-21T16:00:02Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/DefaultFormatFunction.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+public interface DefaultFormatFunction", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxNTk2MA==", "bodyText": "I needed a filler function for non-temporal columns. I agree this is less than ideal, I'm not sure what to replace it with. This function is never actually used in the encoder. I was thinking that in the future we could replace all the appendLong, appendBoolean... methods with a precompiled list of lambda functions to format/add the column value to the encoder. For now we need to figure out a different solution. I could change the List<JsonFormatFunctions> formatFunctions field in JsonRowEncoder to a Map and have the column handle as the key? That way I don't need to access it with the currentColumnIndex.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458415960", "createdAt": "2020-07-21T22:05:22Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/DefaultFormatFunction.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+public interface DefaultFormatFunction", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMDY0NQ=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyODcwNw==", "bodyText": "I find the approach with default function cumbersome. Maybe instead having a hierarchy here we can just have as set of functions and single class with methods delegating to functors. Then we can provide the fuctions we care about as lambdas via builder. The ones which are not explicitly set would just throw exception.\nSth like this:\npublic class JsonFormatFunction\n{\n    private final Function<Instant, String> formatTimestampLegacyFunc;\n    private final Function<LocalDateTime, String> formatTimestampFunc;\n    //private final Function<Something, String> formatSomething;\n\n    public JsonFormatFunction(Function<Instant, String> formatTimestampLegacyFunc, Function<LocalDateTime, String> formatTimestampFunc)\n    {\n        this.formatTimestampLegacyFunc = formatTimestampLegacyFunc;\n        this.formatTimestampFunc = formatTimestampFunc;\n    }\n\n    public String formatTimestampLegacy(Instant value)\n    {\n        return formatTimestampLegacyFunc.apply(value);\n    };\n\n    public String formatTimestamp(LocalDateTime value)\n    {\n        return formatTimestampFunc.apply(value);\n    }\n\n    public static class Builder\n    {\n        private Function<Instant, String> formatTimestampLegacyFunc = (ignored) -> { throw new RuntimeException(\"not supported argument type\"); };\n        private Function<LocalDateTime, String> formatTimestampFunc = (ignored) -> { throw new RuntimeException(\"not supported argument type\"); };\n\n        JsonFormatFunction build()\n        {\n            return new JsonFormatFunction(\n                    formatTimestampLegacyFunc,\n                    formatTimestampFunc);\n        }\n\n        public Builder setFormatTimestampLegacyFunc(Function<Instant, String> formatTimestampLegacyFunc)\n        {\n            this.formatTimestampLegacyFunc = formatTimestampLegacyFunc;\n            return this;\n        }\n\n        public Builder setFormatTimestampFunc(Function<LocalDateTime, String> formatTimestampFunc)\n        {\n            this.formatTimestampFunc = formatTimestampFunc;\n            return this;\n        }\n    }\n}\nOne downside of this is that is a bit verbose. It also involves extra boxing/unboxing - not sure how much of a problem that is with new JVMs.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458728707", "createdAt": "2020-07-22T11:39:10Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/DefaultFormatFunction.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+public interface DefaultFormatFunction", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMDY0NQ=="}, "originalCommit": null, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTQ4NjkwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjoyNjo1MFrOG1AElg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxMTozNzo0MlrOG2sNYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyODg4Ng==", "bodyText": "This looks wrong. It does not seem to me that you should not use same formatting function and just pass different version to it based on selected timestamp semantic.\nAs the semantics is different the formatting should be different. I.e it does not make sense to append any timezone information for non-legacy semantics in output string.\nIt is hard for me to wrap my head around it though.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458228886", "createdAt": "2020-07-21T16:26:50Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());\n+\n+                formatFunctionsBuilder.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, formatHint, columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctionsBuilder.add(defaultFormatFunction());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctionsBuilder.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private JsonDateTimeFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return dateFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME) {\n+            return timeFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {\n+            return timeWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampType) {\n+            return timestampFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampWithTimeZoneType) {\n+            return timestampWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Invalid type '%s' for temporal column '%s'\", type.getDisplayName(), dataFormat, name));\n+        }\n+    }\n+\n+    private String currentColumnName()\n+    {\n+        return columnHandles.get(currentColumnIndex).getName();\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(currentColumnName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(currentColumnName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(daysToMillis(value.getDays())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(value.getMillis()));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(packDateTimeWithZone(value.getMillisUtc(), value.getTimeZoneKey())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        if (session.isLegacyTimestamp()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxNzE2MA==", "bodyText": "Ik the timestamp changes have me confused as well (clearly hahah). I think I've been testing with the legacy timestamp, which would explain why I haven't encountered a problem with this yet, so I'll add different functions and test with the new timestamp.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458417160", "createdAt": "2020-07-21T22:08:08Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());\n+\n+                formatFunctionsBuilder.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, formatHint, columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctionsBuilder.add(defaultFormatFunction());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctionsBuilder.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private JsonDateTimeFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return dateFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME) {\n+            return timeFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {\n+            return timeWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampType) {\n+            return timestampFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampWithTimeZoneType) {\n+            return timestampWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Invalid type '%s' for temporal column '%s'\", type.getDisplayName(), dataFormat, name));\n+        }\n+    }\n+\n+    private String currentColumnName()\n+    {\n+        return columnHandles.get(currentColumnIndex).getName();\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(currentColumnName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(currentColumnName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(daysToMillis(value.getDays())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(value.getMillis()));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(packDateTimeWithZone(value.getMillisUtc(), value.getTimeZoneKey())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        if (session.isLegacyTimestamp()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyODg4Ng=="}, "originalCommit": null, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczNzU0Mg==", "bodyText": "It seems to me that cleanest approach would be to not allow encoding timestamp in non-legacy semantic to any format which clearly denotes an instant (i.e. explicitly specifies a timezone in a value). The problem with that is it would be not compatible with what we already have in decoders (which do not care about timestamp semantics whatsoever).\nMaybe we should assume that logic in decoders only makes sense for legacy timestamp semantics, and enforce that with check in the connector. Then we can focus on implementing just legacy semantics of timestamp in encoders in a way that is compatible with decoders.\nThen we can add non-legacy semantics to both decoders and encoders?\nThe problem with that is that we would break people which use kafka timestamp decoders with timestamp semantic set to non-legacy. I do not expect that it would be many users, but one never knows.\n@findepi, as an expert on hard issues, can you chime in here?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458737542", "createdAt": "2020-07-22T11:56:35Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());\n+\n+                formatFunctionsBuilder.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, formatHint, columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctionsBuilder.add(defaultFormatFunction());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctionsBuilder.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private JsonDateTimeFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return dateFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME) {\n+            return timeFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {\n+            return timeWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampType) {\n+            return timestampFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampWithTimeZoneType) {\n+            return timestampWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Invalid type '%s' for temporal column '%s'\", type.getDisplayName(), dataFormat, name));\n+        }\n+    }\n+\n+    private String currentColumnName()\n+    {\n+        return columnHandles.get(currentColumnIndex).getName();\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(currentColumnName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(currentColumnName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(daysToMillis(value.getDays())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(value.getMillis()));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(packDateTimeWithZone(value.getMillisUtc(), value.getTimeZoneKey())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        if (session.isLegacyTimestamp()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyODg4Ng=="}, "originalCommit": null, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ2ODUwNw==", "bodyText": "@losipiuk i like your proposal.\ni would only add that there seems to be no fundamental problem in decoding timestamp (without zone) from a value containing a zone. You could think of it as a CAST.\nEg JDBC ResultSet.getDate can be called on a date or timestamp, and returns a date part of the value.\nI am OK with dropping this though, for non-legacy. We can always re-add this if we learn about particular requirements.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r459468507", "createdAt": "2020-07-23T13:56:19Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());\n+\n+                formatFunctionsBuilder.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, formatHint, columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctionsBuilder.add(defaultFormatFunction());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctionsBuilder.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private JsonDateTimeFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return dateFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME) {\n+            return timeFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {\n+            return timeWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampType) {\n+            return timestampFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampWithTimeZoneType) {\n+            return timestampWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Invalid type '%s' for temporal column '%s'\", type.getDisplayName(), dataFormat, name));\n+        }\n+    }\n+\n+    private String currentColumnName()\n+    {\n+        return columnHandles.get(currentColumnIndex).getName();\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(currentColumnName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(currentColumnName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(daysToMillis(value.getDays())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(value.getMillis()));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(packDateTimeWithZone(value.getMillisUtc(), value.getTimeZoneKey())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        if (session.isLegacyTimestamp()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyODg4Ng=="}, "originalCommit": null, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDAwMDYxMQ==", "bodyText": "Thanks for comment.\n\n@losipiuk i like your proposal.\ni would only add that there seems to be no fundamental problem in decoding timestamp (without zone) from a value containing a zone. You could think of it as a CAST.\nEg JDBC ResultSet.getDate can be called on a date or timestamp, and returns a date part of the value.\nI am OK with dropping this though, for non-legacy. We can always re-add this if we learn about particular requirements.\n\nYeah - it makes sense for decoding. Less so for encoding, as it not obvious what timezone use in encoded value. And even if timezone is statically defined by encoding format it is kinda smelly.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r460000611", "createdAt": "2020-07-24T11:37:42Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonDateTimeFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.dateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.defaultFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.timestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctionsBuilder = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                JsonFormatFunctions.FormatType dataFormat;\n+                try {\n+                    dataFormat = JsonFormatFunctions.FormatType.valueOf(columnHandle.getDataFormat().toUpperCase().replaceAll(\"-\", \"_\"));\n+                }\n+                catch (IllegalArgumentException e) {\n+                    throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName()), e);\n+                }\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+                if (dataFormat.equals(JsonFormatFunctions.FormatType.CUSTOM_DATE_TIME)) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+                Optional<String> formatHint = Optional.ofNullable(columnHandle.getFormatHint());\n+\n+                formatFunctionsBuilder.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, formatHint, columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctionsBuilder.add(defaultFormatFunction());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctionsBuilder.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private JsonDateTimeFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return dateFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME) {\n+            return timeFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {\n+            return timeWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampType) {\n+            return timestampFormatFunction(dataFormat, formatHint);\n+        }\n+        else if (type instanceof TimestampWithTimeZoneType) {\n+            return timestampWithTZFormatFunction(dataFormat, formatHint);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Invalid type '%s' for temporal column '%s'\", type.getDisplayName(), dataFormat, name));\n+        }\n+    }\n+\n+    private String currentColumnName()\n+    {\n+        return columnHandles.get(currentColumnIndex).getName();\n+    }\n+\n+    @Override\n+    protected void appendNullValue()\n+    {\n+        node.putNull(currentColumnName());\n+    }\n+\n+    @Override\n+    protected void appendLong(long value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendInt(int value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendShort(short value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByte(byte value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendDouble(double value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendFloat(float value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendBoolean(boolean value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendString(String value)\n+    {\n+        node.put(currentColumnName(), value);\n+    }\n+\n+    @Override\n+    protected void appendByteBuffer(ByteBuffer value)\n+    {\n+        node.put(currentColumnName(), value.array());\n+    }\n+\n+    @Override\n+    protected void appendSqlDate(SqlDate value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(daysToMillis(value.getDays())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTime(SqlTime value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(value.getMillis()));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimeWithTimeZone(SqlTimeWithTimeZone value)\n+    {\n+        node.put(currentColumnName(), ((JsonDateTimeFormatFunction) formatFunctions.get(currentColumnIndex)).format(packDateTimeWithZone(value.getMillisUtc(), value.getTimeZoneKey())));\n+    }\n+\n+    @Override\n+    protected void appendSqlTimestamp(SqlTimestamp value)\n+    {\n+        if (session.isLegacyTimestamp()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyODg4Ng=="}, "originalCommit": null, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTUzMDM0OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjozODowOVrOG1AgzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMTo1NzozMVrOG1fJPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ==", "bodyText": "I think those test would benefit if stracture it more granurally, where single testcase defines\n\nformat\ncolumn\nexpected value\n\nSth like this:\n        testCaseBuilder.\n            .addTestCase(\"custom_date_time_json\", \"f_time\", \"TIME '01:02:03.456'\")\n            .addTestCase(\"custom_date_time_json\", \"f_time\", \"TIME '03:02:03.456'\")\n            .addTestCase(\"custom_date_time_json\", \"f_time_with_time_zone\", \"TIME '05:02:03.456 UTC'\")\n            .addTestCase(\"iso8601_json\", \"f_time\", \"TIME '05:02:03.456'\")\nI think it is easier to read as you have all information about single testcase in single line.\nWe can also focus more on data types which are more problematic and have more corner cases.\nUnder the hood we can insert whole row with all columns but one we care about set to null.\nWDYT?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458236109", "createdAt": "2020-07-21T16:38:09Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MzIyMQ==", "bodyText": "On the other hand maybe the unit tests we have in TestJsonDateTime are enough and these should be treated as just smoke coverage?\n@aalbu ?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458243221", "createdAt": "2020-07-21T16:49:01Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODMzMDk1OA==", "bodyText": "I agree this format would be much easier to read and debug. Could probably just use one table as well.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458330958", "createdAt": "2020-07-21T19:17:43Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ2MzQ1NQ==", "bodyText": "@losipiuk I think lighter coverage here and testing all edge cases in TestJsonDateTime is a good idea.  Perhaps what we would need to add here would be some round-trip tests with legacy semantics enabled.  We should talk about that.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458463455", "createdAt": "2020-07-22T00:25:21Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUxNzY4Mg==", "bodyText": "I think that it would be better to test each individual format function. The current tests in TestJsonDateTime helped me figure out how to write the format functions, but they just aren't great tests.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458517682", "createdAt": "2020-07-22T03:50:28Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUxNzc0OQ==", "bodyText": "+1 to lighter smoke testing", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458517749", "createdAt": "2020-07-22T03:50:51Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczNzk4Mg==", "bodyText": "we should talk about that\n\n@aalbu see #4477 (comment)", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458737982", "createdAt": "2020-07-22T11:57:31Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/TestKafkaIntegrationSmokeTest.java", "diffHunk": "@@ -160,7 +162,120 @@ private KafkaTopicFieldDescription createOneFieldDescription(String name, Type t\n         return new KafkaTopicFieldDescription(name, type, mapping, null, dataFormat, null, false);\n     }\n \n-    @Test(dataProvider = \"testRoundTripAllFormatsDataProvider\")\n+    @Test(dataProvider = \"jsonDateTimeFormatsDataProvider\")\n+    public void testJsonDateTimeFormats(JsonDateTimeTestCase testCase)\n+    {\n+        assertUpdate(\"INSERT into write_test.\" + testCase.getTableName() +\n+                \" (\" + testCase.getFieldNames() + \")\" +\n+                \" VALUES \" + testCase.getRowValues(), testCase.getNumRows());\n+        MaterializedResult actual = computeActual(getSession(), \"SELECT \" + testCase.getFieldNames() + \" FROM write_test.\" + testCase.getTableName() + \" LIMIT \" + testCase.getNumRows());\n+        MaterializedResult expected = computeActual(getSession(), \"VALUES \" + testCase.getRowValues());\n+        assertEquals(actual.getMaterializedRows(), expected.getMaterializedRows());\n+    }\n+\n+    @DataProvider\n+    public final Object[][] jsonDateTimeFormatsDataProvider()\n+    {\n+        return jsonDateTimeFormatsData().stream()\n+                .collect(toDataProvider());\n+    }\n+\n+    private List<JsonDateTimeTestCase> jsonDateTimeFormatsData()\n+    {\n+        return ImmutableList.<JsonDateTimeTestCase>builder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjEwOQ=="}, "originalCommit": null, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTU3MDYxOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/encoder/json/TestJsonDateTime.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo0Nzo0NVrOG1A5ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo0Nzo0NVrOG1A5ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MjQ2Mg==", "bodyText": "Use of datatype internal representation here make the test look cryptic. Compute 1594846503123L using java.time.* instead hardcoding it in tests?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458242462", "createdAt": "2020-07-21T16:47:45Z", "author": {"login": "losipiuk"}, "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/encoder/json/TestJsonDateTime.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import io.prestosql.plugin.kafka.KafkaColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.RowEncoder;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.DateType;\n+import io.prestosql.spi.type.TimeType;\n+import io.prestosql.spi.type.TimeWithTimeZoneType;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.testing.TestingConnectorSession;\n+import org.testcontainers.shaded.com.google.common.collect.ImmutableList;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.Optional;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.testing.assertions.Assert.assertEquals;\n+\n+public class TestJsonDateTime\n+{\n+    private static final JsonRowEncoderFactory ENCODER_FACTORY = new JsonRowEncoderFactory(new ObjectMapper());\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat)\n+    {\n+        return createColumnHandle(name, type, dataFormat, null);\n+    }\n+\n+    private static EncoderColumnHandle createColumnHandle(String name, Type type, String dataFormat, String formatHint)\n+    {\n+        return new KafkaColumnHandle(name, type, name, dataFormat, formatHint, false, false, false);\n+    }\n+\n+    private static RowEncoder createRowEncoder(EncoderColumnHandle... columnHandles)\n+    {\n+        return ENCODER_FACTORY.create(TestingConnectorSession.SESSION, Optional.empty(), ImmutableList.copyOf(columnHandles));\n+    }\n+\n+    @Test\n+    public void testCustomFormat()\n+    {\n+        testDateHelper(18458, \"2020-15-07\", \"custom-date-time\", Optional.of(\"yyyy-dd-MM\"));\n+        testTimeHelper(1594846503123L, \"20:55:03.123\", \"custom-date-time\", Optional.of(\"kk:mm:ss.SSS\"));\n+        testTimeWithTZHelper(packDateTimeWithZone(1594846503123L, \"UTC\"), \"20:55:03.123 +0000\", \"custom-date-time\", Optional.of(\"kk:mm:ss.SSS Z\"));\n+        testTimestampHelper(1594846503123L, \"2020-15-07 20:55:03.123\", \"custom-date-time\", Optional.of(\"yyyy-dd-MM kk:mm:ss.SSS\"));\n+        testTimestampWithTZHelper(packDateTimeWithZone(1594846503123L, \"UTC\"), \"2020-15-07 20:55:03.123 +0000\", \"custom-date-time\", Optional.of(\"yyyy-dd-MM kk:mm:ss.SSS Z\"));\n+    }\n+\n+    @Test\n+    public void testIso8601Format()\n+    {\n+        testDateHelper(18458, \"2020-07-15\", \"iso8601\", Optional.empty());\n+        testTimeHelper(1594846503123L, \"20:55:03.123\", \"iso8601\", Optional.empty());\n+        testTimeWithTZHelper(packDateTimeWithZone(1594846503123L, \"UTC\"), \"20:55:03.123Z\", \"iso8601\", Optional.empty());\n+        testTimestampHelper(1594846503123L, \"2020-07-15T20:55:03.123\", \"iso8601\", Optional.empty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MDQ1MjM3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQyMTowMDoxMlrOG1Jk0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQyMTowMDoxMlrOG1Jk0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM4NDU5Mw==", "bodyText": "Make it final, too.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458384593", "createdAt": "2020-07-21T21:00:12Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public class CustomDateTimeFormatFunctions", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MTAxNzI4OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMDo0OToyNlrOG1Oyxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTozODo1M1rOG2Y4YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ3MDA4Ng==", "bodyText": "The parentheses around the return value are not necessary (and I personally feel they reduce readability).  I also like more passing the temporal value to the formatter:\nreturn millis -> formatter.print(new DateTime(millis, UTC));\nA possible optimization could be pre-instantiating formatters for all patterns when creating the encoder and reusing them (the Joda ones are thread safe), as opposed to doing it for every row.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458470086", "createdAt": "2020-07-22T00:49:26Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static JsonDateTimeFormatFunction dateFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH);\n+            return (millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUxNDA3Nw==", "bodyText": "Shouldn't these functions reuse the same DateTimeFormatter's?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r458514077", "createdAt": "2020-07-22T03:35:43Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static JsonDateTimeFormatFunction dateFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH);\n+            return (millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ3MDA4Ng=="}, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY4MzkzNg==", "bodyText": "You're right, you're actually doing what I was suggesting.  I misread the code.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r459683936", "createdAt": "2020-07-23T19:38:53Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static JsonDateTimeFormatFunction dateFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH);\n+            return (millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ3MDA4Ng=="}, "originalCommit": null, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MDAwODE2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTozNzoyMVrOG39VMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTozNzoyMVrOG39VMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTcxNA==", "bodyText": "I think this can be written in a less repetitive way.  Something like:\nif (type == TIME ||\n            type == TIME_WITH_TIME_ZONE ||\n            type instanceof TimestampType ||\n            type instanceof TimestampWithTimeZoneType) {\n    return true;\n}\nreturn supportsDate && type == DATE;", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461329714", "createdAt": "2020-07-28T05:37:21Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (supportsDate) {\n+                return type == DATE ||\n+                        type == TIME ||\n+                        type == TIME_WITH_TIME_ZONE ||\n+                        type instanceof TimestampType ||\n+                        type instanceof TimestampWithTimeZoneType;\n+            }\n+            return type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MDAyMTUwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTo0MzozNlrOG39c1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTo0MzozNlrOG39c1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzMTY2OA==", "bodyText": "This gets called for TimestampType, but the encoding that seems to be expected here is that of a TimestampWithTimeZoneType.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461331668", "createdAt": "2020-07-28T05:43:36Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> dateFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> timeFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(new DateTime(millis, DateTimeZone.UTC));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> timeWithTZFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(new DateTime(\n+                    unpackMillisUtc(encodedMillisWithTZ),\n+                    DateTimeZone.forID(unpackZoneKey(encodedMillisWithTZ).getId())));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> timestampFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(new DateTime(millis, DateTimeZone.UTC));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> legacyTimestampFormatFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(Instant.ofEpochMilli(unpackMillisUtc(encodedMillisWithTZ)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MDAzNTc2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTo0OTo1NlrOG39lFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOToxOToyOFrOG4a-jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzMzc4MA==", "bodyText": "I can't see where this is used outside of tests.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461333780", "createdAt": "2020-07-28T05:49:56Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (supportsDate) {\n+                return type == DATE ||\n+                        type == TIME ||\n+                        type == TIME_WITH_TIME_ZONE ||\n+                        type instanceof TimestampType ||\n+                        type instanceof TimestampWithTimeZoneType;\n+            }\n+            return type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType;\n+        }\n+\n+        @Override\n+        public String toString()\n+        {\n+            return name().toLowerCase(Locale.ENGLISH).replaceAll(\"_\", \"-\");\n+        }\n+    }\n+\n+    private JsonFormatFunctions() {}\n+\n+    public static long daysToEpochMillis(long value)\n+    {\n+        return DAYS.toMillis(value);\n+    }\n+\n+    public static long millisToSeconds(long value)\n+    {\n+        return MILLISECONDS.toSeconds(value);\n+    }\n+\n+    public static Function<Long, String> dateFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.dateFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.dateFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.dateFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeWithTZFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeWithTZFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeWithTZFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeWithTZFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsWithTZFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsWithTZFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timestampFormatFunction(FormatType formatType, Optional<String> formatHint)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxNTQzOA==", "bodyText": "removed and replaced with legacy function", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461815438", "createdAt": "2020-07-28T19:19:28Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (supportsDate) {\n+                return type == DATE ||\n+                        type == TIME ||\n+                        type == TIME_WITH_TIME_ZONE ||\n+                        type instanceof TimestampType ||\n+                        type instanceof TimestampWithTimeZoneType;\n+            }\n+            return type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType;\n+        }\n+\n+        @Override\n+        public String toString()\n+        {\n+            return name().toLowerCase(Locale.ENGLISH).replaceAll(\"_\", \"-\");\n+        }\n+    }\n+\n+    private JsonFormatFunctions() {}\n+\n+    public static long daysToEpochMillis(long value)\n+    {\n+        return DAYS.toMillis(value);\n+    }\n+\n+    public static long millisToSeconds(long value)\n+    {\n+        return MILLISECONDS.toSeconds(value);\n+    }\n+\n+    public static Function<Long, String> dateFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.dateFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.dateFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.dateFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeWithTZFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeWithTZFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeWithTZFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeWithTZFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsWithTZFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsWithTZFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timestampFormatFunction(FormatType formatType, Optional<String> formatHint)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzMzc4MA=="}, "originalCommit": null, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MDAzNzA5OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTo1MDozMVrOG39l7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOToxOTo0MlrOG4a_AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzMzk5Ng==", "bodyText": "This is a confusing name.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461333996", "createdAt": "2020-07-28T05:50:31Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (supportsDate) {\n+                return type == DATE ||\n+                        type == TIME ||\n+                        type == TIME_WITH_TIME_ZONE ||\n+                        type instanceof TimestampType ||\n+                        type instanceof TimestampWithTimeZoneType;\n+            }\n+            return type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType;\n+        }\n+\n+        @Override\n+        public String toString()\n+        {\n+            return name().toLowerCase(Locale.ENGLISH).replaceAll(\"_\", \"-\");\n+        }\n+    }\n+\n+    private JsonFormatFunctions() {}\n+\n+    public static long daysToEpochMillis(long value)\n+    {\n+        return DAYS.toMillis(value);\n+    }\n+\n+    public static long millisToSeconds(long value)\n+    {\n+        return MILLISECONDS.toSeconds(value);\n+    }\n+\n+    public static Function<Long, String> dateFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.dateFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.dateFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.dateFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeWithTZFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeWithTZFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeWithTZFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeWithTZFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsWithTZFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsWithTZFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timestampFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timestampFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timestampFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timestampFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> legacyTimestampFormatFunction(FormatType formatType, Optional<String> formatHint)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxNTU1Mw==", "bodyText": "tried to rename functions to be more descriptive", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461815553", "createdAt": "2020-07-28T19:19:42Z", "author": {"login": "charlesjmorgan"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (supportsDate) {\n+                return type == DATE ||\n+                        type == TIME ||\n+                        type == TIME_WITH_TIME_ZONE ||\n+                        type instanceof TimestampType ||\n+                        type instanceof TimestampWithTimeZoneType;\n+            }\n+            return type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType;\n+        }\n+\n+        @Override\n+        public String toString()\n+        {\n+            return name().toLowerCase(Locale.ENGLISH).replaceAll(\"_\", \"-\");\n+        }\n+    }\n+\n+    private JsonFormatFunctions() {}\n+\n+    public static long daysToEpochMillis(long value)\n+    {\n+        return DAYS.toMillis(value);\n+    }\n+\n+    public static long millisToSeconds(long value)\n+    {\n+        return MILLISECONDS.toSeconds(value);\n+    }\n+\n+    public static Function<Long, String> dateFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.dateFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.dateFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.dateFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timeWithTZFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timeWithTZFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timeWithTZFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timeWithTZFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsWithTZFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsWithTZFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> timestampFormatFunction(FormatType formatType, Optional<String> formatHint)\n+    {\n+        switch (formatType) {\n+            case CUSTOM_DATE_TIME:\n+                checkArgument(formatHint.isPresent(), \"formatHint not defined for custom-date-time column\");\n+                return CustomDateTimeFormatFunctions.timestampFormatFunction(formatHint.get());\n+            case ISO8601:\n+                return ISO8601FormatFunctions.timestampFormatFunction();\n+            case RFC2822:\n+                return RFC2822FormatFunctions.timestampFormatFunction();\n+            case MILLISECONDS_SINCE_EPOCH:\n+                return MillisecondsFormatFunctions.millisecondsFormatFunction();\n+            case SECONDS_SINCE_EPOCH:\n+                return SecondsFormatFunctions.secondsFormatFunction();\n+            default:\n+                throw new IllegalArgumentException(format(\"Invalid dataFormat '%s'\", formatType));\n+        }\n+    }\n+\n+    public static Function<Long, String> legacyTimestampFormatFunction(FormatType formatType, Optional<String> formatHint)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzMzk5Ng=="}, "originalCommit": null, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzUxMTM1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMTowNzowN1rOG4e6Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMTowNzowN1rOG4e6Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg3OTgxMA==", "bodyText": "You actually don't need all the elses.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r461879810", "createdAt": "2020-07-28T21:07:07Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.FormatType;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToEpochMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getDateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        checkArgument(this.session.isLegacyTimestamp(), \"The JSON encoder does not support non-legacy timestamp semantics\");\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctions = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                FormatType dataFormat = parseDataFormat(columnHandle.getDataFormat(), columnHandle.getName());\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+                if (dataFormat == FormatType.CUSTOM_DATE_TIME) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+\n+                formatFunctions.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, Optional.ofNullable(columnHandle.getFormatHint()), columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctions.add(JsonFormatFunction.builder().build());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctions.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private FormatType parseDataFormat(String dataFormat, String columnName)\n+    {\n+        try {\n+            return FormatType.valueOf(dataFormat.toUpperCase().replaceAll(\"-\", \"_\"));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", dataFormat, columnName), e);\n+        }\n+    }\n+\n+    private JsonFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return JsonFormatFunction.builder().setFormatDateFunc(getDateFormatFunction(dataFormat, formatHint)).build();\n+        }\n+        else if (type == TIME) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTkxNzQwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjowNDowN1rOG41TNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjowNDowN1rOG41TNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI0NjcxMQ==", "bodyText": "You can use a static import (below too).", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462246711", "createdAt": "2020-07-29T12:04:07Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTkzMjk5OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjowODoyNVrOG41cKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjowODoyNVrOG41cKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI0OTAwMg==", "bodyText": "Let's be consistent in the way we format.  Either new DateTime(...).toString(fromatter) as here, or formatter.print(new DateTime(...)) as below.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462249002", "createdAt": "2020-07-29T12:08:25Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjA1MTM3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo0MTozMVrOG42jdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo0MTozMVrOG42jdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI2NzI1Mw==", "bodyText": "You could define\nprivate static final Function<Long, String> UNIMPLEMENTED = ignored -> { throw new RuntimeException(\"unsupported argument type\"); };\n\nand reference that:\nprivate Function<Long, String> formatDateFunc = UNIMPLEMENTED;\nprivate Function<Long, String> formatTimeFunc = UNIMPLEMENTED;\n...", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462267253", "createdAt": "2020-07-29T12:41:31Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunction.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+public class JsonFormatFunction\n+{\n+    private final Function<Long, String> formatDateFunc;\n+    private final Function<Long, String> formatTimeFunc;\n+    private final Function<Long, String> formatTimeWithTZFunc;\n+    private final Function<Long, String> formatTimestampFunc;\n+    private final Function<Long, String> formatTimestampWithTZFunc;\n+\n+    private JsonFormatFunction(\n+            Function<Long, String> formatDateFunc,\n+            Function<Long, String> formatTimeFunc,\n+            Function<Long, String> formatTimeWithTZFunc,\n+            Function<Long, String> formatTimestampFunc,\n+            Function<Long, String> formatTimestampWithTZFunc)\n+    {\n+        this.formatDateFunc = formatDateFunc;\n+        this.formatTimeFunc = formatTimeFunc;\n+        this.formatTimeWithTZFunc = formatTimeWithTZFunc;\n+        this.formatTimestampFunc = formatTimestampFunc;\n+        this.formatTimestampWithTZFunc = formatTimestampWithTZFunc;\n+    }\n+\n+    public static Builder builder()\n+    {\n+        return new Builder();\n+    }\n+\n+    public String formatDate(long value)\n+    {\n+        return formatDateFunc.apply(value);\n+    }\n+\n+    public String formatTime(long value)\n+    {\n+        return formatTimeFunc.apply(value);\n+    }\n+\n+    public String formatTimeWithTZ(long value)\n+    {\n+        return formatTimeWithTZFunc.apply(value);\n+    }\n+\n+    public String formatTimestamp(long value)\n+    {\n+        return formatTimestampFunc.apply(value);\n+    }\n+\n+    public String formatTimestampWithTZ(long value)\n+    {\n+        return formatTimestampWithTZFunc.apply(value);\n+    }\n+\n+    public static class Builder\n+    {\n+        private Function<Long, String> formatDateFunc = (ignored) -> { throw new RuntimeException(\"unsupported argument type\"); };", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjA3MzE4OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo0NzoxOVrOG42wig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo0NzoxOVrOG42wig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3MDYwMg==", "bodyText": "This is subjective, but you could just as well inline.  I think DAYS.toMillis(value) reads pretty well.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462270602", "createdAt": "2020-07-29T12:47:19Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunctions.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.util.Locale;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static java.lang.String.format;\n+import static java.util.concurrent.TimeUnit.DAYS;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class JsonFormatFunctions\n+{\n+    public enum FormatType {\n+        CUSTOM_DATE_TIME(true),\n+        ISO8601(true),\n+        RFC2822(true),\n+        MILLISECONDS_SINCE_EPOCH(false),\n+        SECONDS_SINCE_EPOCH(false);\n+\n+        private final boolean supportsDate;\n+\n+        FormatType(boolean supportsDate)\n+        {\n+            this.supportsDate = supportsDate;\n+        }\n+\n+        public boolean isSupportedType(Type type)\n+        {\n+            if (type == TIME ||\n+                    type == TIME_WITH_TIME_ZONE ||\n+                    type instanceof TimestampType ||\n+                    type instanceof TimestampWithTimeZoneType) {\n+                return true;\n+            }\n+            return supportsDate && type == DATE;\n+        }\n+\n+        @Override\n+        public String toString()\n+        {\n+            return name().toLowerCase(Locale.ENGLISH).replaceAll(\"_\", \"-\");\n+        }\n+    }\n+\n+    private JsonFormatFunctions() {}\n+\n+    public static long daysToEpochMillis(long value)\n+    {\n+        return DAYS.toMillis(value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjA4NjE4OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/MillisecondsFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo1MDozMVrOG424Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzowNjo0OVrOG43fmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3MjYxMA==", "bodyText": "Perhaps we should not support this scenario.  This does not seem a meaningful return value - without the tz info, the milliseconds don't make much sense here, right?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462272610", "createdAt": "2020-07-29T12:50:31Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/MillisecondsFormatFunctions.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+\n+public final class MillisecondsFormatFunctions\n+{\n+    private MillisecondsFormatFunctions() {}\n+\n+    public static Function<Long, String> formatMillisFunc()\n+    {\n+        return String::valueOf;\n+    }\n+\n+    public static Function<Long, String> formatMillisWithTZFunc()\n+    {\n+        return encodedMillisWithTZ -> String.valueOf(unpackMillisUtc(encodedMillisWithTZ));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI4MjY0OA==", "bodyText": "Sorry, that was wrong.  This format implies millis since epoch.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462282648", "createdAt": "2020-07-29T13:06:49Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/MillisecondsFormatFunctions.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+\n+public final class MillisecondsFormatFunctions\n+{\n+    private MillisecondsFormatFunctions() {}\n+\n+    public static Function<Long, String> formatMillisFunc()\n+    {\n+        return String::valueOf;\n+    }\n+\n+    public static Function<Long, String> formatMillisWithTZFunc()\n+    {\n+        return encodedMillisWithTZ -> String.valueOf(unpackMillisUtc(encodedMillisWithTZ));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3MjYxMA=="}, "originalCommit": null, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjEwNjI5OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/RFC2822FormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo1NTo0N1rOG43EyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo1NTo0N1rOG43EyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3NTc4NQ==", "bodyText": "Perhaps this would warrant being public in JsonFormatFunctions.  It's being used in ISO8601FormatFunctions, as well.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462275785", "createdAt": "2020-07-29T12:55:47Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/RFC2822FormatFunctions.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.ZonedDateTime;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.time.ZoneOffset.UTC;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+public final class RFC2822FormatFunctions\n+{\n+    private static final DateTimeFormatter RFC_FORMATTER = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\").withLocale(Locale.ENGLISH);\n+\n+    private RFC2822FormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc()\n+    {\n+        return millis -> RFC_FORMATTER.format(\n+                ZonedDateTime.of(\n+                        LocalDate.ofEpochDay(MILLISECONDS.toDays(millis)),\n+                        LocalTime.MIDNIGHT,\n+                        UTC));\n+    }\n+\n+    public static Function<Long, String> formatTimeFunc()\n+    {\n+        return millis -> RFC_FORMATTER.format(\n+                ZonedDateTime.of(\n+                        LocalDate.EPOCH,\n+                        localTimeOfEpochMillis(millis),\n+                        UTC));\n+    }\n+\n+    public static Function<Long, String> formatTimeWithTZFunc()\n+    {\n+        return encodedMillisWithTZ -> RFC_FORMATTER.format(\n+                ZonedDateTime.of(\n+                        LocalDate.EPOCH,\n+                        localTimeOfEpochMillis(unpackMillisUtc(encodedMillisWithTZ)),\n+                        unpackZoneKey(encodedMillisWithTZ).getZoneId()));\n+    }\n+\n+    public static Function<Long, String> formatTimestampFunc()\n+    {\n+        return millis -> RFC_FORMATTER.format(\n+                ZonedDateTime.of(\n+                        localDateTimeOfEpochMillis(millis),\n+                        UTC));\n+    }\n+\n+    public static Function<Long, String> formatTimestampWithTZFunc()\n+    {\n+        return encodedMillisWithTZ -> RFC_FORMATTER.format(\n+                ZonedDateTime.of(\n+                        localDateTimeOfEpochMillis(unpackMillisUtc(encodedMillisWithTZ)),\n+                        unpackZoneKey(encodedMillisWithTZ).getZoneId()));\n+    }\n+\n+    private static LocalDateTime localDateTimeOfEpochMillis(long epochMillis)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjExMDAyOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/SecondsFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMjo1NjozOVrOG43HIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQwOToxMDowNFrOG5avXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3NjM4Nw==", "bodyText": "Another situation in which we're throwing away tz info.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462276387", "createdAt": "2020-07-29T12:56:39Z", "author": {"login": "aalbu"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/SecondsFormatFunctions.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.millisToSeconds;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+\n+public final class SecondsFormatFunctions\n+{\n+    private SecondsFormatFunctions() {}\n+\n+    public static Function<Long, String> formatSecondsFunc()\n+    {\n+        return millis -> String.valueOf(millisToSeconds(millis));\n+    }\n+\n+    public static Function<Long, String> formatSecondsWithTZFunc()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg2MDEyNw==", "bodyText": "This is like unix time(), it's fine.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462860127", "createdAt": "2020-07-30T09:10:04Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/SecondsFormatFunctions.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.millisToSeconds;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+\n+public final class SecondsFormatFunctions\n+{\n+    private SecondsFormatFunctions() {}\n+\n+    public static Function<Long, String> formatSecondsFunc()\n+    {\n+        return millis -> String.valueOf(millisToSeconds(millis));\n+    }\n+\n+    public static Function<Long, String> formatSecondsWithTZFunc()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI3NjM4Nw=="}, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjQ3NjIzOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoxODoxMlrOG46rTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoxODoxMlrOG46rTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMzNDc5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n          \n          \n            \n                            checkArgument(columnHandle.getDataFormat() != null, \"No dataFormat defined for temporal column '%s'\", columnHandle.getName());", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462334798", "createdAt": "2020-07-29T14:18:12Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.FormatType;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToEpochMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getDateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        checkArgument(this.session.isLegacyTimestamp(), \"The JSON encoder does not support non-legacy timestamp semantics\");\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctions = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjQ4MTc3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoxOToyNVrOG46u5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoxOToyNVrOG46u5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMzNTcxNw==", "bodyText": "redundant else (https://github.com/prestosql/presto/#additional-ide-configuration)", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462335717", "createdAt": "2020-07-29T14:19:25Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/JsonRowEncoder.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.prestosql.plugin.kafka.encoder.AbstractRowEncoder;\n+import io.prestosql.plugin.kafka.encoder.EncoderColumnHandle;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunction;\n+import io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.type.SqlDate;\n+import io.prestosql.spi.type.SqlTime;\n+import io.prestosql.spi.type.SqlTimeWithTimeZone;\n+import io.prestosql.spi.type.SqlTimestamp;\n+import io.prestosql.spi.type.SqlTimestampWithTimeZone;\n+import io.prestosql.spi.type.TimestampType;\n+import io.prestosql.spi.type.TimestampWithTimeZoneType;\n+import io.prestosql.spi.type.Type;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.FormatType;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.daysToEpochMillis;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getDateFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimeWithTZFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampFormatFunction;\n+import static io.prestosql.plugin.kafka.encoder.json.format.JsonFormatFunctions.getTimestampWithTZFormatFunction;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.BooleanType.BOOLEAN;\n+import static io.prestosql.spi.type.DateTimeEncoding.packDateTimeWithZone;\n+import static io.prestosql.spi.type.DateType.DATE;\n+import static io.prestosql.spi.type.DoubleType.DOUBLE;\n+import static io.prestosql.spi.type.IntegerType.INTEGER;\n+import static io.prestosql.spi.type.SmallintType.SMALLINT;\n+import static io.prestosql.spi.type.TimeType.TIME;\n+import static io.prestosql.spi.type.TimeWithTimeZoneType.TIME_WITH_TIME_ZONE;\n+import static io.prestosql.spi.type.TinyintType.TINYINT;\n+import static io.prestosql.spi.type.Varchars.isVarcharType;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class JsonRowEncoder\n+        extends AbstractRowEncoder\n+{\n+    private static final Set<Type> PRIMITIVE_SUPPORTED_TYPES = ImmutableSet.of(\n+            BIGINT, INTEGER, SMALLINT, TINYINT, DOUBLE, BOOLEAN);\n+    private static final Set<Type> NON_PARAMETRIC_DATE_TIME_TYPES = ImmutableSet.of(\n+            DATE, TIME, TIME_WITH_TIME_ZONE);\n+\n+    public static final String NAME = \"json\";\n+\n+    private final ObjectMapper objectMapper;\n+    private final ObjectNode node;\n+    private final List<JsonFormatFunction> formatFunctions;\n+\n+    JsonRowEncoder(ConnectorSession session, List<EncoderColumnHandle> columnHandles, ObjectMapper objectMapper)\n+    {\n+        super(session, columnHandles);\n+        checkArgument(this.session.isLegacyTimestamp(), \"The JSON encoder does not support non-legacy timestamp semantics\");\n+\n+        ImmutableList.Builder<JsonFormatFunction> formatFunctions = ImmutableList.builder();\n+        for (EncoderColumnHandle columnHandle : this.columnHandles) {\n+            checkArgument(isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+            if (isDateTimeType(columnHandle.getType())) {\n+                checkArgument(columnHandle.getDataFormat() != null, \"Unsupported or no dataFormat '%s' defined for temporal column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                FormatType dataFormat = parseDataFormat(columnHandle.getDataFormat(), columnHandle.getName());\n+                checkArgument(dataFormat.isSupportedType(columnHandle.getType()), \"Unsupported column type '%s' for column '%s'\", columnHandle.getType(), columnHandle.getName());\n+\n+                if (dataFormat == FormatType.CUSTOM_DATE_TIME) {\n+                    checkArgument(columnHandle.getFormatHint() != null, \"No format hint defined for column '%s'\", columnHandle.getName());\n+                }\n+                else {\n+                    checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                }\n+\n+                formatFunctions.add(getDateTimeFormatFunction(columnHandle.getType(), dataFormat, Optional.ofNullable(columnHandle.getFormatHint()), columnHandle.getName()));\n+            }\n+            else {\n+                checkArgument(columnHandle.getFormatHint() == null, \"Unexpected format hint '%s' defined for column '%s'\", columnHandle.getFormatHint(), columnHandle.getName());\n+                checkArgument(columnHandle.getDataFormat() == null, \"Unexpected data format '%s' defined for column '%s'\", columnHandle.getDataFormat(), columnHandle.getName());\n+                formatFunctions.add(JsonFormatFunction.builder().build());\n+            }\n+        }\n+\n+        this.formatFunctions = formatFunctions.build();\n+        this.objectMapper = requireNonNull(objectMapper, \"objectMapper is null\");\n+        this.node = objectMapper.createObjectNode();\n+    }\n+\n+    private boolean isSupportedType(Type type)\n+    {\n+        return isVarcharType(type) ||\n+                PRIMITIVE_SUPPORTED_TYPES.contains(type) ||\n+                isDateTimeType(type);\n+    }\n+\n+    private boolean isDateTimeType(Type type)\n+    {\n+        return type instanceof TimestampType ||\n+                type instanceof TimestampWithTimeZoneType ||\n+                NON_PARAMETRIC_DATE_TIME_TYPES.contains(type);\n+    }\n+\n+    private FormatType parseDataFormat(String dataFormat, String columnName)\n+    {\n+        try {\n+            return FormatType.valueOf(dataFormat.toUpperCase().replaceAll(\"-\", \"_\"));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Unable to parse data format '%s' for column '%s'\", dataFormat, columnName), e);\n+        }\n+    }\n+\n+    private JsonFormatFunction getDateTimeFormatFunction(Type type, JsonFormatFunctions.FormatType dataFormat, Optional<String> formatHint, String name)\n+    {\n+        if (type == DATE) {\n+            return JsonFormatFunction.builder().setFormatDateFunc(getDateFormatFunction(dataFormat, formatHint)).build();\n+        }\n+        else if (type == TIME) {\n+            return JsonFormatFunction.builder().setFormatTimeFunc(getTimeFormatFunction(dataFormat, formatHint)).build();\n+        }\n+        else if (type == TIME_WITH_TIME_ZONE) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjQ4Njc1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyMDoyMFrOG46xyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyMDoyMFrOG46xyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMzNjQ1Ng==", "bodyText": "avoid abbreviations\nfunc -> function", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462336456", "createdAt": "2020-07-29T14:20:20Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjQ5NTI3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyMTo1MlrOG462yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyMTo1MlrOG462yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMzNzczOQ==", "bodyText": "is the format hint documented to be Joda Time?", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462337739", "createdAt": "2020-07-29T14:21:52Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjUxMzk2OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyNTo0MVrOG47CeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyNTo0MVrOG47CeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0MDcyOQ==", "bodyText": "Code is correct but I would find it more readable if the lambda was outside of try block...", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462340729", "createdAt": "2020-07-29T14:25:41Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);\n+        }\n+        catch (IllegalArgumentException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjUyOTI3OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyODo0OFrOG47MFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyODo0OFrOG47MFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0MzE5MQ==", "bodyText": "I think it would be better to supplement the session zone here.\nThis would make it more similar to the non-legacy case, when we implement it.\nIe\nINSERT ,.. TIMESTAMP 'some_date_time'\nwould be some_date_time session_zone in legacy\nand some_date_time in non-legacy\nand if the format hint does not contain the zone,\nthey would actually be the same.", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462343191", "createdAt": "2020-07-29T14:28:48Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjUzMjU1OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyOToyNVrOG47OJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyOToyNVrOG47OJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0MzcxNw==", "bodyText": "encodedMillisWithTZ -> value", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462343717", "createdAt": "2020-07-29T14:29:25Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimeFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(new DateTime(millis, DateTimeZone.UTC));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimeWithTZFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(new DateTime(\n+                    unpackMillisUtc(encodedMillisWithTZ),\n+                    DateTimeZone.forID(unpackZoneKey(encodedMillisWithTZ).getId())));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimestampFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(Instant.ofEpochMilli(millis));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimestampWithTZFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(new DateTime(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjUzMjk5OnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyOTozM1rOG47Obw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyOTozM1rOG47Obw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0Mzc5MQ==", "bodyText": "joda -> Joda Time", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462343791", "createdAt": "2020-07-29T14:29:33Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/CustomDateTimeFormatFunctions.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Instant;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.Locale;\n+import java.util.function.Function;\n+\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackMillisUtc;\n+import static io.prestosql.spi.type.DateTimeEncoding.unpackZoneKey;\n+import static java.lang.String.format;\n+\n+public final class CustomDateTimeFormatFunctions\n+{\n+    private CustomDateTimeFormatFunctions() {}\n+\n+    public static Function<Long, String> formatDateFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> (new DateTime(millis, DateTimeZone.UTC)).toString(formatter);\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimeFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(new DateTime(millis, DateTimeZone.UTC));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimeWithTZFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(new DateTime(\n+                    unpackMillisUtc(encodedMillisWithTZ),\n+                    DateTimeZone.forID(unpackZoneKey(encodedMillisWithTZ).getId())));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimestampFunc(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return millis -> formatter.print(Instant.ofEpochMilli(millis));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);\n+        }\n+    }\n+\n+    public static Function<Long, String> formatTimestampWithTZFunction(String formatHint)\n+    {\n+        try {\n+            DateTimeFormatter formatter = DateTimeFormat.forPattern(formatHint).withLocale(Locale.ENGLISH).withZoneUTC();\n+            return encodedMillisWithTZ -> formatter.print(new DateTime(\n+                    unpackMillisUtc(encodedMillisWithTZ),\n+                    DateTimeZone.forID(unpackZoneKey(encodedMillisWithTZ).getId())));\n+        }\n+        catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(format(\"Invalid joda pattern '%s' passed as format hint\", formatHint), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjUzNzkwOnYy", "diffSide": "RIGHT", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDozMDoyN1rOG47RPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDozMDoyN1rOG47RPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0NDUwOA==", "bodyText": "withTZ -> withTimeZone", "url": "https://github.com/trinodb/trino/pull/4477#discussion_r462344508", "createdAt": "2020-07-29T14:30:27Z", "author": {"login": "findepi"}, "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/encoder/json/format/JsonFormatFunction.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.kafka.encoder.json.format;\n+\n+import java.util.function.Function;\n+\n+public class JsonFormatFunction\n+{\n+    private final Function<Long, String> formatDateFunc;\n+    private final Function<Long, String> formatTimeFunc;\n+    private final Function<Long, String> formatTimeWithTZFunc;\n+    private final Function<Long, String> formatTimestampFunc;\n+    private final Function<Long, String> formatTimestampWithTZFunc;\n+\n+    private JsonFormatFunction(\n+            Function<Long, String> formatDateFunc,\n+            Function<Long, String> formatTimeFunc,\n+            Function<Long, String> formatTimeWithTZFunc,\n+            Function<Long, String> formatTimestampFunc,\n+            Function<Long, String> formatTimestampWithTZFunc)\n+    {\n+        this.formatDateFunc = formatDateFunc;\n+        this.formatTimeFunc = formatTimeFunc;\n+        this.formatTimeWithTZFunc = formatTimeWithTZFunc;\n+        this.formatTimestampFunc = formatTimestampFunc;\n+        this.formatTimestampWithTZFunc = formatTimestampWithTZFunc;\n+    }\n+\n+    public static Builder builder()\n+    {\n+        return new Builder();\n+    }\n+\n+    public String formatDate(long value)\n+    {\n+        return formatDateFunc.apply(value);\n+    }\n+\n+    public String formatTime(long value)\n+    {\n+        return formatTimeFunc.apply(value);\n+    }\n+\n+    public String formatTimeWithTZ(long value)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3676, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}