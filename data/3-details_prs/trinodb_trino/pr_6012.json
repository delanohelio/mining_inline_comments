{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzNzIyNTUx", "number": 6012, "title": "Validate Hive bucketing on read", "bodyText": "", "createdAt": "2020-11-19T06:56:55Z", "url": "https://github.com/trinodb/trino/pull/6012", "merged": true, "mergeCommit": {"oid": "14e24360438db823d4ac18fbebdb092e6ba01211"}, "closed": true, "closedAt": "2020-11-30T07:08:02Z", "author": {"login": "electrum"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdd9NStABqjQwMTQyNTc3NTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdhX8BpgBqjQwNDk0NjgxMjM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5NDYzODYw", "url": "https://github.com/trinodb/trino/pull/6012#pullrequestreview-539463860", "createdAt": "2020-11-26T16:54:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxNjo1NDoyOFrOH6ipsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxNzoxNTo0NlrOH6jO8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0NzE4Nw==", "bodyText": "ImmutableList.copyOf", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531147187", "createdAt": "2020-11-26T16:54:28Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveSplit.java", "diffHunk": "@@ -318,4 +328,40 @@ public int hashCode()\n             return Objects.hash(tableBucketCount, partitionBucketCount, bucketColumnNames);\n         }\n     }\n+\n+    public static class BucketValidation\n+    {\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final List<HiveColumnHandle> bucketColumns;\n+\n+        @JsonCreator\n+        public BucketValidation(\n+                @JsonProperty(\"bucketingVersion\") BucketingVersion bucketingVersion,\n+                @JsonProperty(\"bucketCount\") int bucketCount,\n+                @JsonProperty(\"bucketColumns\") List<HiveColumnHandle> bucketColumns)\n+        {\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.bucketColumns = requireNonNull(bucketColumns, \"bucketColumns is null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0ODI3OQ==", "bodyText": "consider using dataProvider to increase tests isolation", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531148279", "createdAt": "2020-11-26T16:56:51Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -1722,6 +1724,71 @@ private static void assertBucketTableEvolutionResult(MaterializedResult result,\n         assertEquals(idCount.keySet(), expectedIds);\n     }\n \n+    @Test\n+    public void testBucketedTableValidation()\n+            throws Exception\n+    {\n+        for (HiveStorageFormat storageFormat : createTableFormats) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0OTg3Nw==", "bodyText": "Add test validation that validation does not happen if it is disabled.", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531149877", "createdAt": "2020-11-26T17:00:19Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -1722,6 +1724,71 @@ private static void assertBucketTableEvolutionResult(MaterializedResult result,\n         assertEquals(idCount.keySet(), expectedIds);\n     }\n \n+    @Test\n+    public void testBucketedTableValidation()\n+            throws Exception\n+    {\n+        for (HiveStorageFormat storageFormat : createTableFormats) {\n+            SchemaTableName table = temporaryTable(\"bucket_validation\");\n+            try {\n+                doTestBucketedTableValidation(storageFormat, table);\n+            }\n+            finally {\n+                dropTable(table);\n+            }\n+        }\n+    }\n+\n+    private void doTestBucketedTableValidation(HiveStorageFormat storageFormat, SchemaTableName tableName)\n+            throws Exception\n+    {\n+        createEmptyTable(\n+                tableName,\n+                storageFormat,\n+                ImmutableList.of(\n+                        new Column(\"id\", HIVE_LONG, Optional.empty()),\n+                        new Column(\"name\", HIVE_STRING, Optional.empty())),\n+                ImmutableList.of(),\n+                Optional.of(new HiveBucketProperty(ImmutableList.of(\"id\"), BUCKETING_V1, 8, ImmutableList.of())));\n+\n+        MaterializedResult.Builder dataBuilder = MaterializedResult.resultBuilder(SESSION, BIGINT, VARCHAR);\n+        for (long id = 0; id < 100; id++) {\n+            dataBuilder.row(id, String.valueOf(id));\n+        }\n+        insertData(tableName, dataBuilder.build());\n+\n+        try (Transaction transaction = newTransaction()) {\n+            Set<String> files = listAllDataFiles(transaction, tableName.getSchemaName(), tableName.getTableName());\n+\n+            Path bucket2 = files.stream()\n+                    .map(Path::new)\n+                    .filter(path -> path.getName().startsWith(\"000002_0_\"))\n+                    .collect(onlyElement());\n+\n+            Path bucket5 = files.stream()\n+                    .map(Path::new)\n+                    .filter(path -> path.getName().startsWith(\"000005_0_\"))\n+                    .collect(onlyElement());\n+\n+            HdfsContext context = new HdfsContext(newSession(), tableName.getSchemaName(), tableName.getTableName());\n+            FileSystem fileSystem = hdfsEnvironment.getFileSystem(context, bucket2);\n+            fileSystem.delete(bucket2, false);\n+            fileSystem.rename(bucket5, bucket2);\n+        }\n+\n+        try (Transaction transaction = newTransaction()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1MjEzMA==", "bodyText": "when is that possible? Can you add a comment?", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531152130", "createdAt": "2020-11-26T17:05:10Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -678,6 +691,36 @@ public int getBucketToKeep()\n         }\n     }\n \n+    private static Optional<BucketValidator> createBucketValidator(Path path, Optional<BucketValidation> bucketValidation, OptionalInt bucketNumber, List<ColumnMapping> columnMappings)\n+    {\n+        return bucketValidation.flatMap(validation -> {\n+            Map<Integer, ColumnMapping> baseHiveColumnToBlockIndex = columnMappings.stream()\n+                    .filter(mapping -> mapping.getHiveColumnHandle().isBaseColumn())\n+                    .collect(toImmutableMap(mapping -> mapping.getHiveColumnHandle().getBaseHiveColumnIndex(), identity()));\n+\n+            int[] bucketColumnIndices = new int[validation.getBucketColumns().size()];\n+\n+            List<TypeInfo> bucketColumnTypes = new ArrayList<>();\n+            for (int i = 0; i < validation.getBucketColumns().size(); i++) {\n+                HiveColumnHandle column = validation.getBucketColumns().get(i);\n+                ColumnMapping mapping = baseHiveColumnToBlockIndex.get(column.getBaseHiveColumnIndex());\n+                if (mapping == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NDE1Nw==", "bodyText": "check length of bucketColumnIndices and length of bucketColumnTypes are the same", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531154157", "createdAt": "2020-11-26T17:10:06Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +644,57 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NjcyMA==", "bodyText": "Do we need to handle LongTimestamp.class here? Maybe others?", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531156720", "createdAt": "2020-11-26T17:15:46Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 115}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5OTc4MDU2", "url": "https://github.com/trinodb/trino/pull/6012#pullrequestreview-539978056", "createdAt": "2020-11-27T13:25:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QxMzoyNToyNVrOH6-U9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QxMzozODowOVrOH6-uRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMDYyOQ==", "bodyText": "maybe add a comment what this is & what is for, as the name is not fully self-describing", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531600629", "createdAt": "2020-11-27T13:25:25Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMTY2NQ==", "bodyText": "nit: fmt each arg on separate line", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531601665", "createdAt": "2020-11-27T13:27:28Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }\n+            else {\n+                throw new VerifyException(\"Unknown Java type: \" + javaType);\n+            }\n+        }\n+\n+        int bucket = getHiveBucket(bucketingVersion, bucketCount, typeInfoList, scratch);\n+        if (bucket != expectedBucket) {\n+            throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                    \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMjE0MQ==", "bodyText": "Should i be concerned about overhead of this?\nwould it be enough to do this very other row?\nor eg first 100 rows, and then every 10th row?", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531602141", "createdAt": "2020-11-27T13:28:31Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }\n+            else {\n+                throw new VerifyException(\"Unknown Java type: \" + javaType);\n+            }\n+        }\n+\n+        int bucket = getHiveBucket(bucketingVersion, bucketCount, typeInfoList, scratch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMjk4OQ==", "bodyText": "nit: ftm", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531602989", "createdAt": "2020-11-27T13:30:04Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {\n+                int bucket = getHiveBucket(bucketingVersion, bucketCount, bucketColumnTypes, bucketColumnsPage, position);\n+                if (bucket != expectedBucket) {\n+                    throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                            \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMzIwNQ==", "bodyText": "same here, i would expect this to be not necesarily for every row", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531603205", "createdAt": "2020-11-27T13:30:25Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMzY5Mw==", "bodyText": "wrapRecordCursor or validatingRecordCursor", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531603693", "createdAt": "2020-11-27T13:31:21Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {\n+                int bucket = getHiveBucket(bucketingVersion, bucketCount, bucketColumnTypes, bucketColumnsPage, position);\n+                if (bucket != expectedBucket) {\n+                    throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                            \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));\n+                }\n+            }\n+        }\n+\n+        public RecordCursor toRecordCursor(RecordCursor delegate, TypeManager typeManager)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDI0MA==", "bodyText": "Maybe add a comment why this is only when bucketAdaptation.isEmpty()\nalso, even in case of bucketAdaptation.isEmpty() we should be able to do some validation. How hard would it be? A followup issue?", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531604240", "createdAt": "2020-11-27T13:32:26Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -323,6 +332,10 @@ public ConnectorPageSource createPageSource(\n                     delegate = new HiveCoercionRecordCursor(regularAndInterimColumnMappings, typeManager, delegate);\n                 }\n \n+                if (bucketAdaptation.isEmpty() && bucketValidator.isPresent()) {\n+                    delegate = bucketValidator.get().toRecordCursor(delegate, typeManager);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDkzMw==", "bodyText": "add something from your comment above:\n\nwe don't need to bother with validation since it can't affect the query results\n\nHowever, is it true actually?\nwhat about filters on $bucket?", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531604933", "createdAt": "2020-11-27T13:33:51Z", "author": {"login": "findepi"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -678,6 +691,37 @@ public int getBucketToKeep()\n         }\n     }\n \n+    private static Optional<BucketValidator> createBucketValidator(Path path, Optional<BucketValidation> bucketValidation, OptionalInt bucketNumber, List<ColumnMapping> columnMappings)\n+    {\n+        return bucketValidation.flatMap(validation -> {\n+            Map<Integer, ColumnMapping> baseHiveColumnToBlockIndex = columnMappings.stream()\n+                    .filter(mapping -> mapping.getHiveColumnHandle().isBaseColumn())\n+                    .collect(toImmutableMap(mapping -> mapping.getHiveColumnHandle().getBaseHiveColumnIndex(), identity()));\n+\n+            int[] bucketColumnIndices = new int[validation.getBucketColumns().size()];\n+\n+            List<TypeInfo> bucketColumnTypes = new ArrayList<>();\n+            for (int i = 0; i < validation.getBucketColumns().size(); i++) {\n+                HiveColumnHandle column = validation.getBucketColumns().get(i);\n+                ColumnMapping mapping = baseHiveColumnToBlockIndex.get(column.getBaseHiveColumnIndex());\n+                if (mapping == null) {\n+                    // the bucket column is not read by the query", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNzEwOA==", "bodyText": "How does HiveBucketValidationRecordCursor play with HiveCoercionRecordCursor?\nare they applied in the right order? would be good to have a test\nsame applies to the case when reading with a page source", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531607108", "createdAt": "2020-11-27T13:38:09Z", "author": {"login": "findepi"}, "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -4552,6 +4631,9 @@ protected static void assertPageSourceType(ConnectorPageSource pageSource, HiveS\n         if (pageSource instanceof RecordPageSource) {\n             RecordCursor hiveRecordCursor = ((RecordPageSource) pageSource).getCursor();\n             hiveRecordCursor = ((HiveRecordCursor) hiveRecordCursor).getRegularColumnRecordCursor();\n+            if (hiveRecordCursor instanceof HiveBucketValidationRecordCursor) {\n+                hiveRecordCursor = ((HiveBucketValidationRecordCursor) hiveRecordCursor).delegate();\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwNDkyNjg1", "url": "https://github.com/trinodb/trino/pull/6012#pullrequestreview-540492685", "createdAt": "2020-11-29T15:58:12Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f27b4847feac9790220d7f5e7046df0aec18f275", "author": {"user": {"login": "electrum", "name": "David Phillips"}}, "url": "https://github.com/trinodb/trino/commit/f27b4847feac9790220d7f5e7046df0aec18f275", "committedDate": "2020-11-29T21:43:32Z", "message": "Extract ForwardingRecordCursor"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fdf2be613912592da4d067f158a14b4065b540c", "author": {"user": {"login": "electrum", "name": "David Phillips"}}, "url": "https://github.com/trinodb/trino/commit/8fdf2be613912592da4d067f158a14b4065b540c", "committedDate": "2020-11-29T21:49:59Z", "message": "Validate Hive bucketing on read"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "8fdf2be613912592da4d067f158a14b4065b540c", "author": {"user": {"login": "electrum", "name": "David Phillips"}}, "url": "https://github.com/trinodb/trino/commit/8fdf2be613912592da4d067f158a14b4065b540c", "committedDate": "2020-11-29T21:49:59Z", "message": "Validate Hive bucketing on read"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2638, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}