{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0NDQ0MDU4", "number": 3873, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMjozNjo0NlrOEAfPfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNDowODozM1rOEAhjNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4OTQ3MzI1OnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/rubix/DefaultRubixInitializer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMjozNjo0NlrOGbzFSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMjozNjo0NlrOGbzFSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgwMTY3NQ==", "bodyText": "Now responsibility is extended. The class also takes care of HDFS configuration updating.", "url": "https://github.com/trinodb/trino/pull/3873#discussion_r431801675", "createdAt": "2020-05-28T12:36:46Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/rubix/DefaultRubixInitializer.java", "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.rubix;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.io.Closer;\n+import com.qubole.rubix.bookkeeper.BookKeeper;\n+import com.qubole.rubix.bookkeeper.BookKeeperServer;\n+import com.qubole.rubix.bookkeeper.LocalDataTransferServer;\n+import com.qubole.rubix.core.CachingFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoAzureBlobFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoDistributedFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoGoogleHadoopFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoNativeAzureFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoS3FileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoSecureAzureBlobFileSystem;\n+import com.qubole.rubix.prestosql.CachingPrestoSecureNativeAzureFileSystem;\n+import com.qubole.rubix.prestosql.PrestoClusterManager;\n+import io.airlift.log.Logger;\n+import io.airlift.units.Duration;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.HdfsConfigurationInitializer;\n+import io.prestosql.plugin.hive.util.RetryDriver;\n+import io.prestosql.spi.HostAddress;\n+import io.prestosql.spi.Node;\n+import io.prestosql.spi.NodeManager;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.conf.Configuration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.PreDestroy;\n+import javax.inject.Inject;\n+\n+import java.io.IOException;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Throwables.propagateIfPossible;\n+import static com.qubole.rubix.spi.CacheConfig.enableHeartbeat;\n+import static com.qubole.rubix.spi.CacheConfig.setBookKeeperServerPort;\n+import static com.qubole.rubix.spi.CacheConfig.setCacheDataDirPrefix;\n+import static com.qubole.rubix.spi.CacheConfig.setCacheDataEnabled;\n+import static com.qubole.rubix.spi.CacheConfig.setClusterNodeRefreshTime;\n+import static com.qubole.rubix.spi.CacheConfig.setCoordinatorHostName;\n+import static com.qubole.rubix.spi.CacheConfig.setCurrentNodeHostName;\n+import static com.qubole.rubix.spi.CacheConfig.setDataTransferServerPort;\n+import static com.qubole.rubix.spi.CacheConfig.setEmbeddedMode;\n+import static com.qubole.rubix.spi.CacheConfig.setIsParallelWarmupEnabled;\n+import static com.qubole.rubix.spi.CacheConfig.setOnMaster;\n+import static com.qubole.rubix.spi.CacheConfig.setPrestoClusterManager;\n+import static io.prestosql.plugin.hive.DynamicConfigurationProvider.setCacheKey;\n+import static io.prestosql.plugin.hive.util.ConfigurationUtils.getInitialConfiguration;\n+import static io.prestosql.plugin.hive.util.RetryDriver.DEFAULT_SCALE_FACTOR;\n+import static io.prestosql.plugin.hive.util.RetryDriver.retry;\n+import static io.prestosql.spi.StandardErrorCode.GENERIC_INTERNAL_ERROR;\n+import static java.lang.Integer.MAX_VALUE;\n+import static java.util.concurrent.TimeUnit.MINUTES;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/*\n+ * Responsibilities of this initializer:\n+ * 1. Wait for master and setup RubixConfigurationInitializer with information about master when it becomes available\n+ * 2. Start Rubix Servers.\n+ * 3. Inject BookKeeper object into CachingFileSystem class", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4OTg1MTQwOnYy", "diffSide": "RIGHT", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/rubix/RubixInitializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNDowODozM1rOGb22mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNDowODozM1rOGb22mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTg2MzQ1MQ==", "bodyText": "nit: extraConfigurationInitializer", "url": "https://github.com/trinodb/trino/pull/3873#discussion_r431863451", "createdAt": "2020-05-28T14:08:33Z", "author": {"login": "losipiuk"}, "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/rubix/RubixInitializer.java", "diffHunk": "@@ -108,6 +110,7 @@\n     private final NodeManager nodeManager;\n     private final CatalogName catalogName;\n     private final HdfsConfigurationInitializer hdfsConfigurationInitializer;\n+    private final Optional<ConfigurationInitializer> additionalConfigInitializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4191, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}