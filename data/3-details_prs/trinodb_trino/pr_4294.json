{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyNjQ3ODM1", "number": 4294, "title": "Relax task locking in SourcePartitionedScheduler", "bodyText": "Currently, in a broadcast join - the join tasks are blocked as soon as split queues are full for the join stage tasks. The reason behind that is explained as below in the code in SourcePartitionedScheduler :\n\n// In a broadcast join, output buffers of the tasks in build source stage have to\n// hold onto all data produced before probe side task scheduling finishes,\n// even if the data is acknowledged by all known consumers. This is because\n// new consumers may be added until the probe side task scheduling finishes.\n//\n// As a result, the following line is necessary to prevent deadlock\n// due to neither build nor probe can make any progress.\n// The build side blocks due to a full output buffer.\n// In the meantime the probe side split cannot be consumed since\n// builder side hash table construction has not finished.\n\nThis adds a check for the build stage's output buffer utilization as well. With this change, we'll lock the join tasks if the split queues are and the build output buffer is almost full. This allows improvement in scaling of broadcast joins to new workers incase of small builds.\nThis change only covers the case when SourcePartitionedScheduler is used as a stage scheduler.\nRelates to #4290", "createdAt": "2020-07-01T11:50:45Z", "url": "https://github.com/trinodb/trino/pull/4294", "merged": true, "mergeCommit": {"oid": "d03146f0353cab994775375f99b9e743e71df432"}, "closed": true, "closedAt": "2020-08-17T15:11:21Z", "author": {"login": "rohangarg"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcxPpFEgBqjM1MTAyMjc3ODE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8hs6sAFqTQ2MzE5OTg4OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0NjEwNzQ3", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-444610747", "createdAt": "2020-07-08T10:22:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMDoyMjoxOVrOGuhpUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMTozMjoyOFrOGujwRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQzODkyOQ==", "bodyText": "commit message is too long", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451438929", "createdAt": "2020-07-08T10:22:19Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/TaskStatus.java", "diffHunk": "@@ -247,6 +247,11 @@ public String toString()\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ0MDQzMg==", "bodyText": "Move this method to TestSourcePartitionedScheduler as this method is used only in tests. Rename this method to taskStatusWithOutputBufferUtilization as it's odd to have initial task status with overutilized buffer.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451440432", "createdAt": "2020-07-08T10:25:11Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/TaskStatus.java", "diffHunk": "@@ -247,6 +247,11 @@ public String toString()\n     }\n \n     public static TaskStatus initialTaskStatus(TaskId taskId, URI location, String nodeId)\n+    {\n+        return initialTaskStatusWithOutputBufferUtilization(taskId, location, nodeId, false);\n+    }\n+\n+    public static TaskStatus initialTaskStatusWithOutputBufferUtilization(TaskId taskId, URI location, String nodeId, boolean isOutputBufferOverutilized)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ0Njk2MA==", "bodyText": "We don't have to pass AtomicReference explicitly. It's enough to pass Supplier<Collection<TaskStatus>>. AtomicReference can be handled in supplier itself.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451446960", "createdAt": "2020-07-08T10:38:26Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -133,9 +140,10 @@ public static StageScheduler newSourcePartitionedSchedulerAsStageScheduler(\n             PlanNodeId partitionedNode,\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n-            int splitBatchSize)\n+            int splitBatchSize,\n+            AtomicReference<Supplier<Collection<TaskStatus>>> childTaskStatusSupplier)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ0ODAxMQ==", "bodyText": "A better name might be childStageTaskStatusSupplier", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451448011", "createdAt": "2020-07-08T10:40:39Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -133,9 +140,10 @@ public static StageScheduler newSourcePartitionedSchedulerAsStageScheduler(\n             PlanNodeId partitionedNode,\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n-            int splitBatchSize)\n+            int splitBatchSize,\n+            AtomicReference<Supplier<Collection<TaskStatus>>> childTaskStatusSupplier)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ1MDAxNg==", "bodyText": "We should flip the condition and unblock if any undone task get buffer overutilzed. Otherwise it might happen that n-1 child tasks are blocked and just one is progressing reducing concurrency to 1.\nFor example it might happen that a new build side table scan task was added. However, it only read last 10 remaining rows. It won't be done (as it's in FLUSHING state) nor it will be overutilized. In such case we would get a deadlock as shouldLockdownTasks would be false even though no task could progress.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451450016", "createdAt": "2020-07-08T10:44:36Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -357,7 +365,20 @@ else if (pendingSplits.isEmpty()) {\n             // The build side blocks due to a full output buffer.\n             // In the meantime the probe side split cannot be consumed since\n             // builder side hash table construction has not finished.\n-            overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n+            boolean shouldLockdownTasks = true;\n+            if (anyBlockedOnPlacements && !groupedExecution) {\n+                Supplier<Collection<TaskStatus>> childTaskStatus = childTaskStatusSupplier.get();\n+                if (childTaskStatus != null) {\n+                    boolean anyChildTaskOutputBufferOverutilized = childTaskStatus.get().stream()\n+                            .anyMatch(task -> !task.getState().isDone() && task.isOutputBufferOverutilized());\n+                    if (!anyChildTaskOutputBufferOverutilized) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ1NDQ0MQ==", "bodyText": "let's extract groupedExection alltogether:\nif (groupedExecution) {\n  // The fix is to finish task creation when grouped execution is enabled.\n  // This prevents deadlock when in case of NO_ACTIVE_DRIVER_GROUP and\n  // when partitions on the probe side table are small.\n  overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n} else if (anyBlockedOnPlacements) {\n  ...\n}", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451454441", "createdAt": "2020-07-08T10:53:44Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -357,7 +365,20 @@ else if (pendingSplits.isEmpty()) {\n             // The build side blocks due to a full output buffer.\n             // In the meantime the probe side split cannot be consumed since\n             // builder side hash table construction has not finished.\n-            overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n+            boolean shouldLockdownTasks = true;\n+            if (anyBlockedOnPlacements && !groupedExecution) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ1ODIzOQ==", "bodyText": "task.getState().isDone() seems redundant. Task with FLUSHING state won't be done, so it seems that only finished tasks are done, which don't have any buffer anymore.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451458239", "createdAt": "2020-07-08T11:01:09Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -357,7 +365,20 @@ else if (pendingSplits.isEmpty()) {\n             // The build side blocks due to a full output buffer.\n             // In the meantime the probe side split cannot be consumed since\n             // builder side hash table construction has not finished.\n-            overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n+            boolean shouldLockdownTasks = true;\n+            if (anyBlockedOnPlacements && !groupedExecution) {\n+                Supplier<Collection<TaskStatus>> childTaskStatus = childTaskStatusSupplier.get();\n+                if (childTaskStatus != null) {\n+                    boolean anyChildTaskOutputBufferOverutilized = childTaskStatus.get().stream()\n+                            .anyMatch(task -> !task.getState().isDone() && task.isOutputBufferOverutilized());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ1OTk4Nw==", "bodyText": "use toImmutableList", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451459987", "createdAt": "2020-07-08T11:04:33Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -427,13 +429,14 @@ else if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n \n         stageLinkages.put(stageId, new StageLinkage(plan.getFragment().getId(), parent, childStages));\n \n-        if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n-            Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()\n-                    .map(SqlStageExecution::getAllTasks)\n-                    .flatMap(Collection::stream)\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n+        Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()\n+                .map(SqlStageExecution::getAllTasks)\n+                .flatMap(Collection::stream)\n+                .map(RemoteTask::getTaskStatus)\n+                .collect(toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MDg2MA==", "bodyText": "We could avoid AtomicReference at all if child stages were created before SOURCE_DISTRIBUTION parent stage. This can be done because only dependency seems to be bucketToPartition which gets initialized to Optional.of(new int[1]); in case of SOURCE_DISTRIBUTION.\nPerhaps you could extract createChildStages(...) method.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451460860", "createdAt": "2020-07-08T11:06:19Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -310,6 +311,7 @@ private static void updateQueryOutputLocations(QueryStateMachine queryStateMachi\n \n         Optional<int[]> bucketToPartition;\n         PartitioningHandle partitioningHandle = plan.getFragment().getPartitioning();\n+        AtomicReference<Supplier<Collection<TaskStatus>>> childTaskStatusSupplier = new AtomicReference<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MTkwNQ==", "bodyText": "make this package private", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451461905", "createdAt": "2020-07-08T11:08:33Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -75,16 +77,33 @@ public UniformNodeSelectorFactory(\n         checkArgument(maxSplitsPerNode >= maxPendingSplitsPerTask, \"maxSplitsPerNode must be > maxPendingSplitsPerTask\");\n     }\n \n+    @VisibleForTesting\n+    public UniformNodeSelectorFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MzAzNQ==", "bodyText": "Let's make this method initialize all fields and the one that has @Inject call this(...).\nLet's make this method accept memoization timeout (with 0 meaning memoization disabled)", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451463035", "createdAt": "2020-07-08T11:10:56Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -75,16 +77,33 @@ public UniformNodeSelectorFactory(\n         checkArgument(maxSplitsPerNode >= maxPendingSplitsPerTask, \"maxSplitsPerNode must be > maxPendingSplitsPerTask\");\n     }\n \n+    @VisibleForTesting\n+    public UniformNodeSelectorFactory(\n+            InternalNodeManager nodeManager,\n+            NodeSchedulerConfig config,\n+            NodeTaskMap nodeTaskMap,\n+            boolean memoizeNodeMap)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MzQyOA==", "bodyText": "squash this commit", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451463428", "createdAt": "2020-07-08T11:11:46Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -19,7 +19,6 @@\n import io.prestosql.client.NodeVersion;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MzcyNw==", "bodyText": "add a comment with rationale.\nWhy check for canAddPages. If we can't add pages, it seems even more overutilzed", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451463727", "createdAt": "2020-07-08T11:12:23Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/buffer/BroadcastOutputBuffer.java", "diffHunk": "@@ -104,7 +104,7 @@ public double getUtilization()\n     @Override\n     public boolean isOverutilized()\n     {\n-        return memoryManager.isOverutilized();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3MzEzMA==", "bodyText": "rename to testNewTaskScheduledWhenBufferIsUnderutilized", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451473130", "createdAt": "2020-07-08T11:31:45Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +412,80 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskWhenNodeAdded() throws Exception", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3MzQ3Ng==", "bodyText": "rename to testNoNewTaskScheduledWhenBufferIsOverutilized", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r451473476", "createdAt": "2020-07-08T11:32:28Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +412,80 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskWhenNodeAdded() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, false));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with under utilized output buffer\n+        TaskStatus dummyTaskStatus = initialTaskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                400,\n+                new AtomicReference<>(() -> singletonList(dummyTaskStatus)));\n+\n+        // the queues of 3 running nodes should be full\n+        ScheduleResult scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 3);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 300);\n+\n+        // new node added - the pending splits should go to it since the child tasks are not blocked\n+        nodeManager.addNode(CONNECTOR_ID, new InternalNode(\"other4\", URI.create(\"http://127.0.0.4:14\"), NodeVersion.UNKNOWN, false));\n+        scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 1);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 100);\n+    }\n+\n+    @Test\n+    public void testNoNewTaskWhenNodeAdded() throws Exception", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NjAxNzcx", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-456601771", "createdAt": "2020-07-28T12:56:24Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMjo1NjoyNFrOG4LOSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMjo1NjoyNFrOG4LOSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU1NzMyMQ==", "bodyText": "could we have 1 underutilized and 1 overutilized task?", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r461557321", "createdAt": "2020-07-28T12:56:24Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +412,80 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskScheduledWhenChildStageBufferIsUnderutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, 0));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with under utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                400,\n+                () -> singletonList(dummyTaskStatus));\n+\n+        // the queues of 3 running nodes should be full\n+        ScheduleResult scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 3);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 300);\n+\n+        // new node added - the pending splits should go to it since the child tasks are not blocked\n+        nodeManager.addNode(CONNECTOR_ID, new InternalNode(\"other4\", URI.create(\"http://127.0.0.4:14\"), NodeVersion.UNKNOWN, false));\n+        scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 1);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 100);\n+    }\n+\n+    @Test\n+    public void testNoNewTaskScheduledWhenChildStageBufferIsOverutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, 0));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with over utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NjE0ODQ0", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-456614844", "createdAt": "2020-07-28T13:11:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzoxMTo0MFrOG4L0uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzoxMTo0MFrOG4L0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU2NzE2MA==", "bodyText": "remove this check", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r461567160", "createdAt": "2020-07-28T13:11:40Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,32 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            boolean shouldLockdownTasks = true;\n+            if (sourceTasksProvider != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4Mjk1OTIz", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-458295923", "createdAt": "2020-07-30T10:57:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDo1Nzo0OFrOG5eNLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMzoxODoyM1rOG5imxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxNjkwOA==", "bodyText": "ping", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462916908", "createdAt": "2020-07-30T10:57:48Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,32 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            boolean shouldLockdownTasks = true;\n+            if (sourceTasksProvider != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU2NzE2MA=="}, "originalCommit": null, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxNzAwNQ==", "bodyText": "ping", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462917005", "createdAt": "2020-07-30T10:58:00Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -19,7 +19,6 @@\n import io.prestosql.client.NodeVersion;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ2MzQyOA=="}, "originalCommit": null, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxNzA3Nw==", "bodyText": "ping", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462917077", "createdAt": "2020-07-30T10:58:08Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +412,80 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskScheduledWhenChildStageBufferIsUnderutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, 0));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with under utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                400,\n+                () -> singletonList(dummyTaskStatus));\n+\n+        // the queues of 3 running nodes should be full\n+        ScheduleResult scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 3);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 300);\n+\n+        // new node added - the pending splits should go to it since the child tasks are not blocked\n+        nodeManager.addNode(CONNECTOR_ID, new InternalNode(\"other4\", URI.create(\"http://127.0.0.4:14\"), NodeVersion.UNKNOWN, false));\n+        scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getNewTasks().size(), 1);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 100);\n+    }\n+\n+    @Test\n+    public void testNoNewTaskScheduledWhenChildStageBufferIsOverutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, 0));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with over utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU1NzMyMQ=="}, "originalCommit": null, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxNzY1NQ==", "bodyText": "rename to sourceTasksSupplier", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462917655", "createdAt": "2020-07-30T10:59:19Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -90,6 +93,7 @@\n     private final int splitBatchSize;\n     private final PlanNodeId partitionedNode;\n     private final boolean groupedExecution;\n+    private final Supplier<Collection<TaskStatus>> sourceTasksProvider;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxNzcyNA==", "bodyText": "rename to sourceTasksSupplier", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462917724", "createdAt": "2020-07-30T10:59:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -103,12 +107,14 @@ private SourcePartitionedScheduler(\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n             int splitBatchSize,\n-            boolean groupedExecution)\n+            boolean groupedExecution,\n+            Supplier<Collection<TaskStatus>> sourceTasksProvider)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxODIyOQ==", "bodyText": "change to:\nthis.sourceTasksSupplier = requireNonNull(sourceTasksSupplier, \"sourceTasksSupplier is null\");", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462918229", "createdAt": "2020-07-30T11:00:30Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -103,12 +107,14 @@ private SourcePartitionedScheduler(\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n             int splitBatchSize,\n-            boolean groupedExecution)\n+            boolean groupedExecution,\n+            Supplier<Collection<TaskStatus>> sourceTasksProvider)\n     {\n         this.stage = requireNonNull(stage, \"stage is null\");\n         this.partitionedNode = requireNonNull(partitionedNode, \"partitionedNode is null\");\n         this.splitSource = requireNonNull(splitSource, \"splitSource is null\");\n         this.splitPlacementPolicy = requireNonNull(splitPlacementPolicy, \"splitPlacementPolicy is null\");\n+        this.sourceTasksProvider = sourceTasksProvider;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxODMzOQ==", "bodyText": "rename to sourceTasksSupplier", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462918339", "createdAt": "2020-07-30T11:00:48Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -133,9 +139,16 @@ public static StageScheduler newSourcePartitionedSchedulerAsStageScheduler(\n             PlanNodeId partitionedNode,\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n-            int splitBatchSize)\n+            int splitBatchSize,\n+            Supplier<Collection<TaskStatus>> sourceTasksProvider)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxODk0Mw==", "bodyText": "use () -> ImmutableList.of() instead of null", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462918943", "createdAt": "2020-07-30T11:02:03Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -176,7 +189,7 @@ public static SourceScheduler newSourcePartitionedSchedulerAsSourceScheduler(\n             int splitBatchSize,\n             boolean groupedExecution)\n     {\n-        return new SourcePartitionedScheduler(stage, partitionedNode, splitSource, splitPlacementPolicy, splitBatchSize, groupedExecution);\n+        return new SourcePartitionedScheduler(stage, partitionedNode, splitSource, splitPlacementPolicy, splitBatchSize, groupedExecution, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyNTMzMg==", "bodyText": "please simplify:\n // EXPLANATION COMMENT\n boolean shouldLockdownTasks = sourceTasksProvider.get().stream()\n  .anyMatch(TaskStatus::isOutputBufferOverutilized());", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462925332", "createdAt": "2020-07-30T11:15:54Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,32 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            boolean shouldLockdownTasks = true;\n+            if (sourceTasksProvider != null) {\n+                boolean anySourceTaskOutputBufferOverutilized = sourceTasksProvider.get().stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyNzU4OQ==", "bodyText": "just move that to separate function:\nSet<SqlStageExecution> createChildStages(Optional<int[]> bucketToPartition, ...)\n\npreferably as a separate commit", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462927589", "createdAt": "2020-07-30T11:20:47Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -305,10 +304,37 @@ private static void updateQueryOutputLocations(QueryStateMachine queryStateMachi\n                 queryExecutor,\n                 failureDetector,\n                 schedulerStats);\n-\n         stages.add(stage);\n \n-        Optional<int[]> bucketToPartition;\n+        // function to create child stages recursively by supplying the bucket partitioning (according to parent's partitioning)\n+        Function<Optional<int[]>, Set<SqlStageExecution>> getChildStages = bucketToPartition -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzMDU4OA==", "bodyText": "extract this to separate method:\nprivate static Collection<TaskStatus> getChildTaskStatuses(Set<SqlStageExecution> childStages) {\n  return childStages.stream()\n    .map(SqlStageExecution::getAllTasks)\n    .flatMap(Collection::stream)\n    .map(RemoteTask::getTaskStatus)\n    .collect(toImmutableList());\n}", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462930588", "createdAt": "2020-07-30T11:27:02Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -321,13 +347,39 @@ private static void updateQueryOutputLocations(QueryStateMachine queryStateMachi\n             SplitPlacementPolicy placementPolicy = new DynamicSplitPlacementPolicy(nodeSelector, stage::getAllTasks);\n \n             checkArgument(!plan.getFragment().getStageExecutionDescriptor().isStageGroupedExecution());\n-            stageSchedulers.put(stageId, newSourcePartitionedSchedulerAsStageScheduler(stage, planNodeId, splitSource, placementPolicy, splitBatchSize));\n-            bucketToPartition = Optional.of(new int[1]);\n+\n+            childStages = getChildStages.apply(Optional.of(new int[1]));\n+            Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk4ODMxNw==", "bodyText": "use airlift Duration instead", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462988317", "createdAt": "2020-07-30T13:17:16Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -54,12 +55,23 @@\n     private final int maxPendingSplitsPerTask;\n     private final boolean optimizedLocalScheduling;\n     private final NodeTaskMap nodeTaskMap;\n+    private final int nodeMapMemoizationTime;\n \n     @Inject\n     public UniformNodeSelectorFactory(\n             InternalNodeManager nodeManager,\n             NodeSchedulerConfig config,\n             NodeTaskMap nodeTaskMap)\n+    {\n+        this(nodeManager, config, nodeTaskMap, 5);\n+    }\n+\n+    @VisibleForTesting\n+    UniformNodeSelectorFactory(\n+            InternalNodeManager nodeManager,\n+            NodeSchedulerConfig config,\n+            NodeTaskMap nodeTaskMap,\n+            int nodeMapMemoizationTime)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk4ODk5Nw==", "bodyText": "use () -> ImmutableList.of() instead", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462988997", "createdAt": "2020-07-30T13:18:23Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -318,7 +323,8 @@ public void testNoNodes()\n                     Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n                     Iterables.getOnlyElement(plan.getSplitSources().values()),\n                     new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n-                    2);\n+                    2,\n+                    null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NDA1Mjg0", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-458405284", "createdAt": "2020-07-30T13:35:05Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMzozNTowNVrOG5jRsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMzozNTowNVrOG5jRsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk5OTk4NA==", "bodyText": "let's rename it to createChildStages", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462999984", "createdAt": "2020-07-30T13:35:05Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -305,10 +304,37 @@ private static void updateQueryOutputLocations(QueryStateMachine queryStateMachi\n                 queryExecutor,\n                 failureDetector,\n                 schedulerStats);\n-\n         stages.add(stage);\n \n-        Optional<int[]> bucketToPartition;\n+        // function to create child stages recursively by supplying the bucket partitioning (according to parent's partitioning)\n+        Function<Optional<int[]>, Set<SqlStageExecution>> getChildStages = bucketToPartition -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3OTY4NjM4", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-457968638", "createdAt": "2020-07-29T23:36:52Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMzozNjo1MlrOG5N4eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMzo0MToxNFrOG5N9pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY0OTQ2NA==", "bodyText": "I would place the comment above the statement.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462649464", "createdAt": "2020-07-29T23:36:52Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,32 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            boolean shouldLockdownTasks = true;\n+            if (sourceTasksProvider != null) {\n+                boolean anySourceTaskOutputBufferOverutilized = sourceTasksProvider.get().stream()\n+                        .anyMatch(task -> !task.getState().isDone() && task.isOutputBufferOverutilized());\n+                if (!anySourceTaskOutputBufferOverutilized) {\n+                    shouldLockdownTasks = false; // the child stage is not blocked right now. can add more tasks to the stage", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY0OTg5Mg==", "bodyText": "What if there are only done tasks?", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462649892", "createdAt": "2020-07-29T23:38:21Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,32 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            boolean shouldLockdownTasks = true;\n+            if (sourceTasksProvider != null) {\n+                boolean anySourceTaskOutputBufferOverutilized = sourceTasksProvider.get().stream()\n+                        .anyMatch(task -> !task.getState().isDone() && task.isOutputBufferOverutilized());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY1MDc5MQ==", "bodyText": "Variable should include time unit in the name or be a duration", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r462650791", "createdAt": "2020-07-29T23:41:14Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -54,12 +55,23 @@\n     private final int maxPendingSplitsPerTask;\n     private final boolean optimizedLocalScheduling;\n     private final NodeTaskMap nodeTaskMap;\n+    private final int nodeMapMemoizationTime;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NjY5ODAw", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-459669800", "createdAt": "2020-08-02T18:39:35Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxODozOTozNVrOG6nAZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxODozOTozNVrOG6nAZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDEwOTY2OQ==", "bodyText": "Instead of exposing this code to the complexity of the status of the supplier tasks, it would be easier if we encapsulated this call into Predicate.", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r464109669", "createdAt": "2020-08-02T18:39:35Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,28 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            // Lock task generation in current stage if any of the source tasks' output buffer is overutilized.\n+            // It helps to avoid potential indefinite blocking of the output buffer\n+            boolean shouldLockdownTasks = sourceTasksSupplier.get().stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NjY5OTA2", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-459669906", "createdAt": "2020-08-02T18:41:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxODo0MToyOVrOG6nBNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxODo0MToyOVrOG6nBNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDEwOTg3OA==", "bodyText": "Can we move this Function to a method?", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r464109878", "createdAt": "2020-08-02T18:41:29Z", "author": {"login": "dain"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -306,10 +305,37 @@ private static void updateQueryOutputLocations(QueryStateMachine queryStateMachi\n                 queryExecutor,\n                 failureDetector,\n                 schedulerStats);\n-\n         stages.add(stage);\n \n-        Optional<int[]> bucketToPartition;\n+        // function to create child stages recursively by supplying the bucket partitioning (according to parent's partitioning)\n+        Function<Optional<int[]>, Set<SqlStageExecution>> createChildStages = bucketToPartition -> {\n+            ImmutableSet.Builder<SqlStageExecution> childStagesBuilder = ImmutableSet.builder();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxNjA2NDY0", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-461606464", "createdAt": "2020-08-05T12:15:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjoxNTo1N1rOG8HCqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjoxNTo1N1rOG8HCqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzExMg==", "bodyText": "fix formatting each arg in newline", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465683112", "createdAt": "2020-08-05T12:15:57Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -133,9 +137,16 @@ public static StageScheduler newSourcePartitionedSchedulerAsStageScheduler(\n             PlanNodeId partitionedNode,\n             SplitSource splitSource,\n             SplitPlacementPolicy splitPlacementPolicy,\n-            int splitBatchSize)\n+            int splitBatchSize,\n+            Supplier<Boolean> anySourceTaskBlocked)\n     {\n-        SourcePartitionedScheduler sourcePartitionedScheduler = new SourcePartitionedScheduler(stage, partitionedNode, splitSource, splitPlacementPolicy, splitBatchSize, false);\n+        SourcePartitionedScheduler sourcePartitionedScheduler = new SourcePartitionedScheduler(stage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxNjY5MjIz", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-461669223", "createdAt": "2020-08-05T13:35:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMzozNjowMFrOG8J-Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxNDoyMjowM1rOG8L94Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczMTEyNg==", "bodyText": "use java.util.function.BooleanSupplier instead", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465731126", "createdAt": "2020-08-05T13:36:00Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -90,6 +91,7 @@\n     private final int splitBatchSize;\n     private final PlanNodeId partitionedNode;\n     private final boolean groupedExecution;\n+    private final Supplier<Boolean> anySourceTaskBlocked;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczMTc0Mw==", "bodyText": "make it accept Supplier<Boolean> anySourceTaskBlocked and move TODO to FixedSourcePartitionedScheduler", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465731743", "createdAt": "2020-08-05T13:36:54Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -176,7 +187,9 @@ public static SourceScheduler newSourcePartitionedSchedulerAsSourceScheduler(\n             int splitBatchSize,\n             boolean groupedExecution)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczMjIxOA==", "bodyText": "please add an issue to prestosql and reference it from TODO", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465732218", "createdAt": "2020-08-05T13:37:42Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -176,7 +187,9 @@ public static SourceScheduler newSourcePartitionedSchedulerAsSourceScheduler(\n             int splitBatchSize,\n             boolean groupedExecution)\n     {\n-        return new SourcePartitionedScheduler(stage, partitionedNode, splitSource, splitPlacementPolicy, splitBatchSize, groupedExecution);\n+        // TODO : change anySourceTaskBlocked to accommodate the correct blocked status of source tasks", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNDA3OQ==", "bodyText": "move this large comment into\nelse if (anyBlockedOnPlacements) {\n  // COMMENT HERE", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465734079", "createdAt": "2020-08-05T13:40:29Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,26 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNDM4Mg==", "bodyText": "change it to:\nelse if (anyBlockedOnPlacements && anySourceTaskBlocked.get()) {\n  overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n}", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465734382", "createdAt": "2020-08-05T13:40:56Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,26 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNTA5Mg==", "bodyText": "this comment is redundant to large comment above", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465735092", "createdAt": "2020-08-05T13:41:59Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SourcePartitionedScheduler.java", "diffHunk": "@@ -346,19 +359,26 @@ else if (pendingSplits.isEmpty()) {\n             return new ScheduleResult(false, overallNewTasks.build(), overallSplitAssignmentCount);\n         }\n \n-        if (anyBlockedOnPlacements || groupedExecution) {\n-            // In a broadcast join, output buffers of the tasks in build source stage have to\n-            // hold onto all data produced before probe side task scheduling finishes,\n-            // even if the data is acknowledged by all known consumers. This is because\n-            // new consumers may be added until the probe side task scheduling finishes.\n-            //\n-            // As a result, the following line is necessary to prevent deadlock\n-            // due to neither build nor probe can make any progress.\n-            // The build side blocks due to a full output buffer.\n-            // In the meantime the probe side split cannot be consumed since\n-            // builder side hash table construction has not finished.\n+        // In a broadcast join, output buffers of the tasks in build source stage have to\n+        // hold onto all data produced before probe side task scheduling finishes,\n+        // even if the data is acknowledged by all known consumers. This is because\n+        // new consumers may be added until the probe side task scheduling finishes.\n+        //\n+        // As a result, the following line is necessary to prevent deadlock\n+        // due to neither build nor probe can make any progress.\n+        // The build side blocks due to a full output buffer.\n+        // In the meantime the probe side split cannot be consumed since\n+        // builder side hash table construction has not finished.\n+        if (groupedExecution) {\n             overallNewTasks.addAll(finalizeTaskCreationIfNecessary());\n         }\n+        else if (anyBlockedOnPlacements) {\n+            // Lock task generation in current stage if any of the source tasks' output buffer is blocked", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNjAyOQ==", "bodyText": "make it private", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465736029", "createdAt": "2020-08-05T13:43:18Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -428,30 +453,21 @@ else if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n \n         stageLinkages.put(stageId, new StageLinkage(plan.getFragment().getId(), parent, childStages));\n \n-        if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n-            Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()\n-                    .map(SqlStageExecution::getAllTasks)\n-                    .flatMap(Collection::stream)\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n-\n-            Supplier<Collection<TaskStatus>> writerTasksProvider = () -> stage.getAllTasks().stream()\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n+        return stages.build();\n+    }\n \n-            ScaledWriterScheduler scheduler = new ScaledWriterScheduler(\n-                    stage,\n-                    sourceTasksProvider,\n-                    writerTasksProvider,\n-                    nodeScheduler.createNodeSelector(Optional.empty()),\n-                    schedulerExecutor,\n-                    getWriterMinSize(session));\n-            whenAllStages(childStages, StageState::isDone)\n-                    .addListener(scheduler::finish, directExecutor());\n-            stageSchedulers.put(stageId, scheduler);\n-        }\n+    private static Collection<TaskStatus> getChildTaskStatuses(Set<SqlStageExecution> childStages)\n+    {\n+        return childStages.stream()\n+                .map(SqlStageExecution::getAllTasks)\n+                .flatMap(Collection::stream)\n+                .map(RemoteTask::getTaskStatus)\n+                .collect(toImmutableList());\n+    }\n \n-        return stages.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNzQxNw==", "bodyText": "make this method\nprivate static boolean isAnyTaskBlocked(Set<SqlStageExecution> childStages) {\n  return getChildTaskStatuses(childStages).stream().anyMatch(TaskStatus::isOutputBufferOverutilized);\n}\n\nand move above getChildTaskStatuses", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465737417", "createdAt": "2020-08-05T13:45:17Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -428,30 +453,21 @@ else if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n \n         stageLinkages.put(stageId, new StageLinkage(plan.getFragment().getId(), parent, childStages));\n \n-        if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n-            Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()\n-                    .map(SqlStageExecution::getAllTasks)\n-                    .flatMap(Collection::stream)\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n-\n-            Supplier<Collection<TaskStatus>> writerTasksProvider = () -> stage.getAllTasks().stream()\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n+        return stages.build();\n+    }\n \n-            ScaledWriterScheduler scheduler = new ScaledWriterScheduler(\n-                    stage,\n-                    sourceTasksProvider,\n-                    writerTasksProvider,\n-                    nodeScheduler.createNodeSelector(Optional.empty()),\n-                    schedulerExecutor,\n-                    getWriterMinSize(session));\n-            whenAllStages(childStages, StageState::isDone)\n-                    .addListener(scheduler::finish, directExecutor());\n-            stageSchedulers.put(stageId, scheduler);\n-        }\n+    private static Collection<TaskStatus> getChildTaskStatuses(Set<SqlStageExecution> childStages)\n+    {\n+        return childStages.stream()\n+                .map(SqlStageExecution::getAllTasks)\n+                .flatMap(Collection::stream)\n+                .map(RemoteTask::getTaskStatus)\n+                .collect(toImmutableList());\n+    }\n \n-        return stages.build();\n+    static Supplier<Boolean> getAnyTaskBlockedSupplier(Supplier<Collection<TaskStatus>> taskStatusSupplier)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTczNzg3NA==", "bodyText": "make it return List<TaskStatus>", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465737874", "createdAt": "2020-08-05T13:45:56Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -428,30 +453,21 @@ else if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n \n         stageLinkages.put(stageId, new StageLinkage(plan.getFragment().getId(), parent, childStages));\n \n-        if (partitioningHandle.equals(SCALED_WRITER_DISTRIBUTION)) {\n-            Supplier<Collection<TaskStatus>> sourceTasksProvider = () -> childStages.stream()\n-                    .map(SqlStageExecution::getAllTasks)\n-                    .flatMap(Collection::stream)\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n-\n-            Supplier<Collection<TaskStatus>> writerTasksProvider = () -> stage.getAllTasks().stream()\n-                    .map(RemoteTask::getTaskStatus)\n-                    .collect(toList());\n+        return stages.build();\n+    }\n \n-            ScaledWriterScheduler scheduler = new ScaledWriterScheduler(\n-                    stage,\n-                    sourceTasksProvider,\n-                    writerTasksProvider,\n-                    nodeScheduler.createNodeSelector(Optional.empty()),\n-                    schedulerExecutor,\n-                    getWriterMinSize(session));\n-            whenAllStages(childStages, StageState::isDone)\n-                    .addListener(scheduler::finish, directExecutor());\n-            stageSchedulers.put(stageId, scheduler);\n-        }\n+    private static Collection<TaskStatus> getChildTaskStatuses(Set<SqlStageExecution> childStages)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NTUzMQ==", "bodyText": "use nodeMamMemoizationDuration.getValue() > 0", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465745531", "createdAt": "2020-08-05T13:57:07Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -82,9 +97,15 @@ public NodeSelector createNodeSelector(Optional<CatalogName> catalogName)\n \n         // this supplier is thread-safe. TODO: this logic should probably move to the scheduler since the choice of which node to run in should be\n         // done as close to when the the split is about to be scheduled\n-        Supplier<NodeMap> nodeMap = Suppliers.memoizeWithExpiration(\n-                () -> createNodeMap(catalogName),\n-                5, TimeUnit.SECONDS);\n+        Supplier<NodeMap> nodeMap;\n+        if (nodeMapMemoizationDuration.roundTo(SECONDS) > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NjEwNA==", "bodyText": "use milliseconds instead. There is a build-in duration method: Duration#toMillis", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465746104", "createdAt": "2020-08-05T13:57:56Z", "author": {"login": "sopel39"}, "path": "presto-main/src/main/java/io/prestosql/execution/scheduler/UniformNodeSelectorFactory.java", "diffHunk": "@@ -82,9 +97,15 @@ public NodeSelector createNodeSelector(Optional<CatalogName> catalogName)\n \n         // this supplier is thread-safe. TODO: this logic should probably move to the scheduler since the choice of which node to run in should be\n         // done as close to when the the split is about to be scheduled\n-        Supplier<NodeMap> nodeMap = Suppliers.memoizeWithExpiration(\n-                () -> createNodeMap(catalogName),\n-                5, TimeUnit.SECONDS);\n+        Supplier<NodeMap> nodeMap;\n+        if (nodeMapMemoizationDuration.roundTo(SECONDS) > 0) {\n+            nodeMap = Suppliers.memoizeWithExpiration(\n+                    () -> createNodeMap(catalogName),\n+                    nodeMapMemoizationDuration.roundTo(SECONDS), SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NzkyNQ==", "bodyText": "just use:\n() -> false", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465747925", "createdAt": "2020-08-05T14:00:20Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -318,7 +325,8 @@ public void testNoNodes()\n                     Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n                     Iterables.getOnlyElement(plan.getSplitSources().values()),\n                     new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n-                    2);\n+                    2,\n+                    getAnyTaskBlockedSupplier(ImmutableList::of));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc2MDY3NQ==", "bodyText": "the test does not FullSchedule anymore. I think this test can be removed as we now cover this test by testNewTaskScheduledWhenChildStageBufferIsUnderutilized and testNoNewTaskScheduledWhenChildStageBufferIsOverutilized.\nThe only difference is that this this test was inducing blocked on placements via extra query", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465760675", "createdAt": "2020-08-05T14:17:55Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -396,8 +404,8 @@ public void testBlockCausesFullSchedule()\n         scheduleResult = secondScheduler.schedule();\n         assertFalse(scheduleResult.isFinished());\n         assertTrue(scheduleResult.getBlocked().isDone());\n-        assertEquals(scheduleResult.getNewTasks().size(), 3);\n-        assertEquals(secondStage.getAllTasks().size(), 3);\n+        assertEquals(scheduleResult.getNewTasks().size(), 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc2MzY1Mw==", "bodyText": "just use () -> false here", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465763653", "createdAt": "2020-08-05T14:21:51Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +414,85 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskScheduledWhenChildStageBufferIsUnderutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, new Duration(0, SECONDS)));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(500, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with under utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                500,\n+                getAnyTaskBlockedSupplier(() -> ImmutableList.of(dummyTaskStatus)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc2MzgwOQ==", "bodyText": "just use () -> true here", "url": "https://github.com/trinodb/trino/pull/4294#discussion_r465763809", "createdAt": "2020-08-05T14:22:03Z", "author": {"login": "sopel39"}, "path": "presto-main/src/test/java/io/prestosql/execution/scheduler/TestSourcePartitionedScheduler.java", "diffHunk": "@@ -406,6 +414,85 @@ public void testBlockCausesFullSchedule()\n         secondStage.abort();\n     }\n \n+    @Test\n+    public void testNewTaskScheduledWhenChildStageBufferIsUnderutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, new Duration(0, SECONDS)));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(500, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy task with under utilized output buffer\n+        TaskStatus dummyTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                500,\n+                getAnyTaskBlockedSupplier(() -> ImmutableList.of(dummyTaskStatus)));\n+\n+        // the queues of 3 running nodes should be full\n+        ScheduleResult scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getBlockedReason().get(), SPLIT_QUEUES_FULL);\n+        assertEquals(scheduleResult.getNewTasks().size(), 3);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 300);\n+\n+        // new node added - the pending splits should go to it since the child tasks are not blocked\n+        nodeManager.addNode(CONNECTOR_ID, new InternalNode(\"other4\", URI.create(\"http://127.0.0.4:14\"), NodeVersion.UNKNOWN, false));\n+        scheduleResult = scheduler.schedule();\n+        assertEquals(scheduleResult.getBlockedReason().get(), SPLIT_QUEUES_FULL); // split queue is full but still the source task creation isn't blocked\n+        assertEquals(scheduleResult.getNewTasks().size(), 1);\n+        assertEquals(scheduleResult.getSplitsScheduled(), 100);\n+    }\n+\n+    @Test\n+    public void testNoNewTaskScheduledWhenChildStageBufferIsOverutilized() throws Exception\n+    {\n+        NodeTaskMap nodeTaskMap = new NodeTaskMap(finalizerService);\n+        // use private node manager so we can add a node later\n+        InMemoryNodeManager nodeManager = new InMemoryNodeManager();\n+        nodeManager.addNode(CONNECTOR_ID,\n+                new InternalNode(\"other1\", URI.create(\"http://127.0.0.1:11\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other2\", URI.create(\"http://127.0.0.1:12\"), NodeVersion.UNKNOWN, false),\n+                new InternalNode(\"other3\", URI.create(\"http://127.0.0.1:13\"), NodeVersion.UNKNOWN, false));\n+        NodeScheduler nodeScheduler = new NodeScheduler(new UniformNodeSelectorFactory(nodeManager, new NodeSchedulerConfig().setIncludeCoordinator(false), nodeTaskMap, new Duration(0, SECONDS)));\n+\n+        StageExecutionPlan plan = createPlan(createFixedSplitSource(400, TestingSplit::createRemoteSplit));\n+        SqlStageExecution stage = createSqlStageExecution(plan, nodeTaskMap);\n+\n+        // dummy tasks with over and under utilized output buffers\n+        TaskStatus dummyOverUtilizedTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", true);\n+        TaskStatus dummyUnderUtilizedTaskStatus = taskStatusWithOutputBufferUtilization(new TaskId(\"\"), new URI(\"\"), \"\", false);\n+        StageScheduler scheduler = newSourcePartitionedSchedulerAsStageScheduler(\n+                stage,\n+                Iterables.getOnlyElement(plan.getSplitSources().keySet()),\n+                Iterables.getOnlyElement(plan.getSplitSources().values()),\n+                new DynamicSplitPlacementPolicy(nodeScheduler.createNodeSelector(Optional.of(CONNECTOR_ID)), stage::getAllTasks),\n+                400,\n+                getAnyTaskBlockedSupplier(() -> ImmutableList.of(dummyOverUtilizedTaskStatus, dummyUnderUtilizedTaskStatus)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 143}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e8b27cd5a0470c95549ffe0d974c07f29a04d12", "author": {"user": {"login": "rohangarg", "name": "Rohan Garg"}}, "url": "https://github.com/trinodb/trino/commit/2e8b27cd5a0470c95549ffe0d974c07f29a04d12", "committedDate": "2020-08-06T15:07:06Z", "message": "Relax task locking in SourcePartitionedScheduler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "365b111e580aa94dec23dc726c5b0f004f999e51", "author": {"user": {"login": "rohangarg", "name": "Rohan Garg"}}, "url": "https://github.com/trinodb/trino/commit/365b111e580aa94dec23dc726c5b0f004f999e51", "committedDate": "2020-08-06T15:07:06Z", "message": "Make BroadcastOutputBuffer#isOverutilized aggressive"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "365b111e580aa94dec23dc726c5b0f004f999e51", "author": {"user": {"login": "rohangarg", "name": "Rohan Garg"}}, "url": "https://github.com/trinodb/trino/commit/365b111e580aa94dec23dc726c5b0f004f999e51", "committedDate": "2020-08-06T15:07:06Z", "message": "Make BroadcastOutputBuffer#isOverutilized aggressive"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzMTk5ODg5", "url": "https://github.com/trinodb/trino/pull/4294#pullrequestreview-463199889", "createdAt": "2020-08-07T10:17:28Z", "commit": {"oid": "365b111e580aa94dec23dc726c5b0f004f999e51"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 310, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}