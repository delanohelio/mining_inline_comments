{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyOTcyMzkx", "number": 3425, "title": "Add approx_most_frequent aggregation function", "bodyText": "Purpose\nIn our experience, we need to get the samples from the underlying table which can contain millions of records and its cardinality is significantly skewed. (e.g. suggesting the selection items in UI) We can get the frequent values by using group by count for now.\nBut since the grouping by the high cardinality column (e.g. user ID, email) from a huge table causes out of memory error, we put the limitation on the number of original records by the LIMIT. For example, the following query fetches the top 3 sample values but column v has large cardinality, it is necessary to limit the number of records for the stable execution.\nSELECT\n  v, COUNT(1)\nFROM (\n  SELECT v FROM huge_table LIMIT 10000\n)\nGROUP BY 1\nORDER BY 2 DESC\nLIMIT 3\nIt sometimes provides us non-intuitive samples. (e.g. lack the frequent items). We want to ensure to keep the high-frequency values while omitting the unimportant values efficiently.\nThe space-saving algorithm with a stream summary suggested in [1] will mitigate this type of problem by counting the frequency and truncate low-frequency data in an online manner. The approx_most_frequent returns the map value containing the high-frequency element calculated approximately. It gets 3 arguments:\n\nmax buckets: The number of top K elements in the stream summary\nvalues: Values stored in the stream summary\ncapacity: The maximum capacity of the stream summary. Larger value improves the accuracy of space-saving algorithm.\n\nThe previous example can be rewritten as follows. The third argument is used to control the accuracy of the approximation.\nSELECT\n  approx_most_frequent(3, v, 1000) \nFROM\n  huge_table\nExperiment\nWith my skewed table (1=60%, 2=20%, 3=10%, 4=3%,5=3%,6=3%), approx_most_frequent returns the correct count while the group by count query fails due to memory overflow. This experiment uses 3 node docker based cluster.\npresto:default> select approx_most_frequent(2, cast(v as bigint), 10) from skew_table;\n         _col0\n------------------------\n {1=4014080, 2=2408448}\n(1 row)\n\nQuery 20200414_044201_00086_r2sgg, FINISHED, 2 nodes\nSplits: 25 total, 25 done (100.00%)\n0:05 [8.83M rows, 75.8MB] [1.62M rows/s, 13.9MB/s]\n\npresto:default> select v,count(1) from skew_table group by 1 order by 2 limit 2;\n...\n\nAdditionally, I run the function on the high cardinality table having (e.g. query_id) as follows. The number of unique values of query_id is over 3.5 million.\nselect \n  query_id,\n  count(1) \nfrom queries \ngroup by 1 order by 2 desc limit 5;\nselect \n  items,\n  freq \nfrom (\n  select approx_most_frequent(5, query_id, 1000) as frequent_items \n  from queries \n  cross join unnest(frequent_items) as t(items, freq)\n);\nThe first one consumes over 60 times peak total memory usage than the second one.  approx_most_frequent can significantly reduce the memory pressure on the system without losing the performance. Here is a detailed comparison between these two approaches.\n\n\n\n\nGROUP BY COUNT\nAPPROX_MOST_FREQUENT\n\n\n\n\nElapsed Time\n16.54s\n16.30s\n\n\nCPU Time\n6.15s\n2.65s\n\n\nInternal Network Data\n160.18MB\n6.06KB\n\n\nPeak User Memory\n294.00MB\n32B\n\n\nPeak Total Memory\n316.43MB\n5.03MB\n\n\n\nOf course, the returned value is an approximation which is not exactly the high frequent items in strict means. But we can have a good balance between the accuracy and the stability in terms of the memory usage by controlling the capacity of the stream summary structure.\nThe original implementation was in [2] but it does use the stream summary data structure accurately. Therefore I rewrote the implementation to use stream-lib [3] and fit the latest interface.\nReference\n[1]: A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent and top-k elements in data streams\"  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n[2]: prestodb/presto#6036\n[3]: https://github.com/addthis/stream-lib", "createdAt": "2020-04-14T05:10:31Z", "url": "https://github.com/trinodb/trino/pull/3425", "merged": true, "mergeCommit": {"oid": "eabee442b575523c08ad36ed5fc798d323503939"}, "closed": true, "closedAt": "2020-07-15T17:14:03Z", "author": {"login": "Lewuathe"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcXe77agBqjMyMjk5NzEwNDk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc1CHEcABqjM1NDY3MTM3OTA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3MTAyMjIx", "url": "https://github.com/trinodb/trino/pull/3425#pullrequestreview-437102221", "createdAt": "2020-06-25T01:00:53Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwMTowMDo1M1rOGon-xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwMToyNjowNFrOGooY1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA==", "bodyText": "Why do we need this?", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251270", "createdAt": "2020-06-25T01:00:53Z", "author": {"login": "martint"}, "path": "presto-phoenix/pom.xml", "diffHunk": "@@ -311,6 +311,12 @@\n                         <!-- io.airlift:joni and phoenix-client's org.jruby.joni:joni resource duplicates-->\n                         <ignoredResourcePattern>tables/.*\\.bin</ignoredResourcePattern>\n                     </ignoredResourcePatterns>\n+                    <ignoredDependencies>\n+                        <dependency>\n+                            <groupId>com.clearspring.analytics</groupId>\n+                            <artifactId>stream</artifactId>\n+                        </dependency>\n+                    </ignoredDependencies>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTY1Nw==", "bodyText": "Use primitive long", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251657", "createdAt": "2020-06-25T01:02:26Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(Long key, Long count, DynamicSliceOutput output)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTc2Nw==", "bodyText": "Use primitive long", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251767", "createdAt": "2020-06-25T01:02:54Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(Long key, Long count, DynamicSliceOutput output)\n+    {\n+        output.appendLong(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Long> histogram)\n+    {\n+        Long key = input.readLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MjMxNA==", "bodyText": "Fields can be final", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445252314", "createdAt": "2020-06-25T01:04:52Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1Mjk5Nw==", "bodyText": "Why 1000? Can we estimate based on the number of buckets?", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445252997", "createdAt": "2020-06-25T01:07:09Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MzQxNQ==", "bodyText": "This will return the raw allocated slice, which may be bigger than needed. Use output.slice() instead.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445253415", "createdAt": "2020-06-25T01:08:42Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        output.appendByte(FORMAT_TAG);\n+        output.appendInt(maxBuckets);\n+        output.appendInt(capacity);\n+        // Serialize key and counts.\n+        for (Counter<K> counter : counters) {\n+            serializer.serialize(counter.getItem(), counter.getCount(), output);\n+        }\n+\n+        return output.getUnderlyingSlice();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDE3Nw==", "bodyText": "The implementation of StreamSummary is very \"object-y\" and will end up causing problems with object allocations at some point. It's fine to use for now, but we should consider reimplementing using flat structures (see, for instance, the implementation of QuantileDigest)", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445254177", "createdAt": "2020-06-25T01:11:38Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDQ2MQ==", "bodyText": "Use Slice for storing strings", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445254461", "createdAt": "2020-06-25T01:12:46Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.Slices;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import java.util.Map;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<String>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NzQ4NA==", "bodyText": "This could return an object with two parallel arrays or lists, one with the keys and one for the values (e.g., long[]) to avoid having to create a map every time. None of the callers really needs the map, since they iterate over the entries and write them out to the output.\nAlternatively, it could be replaced with a method that walks over the entires and calls back with each entry. E.g.:\nforEachBucket((key, value) -> {\n    VarcharType.VARCHAR.writeSlice(entryBuilder, key));\n    BigintType.BIGINT.writeLong(entryBuilder, value);\n});", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445257484", "createdAt": "2020-06-25T01:24:20Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        output.appendByte(FORMAT_TAG);\n+        output.appendInt(maxBuckets);\n+        output.appendInt(capacity);\n+        // Serialize key and counts.\n+        for (Counter<K> counter : counters) {\n+            serializer.serialize(counter.getItem(), counter.getCount(), output);\n+        }\n+\n+        return output.getUnderlyingSlice();\n+    }\n+\n+    public void merge(ApproximateMostFrequentHistogram<K> other)\n+    {\n+        List<Counter<K>> counters = other.streamSummary.topK(maxBuckets);\n+        for (Counter<K> counter : counters) {\n+            add(counter.getItem(), counter.getCount());\n+        }\n+    }\n+\n+    public Map<K, Long> getBuckets()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1Nzk0MQ==", "bodyText": "Add some tests involving GROUP BY", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445257941", "createdAt": "2020-06-25T01:26:04Z", "author": {"login": "martint"}, "path": "presto-testing/src/main/java/io/prestosql/testing/AbstractTestAggregations.java", "diffHunk": "@@ -1315,4 +1316,28 @@ public void testGroupingSetsWithDefaultValue()\n                 \"SELECT orderkey, COUNT(DISTINCT k) FROM (SELECT orderkey, 1 k FROM orders) GROUP BY GROUPING SETS ((), orderkey) HAVING orderkey IS NULL\",\n                 \"VALUES (null, 1)\");\n     }\n+\n+    @Test\n+    public void testApproxMostFrequentWithLong()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzMxNDkz", "url": "https://github.com/trinodb/trino/pull/3425#pullrequestreview-446731493", "createdAt": "2020-07-10T22:23:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjoyMzoyNVrOGwHQMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0MjoyOFrOGwHjOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzY2NQ==", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103665", "createdAt": "2020-07-10T22:23:25Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzc3OA==", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103778", "createdAt": "2020-07-10T22:23:50Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),\n+                    LongApproximateMostFrequentStateSerializer::serializeBucket,\n+                    LongApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        histogram.add(value);\n+    }\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState StringState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") Slice value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Slice> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Slice>(toIntExact(buckets), toIntExact(capacity),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzgyMg==", "bodyText": "Remove", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103822", "createdAt": "2020-07-10T22:24:01Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),\n+                    LongApproximateMostFrequentStateSerializer::serializeBucket,\n+                    LongApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        histogram.add(value);\n+    }\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState StringState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") Slice value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Slice> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Slice>(toIntExact(buckets), toIntExact(capacity),\n+                    StringApproximateMostFrequentStateSerializer::serializeBucket,\n+                    StringApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        System.out.println(\"QQQQQQQQ\");\n+        System.out.println(value.toStringUtf8());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNDQ5NQ==", "bodyText": "Make this final", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453104495", "createdAt": "2020-07-10T22:26:32Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDE3Nw=="}, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjE1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    state.set(new ApproximateMostFrequentHistogram<Long>(VARBINARY.getSlice(block, index),\n          \n          \n            \n                    state.set(new ApproximateMostFrequentHistogram<>(VARBINARY.getSlice(block, index),\n          \n      \n    \n    \n  \n\nAlso, one argument per line when splitting arguments across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453106158", "createdAt": "2020-07-10T22:32:46Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(long key, long count, DynamicSliceOutput output)\n+    {\n+        output.appendLong(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Long> histogram)\n+    {\n+        long key = input.readLong();\n+        long count = input.readLong();\n+        histogram.add(key, count);\n+    }\n+\n+    @Override\n+    public Type getSerializedType()\n+    {\n+        return VARBINARY;\n+    }\n+\n+    @Override\n+    public void serialize(ApproximateMostFrequentFunction.LongState state, BlockBuilder out)\n+    {\n+        if (state.get() == null) {\n+            out.appendNull();\n+        }\n+        else {\n+            VARBINARY.writeSlice(out, state.get().serialize());\n+        }\n+    }\n+\n+    @Override\n+    public void deserialize(Block block, int index, ApproximateMostFrequentFunction.LongState state)\n+    {\n+        state.set(new ApproximateMostFrequentHistogram<Long>(VARBINARY.getSlice(block, index),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjU1Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void serialize(K key, Long count, DynamicSliceOutput output);\n          \n          \n            \n                void serialize(K key, long count, DynamicSliceOutput output);", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453106556", "createdAt": "2020-07-10T22:34:23Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentBucketSerializer.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+\n+public interface ApproximateMostFrequentBucketSerializer<K>\n+{\n+    public void serialize(K key, Long count, DynamicSliceOutput output);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNzg0OQ==", "bodyText": "This calculation seems off. From the code below, it needs:\n\n1 byte for the format tag\n4 bytes for maxBuckets\n4 bytes for capacity\n4 bytes for the number of counters\n8 * counters.size() bytes for the count\nfor long keys, 8 * counters.size() bytes for the keys. For string keys, it can vary, but if we just pick 8, it would be an ok estimate that works for most cases (add a comment explaining why we're picking such a number)", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453107849", "createdAt": "2020-07-10T22:39:44Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        int bucketSize = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < bucketSize; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        int estimatedSliceSize = Byte.BYTES + counters.size() * Integer.BYTES * 3; // FORMAT_TAG + Bytes allocated for total buckets\n+        DynamicSliceOutput output = new DynamicSliceOutput(estimatedSliceSize * 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODQwMQ==", "bodyText": "Format as:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public ApproximateMostFrequentHistogram(int maxBuckets,\n          \n          \n            \n                                                        int capacity,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketDeserializer<K> deserializer)\n          \n          \n            \n                public ApproximateMostFrequentHistogram(\n          \n          \n            \n                        int maxBuckets,\n          \n          \n            \n                        int capacity,\n          \n          \n            \n                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                        ApproximateMostFrequentBucketDeserializer<K> deserializer)", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453108401", "createdAt": "2020-07-10T22:41:55Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODUzOA==", "bodyText": "Format as:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public ApproximateMostFrequentHistogram(Slice serialized,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketDeserializer<K> deserializer)\n          \n          \n            \n                public ApproximateMostFrequentHistogram(\n          \n          \n            \n                        Slice serialized,\n          \n          \n            \n                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                        ApproximateMostFrequentBucketDeserializer<K> deserializer)", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453108538", "createdAt": "2020-07-10T22:42:28Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NDczMTQw", "url": "https://github.com/trinodb/trino/pull/3425#pullrequestreview-447473140", "createdAt": "2020-07-13T17:54:17Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNzo1NDoxN1rOGwzaYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNzo1NDoxN1rOGwzaYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyNzE2OQ==", "bodyText": "@mosabua, can you help review this section?", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453827169", "createdAt": "2020-07-13T17:54:17Z", "author": {"login": "martint"}, "path": "presto-docs/src/main/sphinx/functions/aggregate.rst", "diffHunk": "@@ -327,6 +327,27 @@ Approximate Aggregate Functions\n     for all ``value``\\ s. This function is equivalent to the variant of\n     :func:`numeric_histogram` that takes a ``weight``, with a per-item weight of ``1``.\n \n+.. function:: approx_most_frequent(buckets, value, capacity) -> map<[same as value], bigint>\n+\n+    Computes the top frequent values up to ``buckets`` elements approximately.\n+    Approximate estimation of the function enables us to pick up the frequent\n+    values with less memory. Larger ``capacity`` improves the accuracy of\n+    underlying algorithm with sacrificing the memory capacity. The returned\n+    value is a map containing the top elements with corresponding estimated\n+    frequency.\n+\n+    ``buckets`` and ``capacity`` must be ``bigint``. ``value`` can be numeric\n+    or string type.\n+\n+    The function uses the stream summary data structure proposed in the\n+    following paper.\n+\n+    .. code-block:: none\n+\n+        A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent\n+        and top-k elements in data streams\"\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NDc3Nzk5", "url": "https://github.com/trinodb/trino/pull/3425#pullrequestreview-447477799", "createdAt": "2020-07-13T18:00:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODowMDozOFrOGwzpFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODowOTowOFrOGwz8Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMDkzNA==", "bodyText": ".. code-block :: none doesn't mean anything in javadocs -- it's an RST construct.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /**\n          \n          \n            \n             *  Aggregation function that approximates the frequency of the top-K elements.\n          \n          \n            \n             *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n          \n          \n            \n             *  once fewer than the least-frequent \"frequent\" element.\n          \n          \n            \n             *\n          \n          \n            \n             *   The algorithm is based loosely on:\n          \n          \n            \n             *   .. code-block:: none\n          \n          \n            \n             *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n          \n          \n            \n             *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n          \n          \n            \n             *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n          \n          \n            \n             */\n          \n          \n            \n            /**\n          \n          \n            \n             *  <p>\n          \n          \n            \n             *  Aggregation function that approximates the frequency of the top-K elements.\n          \n          \n            \n             *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n          \n          \n            \n             *  once fewer than the least-frequent \"frequent\" element.\n          \n          \n            \n             *  </p>\n          \n          \n            \n             *\n          \n          \n            \n             * <p>\n          \n          \n            \n             * The algorithm is based loosely on:\n          \n          \n            \n             * <a href=\"https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\">Efficient Computation of Frequent and Top-*k* Elements in Data Streams</a>\n          \n          \n            \n             * by Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi\n          \n          \n            \n             * </p>\n          \n          \n            \n             */", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453830934", "createdAt": "2020-07-13T18:00:38Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTI0OQ==", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831249", "createdAt": "2020-07-13T18:01:10Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTM5OA==", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831398", "createdAt": "2020-07-13T18:01:29Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+            int capacity,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTg2OQ==", "bodyText": "Why * 3 ?", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831869", "createdAt": "2020-07-13T18:02:15Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+            int capacity,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        int bucketSize = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < bucketSize; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        int estimatedSliceSize = Byte.BYTES + // FORMAT_TAG\n+                Integer.BYTES + // maxBuckets\n+                Integer.BYTES + // capacity\n+                Integer.BYTES + // Counters size\n+                counters.size() * Long.BYTES * 2; // Bytes allocated for item and count. Although the estimation is not correct for variable length slices, it should work.\n+        DynamicSliceOutput output = new DynamicSliceOutput(estimatedSliceSize * 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMzgwMw==", "bodyText": "Let's rename this to BucketConsumer and the method below to processBucket, or simply process. Calling it a \"function\" is misleading, as this doesn't return any value.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453833803", "createdAt": "2020-07-13T18:05:31Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/BucketReadFunction.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+@FunctionalInterface\n+public interface BucketReadFunction<K>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzNDI4MA==", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453834280", "createdAt": "2020-07-13T18:06:20Z", "author": {"login": "martint"}, "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/StringApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class StringApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.StringState>\n+{\n+    public static void serializeBucket(Slice key, Long count, DynamicSliceOutput output)\n+    {\n+        output.appendInt(key.length());\n+        output.appendBytes(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Slice> histogram)\n+    {\n+        int keySize = input.readInt();\n+        Slice key = input.readSlice(keySize);\n+        long count = input.readLong();\n+        histogram.add(key, count);\n+    }\n+\n+    @Override\n+    public Type getSerializedType()\n+    {\n+        return VARBINARY;\n+    }\n+\n+    @Override\n+    public void serialize(ApproximateMostFrequentFunction.StringState state, BlockBuilder out)\n+    {\n+        if (state.get() == null) {\n+            out.appendNull();\n+        }\n+        else {\n+            VARBINARY.writeSlice(out, state.get().serialize());\n+        }\n+    }\n+\n+    @Override\n+    public void deserialize(Block block, int index, ApproximateMostFrequentFunction.StringState state)\n+    {\n+        state.set(new ApproximateMostFrequentHistogram<Slice>(VARBINARY.getSlice(block, index),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzNTgwMw==", "bodyText": "We may want to add some hint about what are reasonable values for capacity, or how it relates to buckets (if at all) or to the number of elements processed in total.", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453835803", "createdAt": "2020-07-13T18:09:08Z", "author": {"login": "martint"}, "path": "presto-docs/src/main/sphinx/functions/aggregate.rst", "diffHunk": "@@ -327,6 +327,27 @@ Approximate Aggregate Functions\n     for all ``value``\\ s. This function is equivalent to the variant of\n     :func:`numeric_histogram` that takes a ``weight``, with a per-item weight of ``1``.\n \n+.. function:: approx_most_frequent(buckets, value, capacity) -> map<[same as value], bigint>\n+\n+    Computes the top frequent values up to ``buckets`` elements approximately.\n+    Approximate estimation of the function enables us to pick up the frequent\n+    values with less memory. Larger ``capacity`` improves the accuracy of", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "9380b2c7a14716eacb3f72be872ad65d593a9d4a", "author": {"user": {"login": "Lewuathe", "name": "Kai Sasaki"}}, "url": "https://github.com/trinodb/trino/commit/9380b2c7a14716eacb3f72be872ad65d593a9d4a", "committedDate": "2020-07-15T03:31:27Z", "message": "Add approx_most_frequent aggregation function\n\nIn our experience, we need to get the samples from the underlying\ntable which can contain million of records and its cardinality is\nsignificantly skewed. (e.g. suggesting the selection items in UI)\nWe can get the frequent values by using group by count.\n\nBut since the grouping by the high cardinality column from huge\ntable causes out of memory error, we put the limitation on the\nnumber of samples. It sometimes provide us non-intuitive samples.\n(e.g. lack the frequent items)\n\nThe space saving algorithm with stream summary suggested in [1]\nwill mitigate this type of problem by counting the frequency\nand truncate low frequency data in online manner. The\n`approx_most_frequent` returns the map value containing the high\nfrequency element calculated approximately.\n\nReference\n\n* [1]: A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent and top-k elements in data streams\"\n  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "9380b2c7a14716eacb3f72be872ad65d593a9d4a", "author": {"user": {"login": "Lewuathe", "name": "Kai Sasaki"}}, "url": "https://github.com/trinodb/trino/commit/9380b2c7a14716eacb3f72be872ad65d593a9d4a", "committedDate": "2020-07-15T03:31:27Z", "message": "Add approx_most_frequent aggregation function\n\nIn our experience, we need to get the samples from the underlying\ntable which can contain million of records and its cardinality is\nsignificantly skewed. (e.g. suggesting the selection items in UI)\nWe can get the frequent values by using group by count.\n\nBut since the grouping by the high cardinality column from huge\ntable causes out of memory error, we put the limitation on the\nnumber of samples. It sometimes provide us non-intuitive samples.\n(e.g. lack the frequent items)\n\nThe space saving algorithm with stream summary suggested in [1]\nwill mitigate this type of problem by counting the frequency\nand truncate low frequency data in online manner. The\n`approx_most_frequent` returns the map value containing the high\nfrequency element calculated approximately.\n\nReference\n\n* [1]: A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent and top-k elements in data streams\"\n  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1503, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}