{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5NjIxMDc2", "number": 4460, "title": "Fix HDFS impersonation in Iceberg Connector", "bodyText": "Manually tested with production Kerberized HMS and HDFS with impersonation enabled.\nPart of #1324\nThanks to @manishmalhotrawork for reporting and discussing on this.", "createdAt": "2020-07-15T17:14:01Z", "url": "https://github.com/trinodb/trino/pull/4460", "merged": true, "mergeCommit": {"oid": "6d7f35047faa67adc24c99bb78aba01c21aaa990"}, "closed": true, "closedAt": "2020-07-29T22:01:18Z", "author": {"login": "lxynov"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc1iRwTAFqTQ1MDAzMTQwMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc5Nz8WABqjM1OTI0NDcyNDk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMDMxNDAw", "url": "https://github.com/trinodb/trino/pull/4460#pullrequestreview-450031400", "createdAt": "2020-07-16T16:47:56Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo0Nzo1NlrOGyznaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNjo1Nzo1MlrOGyz_LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyNzY1Nw==", "bodyText": "Is this needed? We don't other delete calls.", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455927657", "createdAt": "2020-07-16T16:47:56Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/HdfsFileIo.java", "diffHunk": "@@ -44,26 +41,24 @@ public HdfsFileIo(HdfsEnvironment environment, HdfsContext context)\n     @Override\n     public InputFile newInputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopInputFile.fromLocation(path, configuration);\n+        return new PrestoHadoopInputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public OutputFile newOutputFile(String path)\n     {\n-        Configuration configuration = environment.getConfiguration(context, new Path(path));\n-        return HadoopOutputFile.fromPath(new Path(path), configuration);\n+        return new PrestoHadoopOutputFile(new Path(path), environment, context);\n     }\n \n     @Override\n     public void deleteFile(String pathString)\n     {\n         Path path = new Path(pathString);\n         try {\n-            environment.getFileSystem(context, path).delete(path, false);\n+            environment.doAs(context.getIdentity().getUser(), () -> environment.getFileSystem(context, path).delete(path, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyODI2MQ==", "bodyText": "Same, we don't do this for OrcFileWriterFactory", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455928261", "createdAt": "2020-07-16T16:48:59Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -186,9 +186,9 @@ private IcebergFileWriter createOrcWriter(\n                     try {\n                         return new HdfsOrcDataSource(\n                                 new OrcDataSourceId(outputPath.toString()),\n-                                fileSystem.getFileStatus(outputPath).getLen(),\n+                                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.getFileStatus(outputPath).getLen()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkzMzM4Nw==", "bodyText": "We could name this HdfsInputFile to match HdfsFileIo", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455933387", "createdAt": "2020-07-16T16:57:25Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import io.prestosql.plugin.hive.HdfsEnvironment;\n+import io.prestosql.plugin.hive.HdfsEnvironment.HdfsContext;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.SeekableInputStream;\n+\n+import java.io.IOException;\n+\n+import static io.prestosql.plugin.iceberg.IcebergErrorCode.ICEBERG_FILESYSTEM_ERROR;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoHadoopInputFile", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkzMzc0MA==", "bodyText": "toString() not needed for concatenation", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r455933740", "createdAt": "2020-07-16T16:57:52Z", "author": {"login": "electrum"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PrestoHadoopInputFile.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import io.prestosql.plugin.hive.HdfsEnvironment;\n+import io.prestosql.plugin.hive.HdfsEnvironment.HdfsContext;\n+import io.prestosql.spi.PrestoException;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.SeekableInputStream;\n+\n+import java.io.IOException;\n+\n+import static io.prestosql.plugin.iceberg.IcebergErrorCode.ICEBERG_FILESYSTEM_ERROR;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoHadoopInputFile\n+        implements InputFile\n+{\n+    private final InputFile delegate;\n+    private final HdfsEnvironment environment;\n+    private final String user;\n+\n+    public PrestoHadoopInputFile(Path path, HdfsEnvironment environment, HdfsContext context)\n+    {\n+        requireNonNull(path, \"path is null\");\n+        this.environment = requireNonNull(environment, \"environment is null\");\n+        requireNonNull(context, \"context is null\");\n+        try {\n+            this.delegate = HadoopInputFile.fromPath(path, environment.getFileSystem(context, path), environment.getConfiguration(context, path));\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(ICEBERG_FILESYSTEM_ERROR, \"Failed to create input file: \" + path.toString(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMjMyMjU1", "url": "https://github.com/trinodb/trino/pull/4460#pullrequestreview-450232255", "createdAt": "2020-07-16T21:33:46Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMTozMzo0N1rOGy9kXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMTozMzo0N1rOGy9kXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA5MDcxOQ==", "bodyText": "should we also add recoverAction to IcebergRecordFileWriter  created-at\nas otherwise.\n[this] (https://github.com/prestosql/presto/blob/master/presto-hive/src/main/java/io/prestosql/plugin/hive/RecordFileWriter.java#L197) might fail as its running with Authentication ( doAs )", "url": "https://github.com/trinodb/trino/pull/4460#discussion_r456090719", "createdAt": "2020-07-16T21:33:47Z", "author": {"login": "manishmalhotrawork"}, "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergFileWriterFactory.java", "diffHunk": "@@ -165,9 +165,9 @@ private IcebergFileWriter createOrcWriter(\n     {\n         try {\n             FileSystem fileSystem = hdfsEnvironment.getFileSystem(session.getUser(), outputPath, jobConf);\n-            OrcDataSink orcDataSink = new OutputStreamOrcDataSink(fileSystem.create(outputPath));\n+            OrcDataSink orcDataSink = hdfsEnvironment.doAs(session.getUser(), () -> new OutputStreamOrcDataSink(fileSystem.create(outputPath)));\n             Callable<Void> rollbackAction = () -> {\n-                fileSystem.delete(outputPath, false);\n+                hdfsEnvironment.doAs(session.getUser(), () -> fileSystem.delete(outputPath, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8215f85f1a647f2c579fa4d11fe08eda35f0678", "author": {"user": {"login": "lxynov", "name": "Xingyuan Lin"}}, "url": "https://github.com/trinodb/trino/commit/b8215f85f1a647f2c579fa4d11fe08eda35f0678", "committedDate": "2020-07-28T03:24:49Z", "message": "Add Iceberg in Kerberos product tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6878f023420216d06fd100fe56b146a2abc2acff", "author": {"user": {"login": "lxynov", "name": "Xingyuan Lin"}}, "url": "https://github.com/trinodb/trino/commit/6878f023420216d06fd100fe56b146a2abc2acff", "committedDate": "2020-07-28T03:24:49Z", "message": "Fix HDFS impersonation in Iceberg Connector"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "6878f023420216d06fd100fe56b146a2abc2acff", "author": {"user": {"login": "lxynov", "name": "Xingyuan Lin"}}, "url": "https://github.com/trinodb/trino/commit/6878f023420216d06fd100fe56b146a2abc2acff", "committedDate": "2020-07-28T03:24:49Z", "message": "Fix HDFS impersonation in Iceberg Connector"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4700, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}