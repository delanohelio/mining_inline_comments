{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyMTA2ODI4", "number": 1247, "title": "dump entries that could not be deserialized into files", "bodyText": "The values are dumped when unreadbleDataDumpDirectory is set. If removeUnreadablesFromStore is true, the values are also removed from the presistent store.\n    \"storage\": {\n        ... ,\n        \"unreadbleDataDumpDirectory\":\"./storageDumps\",\n        \"removeUnreadablesFromStore\": true\n    },\nThe logs show when a value is dumped:\nINFO  [2020-06-30 17:12:41]\tc.b.c.i.x.s.SerializingStore\tMaster\tDumping value of key dataset.d10910d8-9dbf-4f9c-a63b-6b6336e228dc to /absolute/path/to/storageDumps/20200630-EXECUTIONS-dataset.d10910d8-9dbf-4f9c-a63b-6b6336e228dc.json (because it cannot be deserialized anymore).\nINFO  [2020-06-30 17:12:41]\tc.b.c.i.x.s.SerializingStore\tMaster\tWhile processing store EXECUTIONS:\n\tEntries processed:\t52\n\tKey read failure:\t0 (0,00%)\n\tValue read failure:\t1 (1,92%)\nINFO  [2020-06-30 17:12:41]\tc.b.c.i.x.s.CachedStore\tMaster\t\tloaded store cached EXECUTIONS(ManagedExecution): 51 entries, 36,8 KiB within 2.988 s", "createdAt": "2020-06-30T15:23:20Z", "url": "https://github.com/bakdata/conquery/pull/1247", "merged": true, "mergeCommit": {"oid": "9361f6c55d83a57a8996302ea457f345f0a2b360"}, "closed": true, "closedAt": "2020-07-20T07:02:13Z", "author": {"login": "thoniTUB"}, "timelineItems": {"totalCount": 39, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcw-SzdAFqTQ0MTY0MDI5NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc2rtckgH2gAyNDQyMTA2ODI4Ojg0Y2I1YzUzZTI4YzM4MTlmOTViZWQxYmIwMThmYWUxODg2ZThiODA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxNjQwMjk1", "url": "https://github.com/bakdata/conquery/pull/1247#pullrequestreview-441640295", "createdAt": "2020-07-02T12:43:01Z", "commit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMjo0MzowMVrOGsLH0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMjo0ODo1OFrOGsLVIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3Mjc1NA==", "bodyText": "kannst du das im constructor reingeben?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448972754", "createdAt": "2020-07-02T12:43:01Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -94,6 +115,22 @@ public SerializingStore(XodusStore store, Validator validator, IStoreInfo storeI\n \t\tkeyReader = Jackson.BINARY_MAPPER\n \t\t\t\t\t\t\t.readerFor(storeInfo.getKeyType())\n \t\t\t\t\t\t\t.withView(InternalOnly.class);\n+\t\t\n+\t\tremoveUnreadablesFromUnderlyingStore = ConqueryConfig.getInstance().getStorage().isRemoveUnreadablesFromStore();\n+\t\t\n+\t\t// Prepare dump directory if there is one set in the config\n+\t\tOptional<File> dumpUnreadable = ConqueryConfig.getInstance().getStorage().getUnreadbleDataDumpDirectory();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MzY0Ng==", "bodyText": "das kannst du als lokale variablen umsetzen", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448973646", "createdAt": "2020-07-02T12:44:35Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -71,6 +81,17 @@\n \t */\n \tprivate final IStoreInfo storeInfo;\n \n+\tprivate int totalProcessed = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NDc2MQ==", "bodyText": "kann mir vorstellen, dass das ganz sch\u00f6n lange logs werden. w\u00fcrde das glaube ich eher pro element einzeln loggen dann habeben wir nicht eine ewig lange zeile", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448974761", "createdAt": "2020-07-02T12:46:29Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +152,65 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n \t@Override\n \tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\ttotalProcessed = 0;\n+\t\tfailedKeys = 0;\n+\t\tfailedValues = 0;\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\ttotalProcessed++;\n \t\t\ttry {\n \t\t\t\ttry {\n \t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n \t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n+\t\t\t\t\tif(unreadableValuesDumpDir != null) {\t\t\t\t\t\t\n+\t\t\t\t\t\tdumpToFile(v, Jackson.BINARY_MAPPER.readerFor(String.class).readValue(k.getBytesUnsafe()), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\t\t\t\t\t\t\n+\t\t\t\t\t}\n+\t\t\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\t\t\tunreadables.add(k);\n+\t\t\t\t\t}\n+\t\t\t\t\tfailedValues++;\n \t\t\t\t}\n \t\t\t} catch (Exception e) {\n \t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tfailedKeys++;\n \t\t\t}\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(String.format(\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\ttotalProcessed, failedKeys,\n+\t\t\t(float) failedKeys/totalProcessed*100,\n+\t\t\tfailedValues,\n+\t\t\t(float) failedValues/totalProcessed*100));\n+\t\t\n+\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.info(\"Removing the following unreadable elements from the store {}: {}\", storeInfo.getXodusName(), unreadables.stream()\n+\t\t\t\t.map(ByteIterable::getBytesUnsafe)\n+\t\t\t\t.map(String::new)\n+\t\t\t\t.collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NTE2NA==", "bodyText": "Namen sanitizen f\u00fcr filename", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448975164", "createdAt": "2020-07-02T12:47:11Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -209,6 +290,36 @@ private ByteIterable write(Object obj, ObjectWriter writer) {\n \t\t}\n \t}\n \n+\t/**\n+\t * Dumps the content of an unreadable value to a file as a json (it tries to parse it as an object and than tries to dump it as a json).\n+\t * @param obj The object to dump.\n+\t * @param keyOfDump The key under which the unreadable value is accessible. It is used for the file name.\n+\t * @param unreadableDumpDir The director to dump to. The method assumes that the directory exists and is okay to write to.\n+\t * @param storeName The name of the store which is also used in the dump file name.\n+\t */\n+\tprivate static void dumpToFile(@NonNull ByteIterable obj, @NonNull String keyOfDump, @NonNull File unreadableDumpDir, @NonNull String storeName) {\n+\t\t// Create dump filehandle\n+\t\tFile dumpfile = new File(Path.of(unreadableDumpDir.getAbsolutePath(), String.format(\"%s-%s-%s.json\",\n+\t\t\t\tDateTimeFormatter.BASIC_ISO_DATE.format(LocalDateTime.now()),\n+\t\t\t\tstoreName,\n+\t\t\t\tkeyOfDump", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NTg4NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tlog.warn(\"Unable to dump unreadable value of key \" + keyOfDump + \" to file \" + dumpfile +\".\", e);\n          \n          \n            \n            \t\t\tlog.error(\"Unable to dump unreadable value of key `{}` to file `{}`\",keyOfDump, dumpfile, e);", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448975884", "createdAt": "2020-07-02T12:48:26Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -209,6 +290,36 @@ private ByteIterable write(Object obj, ObjectWriter writer) {\n \t\t}\n \t}\n \n+\t/**\n+\t * Dumps the content of an unreadable value to a file as a json (it tries to parse it as an object and than tries to dump it as a json).\n+\t * @param obj The object to dump.\n+\t * @param keyOfDump The key under which the unreadable value is accessible. It is used for the file name.\n+\t * @param unreadableDumpDir The director to dump to. The method assumes that the directory exists and is okay to write to.\n+\t * @param storeName The name of the store which is also used in the dump file name.\n+\t */\n+\tprivate static void dumpToFile(@NonNull ByteIterable obj, @NonNull String keyOfDump, @NonNull File unreadableDumpDir, @NonNull String storeName) {\n+\t\t// Create dump filehandle\n+\t\tFile dumpfile = new File(Path.of(unreadableDumpDir.getAbsolutePath(), String.format(\"%s-%s-%s.json\",\n+\t\t\t\tDateTimeFormatter.BASIC_ISO_DATE.format(LocalDateTime.now()),\n+\t\t\t\tstoreName,\n+\t\t\t\tkeyOfDump\n+\t\t\t\t)\n+\t\t\t).toString());\n+\t\tif(dumpfile.exists()) {\n+\t\t\tlog.warn(\"Abort dumping of file {} because it already exists.\",dumpfile);\n+\t\t\treturn;\n+\t\t}\n+\t\t// Write dump\n+\t\ttry {\n+\t\t\tlog.info(\"Dumping value of key {} to {} (because it cannot be deserialized anymore).\", keyOfDump, dumpfile.getCanonicalPath());\n+\t\t\tJsonNode dump = Jackson.BINARY_MAPPER.readerFor(JsonNode.class).readValue(obj.getBytesUnsafe(), 0, obj.getLength());\n+\t\t\tJackson.MAPPER.writer().writeValue(dumpfile, dump);\n+\t\t}\n+\t\tcatch (IOException e) {\n+\t\t\tlog.warn(\"Unable to dump unreadable value of key \" + keyOfDump + \" to file \" + dumpfile +\".\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NjE2MQ==", "bodyText": "reicht null nicht?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r448976161", "createdAt": "2020-07-02T12:48:58Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/config/StorageConfig.java", "diffHunk": "@@ -21,4 +23,14 @@\n \tprivate boolean useWeakDictionaryCaching = true;\n \t@NotNull\n \tprivate Duration weakCacheDuration = Duration.hours(48);\n+\t\n+\t/**\n+\t * Flag for the {@link SerializingStore} whether to delete values from the underlying store, that cannot be mapped to an object anymore.\n+\t */\n+\tprivate boolean removeUnreadablesFromStore = false;\n+\t\n+\t/**\n+\t * When set, all values that could not be deserialized from the persistent store, are dump into individual files.\n+\t */\n+\tprivate Optional<File> unreadbleDataDumpDirectory = Optional.empty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6de402e728ed3f6bdd6f793503248bf5ce8517de"}, "originalPosition": 26}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43afcddbc171830970c89db36b82547a6490d416", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/43afcddbc171830970c89db36b82547a6490d416", "committedDate": "2020-07-16T14:34:50Z", "message": "dump entries that could not be deserialized to file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ece07c940c95fc63a8ce55b162968fbb45ce4709", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/ece07c940c95fc63a8ce55b162968fbb45ce4709", "committedDate": "2020-07-16T14:35:41Z", "message": "set config parameter default value"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40905fb3fed450d1c5a9c5793af5493002281a1b", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/40905fb3fed450d1c5a9c5793af5493002281a1b", "committedDate": "2020-07-16T14:35:41Z", "message": "add comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12b3c2109d7d3526cebfa77566afe106d53fac3c", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/12b3c2109d7d3526cebfa77566afe106d53fac3c", "committedDate": "2020-07-16T14:35:43Z", "message": "adds option to delete unreadble values from store"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a276e50cfd6c15213e11059e30b106ee67da36a1", "author": {"user": {"login": "bakdata-bot", "name": null}}, "url": "https://github.com/bakdata/conquery/commit/a276e50cfd6c15213e11059e30b106ee67da36a1", "committedDate": "2020-07-16T14:36:02Z", "message": "automatic update to docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df87eb6e40d1f7b100e7419258fb88ff7cf30158", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/df87eb6e40d1f7b100e7419258fb88ff7cf30158", "committedDate": "2020-07-16T14:36:04Z", "message": "adds null return value when getting an deleted value"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89d7b80b5f67e9a5c79f4e9817edda390f2bbcd4", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/89d7b80b5f67e9a5c79f4e9817edda390f2bbcd4", "committedDate": "2020-07-16T14:36:05Z", "message": "makes dump funtion static"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "868b20ed31eae8800b26586f3cf616eb9dd34b74", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/868b20ed31eae8800b26586f3cf616eb9dd34b74", "committedDate": "2020-07-16T14:36:05Z", "message": "adds missings method signature changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee05c2c24879aed79ef67f07a04eb2ef0e02031f", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/ee05c2c24879aed79ef67f07a04eb2ef0e02031f", "committedDate": "2020-07-16T14:36:06Z", "message": "Update backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java\n\nCo-authored-by: awildturtok <1553491+awildturtok@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78debfebc49298e281d3992f67c1de6a6dff1fed", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/78debfebc49298e281d3992f67c1de6a6dff1fed", "committedDate": "2020-07-16T14:36:06Z", "message": "sanitize dumpfilename"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdedb2404d02057fb2f10d8095c233a2058b2a30", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/bdedb2404d02057fb2f10d8095c233a2058b2a30", "committedDate": "2020-07-16T14:36:26Z", "message": "removes unnecessary function parameter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c766fa9777e9468f229ebebcc10028156c72f086", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/c766fa9777e9468f229ebebcc10028156c72f086", "committedDate": "2020-07-16T14:36:26Z", "message": "adds test for corrupted values"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32216f71c9c06ffcc0a88264571a90d596503915", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/32216f71c9c06ffcc0a88264571a90d596503915", "committedDate": "2020-07-16T14:36:27Z", "message": "applies split phase to for-each and adds test for corrupt keys."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90f99b2f34f811cad1695feb4eb525a4217506ed", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/90f99b2f34f811cad1695feb4eb525a4217506ed", "committedDate": "2020-07-16T14:36:27Z", "message": "adds test test for removal of corrupt entries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86253b586f4da9f26fe2c4c31c62dbac4a44a90d", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/86253b586f4da9f26fe2c4c31c62dbac4a44a90d", "committedDate": "2020-07-16T14:36:28Z", "message": "tests removal of key and value corrupted entries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c04d1d5efb376ca2f494e9b90fc25ab684bbf800", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/c04d1d5efb376ca2f494e9b90fc25ab684bbf800", "committedDate": "2020-07-16T14:36:29Z", "message": "clean up the test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "840e9eee470f82fb9211f4ca3edf0cf5adf2f5ac", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/840e9eee470f82fb9211f4ca3edf0cf5adf2f5ac", "committedDate": "2020-07-16T14:36:30Z", "message": "also test the content auf the dumpfile to be correct"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ba11eb793a38464c1a4c4cb1bcb66f75aec516d", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/9ba11eb793a38464c1a4c4cb1bcb66f75aec516d", "committedDate": "2020-07-16T14:36:30Z", "message": "shortens log info"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5aeb8e2e48dcefeb9a663cebd59bfc470382ecba", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/5aeb8e2e48dcefeb9a663cebd59bfc470382ecba", "committedDate": "2020-07-16T14:36:31Z", "message": "bubble storage config up to not use the global singleton"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "104bdd98bdb635b0c0f8a2a72b371a08ac547b94", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/104bdd98bdb635b0c0f8a2a72b371a08ac547b94", "committedDate": "2020-07-16T14:32:19Z", "message": "bubble storage config up to not use the global singleton"}, "afterCommit": {"oid": "5aeb8e2e48dcefeb9a663cebd59bfc470382ecba", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/5aeb8e2e48dcefeb9a663cebd59bfc470382ecba", "committedDate": "2020-07-16T14:36:31Z", "message": "bubble storage config up to not use the global singleton"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2568b35229fe379fae7276de8fe3035b09a52360", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/2568b35229fe379fae7276de8fe3035b09a52360", "committedDate": "2020-07-16T14:37:31Z", "message": "Merge 5aeb8e2e48dcefeb9a663cebd59bfc470382ecba into 1a6db33c8864ca4c173045d6dd32b0bcbfab4780"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9", "author": {"user": {"login": "bakdata-bot", "name": null}}, "url": "https://github.com/bakdata/conquery/commit/3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9", "committedDate": "2020-07-16T14:39:10Z", "message": "automatic update to docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNDgyOTIw", "url": "https://github.com/bakdata/conquery/pull/1247#pullrequestreview-450482920", "createdAt": "2020-07-17T08:47:36Z", "commit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODo0NzozNlrOGzK2Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODo1NDowN1rOGzLD1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMwODI4Ng==", "bodyText": "Finde ich in get fragw\u00fcrdig weil du dann theoretisch immer IO im hauptpfad hast", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456308286", "createdAt": "2020-07-17T08:47:36Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +151,90 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMwODg4NQ==", "bodyText": "Das du da den BinaryMaper verwendest sieht mir falsch aus. reicht es nicht die Daten einfach zu dumpen?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456308885", "createdAt": "2020-07-17T08:48:42Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +151,90 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationResult forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationResult result = new IterationResult();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = null;\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n+\t\t\t\tkey = readKey(k);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\tdumpToFile(v, Jackson.BINARY_MAPPER.readerFor(String.class).readValue(k.getBytesUnsafe()), unreadableValuesDumpDir, storeInfo.getXodusName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMwOTU3Ng==", "bodyText": "Refactor mal den ganzen Try-Catch Block in eine Funtion die eine Deserialisierende Funktion bekommt und einen Wert rausgibt, dann sparst du dir redundanz und aufgebl\u00e4hten code", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456309576", "createdAt": "2020-07-17T08:49:57Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +151,90 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationResult forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationResult result = new IterationResult();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = null;\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n+\t\t\t\tkey = readKey(k);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMwOTk1OQ==", "bodyText": "das if kannst du dir hier sparen weil du hier ja nur collectest", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456309959", "createdAt": "2020-07-17T08:50:40Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +151,90 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationResult forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationResult result = new IterationResult();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = null;\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n+\t\t\t\tkey = readKey(k);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\tdumpToFile(v, Jackson.BINARY_MAPPER.readerFor(String.class).readValue(k.getBytesUnsafe()), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t\t\t}\n+\t\t\t\t\tcatch (IOException e1) {\n+\t\t\t\t\t\tlog.warn(\"Cannot dump value for key (Bytes {}) to file because the key could not be parsed to in to a String\", k.toString());\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n \t\t\t\t}\n+\t\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\t\tunreadables.add(k);\n+\t\t\t\t}\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\t\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = null;\n+\t\t\ttry {\n+\t\t\t\tvalue = readValue(v);\n \t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\t\tdumpToFile(v, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t\t} else {\n+\t\t\t\t\tlog.warn(\"Could not parse value for key \" + key, e);\t\t\t\t\t\t\n+\t\t\t\t}\n+\t\t\t\tif(removeUnreadablesFromUnderlyingStore) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxMDEzMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tlog.info(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());\n          \n          \n            \n            \t\t\tlog.warn(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456310130", "createdAt": "2020-07-17T08:50:56Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +151,90 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationResult forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationResult result = new IterationResult();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = null;\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n+\t\t\t\tkey = readKey(k);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\tdumpToFile(v, Jackson.BINARY_MAPPER.readerFor(String.class).readValue(k.getBytesUnsafe()), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t\t\t}\n+\t\t\t\t\tcatch (IOException e1) {\n+\t\t\t\t\t\tlog.warn(\"Cannot dump value for key (Bytes {}) to file because the key could not be parsed to in to a String\", k.toString());\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n \t\t\t\t}\n+\t\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\t\tunreadables.add(k);\n+\t\t\t\t}\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\t\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = null;\n+\t\t\ttry {\n+\t\t\t\tvalue = readValue(v);\n \t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\t\tdumpToFile(v, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t\t} else {\n+\t\t\t\t\tlog.warn(\"Could not parse value for key \" + key, e);\t\t\t\t\t\t\n+\t\t\t\t}\n+\t\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\t\tunreadables.add(k);\n+\t\t\t\t}\n+\t\t\t\tresult.incrFailedValues();\n+\t\t\t\treturn;\n \t\t\t}\n+\t\t\t\n+\t\t\t// Apply the conusmer to key and value\n+\t\t\ttry {\n+\t\t\t\tconsumer.accept(key, value, v.getLength());\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tlog.warn(\"Unable to apply for-each consumer on key[{}]\", key, e);\n+\t\t\t}\n+\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(String.format(\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\tresult.getTotalProcessed(), result.getFailedKeys(),\n+\t\t\t(float) result.getFailedKeys()/result.getTotalProcessed()*100,\n+\t\t\tresult.getFailedValues(),\n+\t\t\t(float) result.getFailedValues()/result.getTotalProcessed()*100));\n+\t\t\n+\t\t// Remove corrupted entries from the store if configured so\n+\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.info(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxMDMzNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tlog.trace(\"Removing value to key {} from store\", key, storeInfo.getXodusName());\n          \n          \n            \n            \t\tlog.trace(\"Removing value to key {} from Store[{}]\", key, storeInfo.getXodusName());", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456310337", "createdAt": "2020-07-17T08:51:22Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -148,6 +252,7 @@ public void update(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic void remove(KEY key) {\n+\t\tlog.trace(\"Removing value to key {} from store\", key, storeInfo.getXodusName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxMDc5NA==", "bodyText": "W\u00e4re glaube ich auch Sinnvoller alles in eine Datei zu schreiben/appenden, dann sparst du dir IO und File Handles.", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456310794", "createdAt": "2020-07-17T08:52:13Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -209,6 +314,44 @@ private ByteIterable write(Object obj, ObjectWriter writer) {\n \t\t}\n \t}\n \n+\t/**\n+\t * Dumps the content of an unreadable value to a file as a json (it tries to parse it as an object and than tries to dump it as a json).\n+\t * @param obj The object to dump.\n+\t * @param keyOfDump The key under which the unreadable value is accessible. It is used for the file name.\n+\t * @param unreadableDumpDir The director to dump to. The method assumes that the directory exists and is okay to write to.\n+\t * @param storeName The name of the store which is also used in the dump file name.\n+\t */\n+\tprivate static void dumpToFile(@NonNull ByteIterable obj, @NonNull String keyOfDump, @NonNull File unreadableDumpDir, @NonNull String storeName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxMTc2NA==", "bodyText": "https://stackoverflow.com/a/15075907/409761", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456311764", "createdAt": "2020-07-17T08:54:07Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -209,6 +314,44 @@ private ByteIterable write(Object obj, ObjectWriter writer) {\n \t\t}\n \t}\n \n+\t/**\n+\t * Dumps the content of an unreadable value to a file as a json (it tries to parse it as an object and than tries to dump it as a json).\n+\t * @param obj The object to dump.\n+\t * @param keyOfDump The key under which the unreadable value is accessible. It is used for the file name.\n+\t * @param unreadableDumpDir The director to dump to. The method assumes that the directory exists and is okay to write to.\n+\t * @param storeName The name of the store which is also used in the dump file name.\n+\t */\n+\tprivate static void dumpToFile(@NonNull ByteIterable obj, @NonNull String keyOfDump, @NonNull File unreadableDumpDir, @NonNull String storeName) {\n+\t\t// Create dump filehandle\n+\t\tFile dumpfile = new File(unreadableDumpDir, makeDumpfileName(keyOfDump, storeName));\n+\t\tif(dumpfile.exists()) {\n+\t\t\tlog.warn(\"Abort dumping of file {} because it already exists.\",dumpfile);\n+\t\t\treturn;\n+\t\t}\n+\t\t// Write dump\n+\t\ttry {\n+\t\t\tlog.info(\"Dumping value of key {} to {} (because it cannot be deserialized anymore).\", keyOfDump, dumpfile.getCanonicalPath());\n+\t\t\tJsonNode dump = Jackson.BINARY_MAPPER.readerFor(JsonNode.class).readValue(obj.getBytesUnsafe(), 0, obj.getLength());\n+\t\t\tJackson.MAPPER.writer().writeValue(dumpfile, dump);\n+\t\t}\n+\t\tcatch (IOException e) {\n+\t\t\tlog.error(\"Unable to dump unreadable value of key `{}` to file `{}`\",keyOfDump, dumpfile, e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Generates a valid file name from the key of the dump object, the store and the current time.\n+\t * However, it does not ensure that there is no file with such a name.\n+\t */\n+\tprivate static String makeDumpfileName(String keyOfDump, String storeName) {\n+\t\treturn String.format(\"%s-%s-%s.%s\",\n+\t\t\tDateTimeFormatter.BASIC_ISO_DATE.format(LocalDateTime.now()),\n+\t\t\tstoreName,\n+\t\t\tkeyOfDump,\n+\t\t\tDUMP_FILE_EXTENTION\n+\t\t\t).replaceAll(\"[\\\\\\\\/:*?\\\"<>|]\", \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3da3ca60bc214ce77a1e1d0d6d74a2aad55dd4b9"}, "originalPosition": 228}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb2e9c601db55683af7525e398623c6a6fe1bb9d", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/fb2e9c601db55683af7525e398623c6a6fe1bb9d", "committedDate": "2020-07-17T11:15:00Z", "message": "Update backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java\n\nCo-authored-by: awildturtok <1553491+awildturtok@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe8a96fa5955a909533e70bdd9ada4917ca3fb38", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/fe8a96fa5955a909533e70bdd9ada4917ca3fb38", "committedDate": "2020-07-17T11:15:32Z", "message": "Update backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java\n\nCo-authored-by: awildturtok <1553491+awildturtok@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd14e7d178e972736ca317e157228eea46e180b2", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/bd14e7d178e972736ca317e157228eea46e180b2", "committedDate": "2020-07-17T11:51:06Z", "message": "change sanitizer statement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68f76b37a2e4b681d5bb946efbb720e2e924a0cf", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/68f76b37a2e4b681d5bb946efbb720e2e924a0cf", "committedDate": "2020-07-17T11:54:34Z", "message": "remove unnecessary ifs for collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f8b309ea8b932a096105b227ddd48b257a7c19e", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/7f8b309ea8b932a096105b227ddd48b257a7c19e", "committedDate": "2020-07-17T12:26:51Z", "message": "extracts method for deserialization"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82ec48ee07b0259ec924c2c89db610446bdc6b3a", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/82ec48ee07b0259ec924c2c89db610446bdc6b3a", "committedDate": "2020-07-17T12:44:13Z", "message": "extracts dumping into deserialization method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b069cbdfd6f691d4fde2d997189d3304c83a5620", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/b069cbdfd6f691d4fde2d997189d3304c83a5620", "committedDate": "2020-07-17T12:52:58Z", "message": "compiles the regex once"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/0b97152388bee6773ae9b50f23a0271cc3d1b520", "committedDate": "2020-07-17T12:55:28Z", "message": "Merge branch 'develop' into feature/dump-entries-that-could-not-be-deserialized"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2dca2869f2c11f75d194d10b66a5be08706a494e", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/2dca2869f2c11f75d194d10b66a5be08706a494e", "committedDate": "2020-07-17T13:10:22Z", "message": "surpress NaN output"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNjQ0NzU0", "url": "https://github.com/bakdata/conquery/pull/1247#pullrequestreview-450644754", "createdAt": "2020-07-17T13:12:23Z", "commit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMzoxMjoyNFrOGzScSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxMzoyMDowNFrOGzSsmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzMjcxNA==", "bodyText": "Ist das nicht sogar komplett statisch?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456432714", "createdAt": "2020-07-17T13:12:24Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +155,100 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n+\t/**\n+\t * Iterates a given consumer over the entries of this store.\n+\t * Depending on the {@link StorageConfig} corrupt entries may be dump to a file and/or removed from the store.\n+\t * These entries are not submitted to the consumer.\n+\t */\n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationStatistic forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationStatistic result = new IterationStatistic();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = getDeserializedAndDumpFailed(\n+\t\t\t\tk,\n+\t\t\t\tthis::readKey,\n+\t\t\t\t() -> new String(k.getBytesUnsafe()),\n+\t\t\t\tv,\n+\t\t\t\t\"Could not parse key [{}]\");\n+\t\t\tif (key == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = getDeserializedAndDumpFailed(\n+\t\t\t\tv, \n+\t\t\t\tthis::readValue, \n+\t\t\t\t() -> key.toString(),\n+\t\t\t\tv, \n+\t\t\t\t\"Could not parse value for key [{}]\");\n+\t\t\tif (value == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedValues();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Apply the conusmer to key and value\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n-\t\t\t\t}\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tconsumer.accept(key, value, v.getLength());\n+\t\t\t}\n+\t\t\tcatch (Exception e) {\n+\t\t\t\tlog.warn(\"Unable to apply for-each consumer on key[{}]\", key, e);\n \t\t\t}\n+\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(\n+\t\t\tString.format(\n+\t\t\t\t\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\t\tresult.getTotalProcessed(),\n+\t\t\t\tresult.getFailedKeys(),\n+\t\t\t\t(float) result.getFailedKeys() / result.getTotalProcessed() * 100,\n+\t\t\t\tresult.getFailedValues(),\n+\t\t\t\t(float) result.getFailedValues() / result.getTotalProcessed() * 100));\n+\n+\t\t// Remove corrupted entries from the store if configured so\n+\t\tif (removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.warn(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());\n+\t\t\tunreadables.forEach(store::remove);\n+\t\t}\n+\t\treturn result;\n+\t}\n+\t\n+\tprivate <TYPE> TYPE getDeserializedAndDumpFailed(ByteIterable serial, Function<ByteIterable, TYPE> deserializer, Supplier<String> onFailKeyStringSupplier, ByteIterable onFailOrigValue, String onFailWarnMsgFmt ){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzNDAwMg==", "bodyText": "Sollte das nicht immer warnen?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456434002", "createdAt": "2020-07-17T13:14:42Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +155,100 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n+\t/**\n+\t * Iterates a given consumer over the entries of this store.\n+\t * Depending on the {@link StorageConfig} corrupt entries may be dump to a file and/or removed from the store.\n+\t * These entries are not submitted to the consumer.\n+\t */\n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationStatistic forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationStatistic result = new IterationStatistic();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = getDeserializedAndDumpFailed(\n+\t\t\t\tk,\n+\t\t\t\tthis::readKey,\n+\t\t\t\t() -> new String(k.getBytesUnsafe()),\n+\t\t\t\tv,\n+\t\t\t\t\"Could not parse key [{}]\");\n+\t\t\tif (key == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = getDeserializedAndDumpFailed(\n+\t\t\t\tv, \n+\t\t\t\tthis::readValue, \n+\t\t\t\t() -> key.toString(),\n+\t\t\t\tv, \n+\t\t\t\t\"Could not parse value for key [{}]\");\n+\t\t\tif (value == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedValues();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Apply the conusmer to key and value\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n-\t\t\t\t}\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tconsumer.accept(key, value, v.getLength());\n+\t\t\t}\n+\t\t\tcatch (Exception e) {\n+\t\t\t\tlog.warn(\"Unable to apply for-each consumer on key[{}]\", key, e);\n \t\t\t}\n+\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(\n+\t\t\tString.format(\n+\t\t\t\t\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\t\tresult.getTotalProcessed(),\n+\t\t\t\tresult.getFailedKeys(),\n+\t\t\t\t(float) result.getFailedKeys() / result.getTotalProcessed() * 100,\n+\t\t\t\tresult.getFailedValues(),\n+\t\t\t\t(float) result.getFailedValues() / result.getTotalProcessed() * 100));\n+\n+\t\t// Remove corrupted entries from the store if configured so\n+\t\tif (removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.warn(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());\n+\t\t\tunreadables.forEach(store::remove);\n+\t\t}\n+\t\treturn result;\n+\t}\n+\t\n+\tprivate <TYPE> TYPE getDeserializedAndDumpFailed(ByteIterable serial, Function<ByteIterable, TYPE> deserializer, Supplier<String> onFailKeyStringSupplier, ByteIterable onFailOrigValue, String onFailWarnMsgFmt ){\n+\t\ttry {\n+\t\t\treturn deserializer.apply(serial);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(onFailOrigValue, onFailKeyStringSupplier.get(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t} else {\n+\t\t\t\tlog.warn(onFailWarnMsgFmt, onFailKeyStringSupplier.get(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzNDE0Ng==", "bodyText": "Sonst wei\u00dft du ja gar nicht sicher, dass es was gedumpt hat?", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456434146", "createdAt": "2020-07-17T13:14:56Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +155,100 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n+\t/**\n+\t * Iterates a given consumer over the entries of this store.\n+\t * Depending on the {@link StorageConfig} corrupt entries may be dump to a file and/or removed from the store.\n+\t * These entries are not submitted to the consumer.\n+\t */\n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationStatistic forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationStatistic result = new IterationStatistic();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = getDeserializedAndDumpFailed(\n+\t\t\t\tk,\n+\t\t\t\tthis::readKey,\n+\t\t\t\t() -> new String(k.getBytesUnsafe()),\n+\t\t\t\tv,\n+\t\t\t\t\"Could not parse key [{}]\");\n+\t\t\tif (key == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = getDeserializedAndDumpFailed(\n+\t\t\t\tv, \n+\t\t\t\tthis::readValue, \n+\t\t\t\t() -> key.toString(),\n+\t\t\t\tv, \n+\t\t\t\t\"Could not parse value for key [{}]\");\n+\t\t\tif (value == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedValues();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Apply the conusmer to key and value\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n-\t\t\t\t}\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tconsumer.accept(key, value, v.getLength());\n+\t\t\t}\n+\t\t\tcatch (Exception e) {\n+\t\t\t\tlog.warn(\"Unable to apply for-each consumer on key[{}]\", key, e);\n \t\t\t}\n+\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(\n+\t\t\tString.format(\n+\t\t\t\t\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\t\tresult.getTotalProcessed(),\n+\t\t\t\tresult.getFailedKeys(),\n+\t\t\t\t(float) result.getFailedKeys() / result.getTotalProcessed() * 100,\n+\t\t\t\tresult.getFailedValues(),\n+\t\t\t\t(float) result.getFailedValues() / result.getTotalProcessed() * 100));\n+\n+\t\t// Remove corrupted entries from the store if configured so\n+\t\tif (removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.warn(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());\n+\t\t\tunreadables.forEach(store::remove);\n+\t\t}\n+\t\treturn result;\n+\t}\n+\t\n+\tprivate <TYPE> TYPE getDeserializedAndDumpFailed(ByteIterable serial, Function<ByteIterable, TYPE> deserializer, Supplier<String> onFailKeyStringSupplier, ByteIterable onFailOrigValue, String onFailWarnMsgFmt ){\n+\t\ttry {\n+\t\t\treturn deserializer.apply(serial);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(onFailOrigValue, onFailKeyStringSupplier.get(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t} else {\n+\t\t\t\tlog.warn(onFailWarnMsgFmt, onFailKeyStringSupplier.get(), e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzNDAwMg=="}, "originalCommit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzNDQ0Ng==", "bodyText": "hier fehlt etwas doku aber brauchst es nicht \u00fcbertreiben intention reicht", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456434446", "createdAt": "2020-07-17T13:15:28Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/stores/SerializingStore.java", "diffHunk": "@@ -115,22 +155,100 @@ public void add(KEY key, VALUE value) throws JSONException {\n \n \t@Override\n \tpublic VALUE get(KEY key) {\n-\t\treturn readValue(store.get(writeKey(key)));\n+\t\tByteIterable binValue = store.get(writeKey(key));\n+\t\ttry {\n+\t\t\treturn readValue(binValue);\t\t\t\n+\t\t} catch (Exception e) {\n+\t\t\tif(unreadableValuesDumpDir != null) {\n+\t\t\t\tdumpToFile(binValue, key.toString(), unreadableValuesDumpDir, storeInfo.getXodusName());\n+\t\t\t}\n+\t\t\tif(removeUnreadablesFromUnderlyingStore) {\n+\t\t\t\tremove(key);\n+\t\t\t\t// Null seems to be an acceptable return value in this case\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tThrowables.throwIfUnchecked(e);\n+\t\t\tthrow new RuntimeException(e);\n+\t\t}\n \t}\n \n+\t/**\n+\t * Iterates a given consumer over the entries of this store.\n+\t * Depending on the {@link StorageConfig} corrupt entries may be dump to a file and/or removed from the store.\n+\t * These entries are not submitted to the consumer.\n+\t */\n \t@Override\n-\tpublic void forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\tpublic IterationStatistic forEach(StoreEntryConsumer<KEY, VALUE> consumer) {\n+\t\tIterationStatistic result = new IterationStatistic();\n+\t\tArrayList<ByteIterable> unreadables = new ArrayList<>();\n \t\tstore.forEach((k, v) -> {\n+\t\t\tresult.incrTotalProcessed();\n+\n+\t\t\t// Try to read the key first\n+\t\t\tKEY key = getDeserializedAndDumpFailed(\n+\t\t\t\tk,\n+\t\t\t\tthis::readKey,\n+\t\t\t\t() -> new String(k.getBytesUnsafe()),\n+\t\t\t\tv,\n+\t\t\t\t\"Could not parse key [{}]\");\n+\t\t\tif (key == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedKeys();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Try to read the value\n+\t\t\tVALUE value = getDeserializedAndDumpFailed(\n+\t\t\t\tv, \n+\t\t\t\tthis::readValue, \n+\t\t\t\t() -> key.toString(),\n+\t\t\t\tv, \n+\t\t\t\t\"Could not parse value for key [{}]\");\n+\t\t\tif (value == null) {\n+\t\t\t\tunreadables.add(k);\n+\t\t\t\tresult.incrFailedValues();\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// Apply the conusmer to key and value\n \t\t\ttry {\n-\t\t\t\ttry {\n-\t\t\t\t\tconsumer.accept(readKey(k), readValue(v), v.getLength());\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tlog.warn(\"Could not parse value for key \" + readKey(k), e);\n-\t\t\t\t}\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tlog.warn(\"Could not parse key \" + k, e);\n+\t\t\t\tconsumer.accept(key, value, v.getLength());\n+\t\t\t}\n+\t\t\tcatch (Exception e) {\n+\t\t\t\tlog.warn(\"Unable to apply for-each consumer on key[{}]\", key, e);\n \t\t\t}\n+\n \t\t});\n+\t\t// Print some statistics\n+\t\tlog.info(\n+\t\t\tString.format(\n+\t\t\t\t\"While processing store %s:\\n\\tEntries processed:\\t%d\\n\\tKey read failure:\\t%d (%.2f%%)\\n\\tValue read failure:\\t%d (%.2f%%)\",\n+\t\t\t\tthis.storeInfo.getXodusName(),\n+\t\t\t\tresult.getTotalProcessed(),\n+\t\t\t\tresult.getFailedKeys(),\n+\t\t\t\t(float) result.getFailedKeys() / result.getTotalProcessed() * 100,\n+\t\t\t\tresult.getFailedValues(),\n+\t\t\t\t(float) result.getFailedValues() / result.getTotalProcessed() * 100));\n+\n+\t\t// Remove corrupted entries from the store if configured so\n+\t\tif (removeUnreadablesFromUnderlyingStore) {\n+\t\t\tlog.warn(\"Removing {} unreadable elements from the store {}.\", unreadables.size(), storeInfo.getXodusName());\n+\t\t\tunreadables.forEach(store::remove);\n+\t\t}\n+\t\treturn result;\n+\t}\n+\t\n+\tprivate <TYPE> TYPE getDeserializedAndDumpFailed(ByteIterable serial, Function<ByteIterable, TYPE> deserializer, Supplier<String> onFailKeyStringSupplier, ByteIterable onFailOrigValue, String onFailWarnMsgFmt ){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQzNjg5MA==", "bodyText": "Das nimmt auch ein Lambda wie in PreprocessorCommand: listFiles(((dir, name) -> name.endsWith(ConqueryConstants.EXTENSION_DESCRIPTION)));", "url": "https://github.com/bakdata/conquery/pull/1247#discussion_r456436890", "createdAt": "2020-07-17T13:20:04Z", "author": {"login": "awildturtok"}, "path": "backend/src/test/java/com/bakdata/conquery/io/xodus/stores/SerializingStoreDumpTest.java", "diffHunk": "@@ -0,0 +1,216 @@\n+package com.bakdata.conquery.io.xodus.stores;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.File;\n+import java.io.FileFilter;\n+import java.io.IOException;\n+import java.util.Optional;\n+import java.util.UUID;\n+\n+import javax.validation.Validator;\n+\n+import com.bakdata.conquery.apiv1.QueryDescription;\n+import com.bakdata.conquery.io.jackson.Jackson;\n+import com.bakdata.conquery.io.xodus.StoreInfo;\n+import com.bakdata.conquery.io.xodus.stores.SerializingStore.IterationStatistic;\n+import com.bakdata.conquery.models.auth.entities.User;\n+import com.bakdata.conquery.models.config.StorageConfig;\n+import com.bakdata.conquery.models.exceptions.JSONException;\n+import com.bakdata.conquery.models.identifiable.ids.specific.DatasetId;\n+import com.bakdata.conquery.models.identifiable.ids.specific.ManagedExecutionId;\n+import com.bakdata.conquery.models.identifiable.ids.specific.UserId;\n+import com.bakdata.conquery.models.query.concept.ConceptQuery;\n+import com.bakdata.conquery.models.query.concept.specific.CQReusedQuery;\n+import com.google.common.io.Files;\n+import io.dropwizard.jersey.validation.Validators;\n+import jetbrains.exodus.env.Environment;\n+import jetbrains.exodus.env.Environments;\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.io.FileUtils;\n+import org.assertj.core.api.Condition;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+@Slf4j\n+public class SerializingStoreDumpTest {\n+\n+\tprivate File tmpDir;\n+\tprivate Environment env;\n+\tprivate StorageConfig config;\n+\t\n+\t// Test data\n+\tprivate final ConceptQuery cQuery = new ConceptQuery(new CQReusedQuery(new ManagedExecutionId(new DatasetId(\"testD\"), UUID.randomUUID())));\n+\tprivate final User user = new User(\"username\",\"userlabel\");\n+\t\n+\t@BeforeEach\n+\tpublic void init() {\n+\t\ttmpDir = Files.createTempDir();\n+\t\tenv = Environments.newInstance(tmpDir);\n+\t\tconfig = new StorageConfig();\n+\t}\n+\t\n+\t@AfterEach\n+\tpublic void destroy() throws IOException {\n+\t\tenv.close();\n+\t\tFileUtils.deleteDirectory(tmpDir);\n+\t}\n+\t\n+\tprivate <KEY, VALUE> SerializingStore<KEY, VALUE> createSerializedStore(StorageConfig config, Environment environment, Validator validator, IStoreInfo storeId) {\n+\t\treturn new SerializingStore<>(config, new XodusStore(environment, storeId), validator, storeId);\n+\t}\n+\t\n+\t/**\n+\t * Tests if entries with corrupted values are dumped.\n+\t */\n+\t@Test\n+\tpublic void testCorruptValueDump() throws JSONException, IOException {\n+\t\t// Set dump directory to this tests temp-dir\n+\t\tconfig.setUnreadbleDataDumpDirectory(Optional.of(tmpDir));\n+\t\t\n+\t\t// Open a store and insert a valid key-value pair (UserId & User)\n+\t\ttry (SerializingStore<UserId, User> store = createSerializedStore(config, env, Validators.newValidator(), StoreInfo.AUTH_USER)){\n+\t\t\tstore.add(user.getId(), user);\n+\t\t}\n+\t\t\n+\t\t// Open that store again, with a different config to insert a corrupt entry (UserId & ManagedQuery)\t\t\n+\t\ttry (SerializingStore<UserId, QueryDescription> store = createSerializedStore(config, env, Validators.newValidator(), new CorruptableStoreInfo(StoreInfo.AUTH_USER.getXodusName(), UserId.class, QueryDescription.class))){\n+\t\t\tstore.add(new UserId(\"testU2\"), cQuery);\n+\t\t}\n+\t\t\n+\t\t// Reopen the store with the initial value and try to iterate over all entries (this triggers the dump or removal of invalid entries)\n+\t\ttry (SerializingStore<UserId, User> store = createSerializedStore(config, env, Validators.newValidator(), StoreInfo.AUTH_USER)){\n+\t\t\tIterationStatistic expectedResult = new IterationStatistic();\n+\t\t\texpectedResult.setTotalProcessed(2);\n+\t\t\texpectedResult.setFailedKeys(0);\n+\t\t\texpectedResult.setFailedValues(1);\n+\t\t\t\n+\t\t\t// Iterate (do nothing with the entries themselves)\n+\t\t\tIterationStatistic result = store.forEach((k,v,s) -> {});\n+\t\t\tassertThat(result).isEqualTo(expectedResult);\n+\t\t}\n+\t\t\n+\t\t// Test if the correct number of dumpfiles was generated\n+\t\tCondition<File> dumpFileCond = new Condition<>(f -> f.getName().endsWith(SerializingStore.DUMP_FILE_EXTENTION) , \"dump file\");\n+\t\tassertThat(tmpDir.listFiles()).areExactly(1, dumpFileCond);\n+\t\t\n+\t\t// Test if the dump is correct\n+\t\tFile dumpFile = getDumpFile(dumpFileCond);\n+\n+\t\tassertThat((QueryDescription) Jackson.MAPPER.readerFor(QueryDescription.class).readValue(dumpFile)).isEqualTo(cQuery);\n+\t}\n+\n+\tprivate File getDumpFile(Condition<File> dumpFileCond) {\n+\t\tFile dumpFile = tmpDir.listFiles(new FileFilter() {\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean accept(File pathname) {\n+\t\t\t\treturn dumpFileCond.matches(pathname);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b97152388bee6773ae9b50f23a0271cc3d1b520"}, "originalPosition": 111}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "168d1a20947aee5b371327ff8b0ad3873f32d7b9", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/168d1a20947aee5b371327ff8b0ad3873f32d7b9", "committedDate": "2020-07-17T14:12:20Z", "message": "review changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d4dae536c80426410ba821a49c29499c42545ca", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/6d4dae536c80426410ba821a49c29499c42545ca", "committedDate": "2020-07-17T14:20:33Z", "message": "Merge branch 'develop' into feature/dump-entries-that-could-not-be-deserialized"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c48d2a030120bf92d1eb7f5aeb3dded2acbdf7b1", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/c48d2a030120bf92d1eb7f5aeb3dded2acbdf7b1", "committedDate": "2020-07-17T15:08:09Z", "message": "Merge branch 'develop' into feature/dump-entries-that-could-not-be-deserialized"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNzUxMjQx", "url": "https://github.com/bakdata/conquery/pull/1247#pullrequestreview-450751241", "createdAt": "2020-07-17T15:26:09Z", "commit": {"oid": "c48d2a030120bf92d1eb7f5aeb3dded2acbdf7b1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84cb5c53e28c3819f95bed1bb018fae1886e8b80", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/84cb5c53e28c3819f95bed1bb018fae1886e8b80", "committedDate": "2020-07-20T06:33:33Z", "message": "Merge branch 'develop' into feature/dump-entries-that-could-not-be-deserialized"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4477, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}