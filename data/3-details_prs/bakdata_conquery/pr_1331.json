{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc2MzI5NjE4", "number": 1331, "title": "Feature/fix processing of not contained entities", "bodyText": "NotContained entities failed the whole query previously", "createdAt": "2020-08-31T14:19:06Z", "url": "https://github.com/bakdata/conquery/pull/1331", "merged": true, "mergeCommit": {"oid": "1f70daefcc90ddd49255760650b28095f5771780"}, "closed": true, "closedAt": "2020-09-02T13:40:30Z", "author": {"login": "thoniTUB"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdETbKkAH2gAyNDc2MzI5NjE4OjBjNTlhZjRlNGNjNzc3OGMxOWZmZDBkYWFhYTgxYzM5NmZiMGFmODg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdE7cZggH2gAyNDc2MzI5NjE4OmQwN2QxMGVkZTIwZDA1ZjU3ZjRlYWU1MDg3NWY5NDkwMDZlYjYyNTM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0c59af4e4cc7778c19ffd0daaaa81c396fb0af88", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/0c59af4e4cc7778c19ffd0daaaa81c396fb0af88", "committedDate": "2020-08-31T14:10:48Z", "message": "fix dataset deletion test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c9fc72a67febfbfec8f633f05a7d9d92de026fe", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/1c9fc72a67febfbfec8f633f05a7d9d92de026fe", "committedDate": "2020-08-31T14:12:07Z", "message": "adds helper method for column count of a entity result"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a157c0a2967340f92ed12ac6bcd0289489a29801", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/a157c0a2967340f92ed12ac6bcd0289489a29801", "committedDate": "2020-08-31T14:14:43Z", "message": "check datecontexts for formquery for consistency and precalculate the number of constants"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f00bf2daef4c7ac967a81cf4ef64d0e5b3f664a", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/1f00bf2daef4c7ac967a81cf4ef64d0e5b3f664a", "committedDate": "2020-08-31T14:17:58Z", "message": "also support NotContained in relativeformqueryplan subquery"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79393422abd2fef4ecab26aed206d15cec8b6774", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/79393422abd2fef4ecab26aed206d15cec8b6774", "committedDate": "2020-09-01T08:53:42Z", "message": "adapted test to provoke casting error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1547c2449c46373306a3b95cad1e940ab0db0096", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/1547c2449c46373306a3b95cad1e940ab0db0096", "committedDate": "2020-09-01T08:54:02Z", "message": "Merge branch 'feature/test-failing-on-not-contained-entities' into feature/fix-processing-of-not-contained-entities"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/2a556db45fc7486853ab6741ceb72d0b5cbc9771", "committedDate": "2020-09-01T09:11:39Z", "message": "correct subresult check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwNzQ5NTA1", "url": "https://github.com/bakdata/conquery/pull/1331#pullrequestreview-480749505", "createdAt": "2020-09-02T12:02:34Z", "commit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxMjowMjozNFrOHLr3wQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxMjowNzoyNFrOHLsBZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNTE2OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t// Check if the result if of an processible type (multiline or not contained)\n          \n          \n            \n            \t\t// Check if the result is processible (type is multiline or not contained)", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482015169", "createdAt": "2020-09-02T12:02:34Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNTU4Mg==", "bodyText": "kannst du das in zwei checks aufsplitten?", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482015582", "createdAt": "2020-09-02T12:03:24Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);\n+\t\tcheckIfResultProcessible(outcomeResult);\n+\n+\t\tif (!featureResult.isContained() && !outcomeResult.isContained()) {\n+\t\t\t// if both, feature and outcome are not contained fast quit.\n+\t\t\treturn EntityResult.notContained();\n+\t\t}\n+\n+\t\t// determine result length and check against aggregators in query\n+\t\tint featureLength = determineResultWithAndCheck(featureSubquery, featureResult);\n+\t\tint outcomeLength = determineResultWithAndCheck(outcomeSubquery, outcomeResult);\n \n-\t\tList<Object[]> values = new ArrayList<>();\n-\t\t// We look at the first result line to determine the length of the subresult\n-\t\tint featureLength = featureResult.getValues().get(0).length;\n-\t\tint outcomeLength = outcomeResult.getValues().get(0).length;\n-\t\t\n \t\t/*\n-\t\t *  Whole result is the concatenation of the subresults. The final output format combines resolution info, index and eventdate of both sub queries.\n-\t\t *  The feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... \n-\t\t *  The wanted format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR], [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n+\t\t * Whole result is the concatenation of the subresults. The final output format\n+\t\t * combines resolution info, index and eventdate of both sub queries. The\n+\t\t * feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX],\n+\t\t * [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... The wanted\n+\t\t * format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR],\n+\t\t * [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n \t\t */\n-\t\tint size = featureLength + outcomeLength - 3/*= [RESOLUTION], [INDEX], [EVENTDATE]*/;\n+\t\tint size = featureLength + outcomeLength - 3/* ^= [RESOLUTION], [INDEX], [EVENTDATE] */;\n \n \t\tint resultStartIndex = 0;\n-\t\tif(hasCompleteDateContexts(contexts)) {\n-\t\t\t// merge a line for the complete daterange, when two dateContext were generated that don't target the same feature group,\n+\t\tList<Object[]> values = new ArrayList<>();\n+\t\tif (hasCompleteDateContexts(contexts)) {\n+\t\t\t// merge a line for the complete daterange, when two dateContext were generated\n+\t\t\t// that don't target the same feature group,\n \t\t\t// which would be a mistake by the generation\n-\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE is the coarsed resolution it must be at the first\n+\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE\n+\t\t\t// is the coarsed resolution it must be at the first\n \t\t\t// to indexes of the list.\n \t\t\tObject[] mergedFull = new Object[size];\n-\t\t\tsetFeatureValues(mergedFull, featureResult.getValues().get(resultStartIndex));\n-\t\t\tsetOutcomeValues(mergedFull, outcomeResult.getValues().get(resultStartIndex), featureLength);\n+\t\t\tif (featureResult.isContained()) {\n+\t\t\t\tsetFeatureValues(mergedFull, ((MultilineContainedEntityResult) featureResult).getValues().get(resultStartIndex));\n+\t\t\t}\n+\t\t\tif (outcomeResult.isContained()) {\n+\t\t\t\tsetOutcomeValues(\n+\t\t\t\t\tmergedFull,\n+\t\t\t\t\t((MultilineContainedEntityResult) outcomeResult).getValues().get(resultStartIndex),\n+\t\t\t\t\tfeatureLength);\n+\t\t\t}\n \t\t\tvalues.add(mergedFull);\n \t\t\tresultStartIndex++;\n \t\t}\n \n \t\t// append all other lines directly\n-\t\tfor (int i = resultStartIndex; i < featureResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetFeatureValues(result, featureResult.getValues().get(i));\n-\t\t\tvalues.add(result);\n+\t\tif (featureResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) featureResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetFeatureValues(result, multiresult.getValues().get(i));\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n-\t\tfor (int i = resultStartIndex; i < outcomeResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetOutcomeValues(result, outcomeResult.getValues().get(i), featureLength);\n-\t\t\tvalues.add(result);\n+\t\tif (outcomeResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) outcomeResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetOutcomeValues(result, multiresult.getValues().get(i), featureLength);\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n \t\treturn EntityResult.multilineOf(entity.getId(), values);\n \t}\n \n+\tprivate int determineResultWithAndCheck(FormQueryPlan subquery, EntityResult subResult) {\n+\t\tint featureLength = subquery.columnCount();\n+\t\tint featureResultColumnCount;\n+\t\tif (subResult.isContained() && (featureResultColumnCount = subResult.asContained().columnCount()) != featureLength) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjAyMg==", "bodyText": "wenn das ne fehlermeldung wirft, w\u00fcrde ich das assertProcessible oder so nennen", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482016022", "createdAt": "2020-09-02T12:04:19Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjc1Mw==", "bodyText": "die methode macht zu viel auf einmal, kannst du das nicht splitten?", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482016753", "createdAt": "2020-09-02T12:05:43Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);\n+\t\tcheckIfResultProcessible(outcomeResult);\n+\n+\t\tif (!featureResult.isContained() && !outcomeResult.isContained()) {\n+\t\t\t// if both, feature and outcome are not contained fast quit.\n+\t\t\treturn EntityResult.notContained();\n+\t\t}\n+\n+\t\t// determine result length and check against aggregators in query\n+\t\tint featureLength = determineResultWithAndCheck(featureSubquery, featureResult);\n+\t\tint outcomeLength = determineResultWithAndCheck(outcomeSubquery, outcomeResult);\n \n-\t\tList<Object[]> values = new ArrayList<>();\n-\t\t// We look at the first result line to determine the length of the subresult\n-\t\tint featureLength = featureResult.getValues().get(0).length;\n-\t\tint outcomeLength = outcomeResult.getValues().get(0).length;\n-\t\t\n \t\t/*\n-\t\t *  Whole result is the concatenation of the subresults. The final output format combines resolution info, index and eventdate of both sub queries.\n-\t\t *  The feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... \n-\t\t *  The wanted format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR], [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n+\t\t * Whole result is the concatenation of the subresults. The final output format\n+\t\t * combines resolution info, index and eventdate of both sub queries. The\n+\t\t * feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX],\n+\t\t * [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... The wanted\n+\t\t * format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR],\n+\t\t * [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n \t\t */\n-\t\tint size = featureLength + outcomeLength - 3/*= [RESOLUTION], [INDEX], [EVENTDATE]*/;\n+\t\tint size = featureLength + outcomeLength - 3/* ^= [RESOLUTION], [INDEX], [EVENTDATE] */;\n \n \t\tint resultStartIndex = 0;\n-\t\tif(hasCompleteDateContexts(contexts)) {\n-\t\t\t// merge a line for the complete daterange, when two dateContext were generated that don't target the same feature group,\n+\t\tList<Object[]> values = new ArrayList<>();\n+\t\tif (hasCompleteDateContexts(contexts)) {\n+\t\t\t// merge a line for the complete daterange, when two dateContext were generated\n+\t\t\t// that don't target the same feature group,\n \t\t\t// which would be a mistake by the generation\n-\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE is the coarsed resolution it must be at the first\n+\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE\n+\t\t\t// is the coarsed resolution it must be at the first\n \t\t\t// to indexes of the list.\n \t\t\tObject[] mergedFull = new Object[size];\n-\t\t\tsetFeatureValues(mergedFull, featureResult.getValues().get(resultStartIndex));\n-\t\t\tsetOutcomeValues(mergedFull, outcomeResult.getValues().get(resultStartIndex), featureLength);\n+\t\t\tif (featureResult.isContained()) {\n+\t\t\t\tsetFeatureValues(mergedFull, ((MultilineContainedEntityResult) featureResult).getValues().get(resultStartIndex));\n+\t\t\t}\n+\t\t\tif (outcomeResult.isContained()) {\n+\t\t\t\tsetOutcomeValues(\n+\t\t\t\t\tmergedFull,\n+\t\t\t\t\t((MultilineContainedEntityResult) outcomeResult).getValues().get(resultStartIndex),\n+\t\t\t\t\tfeatureLength);\n+\t\t\t}\n \t\t\tvalues.add(mergedFull);\n \t\t\tresultStartIndex++;\n \t\t}\n \n \t\t// append all other lines directly\n-\t\tfor (int i = resultStartIndex; i < featureResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetFeatureValues(result, featureResult.getValues().get(i));\n-\t\t\tvalues.add(result);\n+\t\tif (featureResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) featureResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetFeatureValues(result, multiresult.getValues().get(i));\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n-\t\tfor (int i = resultStartIndex; i < outcomeResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetOutcomeValues(result, outcomeResult.getValues().get(i), featureLength);\n-\t\t\tvalues.add(result);\n+\t\tif (outcomeResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) outcomeResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetOutcomeValues(result, multiresult.getValues().get(i), featureLength);\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n \t\treturn EntityResult.multilineOf(entity.getId(), values);\n \t}\n \n+\tprivate int determineResultWithAndCheck(FormQueryPlan subquery, EntityResult subResult) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNzYzOA==", "bodyText": "danke!", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482017638", "createdAt": "2020-09-02T12:07:24Z", "author": {"login": "awildturtok"}, "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -160,16 +214,6 @@ public RelativeFormQueryPlan clone(CloneContext ctx) {\n \n \t@Override\n \tpublic boolean isOfInterest(Entity entity) {\n-\t\treturn query.isOfInterest(entity);\n+\t\treturn query.isOfInterest(entity) || featurePlan.isOfInterest(entity) || outcomePlan.isOfInterest(entity);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771"}, "originalPosition": 159}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afd22368728008e5e54a67077c8f45c8b1e74f4c", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/afd22368728008e5e54a67077c8f45c8b1e74f4c", "committedDate": "2020-09-02T12:34:41Z", "message": "Update backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java\n\nCo-authored-by: awildturtok <1553491+awildturtok@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19eb30e0eb0ef4edd101dbdcbe71a001ea116f96", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/19eb30e0eb0ef4edd101dbdcbe71a001ea116f96", "committedDate": "2020-09-02T12:46:28Z", "message": "review cleanup of resultWidth calculation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d07d10ede20d05f57f4eae50875f949006eb6253", "author": {"user": {"login": "thoniTUB", "name": "MT"}}, "url": "https://github.com/bakdata/conquery/commit/d07d10ede20d05f57f4eae50875f949006eb6253", "committedDate": "2020-09-02T12:48:21Z", "message": "method renaming"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4567, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}