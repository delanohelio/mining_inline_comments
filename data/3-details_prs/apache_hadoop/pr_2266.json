{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3MzU2OTYz", "number": 2266, "title": "HDFS-15554. RBF: force router check file existence in destinations before adding/updating mount points", "bodyText": "\u2026t points\nNOTICE\nPlease create an issue in ASF JIRA before opening a pull request,\nand you need to set the title of the pull request which starts with\nthe corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.)\nFor more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute", "createdAt": "2020-09-01T21:49:58Z", "url": "https://github.com/apache/hadoop/pull/2266", "merged": true, "mergeCommit": {"oid": "3e8b1e74268994d244eeeb6400c6144edbbb486f"}, "closed": true, "closedAt": "2020-09-21T17:54:13Z", "author": {"login": "fengnanli"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdEudvZgH2gAyNDc3MzU2OTYzOjRkZGZiMzRiZGFlYzEzZjYwOWQ0MjEzOTExMDhlZGIwMjE2MzhmMjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdLHMjdgFqTQ5Mjg1MDM1Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/4ddfb34bdaec13f609d421391108edb021638f26", "committedDate": "2020-09-01T21:41:03Z", "message": "[RBF] Force check destination file exists before adding/updating mount points"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwMTQ5OTY0", "url": "https://github.com/apache/hadoop/pull/2266#pullrequestreview-480149964", "createdAt": "2020-09-01T22:05:46Z", "commit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMjowNTo0NlrOHLJ43Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMjowNzo1OFrOHLJ8OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1ODM5Nw==", "bodyText": "Avoid", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481458397", "createdAt": "2020-09-01T22:05:46Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -128,7 +166,6 @@ public void testAddMountTable() throws IOException {\n     MountTable newEntry = MountTable.newInstance(\n         \"/testpath\", Collections.singletonMap(\"ns0\", \"/testdir\"),\n         Time.now(), Time.now());\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1ODU2Mg==", "bodyText": "Add a comment highlighting what this part does.", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481458562", "createdAt": "2020-09-01T22:06:11Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -103,11 +113,39 @@ public static void globalSetUp() throws Exception {\n         createNamenodeReport(\"ns1\", \"nn1\", HAServiceState.ACTIVE));\n     stateStore.refreshCaches(true);\n \n+    setUpMocks();\n+  }\n+\n+  private static void setUpMocks() throws IOException {\n     RouterRpcServer spyRpcServer =\n         Mockito.spy(routerContext.getRouter().createRpcServer());\n     Whitebox\n         .setInternalState(routerContext.getRouter(), \"rpcServer\", spyRpcServer);\n     Mockito.doReturn(null).when(spyRpcServer).getFileInfo(Mockito.anyString());\n+\n+    mockRpcClient = Mockito.spy(spyRpcServer.getRPCClient());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1ODYyNw==", "bodyText": "Add javadoc", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481458627", "createdAt": "2020-09-01T22:06:20Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -103,11 +113,39 @@ public static void globalSetUp() throws Exception {\n         createNamenodeReport(\"ns1\", \"nn1\", HAServiceState.ACTIVE));\n     stateStore.refreshCaches(true);\n \n+    setUpMocks();\n+  }\n+\n+  private static void setUpMocks() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1ODg4MQ==", "bodyText": "I think whitebox needed to be deprecated.", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481458881", "createdAt": "2020-09-01T22:06:56Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -103,11 +113,39 @@ public static void globalSetUp() throws Exception {\n         createNamenodeReport(\"ns1\", \"nn1\", HAServiceState.ACTIVE));\n     stateStore.refreshCaches(true);\n \n+    setUpMocks();\n+  }\n+\n+  private static void setUpMocks() throws IOException {\n     RouterRpcServer spyRpcServer =\n         Mockito.spy(routerContext.getRouter().createRpcServer());\n     Whitebox\n         .setInternalState(routerContext.getRouter(), \"rpcServer\", spyRpcServer);\n     Mockito.doReturn(null).when(spyRpcServer).getFileInfo(Mockito.anyString());\n+\n+    mockRpcClient = Mockito.spy(spyRpcServer.getRPCClient());\n+    Whitebox", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1OTA3Ng==", "bodyText": "What are we doing with this? Is there a test actually using it?", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481459076", "createdAt": "2020-09-01T22:07:28Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -103,11 +113,39 @@ public static void globalSetUp() throws Exception {\n         createNamenodeReport(\"ns1\", \"nn1\", HAServiceState.ACTIVE));\n     stateStore.refreshCaches(true);\n \n+    setUpMocks();\n+  }\n+\n+  private static void setUpMocks() throws IOException {\n     RouterRpcServer spyRpcServer =\n         Mockito.spy(routerContext.getRouter().createRpcServer());\n     Whitebox\n         .setInternalState(routerContext.getRouter(), \"rpcServer\", spyRpcServer);\n     Mockito.doReturn(null).when(spyRpcServer).getFileInfo(Mockito.anyString());\n+\n+    mockRpcClient = Mockito.spy(spyRpcServer.getRPCClient());\n+    Whitebox\n+        .setInternalState(spyRpcServer, \"rpcClient\", mockRpcClient);\n+    RemoteLocation remoteLocation0 = new RemoteLocation(\"ns0\", \"/testdir\", null);\n+    RemoteLocation remoteLocation1 = new RemoteLocation(\"ns1\", \"/\", null);\n+    mockResponse0.put(remoteLocation0,\n+        new HdfsFileStatus.Builder().build());\n+    Mockito.doReturn(mockResponse0).when(mockRpcClient).invokeConcurrent(\n+        Mockito.eq(Lists.newArrayList(remoteLocation0)),\n+        Mockito.any(RemoteMethod.class),\n+        Mockito.eq(false),\n+        Mockito.eq(false),\n+        Mockito.eq(HdfsFileStatus.class)\n+    );\n+    mockResponse1.put(remoteLocation1,\n+        new HdfsFileStatus.Builder().build());\n+    Mockito.doReturn(mockResponse1).when(mockRpcClient).invokeConcurrent(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ1OTI1Nw==", "bodyText": "Add exception reasons", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481459257", "createdAt": "2020-09-01T22:07:58Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterAdminServer.java", "diffHunk": "@@ -562,11 +595,35 @@ public GetDestinationResponse getDestination(\n       LOG.error(\"Cannot get location for {}: {}\",\n           src, ioe.getMessage());\n     }\n-    if (nsIds.isEmpty() && !locations.isEmpty()) {\n-      String nsId = locations.get(0).getNameserviceId();\n-      nsIds.add(nsId);\n+    return nsIds;\n+  }\n+\n+  /**\n+   * Verify the file exists in destination nameservices to avoid dangling\n+   * mount points.\n+   *\n+   * @param entry the new mount points added, could be from add or update.\n+   * @return destination nameservices where the file doesn't exist.\n+   * @throws IOException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwNDU3MDgz", "url": "https://github.com/apache/hadoop/pull/2266#pullrequestreview-480457083", "createdAt": "2020-09-02T03:29:41Z", "commit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQwMzoyOTo0MlrOHLS8mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQwMzoyOTo0MlrOHLS8mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTYwNjgwOA==", "bodyText": "I would unit tests just for this function if possible.", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r481606808", "createdAt": "2020-09-02T03:29:42Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterAdminServer.java", "diffHunk": "@@ -562,11 +595,35 @@ public GetDestinationResponse getDestination(\n       LOG.error(\"Cannot get location for {}: {}\",\n           src, ioe.getMessage());\n     }\n-    if (nsIds.isEmpty() && !locations.isEmpty()) {\n-      String nsId = locations.get(0).getNameserviceId();\n-      nsIds.add(nsId);\n+    return nsIds;\n+  }\n+\n+  /**\n+   * Verify the file exists in destination nameservices to avoid dangling\n+   * mount points.\n+   *\n+   * @param entry the new mount points added, could be from add or update.\n+   * @return destination nameservices where the file doesn't exist.\n+   * @throws IOException\n+   */\n+  private List<String> verifyFileInDestinations(MountTable entry)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ddfb34bdaec13f609d421391108edb021638f26"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "173407f369cc42db84502ad5b5c160bd7f1378d8", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/173407f369cc42db84502ad5b5c160bd7f1378d8", "committedDate": "2020-09-04T05:38:23Z", "message": "[WIP] Fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c206b268a3029502527a0b8755ba1af0020236d", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/8c206b268a3029502527a0b8755ba1af0020236d", "committedDate": "2020-09-07T21:17:17Z", "message": "Add config to control the logic, avoid changing massive tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9274efe2c77bcddf5968491791cb74044b269d44", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/9274efe2c77bcddf5968491791cb74044b269d44", "committedDate": "2020-09-09T06:09:01Z", "message": "Remove unused whitebox import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzY0NDA4", "url": "https://github.com/apache/hadoop/pull/2266#pullrequestreview-485364408", "createdAt": "2020-09-09T20:05:59Z", "commit": {"oid": "9274efe2c77bcddf5968491791cb74044b269d44"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDowNTo1OVrOHPYc2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDowNTo1OVrOHPYc2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg5MTI4OQ==", "bodyText": "Avoid the empty change", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r485891289", "createdAt": "2020-09-09T20:05:59Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -128,7 +175,6 @@ public void testAddMountTable() throws IOException {\n     MountTable newEntry = MountTable.newInstance(\n         \"/testpath\", Collections.singletonMap(\"ns0\", \"/testdir\"),\n         Time.now(), Time.now());\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9274efe2c77bcddf5968491791cb74044b269d44"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzY1MjM5", "url": "https://github.com/apache/hadoop/pull/2266#pullrequestreview-485365239", "createdAt": "2020-09-09T20:07:21Z", "commit": {"oid": "9274efe2c77bcddf5968491791cb74044b269d44"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDowNzoyMVrOHPYfuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDowNzoyMVrOHPYfuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg5MjAyNQ==", "bodyText": "checkstyle is complaining", "url": "https://github.com/apache/hadoop/pull/2266#discussion_r485892025", "createdAt": "2020-09-09T20:07:21Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterAdmin.java", "diffHunk": "@@ -78,6 +83,11 @@\n       \"Hadoop:service=Router,name=FederationRPC\";\n   private static List<MountTable> mockMountTable;\n   private static StateStoreService stateStore;\n+  private static RouterRpcClient mockRpcClient;\n+  private static final Map<RemoteLocation, HdfsFileStatus> mockResponse0 =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9274efe2c77bcddf5968491791cb74044b269d44"}, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebcaf4c0405352f6887c592e1509b4c4cfa556d7", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/ebcaf4c0405352f6887c592e1509b4c4cfa556d7", "committedDate": "2020-09-09T20:36:32Z", "message": "Fix style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2dd5214764f9bfce29920aa86bdcbe908968a8f4", "author": {"user": {"login": "fengnanli", "name": "lfengnan"}}, "url": "https://github.com/apache/hadoop/commit/2dd5214764f9bfce29920aa86bdcbe908968a8f4", "committedDate": "2020-09-10T20:36:25Z", "message": "Fixing checkstyle again"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyODUwMzU2", "url": "https://github.com/apache/hadoop/pull/2266#pullrequestreview-492850356", "createdAt": "2020-09-21T17:53:28Z", "commit": {"oid": "2dd5214764f9bfce29920aa86bdcbe908968a8f4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3588, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}